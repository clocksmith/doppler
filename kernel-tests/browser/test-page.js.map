{
  "version": 3,
  "sources": ["../../src/config/schema/manifest.schema.ts", "../../src/config/schema/kernel-path.schema.ts", "../../src/config/schema/inference.schema.ts", "../../src/config/schema/conversion.schema.ts", "../../src/config/schema/loading.schema.ts", "../../src/config/schema/kernel-registry.schema.ts", "../../src/config/schema/storage.schema.ts", "../../src/config/schema/inference-defaults.schema.ts", "../../src/config/schema/distribution.schema.ts", "../../src/config/schema/moe.schema.ts", "../../src/config/schema/kvcache.schema.ts", "../../src/config/schema/gpu-cache.schema.ts", "../../src/config/schema/tuner.schema.ts", "../../src/config/schema/debug.schema.ts", "../../src/config/schema/hotswap.schema.ts", "../../src/config/schema/buffer-pool.schema.ts", "../../src/config/schema/memory-limits.schema.ts", "../../src/config/schema/bridge.schema.ts", "../../src/config/schema/quantization-defaults.schema.ts", "../../src/config/schema/kernel-thresholds.schema.ts", "../../src/config/schema/doppler.schema.ts", "../../src/config/schema/index.ts", "../../src/config/runtime.ts", "../../src/debug/index.ts", "../../src/gpu/perf-guards.ts", "../../src/gpu/submit-tracker.ts", "../../src/config/platforms/loader.js", "../../src/config/kernels/registry.js", "../../src/gpu/device.ts", "../../src/gpu/tensor.ts", "../../src/gpu/profiler.ts", "../../src/gpu/kernel-tuner.ts", "../../src/gpu/uniform-cache.ts", "../../src/gpu/kernels/utils.ts", "../../src/gpu/weight-buffer.ts", "../../src/gpu/buffer-pool.ts", "../../src/gpu/kernels/dispatch.ts", "../../src/gpu/kernels/constants.ts", "../../src/gpu/kernels/fused_matmul_rmsnorm.ts", "test-page.ts", "../../src/config/kernel-path-loader.ts", "../../src/config/presets/kernel-paths/gemma2-q4k-fused.json", "../../src/config/presets/kernel-paths/gemma2-q4k-dequant-f32.json", "../../src/config/presets/kernel-paths/gemma2-q4k-dequant-f16.json", "../../src/config/presets/kernel-paths/gemma2-f16-native.json", "../../src/gpu/kernel-selector.ts", "../../src/gpu/kernels/index.ts", "../../src/gpu/kernels/matmul.ts", "../../src/gpu/kernels/kernel-base.ts", "../../src/gpu/kernels/dequant.ts", "../../src/loader/quantization-constants.ts", "../../src/gpu/kernels/attention.ts", "../../src/gpu/kernels/rmsnorm.ts", "../../src/gpu/kernels/softmax.ts", "../../src/gpu/kernels/rope.ts", "../../src/gpu/kernels/silu.ts", "../../src/gpu/kernels/gelu.ts", "../../src/gpu/kernels/scale.ts", "../../src/gpu/kernels/gather.ts", "../../src/gpu/kernels/residual.ts", "../../src/gpu/kernels/cast.ts", "../../src/gpu/kernels/moe.ts", "../../src/gpu/kernels/sample.ts", "../../src/gpu/kernels/fused_ffn.ts", "../../src/gpu/kernels/fused_matmul_residual.ts", "../../src/gpu/command-recorder.ts", "../../src/gpu/kernel-benchmark.ts", "../../src/gpu/kernels/split_qkv.ts", "../../src/gpu/perf-profiler.ts", "../src/reference/index.ts", "../src/reference/matmul.ts", "../src/reference/softmax.ts", "../src/reference/silu.ts", "../src/reference/rmsnorm.ts", "../src/reference/rope.ts", "../src/reference/attention.ts", "../src/reference/topk.ts", "../src/reference/scatter-add.ts", "../src/reference/moe-gather.ts", "../src/reference/gather.ts", "../src/reference/residual.ts", "../src/reference/dequant.ts", "../src/reference/sample.ts", "../src/harness/tolerance.ts"],
  "sourcesContent": ["/**\n * Manifest Schema Definitions\n *\n * Single source of truth for RDRR manifest structure.\n * Schema = type definition (what fields exist)\n *\n * @module config/schema/manifest\n */\n\nimport type { KernelPathRef } from './kernel-path.schema.js';\n\n// =============================================================================\n// Hash & Versioning\n// =============================================================================\n\n/** Supported hash algorithms */\nexport type HashAlgorithm = 'sha256' | 'blake3';\n\n/** RDRR format version */\nexport const RDRR_VERSION = 1;\n\n/** Default shard size (64MB) */\nexport const SHARD_SIZE = 64 * 1024 * 1024;\n\n/** External tensors filename */\nexport const TENSORS_FILENAME = 'tensors.json';\n\n// =============================================================================\n// Model Types\n// =============================================================================\n\n/** Supported model architectures */\nexport type ModelType =\n  | 'transformer'  // Dense transformer (Llama, Gemma, Mistral, GPT)\n  | 'mamba'        // Pure Mamba SSM\n  | 'rwkv'         // RWKV architecture\n  | 'jamba'        // Hybrid Mamba + Attention + MoE\n  | 'mixtral'      // MoE transformer (Mixtral, Arctic)\n  | 'deepseek'     // MoE with shared experts\n  | string;        // Allow future extensions\n\n/** Component group types */\nexport type ComponentGroupType =\n  | 'embed'   // Embedding layer\n  | 'layer'   // Dense layer (full transformer/mamba/rwkv layer)\n  | 'head'    // Output head (lm_head + final_norm)\n  | 'expert'  // MoE expert\n  | 'shared'  // MoE shared components (router, etc.)\n  | 'mamba'   // Mamba block in hybrid\n  | 'rwkv'    // RWKV block\n  | 'attn';   // Attention block in hybrid\n\n/** Weight storage layout */\nexport type WeightLayout = 'row' | 'column';\n\n/** Quantization value (string for forward compatibility) */\nexport type QuantizationValue =\n  | 'q4k'      // Q4_K_M block quantization (canonical short form)\n  | 'q6k'      // Q6_K block quantization\n  | 'q8_0'     // Q8_0 quantization\n  | 'f16'      // Float16\n  | 'bf16'     // BFloat16\n  | 'f32'      // Float32\n  | 'fp8e4'    // Float8 E4M3\n  | 'fp8e5'    // Float8 E5M2\n  | 'i8'       // Int8\n  | 'i4'       // Int4\n  | string;    // Allow future extensions\n\n/**\n * Quantization metadata for different weight groups.\n *\n * Naming convention (storage-only, no runtime info):\n * - Base model: `{name}-w{weights}[-e{embeddings}][-h{head}][-v{vision}][-a{audio}][-t{tts}][-p{projector}]`\n * - Standalone adapter: `{base}-w{quant}+{type}-{name}-{quant}r{rank}`\n * - Merged adapter: `{name}-w{weights}~{type}-{name}-{quant}r{rank}`\n *\n * Examples:\n * - `gemma-2b-wq4k` (weights Q4K, embeddings default to weights)\n * - `gemma-2b-wq4k-ef16` (weights Q4K, embeddings F16)\n * - `llama-8b-wq4k-ef16-hf16` (with separate head)\n * - `qwen2-vl-7b-wq4k-vf16-pf16` (multimodal with vision + projector)\n * - `gemma-2b-wq4k+lora-coding-f16r16` (standalone adapter)\n * - `gemma-2b-wq4k~lora-coding-f16r16` (merged adapter)\n */\nexport interface QuantizationInfoSchema {\n  // Core text model components\n  weights: QuantizationValue;\n  embeddings?: QuantizationValue;\n  lmHead?: QuantizationValue;\n\n  // Multimodal components\n  vision?: QuantizationValue;      // Vision encoder (ViT, SigLIP, CLIP)\n  audio?: QuantizationValue;       // Audio encoder (Whisper, wav2vec)\n  tts?: QuantizationValue;         // TTS decoder\n  projector?: QuantizationValue;   // Cross-modal projection layers\n\n  // Runtime hints (NOT included in variantTag - these are runtime, not storage)\n  kvCache?: QuantizationValue;\n  compute?: QuantizationValue;\n\n  // Generated variant tag for modelId suffix\n  variantTag?: string;\n}\n\n/**\n * Adapter configuration for LoRA/QLoRA adapters.\n */\nexport interface AdapterConfigSchema {\n  /** Adapter type */\n  type: 'lora' | 'qlora';\n  /** Adapter name/purpose (e.g., 'coding', 'roleplay', 'japanese') */\n  name: string;\n  /** LoRA rank */\n  rank: number;\n  /** LoRA alpha scaling factor */\n  alpha?: number;\n  /** Quantization of adapter weights */\n  quant: QuantizationValue;\n  /** Target modules */\n  targetModules?: string[];\n  /** Dropout rate during training */\n  dropout?: number;\n}\n\n/**\n * Model provenance for frankenmodels and merges.\n */\nexport interface ProvenanceSchema {\n  /** Source models used in merge */\n  sources: string[];\n  /** Merge method (e.g., 'slerp', 'ties', 'dare', 'linear') */\n  method?: string;\n  /** Merge parameters (method-specific) */\n  params?: Record<string, unknown>;\n  /** Adapters applied before merge */\n  adapters?: string[];\n  /** Original model this was derived from */\n  baseModel?: string;\n  /** Conversion/creation timestamp */\n  createdAt?: string;\n  /** Tool used for merge/conversion */\n  tool?: string;\n}\n\n// =============================================================================\n// Architecture Schema\n// =============================================================================\n\n/** Model architecture parameters */\nexport interface ArchitectureSchema {\n  numLayers: number;\n  hiddenSize: number;\n  intermediateSize: number;\n  numAttentionHeads: number;\n  numKeyValueHeads: number;\n  headDim: number;\n  vocabSize: number;\n  maxSeqLen: number;\n  ropeTheta?: number;\n  rmsNormEps?: number;\n}\n\n// =============================================================================\n// Inference Schema (Model-Specific Inference Parameters)\n// =============================================================================\n\n/**\n * Attention configuration for inference.\n * All fields required - converter must populate everything.\n * Use `null` to indicate \"not applicable\" (e.g., no softcapping).\n */\nexport interface ManifestAttentionSchema {\n  /** Query pre-attention scalar (Gemma 2: 256, standard: sqrt(headDim)) */\n  queryPreAttnScalar: number;\n  /** Attention logit softcapping (Gemma 2: 50, null = disabled) */\n  attnLogitSoftcapping: number | null;\n  /** Sliding window size for local attention (null = full attention) */\n  slidingWindow: number | null;\n  /** Query-key normalization */\n  queryKeyNorm: boolean;\n}\n\n/**\n * Normalization configuration for inference.\n * Controls RMSNorm behavior and sandwich norm architecture.\n */\nexport interface ManifestNormalizationSchema {\n  /** Use (1 + weight) pattern for RMSNorm (Gemma models) */\n  rmsNormWeightOffset: boolean;\n  /** Has post-attention normalization (sandwich norm) */\n  postAttentionNorm: boolean;\n  /** Has pre-feedforward normalization (sandwich norm) */\n  preFeedforwardNorm: boolean;\n  /** Has post-feedforward normalization (sandwich norm) */\n  postFeedforwardNorm: boolean;\n}\n\n/**\n * FFN configuration for inference.\n */\nexport interface ManifestFFNSchema {\n  /** Activation function type */\n  activation: 'silu' | 'gelu' | 'geglu' | 'swiglu' | 'relu';\n  /** Whether activation is gated (e.g., SwiGLU, GeGLU) */\n  gatedActivation: boolean;\n}\n\n/**\n * RoPE configuration for inference.\n * All fields required - converter must populate everything.\n * This is the canonical source for RoPE params (not architecture.ropeTheta).\n */\nexport interface ManifestRoPESchema {\n  /** Base theta for rotary embeddings (canonical source for execution) */\n  ropeTheta: number;\n  /** Local theta for sliding window layers (null = same as ropeTheta) */\n  ropeLocalTheta: number | null;\n  /** RoPE scaling type (null = no scaling, 'linear', 'dynamic', 'yarn') */\n  ropeScalingType: string | null;\n  /** RoPE scaling factor (1.0 if no scaling) */\n  ropeScalingFactor: number;\n  /** YARN beta_fast parameter (null if not YARN scaling) */\n  yarnBetaFast: number | null;\n  /** YARN beta_slow parameter (null if not YARN scaling) */\n  yarnBetaSlow: number | null;\n  /** YARN original max position embeddings (null if not YARN scaling) */\n  yarnOriginalMaxPos: number | null;\n}\n\n/**\n * Output configuration for inference.\n * All fields required - converter must populate everything.\n */\nexport interface ManifestOutputSchema {\n  /** Final logit softcapping (Gemma 2: 30, null = disabled) */\n  finalLogitSoftcapping: number | null;\n  /** Whether embeddings and LM head share weights */\n  tieWordEmbeddings: boolean;\n  /** Scale embeddings by sqrt(hiddenSize) (Gemma models: true) */\n  scaleEmbeddings: boolean;\n}\n\n/**\n * Layer pattern for hybrid attention models.\n * Defines which layers use global vs sliding window attention.\n */\nexport interface ManifestLayerPatternSchema {\n  /** Pattern type */\n  type: 'uniform' | 'alternating' | 'every_n';\n  /** For alternating: which layers are global ('odd' or 'even') */\n  globalPattern?: 'odd' | 'even';\n  /** For every_n: period of global layers */\n  period?: number;\n}\n\n/**\n * Complete inference configuration embedded in manifest.\n *\n * This captures all model-specific inference parameters that were previously\n * scattered across model presets. By embedding these in the manifest at\n * conversion time, the manifest becomes the single source of truth for\n * how to run inference on this model.\n */\nexport interface ManifestInferenceSchema {\n  /** Attention configuration */\n  attention: ManifestAttentionSchema;\n  /** Normalization configuration */\n  normalization: ManifestNormalizationSchema;\n  /** FFN configuration */\n  ffn: ManifestFFNSchema;\n  /** RoPE configuration */\n  rope: ManifestRoPESchema;\n  /** Output configuration */\n  output: ManifestOutputSchema;\n  /** Layer pattern for hybrid attention */\n  layerPattern?: ManifestLayerPatternSchema;\n  /** Default kernel path for this model (e.g., 'gemma2-q4k-fused') */\n  defaultKernelPath?: string;\n}\n\n/**\n * Standard inference configuration template.\n *\n * PURPOSE: Converter template and test fixtures ONLY.\n * NOT a runtime fallback - if manifest is missing fields, validation fails.\n *\n * These values represent a \"standard transformer\" (no special features).\n * Converter uses this as a base, then overrides for specific model families.\n */\nexport const DEFAULT_MANIFEST_INFERENCE: ManifestInferenceSchema = {\n  attention: {\n    queryPreAttnScalar: 8,  // sqrt(64) for standard 64-dim heads\n    attnLogitSoftcapping: null,  // No softcapping\n    slidingWindow: null,  // Full attention\n    queryKeyNorm: false,\n  },\n  normalization: {\n    rmsNormWeightOffset: false,\n    postAttentionNorm: false,\n    preFeedforwardNorm: false,\n    postFeedforwardNorm: false,\n  },\n  ffn: {\n    activation: 'silu',\n    gatedActivation: true,\n  },\n  rope: {\n    ropeTheta: 10000,\n    ropeLocalTheta: null,  // Same as ropeTheta\n    ropeScalingType: null,  // No scaling\n    ropeScalingFactor: 1.0,\n    yarnBetaFast: null,  // No YARN\n    yarnBetaSlow: null,\n    yarnOriginalMaxPos: null,\n  },\n  output: {\n    finalLogitSoftcapping: null,  // No softcapping\n    tieWordEmbeddings: false,\n    scaleEmbeddings: false,\n  },\n};\n\n// =============================================================================\n// Shard Schema\n// =============================================================================\n\n/** Individual shard metadata */\nexport interface ShardSchema {\n  index: number;\n  filename: string;\n  size: number;\n  hash: string;\n  hashAlgorithm?: HashAlgorithm;\n  offset?: number;\n}\n\n// =============================================================================\n// Tensor Schema\n// =============================================================================\n\n/** Tensor span for multi-shard tensors */\nexport interface TensorSpanSchema {\n  shardIndex: number;\n  offset: number;\n  size: number;\n}\n\n/** Tensor location in shards */\nexport interface TensorSchema {\n  shard: number;\n  offset: number;\n  size: number;\n  shape: number[];\n  dtype: string;\n  group?: string;\n  spans?: TensorSpanSchema[];\n  layout?: WeightLayout;\n  originalShape?: number[];\n}\n\n/** External tensor map (tensors.json) */\nexport type TensorMapSchema = Record<string, TensorSchema>;\n\n// =============================================================================\n// Component Group Schema\n// =============================================================================\n\n/** Component group for hot-swap capability */\nexport interface ComponentGroupSchema {\n  type: ComponentGroupType;\n  version: string;\n  shards: number[];\n  tensors: string[];\n  hash: string;\n  layerIndex?: number;\n  expertIndex?: number;\n}\n\n// =============================================================================\n// MoE Schema\n// =============================================================================\n\n/** Mixture of Experts configuration */\nexport interface MoEConfigSchema {\n  numExperts: number;\n  numExpertsPerToken: number;\n  sharedExperts?: number[];\n  expertShardMap?: Record<string, number[]>;\n  expertTensors?: Record<string, string[]>;\n  expertBytes?: number;\n}\n\n// =============================================================================\n// Tokenizer Schema\n// =============================================================================\n\n/** Tokenizer metadata */\nexport interface TokenizerSchema {\n  type: string;\n  file?: string;\n  vocabSize: number;\n}\n\n// =============================================================================\n// Runtime Optimizations Schema\n// =============================================================================\n\n/** Runtime optimization plan */\nexport interface RuntimeOptimizationsSchema {\n  /** Preferred kernel path override */\n  kernelPath?: KernelPathRef;\n}\n\n// =============================================================================\n// Conversion Metadata Schema\n// =============================================================================\n\n/** Conversion metadata */\nexport interface ConversionInfoSchema {\n  source: string;\n  convertedAt: string;\n  tool?: string;\n  version?: string;\n}\n\n// =============================================================================\n// Full Manifest Schema\n// =============================================================================\n\n/** Complete RDRR manifest structure */\nexport interface ManifestSchema {\n  // Required fields\n  version: number;\n  modelId: string;\n  modelType: ModelType;\n  quantization: string;\n  quantizationInfo?: QuantizationInfoSchema;\n  hashAlgorithm: HashAlgorithm;\n  totalSize: number;\n\n  // Architecture (required, but can be string for legacy)\n  architecture: ArchitectureSchema | string;\n\n  // Inference configuration (required, populated by converter)\n  // Contains all model-specific inference parameters\n  // Manifests without this field are invalid and must be re-converted\n  inference: ManifestInferenceSchema;\n\n  // Shards (required)\n  shards: ShardSchema[];\n\n  // v1: External tensor file\n  tensorsFile?: string;\n  tensorCount?: number;\n\n  // v1: Component groups\n  groups?: Record<string, ComponentGroupSchema>;\n\n  // Legacy: Inline tensors (deprecated in v1)\n  tensors?: TensorMapSchema;\n\n  // Optional\n  config?: Record<string, unknown>;\n  tokenizer?: TokenizerSchema;\n  moeConfig?: MoEConfigSchema | null;\n  optimizations?: RuntimeOptimizationsSchema;\n  conversion?: ConversionInfoSchema;\n\n  // Adapter support (for LoRA/QLoRA)\n  /** Adapter type - present only for adapter manifests */\n  adapterType?: 'lora' | 'qlora';\n  /** Base model compatibility - required for adapter manifests */\n  baseCompatibility?: string[];\n  /** Merged adapter info - present when adapter is baked into weights */\n  mergedAdapter?: AdapterConfigSchema;\n  /** Adapter config - full config for standalone adapter manifests */\n  adapterConfig?: AdapterConfigSchema;\n\n  // Provenance (for merged/frankenstein models)\n  provenance?: ProvenanceSchema;\n\n  // Legacy field aliases\n  name?: string;\n}\n\n// =============================================================================\n// Validation Helpers\n// =============================================================================\n\n/** Check if manifest is v1 format (has groups) */\nexport function isV1Manifest(manifest: ManifestSchema): boolean {\n  return manifest.version === 1 && !!manifest.groups;\n}\n\n/** Check if manifest has MoE config */\nexport function hasMoEConfig(manifest: ManifestSchema): boolean {\n  return manifest.moeConfig != null && manifest.moeConfig.numExperts > 1;\n}\n\n/**\n * Validate manifest has required inference configuration.\n * Throws if manifest is missing inference field (legacy manifest).\n *\n * @throws Error if manifest.inference is missing\n */\nexport function validateManifestInference(\n  manifest: { modelId: string; inference?: ManifestInferenceSchema }\n): void {\n  if (!manifest.inference) {\n    throw new Error(\n      `Manifest for \"${manifest.modelId}\" is missing required 'inference' field. ` +\n      `This model was converted with an older version of DOPPLER. ` +\n      `Please re-convert the model using the latest converter.`\n    );\n  }\n}\n\n/**\n * Type guard to check if manifest has inference config.\n * Use validateManifestInference() to fail fast; this is for conditional checks.\n */\nexport function hasInferenceConfig<T extends { inference?: ManifestInferenceSchema }>(\n  manifest: T\n): manifest is T & { inference: ManifestInferenceSchema } {\n  return manifest.inference != null;\n}\n", "/**\n * Kernel Path Schema\n *\n * Defines explicit, ordered kernel dispatch sequences for inference.\n * Replaces the implicit q4kStrategy/fusedFFNQ4K configuration.\n *\n * A kernel path is a complete specification of:\n * - Which kernels run\n * - In what order\n * - With what override constants\n * - With what entry points\n *\n * @module config/schema/kernel-path\n */\n\n// =============================================================================\n// Kernel Step\n// =============================================================================\n\n/**\n * A single kernel dispatch in the path.\n */\nexport interface KernelStepSchema {\n  /**\n   * Logical operation name (for debugging/tracing).\n   * Examples: 'rmsnorm', 'q_proj', 'attention', 'ffn_fused'\n   */\n  op: string;\n\n  /**\n   * Kernel file name (without path).\n   * Examples: 'rmsnorm.wgsl', 'fused_matmul_q4.wgsl'\n   */\n  kernel: string;\n\n  /**\n   * Entry point function name.\n   * @default 'main'\n   */\n  entry?: string;\n\n  /**\n   * Override constants for pipeline creation.\n   * These are compile-time constants that affect code generation.\n   */\n  constants?: Record<string, number | boolean>;\n\n  /**\n   * Weight buffer reference (for matmul ops).\n   * Uses template syntax: 'layer.{L}.self_attn.q_proj'\n   * {L} is replaced with layer index at runtime.\n   */\n  weights?: string;\n\n  /**\n   * Input buffer slot name.\n   * @default 'hidden_state'\n   */\n  input?: string;\n\n  /**\n   * Output buffer slot name.\n   * @default 'hidden_state'\n   */\n  output?: string;\n}\n\n// =============================================================================\n// Layer Path\n// =============================================================================\n\n/**\n * Kernel sequence for a single transformer layer.\n */\nexport interface LayerKernelPathSchema {\n  /** Ordered list of kernel dispatches */\n  steps: KernelStepSchema[];\n}\n\n/**\n * Override for specific layers (e.g., first/last layer differences).\n */\nexport interface LayerOverrideSchema {\n  /** Layer indices this override applies to */\n  layers: number[];\n\n  /** Steps to use instead of default */\n  steps: KernelStepSchema[];\n}\n\n// =============================================================================\n// Full Kernel Path\n// =============================================================================\n\n/**\n * Complete kernel path specification for a model.\n */\nexport interface KernelPathSchema {\n  /** Path identifier */\n  id: string;\n\n  /** Human-readable name */\n  name: string;\n\n  /** Description of this path's characteristics */\n  description?: string;\n\n  /**\n   * Prefill phase kernel sequence (M > 1).\n   * If not specified, uses decode with batched variants.\n   */\n  prefill?: LayerKernelPathSchema;\n\n  /**\n   * Decode phase kernel sequence (M = 1).\n   */\n  decode: LayerKernelPathSchema;\n\n  /**\n   * Layer-specific overrides.\n   * For models with different first/last layer behavior.\n   */\n  layerOverrides?: LayerOverrideSchema[];\n\n  /**\n   * Pre-layer operations (embedding lookup, initial norm).\n   */\n  preLayer?: KernelStepSchema[];\n\n  /**\n   * Post-layer operations (final norm, LM head).\n   */\n  postLayer?: KernelStepSchema[];\n\n  /**\n   * Sampling kernels.\n   */\n  sampling?: KernelStepSchema[];\n}\n\n// =============================================================================\n// Path Registry\n// =============================================================================\n\n/**\n * Built-in kernel path identifiers.\n * These are the known preset IDs, but custom presets can also be registered.\n */\nexport type BuiltinKernelPathId =\n  | 'q4k-fused'        // Q4K weights, fused matmul, fused FFN\n  | 'q4k-fused-ffn'    // Q4K weights, fused matmul, fused FFN (explicit)\n  | 'q4k-dequant-f32'  // Q4K -> F32 dequant, F32 matmul\n  | 'q4k-dequant-f16'  // Q4K -> F16 dequant, F16 matmul\n  | 'f16-native'       // Native F16 weights\n  | 'f32-native';      // Native F32 weights (debug)\n\n/**\n * Kernel path reference - preset ID (string) or inline path schema.\n * Accepts any string for custom preset IDs, not just built-in IDs.\n */\nexport type KernelPathRef = string | KernelPathSchema;\n\n// =============================================================================\n// Defaults\n// =============================================================================\n\n/** Default entry point */\nexport const DEFAULT_ENTRY = 'main';\n\n/** Default input slot */\nexport const DEFAULT_INPUT = 'hidden_state';\n\n/** Default output slot */\nexport const DEFAULT_OUTPUT = 'hidden_state';\n", "import type { ProbeStage } from './debug.schema.js';\nimport type { KernelPathRef } from './kernel-path.schema.js';\n\n/**\n * Inference Schema Definitions\n *\n * Configuration for model inference behavior.\n * These are runtime settings that affect how the model executes.\n *\n * @module config/schema/inference\n */\n\n// =============================================================================\n// RoPE (Rotary Position Embedding)\n// =============================================================================\n\n/** RoPE configuration for positional embeddings */\nexport interface RoPEConfigSchema {\n  /** Base frequency for RoPE (default 10000, modern models use 1000000) */\n  ropeTheta?: number;\n\n  /** Local RoPE theta for sliding window layers (Gemma 3 uses 10000) */\n  ropeLocalTheta?: number;\n\n  /** RoPE scaling type */\n  ropeScalingType?: 'linear' | 'dynamic' | 'yarn' | null;\n\n  /** RoPE scaling factor */\n  ropeScalingFactor?: number;\n\n  /** YARN beta_fast parameter */\n  yarnBetaFast?: number;\n\n  /** YARN beta_slow parameter */\n  yarnBetaSlow?: number;\n\n  /** YARN original max position embeddings */\n  yarnOriginalMaxPos?: number;\n}\n\n/** Default RoPE configuration */\nexport const DEFAULT_ROPE_CONFIG: RoPEConfigSchema = {\n  ropeTheta: 10000,\n  ropeLocalTheta: undefined,\n  ropeScalingType: null,\n  ropeScalingFactor: 1.0,\n  yarnBetaFast: 32,\n  yarnBetaSlow: 1,\n  yarnOriginalMaxPos: 4096,\n};\n\n// =============================================================================\n// Attention Schema\n// =============================================================================\n\n/** Attention mechanism configuration */\nexport interface AttentionSchema {\n  /** Use sliding window attention */\n  slidingWindow?: number | null;\n  /** Softcap attention logits before softmax */\n  attnLogitSoftcapping?: number | null;\n  /** Use query-key normalization */\n  queryKeyNorm?: boolean;\n  /** @deprecated Use RoPEConfigSchema.ropeScalingType instead */\n  ropeScalingType?: 'linear' | 'dynamic' | 'yarn' | null;\n  /** @deprecated Use RoPEConfigSchema.ropeScalingFactor instead */\n  ropeScalingFactor?: number;\n}\n\n// =============================================================================\n// Normalization Schema\n// =============================================================================\n\n/** Normalization configuration */\nexport interface NormalizationSchema {\n  /** Add 1.0 to RMSNorm weights (Gemma-style) */\n  rmsNormWeightOffset?: boolean;\n  /** RMSNorm epsilon */\n  rmsNormEps?: number;\n  /** Use post-attention norm */\n  postAttentionNorm?: boolean;\n  /** Use pre-feedforward norm */\n  preFeedforwardNorm?: boolean;\n  /** Use post-feedforward norm */\n  postFeedforwardNorm?: boolean;\n}\n\n// =============================================================================\n// FFN Schema\n// =============================================================================\n\n/** Feed-forward network configuration */\nexport interface FFNSchema {\n  /** Activation function */\n  activation?: 'silu' | 'gelu' | 'relu' | 'swiglu';\n  /** Use gated FFN (SwiGLU) */\n  gatedFFN?: boolean;\n  /** Use fused gate+up projection */\n  fusedGateUp?: boolean;\n}\n\n// =============================================================================\n// Chat Template Schema\n// =============================================================================\n\n/** Built-in chat template types */\nexport type ChatTemplateType = 'gemma' | 'llama3' | 'gpt-oss' | null;\n\n/** Chat template configuration for instruct models */\nexport interface ChatTemplateSchema {\n  /** Template type identifier (gemma, llama3, gpt-oss) */\n  type?: ChatTemplateType;\n\n  /** Whether to apply chat template by default (instruct models should set true) */\n  enabled?: boolean;\n\n  /** Custom template with {prompt} placeholder (overrides type) */\n  custom?: string;\n}\n\n// =============================================================================\n// Layer Pipeline Schema\n// =============================================================================\n\nexport type LayerPipelineOp =\n  | 'save'\n  | 'load'\n  | 'attention'\n  | 'rmsnorm'\n  | 'ffn'\n  | 'residual_add'\n  | 'noop';\n\nexport type LayerPipelineNormWeight =\n  | 'input'\n  | 'post_attention'\n  | 'post_attn'\n  | 'pre_ffn'\n  | 'post_ffn';\n\nexport interface LayerPipelineStepSchema {\n  op: LayerPipelineOp;\n  /** Source slot (default: \"state\") */\n  src?: string;\n  /** Destination slot (default: \"state\") */\n  dst?: string;\n  /** Slot name for save/load operations */\n  name?: string;\n  /** Norm weight selector (rmsnorm only) */\n  weight?: LayerPipelineNormWeight;\n  /** Residual slot for fused ops (optional) */\n  residual?: string | null;\n  /** Residual add inputs (defaults: a=\"state\", b=\"residual\") */\n  a?: string;\n  b?: string;\n  /** FFN variant override */\n  variant?: 'auto' | 'dense' | 'moe';\n  /** Skip input norm inside attention (use when providing explicit rmsnorm) */\n  skipInputNorm?: boolean;\n  /** Optional probe stage to emit for this step */\n  probeStage?: ProbeStage;\n}\n\nexport interface LayerPipelineOverrideSchema {\n  layers: number[];\n  steps: LayerPipelineStepSchema[];\n}\n\nexport interface LayerPipelineSchema {\n  steps: LayerPipelineStepSchema[];\n  overrides?: LayerPipelineOverrideSchema[];\n}\n\n// =============================================================================\n// Output Schema\n// =============================================================================\n\n/** Output/sampling configuration */\nexport interface OutputSchema {\n  /** Softcap final logits */\n  finalLogitSoftcapping?: number | null;\n  /** Tie embeddings to output */\n  tieWordEmbeddings?: boolean;\n}\n\n// =============================================================================\n// Layer Pattern Schema\n// =============================================================================\n\n/** Layer type for hybrid models */\nexport type LayerType = 'attention' | 'mamba' | 'rwkv';\n\n/** Global layer pattern (computed at runtime from numLayers) */\nexport type GlobalLayerPattern =\n  | 'even'       // Layers 0, 2, 4, ... are global (Gemma 2)\n  | 'odd'        // Layers 1, 3, 5, ... are global\n  | 'every_n';   // Every Nth layer is global (Gemma 3: every 6th)\n\n/** Layer pattern for hybrid architectures */\nexport interface LayerPatternSchema {\n  /** Pattern type: 'all_attention', 'alternating', 'custom' */\n  type: 'all_attention' | 'alternating' | 'custom';\n  /** For 'alternating': pattern for global/full attention layers */\n  globalPattern?: GlobalLayerPattern;\n  /** For 'alternating' with 'every_n': the N value (e.g., 6 for Gemma 3) */\n  globalPatternN?: number;\n  /** @deprecated Use globalPattern instead */\n  attentionLayers?: number[];\n  /** For 'custom': explicit layer type mapping */\n  layerTypes?: LayerType[];\n}\n\n/**\n * Compute global attention layer indices from pattern.\n * Used at runtime when numLayers is known.\n */\nexport function computeGlobalLayers(\n  pattern: LayerPatternSchema,\n  numLayers: number\n): number[] {\n  if (pattern.attentionLayers) {\n    // Legacy: use explicit array (filtered to valid range)\n    return pattern.attentionLayers.filter(i => i < numLayers);\n  }\n\n  if (!pattern.globalPattern) {\n    // Default: all layers are global\n    return Array.from({ length: numLayers }, (_, i) => i);\n  }\n\n  switch (pattern.globalPattern) {\n    case 'even':\n      return Array.from({ length: numLayers }, (_, i) => i).filter(i => i % 2 === 0);\n    case 'odd':\n      return Array.from({ length: numLayers }, (_, i) => i).filter(i => i % 2 === 1);\n    case 'every_n': {\n      const n = pattern.globalPatternN ?? 6;\n      return Array.from({ length: numLayers }, (_, i) => i).filter(i => i % n === 0);\n    }\n    default:\n      return Array.from({ length: numLayers }, (_, i) => i);\n  }\n}\n\n// =============================================================================\n// Full Inference Config Schema\n// =============================================================================\n\n/** Complete inference configuration */\nexport interface InferenceConfigSchema {\n  attention?: AttentionSchema;\n  normalization?: NormalizationSchema;\n  ffn?: FFNSchema;\n  output?: OutputSchema;\n  layerPattern?: LayerPatternSchema;\n  rope?: RoPEConfigSchema;\n  pipeline?: LayerPipelineSchema | null;\n  /** Chat template for instruct models */\n  chatTemplate?: ChatTemplateSchema;\n  /**\n   * Kernel path for explicit kernel dispatch ordering.\n   * Specifies exactly which kernels run, in what order, with what configs.\n   * Can be a preset ID (e.g., 'gemma2-q4k-fused') or inline KernelPathSchema.\n   */\n  kernelPath?: KernelPathRef;\n}\n\n// =============================================================================\n// Sampling Schema\n// =============================================================================\n\n/** Sampling parameters */\nexport interface SamplingSchema {\n  temperature?: number;\n  topK?: number;\n  topP?: number;\n  repetitionPenalty?: number;\n  maxTokens?: number;\n}\n\n// =============================================================================\n// Tokenizer Runtime Schema\n// =============================================================================\n\n/** Tokenizer runtime configuration */\nexport interface TokenizerConfigSchema {\n  /** BOS token string */\n  bosToken?: string;\n  /** EOS token strings (can be multiple) */\n  eosTokens?: string[];\n  /** Pad token string */\n  padToken?: string;\n  /** Add BOS token to input */\n  addBosToken?: boolean;\n  /** Add EOS token to output */\n  addEosToken?: boolean;\n  /** Chat template (jinja2-style) */\n  chatTemplate?: string;\n}\n", "/**\n * Conversion Schema Definitions\n *\n * Types for model format conversion (GGUF/SafeTensors \u2192 RDRR).\n *\n * @module config/schema/conversion\n */\n\nimport type { HashAlgorithm, ModelType, WeightLayout, QuantizationInfoSchema } from './manifest.schema.js';\n\n// =============================================================================\n// Tensor Info Schema\n// =============================================================================\n\n/** Tensor information from source format */\nexport interface TensorInfoSchema {\n  name: string;\n  shape: number[];\n  dtype: string;\n  size: number;\n  offset?: number;\n  /** Platform-specific source reference */\n  _source?: unknown;\n}\n\n// =============================================================================\n// Parsed Model Schema\n// =============================================================================\n\n/** Parsed model ready for conversion */\nexport interface ParsedModelSchema {\n  tensors: TensorInfoSchema[];\n  config: RawModelConfigSchema;\n  architecture?: string;\n  quantization?: string;\n  tokenizerJson?: unknown;\n}\n\n// =============================================================================\n// Raw Model Config Schema\n// =============================================================================\n\n/** Raw config from source (HuggingFace or GGUF style) */\nexport interface RawModelConfigSchema {\n  // HuggingFace style\n  architectures?: string[];\n  model_type?: string;\n  hidden_size?: number;\n  num_hidden_layers?: number;\n  num_attention_heads?: number;\n  num_key_value_heads?: number;\n  intermediate_size?: number;\n  vocab_size?: number;\n  max_position_embeddings?: number;\n  rope_theta?: number;\n  rms_norm_eps?: number;\n  head_dim?: number;\n  _name_or_path?: string;\n\n  // GGUF style\n  n_layer?: number;\n  n_embd?: number;\n  n_head?: number;\n  n_inner?: number;\n  n_positions?: number;\n\n  // MoE\n  num_local_experts?: number;\n  num_experts?: number;\n  n_shared_experts?: number;\n\n  // Allow additional fields\n  [key: string]: unknown;\n}\n\n// =============================================================================\n// Conversion Options Schema\n// =============================================================================\n\n/** Quantization target types */\nexport type QuantizationType = 'q4_k_m' | 'q6_k' | 'q8_0' | 'f16' | 'f32' | null;\n\n/** Conversion options */\nexport interface ConversionOptionsSchema {\n  /** Output model ID */\n  modelId?: string;\n  /** Target quantization */\n  quantize?: QuantizationType;\n  /** Also quantize embeddings */\n  quantizeEmbeddings?: boolean;\n  /** Shard size in bytes */\n  shardSize?: number;\n  /** Progress callback */\n  onProgress?: (progress: ConversionProgressSchema) => void;\n  /** Abort signal */\n  signal?: AbortSignal;\n}\n\n// =============================================================================\n// Conversion Progress Schema\n// =============================================================================\n\n/** Conversion stages */\nexport const ConversionStage = {\n  DETECTING: 'detecting',\n  PARSING: 'parsing',\n  QUANTIZING: 'quantizing',\n  WRITING: 'writing',\n  MANIFEST: 'manifest',\n  COMPLETE: 'complete',\n  ERROR: 'error',\n} as const;\n\nexport type ConversionStageType = (typeof ConversionStage)[keyof typeof ConversionStage];\n\n/** Conversion progress */\nexport interface ConversionProgressSchema {\n  stage: ConversionStageType;\n  message: string;\n  format?: string;\n  modelId?: string;\n  tensorCount?: number;\n  totalSize?: string;\n  current?: number;\n  total?: number;\n  percent?: number;\n  shardCount?: number;\n  error?: Error;\n}\n\n// =============================================================================\n// Writer Options Schema\n// =============================================================================\n\n/** RDRR writer options */\nexport interface WriterOptionsSchema {\n  shardSize?: number;\n  hashAlgorithm?: HashAlgorithm;\n  modelId?: string;\n  modelType?: ModelType;\n  architecture?: string;\n  quantization?: string;\n  quantizationInfo?: QuantizationInfoSchema;\n  /** Pre-transpose weights for column-major access */\n  transposeWeights?: boolean;\n  /** Fuse gate+up projections for FFN */\n  fuseGateUp?: boolean;\n}\n\n// =============================================================================\n// Tensor Location Schema (Writer Output)\n// =============================================================================\n\n/** Tensor location after writing */\nexport interface TensorLocationSchema {\n  shardIndex: number;\n  offset: number;\n  size: number;\n  shape: number[];\n  dtype: string;\n  spans?: Array<{ shardIndex: number; offset: number; size: number }>;\n  layout?: WeightLayout;\n  originalShape?: number[];\n  group?: string;\n}\n\n// =============================================================================\n// Write Result Schema\n// =============================================================================\n\n/** Result of RDRR write operation */\nexport interface WriteResultSchema {\n  manifestPath: string;\n  shardCount: number;\n  totalSize: number;\n  tensorCount: number;\n}\n\n// =============================================================================\n// I/O Adapter Schema\n// =============================================================================\n\n/** Platform-specific I/O adapter */\nexport interface ConversionIOSchema {\n  /** Read tensor data from source */\n  readTensorData(tensor: TensorInfoSchema): Promise<ArrayBuffer>;\n  /** Write shard data, returns hash */\n  writeShard(index: number, data: Uint8Array): Promise<string>;\n  /** Write manifest JSON */\n  writeManifest(manifest: unknown): Promise<void>;\n  /** Optional: compute hash */\n  computeHash?(data: Uint8Array): Promise<string>;\n}\n", "/**\n * Loading Config Schema Definitions\n *\n * Configuration for model loading behavior: shard caching, memory management,\n * and storage settings. These values were previously hardcoded across the codebase.\n *\n * @module config/schema/loading\n */\n\n// =============================================================================\n// Shard Cache Config\n// =============================================================================\n\n/**\n * Configuration for the shard LRU cache.\n *\n * The cache stores recently-used model shards to avoid redundant disk/network reads.\n * Different loading scenarios need different cache sizes:\n * - OPFS (disk): Small cache (2 shards) since disk reads are fast\n * - Network: Large cache (16 shards) to avoid re-fetching over network\n * - MoE: Dynamic sizing based on experts per token\n */\nexport interface ShardCacheConfigSchema {\n  /** Max entries when loading from OPFS (disk reads are fast) */\n  opfsEntries: number;\n\n  /** Max entries when loading from network (avoid re-fetching) */\n  networkEntries: number;\n\n  /** Max entries for MoE models (caps the dynamic formula) */\n  moeMaxEntries: number;\n}\n\n/** Default shard cache configuration */\nexport const DEFAULT_SHARD_CACHE_CONFIG: ShardCacheConfigSchema = {\n  opfsEntries: 2,\n  networkEntries: 16,\n  moeMaxEntries: 16,\n};\n\n// =============================================================================\n// Memory Management Config\n// =============================================================================\n\n/**\n * Configuration for memory management during model loading.\n *\n * Controls when to flush caches and GPU queues to manage memory pressure.\n */\nexport interface MemoryManagementConfigSchema {\n  /** Flush shard cache every N layers during loading */\n  flushIntervalLayers: number;\n\n  /** Flush shard cache when it exceeds this size in bytes */\n  flushThresholdBytes: number;\n\n  /** Flush GPU queue every N layers (releases Chrome staging memory) */\n  gpuQueueFlushLayers: number;\n\n  /** Log memory stats every N milliseconds during loading */\n  logIntervalMs: number;\n}\n\n/** Default memory management configuration */\nexport const DEFAULT_MEMORY_MANAGEMENT_CONFIG: MemoryManagementConfigSchema = {\n  flushIntervalLayers: 4,\n  flushThresholdBytes: 256 * 1024 * 1024, // 256MB\n  gpuQueueFlushLayers: 4,\n  logIntervalMs: 30000, // 30 seconds\n};\n\n// =============================================================================\n// OPFS Path Config\n// =============================================================================\n\n/**\n * Configuration for OPFS directory paths.\n *\n * Note: This is distinct from StorageFullConfigSchema (in storage.schema.ts)\n * which handles quota, VRAM estimation, and alignment settings.\n */\nexport interface OpfsPathConfigSchema {\n  /** Root directory name in OPFS for model storage */\n  opfsRootDir: string;\n}\n\n/** Default OPFS path configuration */\nexport const DEFAULT_OPFS_PATH_CONFIG: OpfsPathConfigSchema = {\n  opfsRootDir: 'doppler-models',\n};\n\n// =============================================================================\n// Expert Cache Config\n// =============================================================================\n\n/**\n * Configuration for the MoE expert LRU cache.\n *\n * Controls how much VRAM is allocated for caching expert weights.\n */\nexport interface ExpertCacheConfigSchema {\n  /** Default maximum cache size in bytes */\n  defaultSizeBytes: number;\n\n  /** Maximum percentage of adapter's maxBufferSize to use (0-1) */\n  maxBufferPercentage: number;\n}\n\n/** Default expert cache configuration */\nexport const DEFAULT_EXPERT_CACHE_CONFIG: ExpertCacheConfigSchema = {\n  defaultSizeBytes: 2 * 1024 * 1024 * 1024, // 2GB\n  maxBufferPercentage: 0.25, // 25% of max buffer\n};\n\n// =============================================================================\n// Complete Loading Config\n// =============================================================================\n\n/**\n * Complete loading configuration schema.\n *\n * Controls all aspects of model loading behavior.\n */\nexport interface LoadingConfigSchema {\n  shardCache: ShardCacheConfigSchema;\n  memoryManagement: MemoryManagementConfigSchema;\n  opfsPath: OpfsPathConfigSchema;\n  expertCache: ExpertCacheConfigSchema;\n}\n\n/** Default loading configuration */\nexport const DEFAULT_LOADING_CONFIG: LoadingConfigSchema = {\n  shardCache: DEFAULT_SHARD_CACHE_CONFIG,\n  memoryManagement: DEFAULT_MEMORY_MANAGEMENT_CONFIG,\n  opfsPath: DEFAULT_OPFS_PATH_CONFIG,\n  expertCache: DEFAULT_EXPERT_CACHE_CONFIG,\n};\n", "/**\n * Kernel Registry Schema Definitions\n *\n * Defines the structure for kernel metadata: variants, bindings, uniforms,\n * workgroup sizes, and GPU feature requirements.\n *\n * @module config/schema/kernel-registry\n */\n\n// =============================================================================\n// GPU Feature Requirements\n// =============================================================================\n\n/**\n * GPU features that a kernel variant may require.\n * These map to WebGPU adapter features.\n */\nexport type GpuFeature = 'shader-f16' | 'subgroups' | 'subgroups-f16';\n\n// =============================================================================\n// Binding Types\n// =============================================================================\n\n/**\n * WebGPU buffer binding types.\n */\nexport type BindingType = 'uniform' | 'storage' | 'read-only-storage';\n\n/**\n * A single buffer binding in a kernel's bind group layout.\n */\nexport interface BindingSchema {\n  /** Binding index in the bind group */\n  index: number;\n\n  /** Human-readable name for debugging */\n  name: string;\n\n  /** Buffer type (uniform, storage, read-only-storage) */\n  type: BindingType;\n\n  /** Optional: whether this binding is optional (can be null) */\n  optional?: boolean;\n}\n\n// =============================================================================\n// Uniform Fields\n// =============================================================================\n\n/**\n * Primitive types for uniform struct fields.\n */\nexport type UniformFieldType = 'u32' | 'i32' | 'f32' | 'f16';\n\n/**\n * A field in a uniform buffer struct.\n */\nexport interface UniformFieldSchema {\n  /** Field name (matches WGSL struct field) */\n  name: string;\n\n  /** Data type */\n  type: UniformFieldType;\n\n  /** Byte offset in the uniform buffer */\n  offset: number;\n}\n\n/**\n * Complete uniform buffer schema for a kernel.\n */\nexport interface UniformsSchema {\n  /** Total size in bytes (must be 16-byte aligned for WebGPU) */\n  size: number;\n\n  /** Fields in the uniform struct */\n  fields: UniformFieldSchema[];\n}\n\n// =============================================================================\n// Kernel Variant\n// =============================================================================\n\n/**\n * WGSL override constants that can be set at pipeline creation.\n */\nexport interface WgslOverridesSchema {\n  [constantName: string]: number;\n}\n\n/**\n * A single kernel variant (e.g., matmul/f16, matmul/q4_fused).\n */\nexport interface KernelVariantSchema {\n  /** WGSL shader filename (relative to kernels directory) */\n  wgsl: string;\n\n  /** Entry point function name in the shader */\n  entryPoint: string;\n\n  /** Workgroup size [x, y, z] */\n  workgroup: [number, number, number];\n\n  /** GPU features required to use this variant */\n  requires?: GpuFeature[];\n\n  /** Estimated shared memory usage in bytes */\n  sharedMemory?: number;\n\n  /** WGSL override constants to set at pipeline creation */\n  wgslOverrides?: WgslOverridesSchema;\n\n  /** Additional bindings beyond the base operation bindings */\n  bindingsOverride?: BindingSchema[];\n\n  /** Override uniform schema (if different from base) */\n  uniformsOverride?: UniformsSchema;\n\n  /** Human-readable description */\n  description?: string;\n}\n\n// =============================================================================\n// Operation\n// =============================================================================\n\n/**\n * An operation (e.g., matmul, attention, rmsnorm) with all its variants.\n */\nexport interface OperationSchema {\n  /** Base bindings shared by all variants */\n  baseBindings: BindingSchema[];\n\n  /** Base uniforms shared by all variants */\n  baseUniforms: UniformsSchema;\n\n  /** Available variants for this operation */\n  variants: Record<string, KernelVariantSchema>;\n\n  /** Human-readable description of the operation */\n  description?: string;\n}\n\n// =============================================================================\n// Kernel Registry\n// =============================================================================\n\n/**\n * Complete kernel registry with all operations and their variants.\n */\nexport interface KernelRegistrySchema {\n  /** Schema version for compatibility checking */\n  version: string;\n\n  /** All kernel operations */\n  operations: Record<string, OperationSchema>;\n}\n\n// =============================================================================\n// Resolved Types (after merging base + variant)\n// =============================================================================\n\n/**\n * Fully resolved kernel configuration after merging base and variant.\n */\nexport interface ResolvedKernelConfig {\n  /** Operation name */\n  operation: string;\n\n  /** Variant name */\n  variant: string;\n\n  /** WGSL shader filename */\n  wgsl: string;\n\n  /** Entry point function name */\n  entryPoint: string;\n\n  /** Workgroup size [x, y, z] */\n  workgroup: [number, number, number];\n\n  /** GPU features required */\n  requires: GpuFeature[];\n\n  /** All bindings (base + override merged) */\n  bindings: BindingSchema[];\n\n  /** Uniform schema (base or overridden) */\n  uniforms: UniformsSchema;\n\n  /** WGSL override constants */\n  wgslOverrides: WgslOverridesSchema;\n\n  /** Estimated shared memory usage in bytes */\n  sharedMemory: number;\n}\n\n// =============================================================================\n// Helper Functions\n// =============================================================================\n\n/**\n * Merge base and variant bindings.\n * Variant bindings with matching indices override base bindings.\n */\nexport function mergeBindings(\n  base: BindingSchema[],\n  override?: BindingSchema[]\n): BindingSchema[] {\n  if (!override || override.length === 0) {\n    return [...base];\n  }\n\n  const result = [...base];\n  for (const binding of override) {\n    const existingIdx = result.findIndex(b => b.index === binding.index);\n    if (existingIdx >= 0) {\n      result[existingIdx] = binding;\n    } else {\n      result.push(binding);\n    }\n  }\n\n  return result.sort((a, b) => a.index - b.index);\n}\n\n/**\n * Resolve a kernel variant to a complete configuration.\n */\nexport function resolveKernelConfig(\n  operation: string,\n  variant: string,\n  opSchema: OperationSchema,\n  variantSchema: KernelVariantSchema\n): ResolvedKernelConfig {\n  return {\n    operation,\n    variant,\n    wgsl: variantSchema.wgsl,\n    entryPoint: variantSchema.entryPoint,\n    workgroup: variantSchema.workgroup,\n    requires: variantSchema.requires ?? [],\n    bindings: mergeBindings(opSchema.baseBindings, variantSchema.bindingsOverride),\n    uniforms: variantSchema.uniformsOverride ?? opSchema.baseUniforms,\n    wgslOverrides: variantSchema.wgslOverrides ?? {},\n    sharedMemory: variantSchema.sharedMemory ?? 0,\n  };\n}\n", "/**\n * Storage Config Schema\n *\n * Configuration for OPFS storage, quota management, and memory estimation.\n * These settings control how the system monitors disk space, estimates VRAM,\n * and aligns storage buffers.\n *\n * @module config/schema/storage\n */\n\n// =============================================================================\n// Quota Config\n// =============================================================================\n\n/**\n * Configuration for OPFS quota monitoring.\n *\n * Controls thresholds for warning about low disk space and\n * the frequency of quota checks.\n */\nexport interface QuotaConfigSchema {\n  /** Threshold in bytes below which space is considered low (warn user) */\n  lowSpaceThresholdBytes: number;\n\n  /** Threshold in bytes below which space is critical (block operations) */\n  criticalSpaceThresholdBytes: number;\n\n  /** Interval in milliseconds between quota monitoring checks */\n  monitorIntervalMs: number;\n}\n\n/** Default quota configuration */\nexport const DEFAULT_QUOTA_CONFIG: QuotaConfigSchema = {\n  lowSpaceThresholdBytes: 500 * 1024 * 1024, // 500MB\n  criticalSpaceThresholdBytes: 100 * 1024 * 1024, // 100MB\n  monitorIntervalMs: 30000, // 30 seconds\n};\n\n// =============================================================================\n// VRAM Estimation Config\n// =============================================================================\n\n/**\n * Configuration for VRAM estimation on different platforms.\n *\n * Used to estimate available GPU memory when WebGPU doesn't provide\n * accurate limits (especially on unified memory systems like Apple Silicon).\n */\nexport interface VramEstimationConfigSchema {\n  /** Ratio of system RAM to use for VRAM estimation on unified memory systems (0-1) */\n  unifiedMemoryRatio: number;\n\n  /** Fallback VRAM size in bytes when estimation is not possible */\n  fallbackVramBytes: number;\n\n  /** Headroom to leave when VRAM is low, in bytes */\n  lowVramHeadroomBytes: number;\n}\n\n/** Default VRAM estimation configuration */\nexport const DEFAULT_VRAM_ESTIMATION_CONFIG: VramEstimationConfigSchema = {\n  unifiedMemoryRatio: 0.5, // 50% of system RAM\n  fallbackVramBytes: 2 * 1024 * 1024 * 1024, // 2GB\n  lowVramHeadroomBytes: 500 * 1024 * 1024, // 500MB\n};\n\n// =============================================================================\n// Storage Alignment Config\n// =============================================================================\n\n/**\n * Configuration for storage buffer alignment.\n *\n * Ensures buffers are aligned to optimal boundaries for GPU access.\n */\nexport interface StorageAlignmentConfigSchema {\n  /** Alignment boundary in bytes for storage buffers */\n  bufferAlignmentBytes: number;\n}\n\n/** Default storage alignment configuration */\nexport const DEFAULT_STORAGE_ALIGNMENT_CONFIG: StorageAlignmentConfigSchema = {\n  bufferAlignmentBytes: 4096, // 4KB alignment (typical page size)\n};\n\n// =============================================================================\n// Complete Storage Config\n// =============================================================================\n\n/**\n * Complete storage configuration schema.\n *\n * Combines quota monitoring, VRAM estimation, and alignment settings.\n */\nexport interface StorageFullConfigSchema {\n  quota: QuotaConfigSchema;\n  vramEstimation: VramEstimationConfigSchema;\n  alignment: StorageAlignmentConfigSchema;\n}\n\n/** Default storage configuration */\nexport const DEFAULT_STORAGE_FULL_CONFIG: StorageFullConfigSchema = {\n  quota: DEFAULT_QUOTA_CONFIG,\n  vramEstimation: DEFAULT_VRAM_ESTIMATION_CONFIG,\n  alignment: DEFAULT_STORAGE_ALIGNMENT_CONFIG,\n};\n", "/**\n * Inference Defaults Config Schema\n *\n * Default values for inference pipeline: batching, sampling, generation.\n * These defaults are used when no model-specific or user overrides are provided.\n *\n * Note: SamplingDefaultsSchema provides defaults for fields from SamplingSchema\n * (in inference.schema.ts), plus the greedyThreshold which is unique to defaults.\n *\n * @module config/schema/inference-defaults\n */\n\nimport type { ChatTemplateSchema, LayerPipelineSchema, SamplingSchema, TokenizerConfigSchema } from './inference.schema.js';\nimport type { KernelPathRef } from './kernel-path.schema.js';\nimport type { ManifestInferenceSchema } from './manifest.schema.js';\n\n// Re-export for convenience\nexport type { ManifestInferenceSchema };\n\n/**\n * Deep partial type for runtime overrides of model-specific inference config.\n * Allows overriding any nested field in ManifestInferenceSchema.\n */\nexport type ModelInferenceOverrides = {\n  [P in keyof ManifestInferenceSchema]?: ManifestInferenceSchema[P] extends object\n    ? { [K in keyof ManifestInferenceSchema[P]]?: ManifestInferenceSchema[P][K] }\n    : ManifestInferenceSchema[P];\n};\n\n// =============================================================================\n// Batching Defaults\n// =============================================================================\n\n/**\n * Default batching configuration for inference.\n *\n * Controls how tokens are batched during generation.\n */\nexport interface BatchingDefaultsSchema {\n  /** Number of sequences to process in parallel (default: 1) */\n  batchSize: number;\n\n  /** Maximum tokens to generate per sequence (default: 512) */\n  maxTokens: number;\n\n  /** When to check for stop conditions: per-token or per-batch (default: 'per-token') */\n  stopCheckMode: 'per-token' | 'batch';\n}\n\n/** Default batching configuration */\nexport const DEFAULT_BATCHING_DEFAULTS: BatchingDefaultsSchema = {\n  batchSize: 1,  // Compare single-token\n  maxTokens: 512,\n  stopCheckMode: 'per-token',\n};\n\n// =============================================================================\n// Compute Defaults\n// =============================================================================\n\n/**\n * Default compute precision configuration.\n *\n * Controls dtype for intermediate activations and compute operations.\n * F16 reduces memory bandwidth by 2x but may have precision implications.\n */\nexport interface ComputeDefaultsSchema {\n  /** Dtype for hidden state activations (default: 'f32', experimental: 'f16') */\n  activationDtype: 'f16' | 'f32';\n\n  /** Parameter count threshold for \"large model\" classification (default: 4e9 = 4B params) */\n  largeModelParamThreshold: number;\n\n  /** Multiplier for estimating model params from hidden^2 \u00D7 layers (default: 12) */\n  paramEstimationMultiplier: number;\n}\n\n/** Default compute configuration */\nexport const DEFAULT_COMPUTE_DEFAULTS: ComputeDefaultsSchema = {\n  activationDtype: 'f32',  // Safe default, F16 is experimental\n  largeModelParamThreshold: 4e9,  // 4B parameters\n  paramEstimationMultiplier: 12,  // Rough approximation: 12 * hidden^2 * layers\n};\n\n// =============================================================================\n// Large Weight Handling\n// =============================================================================\n\n/**\n * Configuration for oversized weights (embeddings, LM head).\n *\n * When weights exceed device binding limits, DOPPLER can keep them on CPU\n * and stream chunks to the GPU for matmul or gather operations.\n */\nexport interface LargeWeightConfigSchema {\n  /** Enable CPU-backed chunking for oversized weights */\n  enabled: boolean;\n  /** Safety ratio applied to GPU binding limits (0..1). Default: 0.9 */\n  safetyRatio: number;\n  /** Prefer uploading F16 chunks when supported (reduces chunk size) */\n  preferF16: boolean;\n  /** Optional override for LM head chunk rows (null = auto) */\n  lmHeadChunkRows?: number | null;\n}\n\n/** Default large-weight configuration */\nexport const DEFAULT_LARGE_WEIGHT_CONFIG: LargeWeightConfigSchema = {\n  enabled: true,\n  safetyRatio: 0.9,\n  preferF16: true,\n  lmHeadChunkRows: null,\n};\n\n// =============================================================================\n// Sampling Defaults\n// =============================================================================\n\n/**\n * Default sampling configuration for token selection.\n *\n * Extends Required<SamplingSchema> with greedyThreshold for runtime decisions.\n * SamplingSchema (in inference.schema.ts) uses optional fields for partial overrides;\n * this schema provides concrete defaults for all sampling parameters.\n */\nexport interface SamplingDefaultsSchema extends Required<Omit<SamplingSchema, 'maxTokens'>> {\n  /** Temperature below this uses greedy decoding (default: 0.01) */\n  greedyThreshold: number;\n\n  /** Number of recent tokens to consider for repetition penalty (default: 100) */\n  repetitionPenaltyWindow: number;\n}\n\n/** Default sampling configuration */\nexport const DEFAULT_SAMPLING_DEFAULTS: SamplingDefaultsSchema = {\n  temperature: 0.7,\n  topP: 0.9,\n  topK: 40,\n  repetitionPenalty: 1.1,\n  greedyThreshold: 0.01,\n  repetitionPenaltyWindow: 100,\n};\n\n// =============================================================================\n// Tokenizer Defaults\n// =============================================================================\n\n/**\n * Default tokenizer configuration.\n *\n * Provides defaults for common tokenizer behavior. Actual token strings\n * come from the model's tokenizer config; these control runtime behavior.\n */\nexport interface TokenizerDefaultsSchema {\n  /** Add BOS token to input (default: true for most models) */\n  addBosToken: boolean;\n\n  /** Add EOS token to output (default: false, model decides) */\n  addEosToken: boolean;\n}\n\n/** Default tokenizer configuration */\nexport const DEFAULT_TOKENIZER_DEFAULTS: TokenizerDefaultsSchema = {\n  addBosToken: true,\n  addEosToken: false,\n};\n\n// =============================================================================\n// Complete Inference Defaults Config\n// =============================================================================\n\n/**\n * Complete inference defaults configuration schema.\n *\n * Combines batching, sampling, compute, and tokenizer defaults for the inference pipeline.\n */\nexport interface InferenceDefaultsConfigSchema {\n  batching: BatchingDefaultsSchema;\n  sampling: SamplingDefaultsSchema;\n  compute: ComputeDefaultsSchema;\n  tokenizer: TokenizerDefaultsSchema;\n  /** Handling for oversized embeddings/LM head */\n  largeWeights: LargeWeightConfigSchema;\n  /** Optional default prompt text for test harnesses */\n  prompt?: string | null;\n  pipeline?: LayerPipelineSchema | null;\n  /**\n   * Kernel path for explicit kernel dispatch ordering.\n   * Specifies exactly which kernels run, in what order, with what configs.\n   * Can be a preset ID (e.g., 'gemma2-q4k-fused') or inline KernelPathSchema.\n   */\n  kernelPath?: KernelPathRef;\n  /**\n   * Chat template override for runtime config.\n   * When set, overrides the model preset's chatTemplate.enabled setting.\n   */\n  chatTemplate?: ChatTemplateSchema;\n  /**\n   * Model-specific inference overrides.\n   * Allows runtime override of any manifest inference field (attention, normalization, rope, etc.).\n   * These are merged with manifest.inference via mergeConfig().\n   */\n  modelOverrides?: ModelInferenceOverrides;\n}\n\n/** Default inference configuration */\nexport const DEFAULT_INFERENCE_DEFAULTS_CONFIG: InferenceDefaultsConfigSchema = {\n  batching: DEFAULT_BATCHING_DEFAULTS,\n  sampling: DEFAULT_SAMPLING_DEFAULTS,\n  compute: DEFAULT_COMPUTE_DEFAULTS,\n  tokenizer: DEFAULT_TOKENIZER_DEFAULTS,\n  largeWeights: DEFAULT_LARGE_WEIGHT_CONFIG,\n  prompt: null,\n  pipeline: null,\n  kernelPath: undefined,\n};\n", "/**\n * Distribution Config Schema\n *\n * Configuration for network downloads, CDN settings, and retry policies.\n * These values control how model shards are fetched from remote servers.\n *\n * @module config/schema/distribution\n */\n\n// =============================================================================\n// Distribution Config\n// =============================================================================\n\n/**\n * Configuration for network distribution and download behavior.\n *\n * Controls concurrent downloads, retry policies, chunk sizes, and CDN routing.\n * These settings affect network performance and reliability when fetching\n * model shards from remote servers.\n */\nexport interface DistributionConfigSchema {\n  /** Number of concurrent shard downloads (1-8) */\n  concurrentDownloads: number;\n\n  /** Maximum retry attempts for failed downloads */\n  maxRetries: number;\n\n  /** Initial delay before first retry in milliseconds */\n  initialRetryDelayMs: number;\n\n  /** Maximum delay between retries in milliseconds (exponential backoff cap) */\n  maxRetryDelayMs: number;\n\n  /** Maximum chunk size for streaming downloads in bytes */\n  maxChunkSizeBytes: number;\n\n  /** CDN base path override (null uses origin server) */\n  cdnBasePath: string | null;\n\n  /** Minimum interval between progress callbacks in milliseconds */\n  progressUpdateIntervalMs: number;\n}\n\n/** Default distribution configuration */\nexport const DEFAULT_DISTRIBUTION_CONFIG: DistributionConfigSchema = {\n  concurrentDownloads: 3,\n  maxRetries: 3,\n  initialRetryDelayMs: 1000,\n  maxRetryDelayMs: 30000,\n  maxChunkSizeBytes: 8 * 1024 * 1024, // 8MB\n  cdnBasePath: null,\n  progressUpdateIntervalMs: 100,\n};\n", "/**\n * MoE Config Schema\n *\n * Configuration for Mixture of Experts routing and caching.\n * These are runtime settings that affect how MoE layers execute.\n *\n * @module config/schema/moe\n */\n\n// =============================================================================\n// Router Dtype\n// =============================================================================\n\n/** Supported data types for router computation */\nexport type RouterDtype = 'f16' | 'f32';\n\n// =============================================================================\n// MoE Routing Config\n// =============================================================================\n\n/**\n * Configuration for MoE routing behavior.\n *\n * Controls how tokens are routed to experts during inference.\n */\nexport interface MoERoutingConfigSchema {\n  /** Number of experts in the MoE layer */\n  numExperts: number;\n\n  /** Number of experts to activate per token (top-K routing) */\n  topK: number;\n\n  /** Normalize expert weights after routing */\n  normalizeWeights: boolean;\n\n  /** Data type for router computation */\n  routerDtype: RouterDtype;\n}\n\n/** Default MoE routing configuration */\nexport const DEFAULT_MOE_ROUTING_CONFIG: MoERoutingConfigSchema = {\n  numExperts: 8,\n  topK: 2,\n  normalizeWeights: true,\n  routerDtype: 'f32',\n};\n\n// =============================================================================\n// MoE Cache Config\n// =============================================================================\n\n/**\n * Configuration for MoE dequantization caching.\n *\n * Controls the LRU cache for dequantized expert weights to avoid\n * redundant dequantization when experts are reused across tokens.\n */\nexport interface MoECacheConfigSchema {\n  /** Maximum number of dequantized expert entries to cache */\n  dequantCacheMaxEntries: number;\n}\n\n/** Default MoE cache configuration */\nexport const DEFAULT_MOE_CACHE_CONFIG: MoECacheConfigSchema = {\n  dequantCacheMaxEntries: 128,\n};\n\n// =============================================================================\n// Complete MoE Runtime Config\n// =============================================================================\n\n/**\n * Complete MoE runtime configuration schema.\n *\n * Controls all aspects of MoE inference behavior.\n */\nexport interface MoERuntimeConfigSchema {\n  routing: MoERoutingConfigSchema;\n  cache: MoECacheConfigSchema;\n}\n\n/** Default MoE runtime configuration */\nexport const DEFAULT_MOE_RUNTIME_CONFIG: MoERuntimeConfigSchema = {\n  routing: DEFAULT_MOE_ROUTING_CONFIG,\n  cache: DEFAULT_MOE_CACHE_CONFIG,\n};\n", "/**\n * KV Cache Config Schema\n *\n * Configuration for key-value cache: dtype, layout, sizing.\n * Controls memory allocation and access patterns for transformer attention.\n *\n * @module config/schema/kvcache\n */\n\n// =============================================================================\n// KV Dtype\n// =============================================================================\n\n/**\n * Data type for KV cache storage.\n *\n * - 'f16': Half precision (2 bytes per element, lower memory, slight accuracy loss)\n * - 'f32': Full precision (4 bytes per element, higher memory, full accuracy)\n */\nexport type KVDtype = 'f16' | 'f32';\n\n// =============================================================================\n// KV Layout\n// =============================================================================\n\n/**\n * Memory layout for KV cache.\n *\n * - 'contiguous': Single contiguous buffer per layer (simpler, better for short sequences)\n * - 'paged': Page-based allocation (better memory efficiency for variable sequences)\n */\nexport type KVLayout = 'contiguous' | 'paged';\n\n// =============================================================================\n// KV Cache Config Schema\n// =============================================================================\n\n/**\n * Configuration for the key-value cache.\n *\n * The KV cache stores computed key and value tensors from attention layers\n * to avoid recomputation during autoregressive decoding. These settings\n * control memory allocation, precision, and layout strategies.\n */\nexport interface KVCacheConfigSchema {\n  /** Maximum sequence length the cache can hold */\n  maxSeqLen: number;\n\n  /** Data type for cache storage */\n  kvDtype: KVDtype;\n\n  /** Memory layout strategy */\n  layout: KVLayout;\n\n  /** Page size for paged layout (number of tokens per page) */\n  pageSize: number;\n\n  /** Sliding window size for sliding window attention models */\n  windowSize: number;\n}\n\n// =============================================================================\n// Default Config\n// =============================================================================\n\n/** Default KV cache configuration */\nexport const DEFAULT_KVCACHE_CONFIG: KVCacheConfigSchema = {\n  maxSeqLen: 4096,\n  kvDtype: 'f16',\n  layout: 'contiguous',\n  pageSize: 256,\n  windowSize: 1024,\n};\n", "/**\n * GPU Cache Config Schema\n *\n * Configuration for GPU uniform buffer caching.\n * These settings control cache size, entry limits, and expiration policies\n * for the uniform buffer cache that reduces GPU buffer allocations.\n *\n * @module config/schema/gpu-cache\n */\n\n// =============================================================================\n// Uniform Buffer Cache Config\n// =============================================================================\n\n/**\n * Configuration for the uniform buffer cache.\n *\n * The uniform buffer cache stores small GPU buffers by content hash,\n * allowing reuse across kernel dispatches instead of repeated allocations.\n */\nexport interface GpuCacheConfigSchema {\n  /** Maximum number of entries in the uniform buffer cache */\n  uniformCacheMaxEntries: number;\n\n  /** Maximum age in milliseconds before an unused entry becomes stale */\n  uniformCacheMaxAgeMs: number;\n}\n\n/** Default GPU cache configuration */\nexport const DEFAULT_GPU_CACHE_CONFIG: GpuCacheConfigSchema = {\n  uniformCacheMaxEntries: 256,\n  uniformCacheMaxAgeMs: 60000, // 60 seconds\n};\n", "/**\n * Tuner Config Schema\n *\n * Configuration for the kernel auto-tuner, which benchmarks different\n * workgroup sizes to find optimal configurations for each kernel type.\n * Results are cached in localStorage for persistence across sessions.\n *\n * @module config/schema/tuner\n */\n\n// =============================================================================\n// Tuner Config\n// =============================================================================\n\n/**\n * Configuration for the kernel auto-tuner.\n *\n * Controls cache key prefixes and default iteration counts for warmup\n * and timed benchmarking passes.\n */\nexport interface TunerConfigSchema {\n  /** Prefix for localStorage cache keys (device signature appended) */\n  cacheKeyPrefix: string;\n\n  /** Number of warmup iterations before timing (not included in measurements) */\n  defaultWarmupIterations: number;\n\n  /** Number of timed iterations to average for benchmark results */\n  defaultTimedIterations: number;\n}\n\n/** Default tuner configuration */\nexport const DEFAULT_TUNER_CONFIG: TunerConfigSchema = {\n  cacheKeyPrefix: 'doppler_kernel_tune_',\n  defaultWarmupIterations: 3,\n  defaultTimedIterations: 10,\n};\n", "/**\n * Debug Config Schema\n *\n * Configuration for the DOPPLER debug module, including log history limits,\n * default log levels, trace categories, and decode step limits.\n *\n * @module config/schema/debug\n */\n\n// =============================================================================\n// Log Output Config\n// =============================================================================\n\n/**\n * Configuration for log output destinations.\n *\n * Controls where logs are written: stdout, file, or both.\n */\nexport interface LogOutputConfigSchema {\n  /** Write logs to stdout/console (default: true) */\n  stdout: boolean;\n  /** Path to log file (null = no file output) */\n  file: string | null;\n  /** Append to existing file vs overwrite (default: true) */\n  append: boolean;\n}\n\n/** Default log output configuration */\nexport const DEFAULT_LOG_OUTPUT_CONFIG: LogOutputConfigSchema = {\n  stdout: true,\n  file: null,\n  append: true,\n};\n\n// =============================================================================\n// Log History Config\n// =============================================================================\n\n/**\n * Configuration for log history retention.\n *\n * Controls how many log entries are kept in memory for debugging\n * and diagnostic purposes.\n */\nexport interface LogHistoryConfigSchema {\n  /** Maximum number of log entries to retain in memory */\n  maxLogHistoryEntries: number;\n}\n\n/** Default log history configuration */\nexport const DEFAULT_LOG_HISTORY_CONFIG: LogHistoryConfigSchema = {\n  maxLogHistoryEntries: 1000,\n};\n\n// =============================================================================\n// Log Level Config\n// =============================================================================\n\n/** Valid log levels */\nexport const LOG_LEVELS = ['debug', 'verbose', 'info', 'warn', 'error', 'silent'] as const;\n\n/** Log level type */\nexport type LogLevel = typeof LOG_LEVELS[number];\n\n/**\n * Configuration for default log level.\n *\n * Controls the initial verbosity level when the debug module initializes.\n */\nexport interface LogLevelConfigSchema {\n  /** Default log level (debug, verbose, info, warn, error, silent) */\n  defaultLogLevel: LogLevel;\n}\n\n/** Default log level configuration */\nexport const DEFAULT_LOG_LEVEL_CONFIG: LogLevelConfigSchema = {\n  defaultLogLevel: 'info',\n};\n\n// =============================================================================\n// Trace Config\n// =============================================================================\n\n/** Available trace categories */\nexport type TraceCategory =\n  | 'loader'\n  | 'kernels'\n  | 'logits'\n  | 'embed'\n  | 'attn'\n  | 'ffn'\n  | 'kv'\n  | 'sample'\n  | 'buffers'\n  | 'perf'\n  | 'all';\n\n/**\n * Configuration for trace output.\n *\n * Controls trace categories, output destination, and limits.\n */\nexport interface TraceConfigSchema {\n  /** Enable tracing (default: false) */\n  enabled: boolean;\n  /** Trace categories to enable (default: all) */\n  categories: TraceCategory[];\n  /** Filter to specific layer indices (null = all layers) */\n  layers: number[] | null;\n  /** Maximum decode steps to trace (0 = unlimited) */\n  maxDecodeSteps: number;\n  /** Path to trace file for JSONL output (null = no file) */\n  file: string | null;\n}\n\n/** Default trace configuration */\nexport const DEFAULT_TRACE_CONFIG: TraceConfigSchema = {\n  enabled: false,\n  categories: ['all'],\n  layers: null,\n  maxDecodeSteps: 0,\n  file: null,\n};\n\n// =============================================================================\n// Pipeline Debug Config (debug-utils)\n// =============================================================================\n\n/** Debug categories for pipeline debug-utils (kernel/layer inspection) */\nexport type PipelineDebugCategory =\n  | 'embed'\n  | 'layer'\n  | 'attn'\n  | 'ffn'\n  | 'kv'\n  | 'logits'\n  | 'sample'\n  | 'io'\n  | 'perf'\n  | 'kernel'\n  | 'all';\n\n/**\n * Pipeline debug configuration.\n *\n * Controls debug-utils categories and expensive readback helpers.\n */\nexport interface PipelineDebugConfigSchema {\n  /** Enable pipeline debug (default: false) */\n  enabled: boolean;\n  /** Debug categories to enable (default: none) */\n  categories: PipelineDebugCategory[];\n  /** Filter to specific layer indices (null = all layers) */\n  layers: number[] | null;\n  /** Maximum decode steps to log (0 = unlimited) */\n  maxDecodeSteps: number;\n  /** Warn if maxAbs exceeds this */\n  maxAbsThreshold: number;\n  /** Enable expensive GPU buffer stats */\n  bufferStats: boolean;\n  /** Maximum bytes to readback for debug samples (default: 512) */\n  readbackSampleSize: number;\n}\n\n/** Default pipeline debug configuration */\nexport const DEFAULT_PIPELINE_DEBUG_CONFIG: PipelineDebugConfigSchema = {\n  enabled: false,\n  categories: [],\n  layers: null,\n  maxDecodeSteps: 0,\n  maxAbsThreshold: 10000,\n  bufferStats: false,\n  readbackSampleSize: 512,\n};\n\n// =============================================================================\n// Probe Config\n// =============================================================================\n\n/** Pipeline probe stages */\nexport type ProbeStage =\n  | 'embed_out'\n  // Attention stages (per-layer)\n  | 'attn_input'      // Input to attention (after residual from previous layer)\n  | 'attn_normed'     // After input RMSNorm\n  | 'q_proj'          // Q projection output\n  | 'k_proj'          // K projection output\n  | 'v_proj'          // V projection output\n  | 'q_rope'          // Q after RoPE\n  | 'k_rope'          // K after RoPE\n  | 'attn_scores'     // Attention scores (pre-softmax)\n  | 'attn_out'        // Attention output (before o_proj)\n  | 'o_proj'          // Output projection\n  | 'post_attn'       // After attention residual\n  // FFN stages (per-layer)\n  | 'ffn_normed'      // After post-attention RMSNorm\n  | 'ffn_in'          // FFN gate/up input\n  | 'ffn_gate'        // Gate projection output\n  | 'ffn_up'          // Up projection output\n  | 'ffn_act'         // After activation\n  | 'ffn_out'         // Down projection output\n  | 'layer_out'       // Final layer output (after FFN residual)\n  // Final stages\n  | 'pre_final_norm'\n  | 'final_norm'\n  | 'logits'\n  | 'logits_final';\n\n/**\n * Probe configuration for targeted value inspection.\n *\n * Probes read specific token/dimension values from GPU buffers at\n * named pipeline stages.\n */\nexport interface ProbeConfigSchema {\n  /** Optional probe id (included in logs) */\n  id?: string;\n  /** Stage to probe */\n  stage: ProbeStage;\n  /** Restrict to specific layers (null = all layers) */\n  layers?: number[] | null;\n  /** Token indices to sample (null = default to token 0) */\n  tokens?: number[] | null;\n  /** Dimension indices to sample */\n  dims: number[];\n  /** Override trace category (defaults to stage category) */\n  category?: TraceCategory;\n}\n\n// =============================================================================\n// Complete Debug Config\n// =============================================================================\n\n/**\n * Complete debug configuration schema.\n *\n * Combines log output, log history, log level, and trace settings.\n */\nexport interface DebugConfigSchema {\n  logOutput: LogOutputConfigSchema;\n  logHistory: LogHistoryConfigSchema;\n  logLevel: LogLevelConfigSchema;\n  trace: TraceConfigSchema;\n  pipeline: PipelineDebugConfigSchema;\n  probes: ProbeConfigSchema[];\n}\n\n/** Default debug configuration */\nexport const DEFAULT_DEBUG_CONFIG: DebugConfigSchema = {\n  logOutput: DEFAULT_LOG_OUTPUT_CONFIG,\n  logHistory: DEFAULT_LOG_HISTORY_CONFIG,\n  logLevel: DEFAULT_LOG_LEVEL_CONFIG,\n  trace: DEFAULT_TRACE_CONFIG,\n  pipeline: DEFAULT_PIPELINE_DEBUG_CONFIG,\n  probes: [],\n};\n", "/**\n * Hot-Swap Config Schema\n *\n * Security policy for swapping JS/WGSL/JSON artifacts at runtime.\n *\n * @module config/schema/hotswap\n */\n\n// =============================================================================\n// Signer Schema\n// =============================================================================\n\n/**\n * Trusted signer entry.\n *\n * `publicKeyJwk` is used for signature verification.\n */\nexport interface HotSwapSignerSchema {\n  /** Stable signer ID */\n  id: string;\n  /** Public key in JWK format */\n  publicKeyJwk: JsonWebKey;\n}\n\n// =============================================================================\n// Hot-Swap Config\n// =============================================================================\n\n/**\n * Hot-swap configuration.\n */\nexport interface HotSwapConfigSchema {\n  /** Enable hot-swap loading (default: false) */\n  enabled: boolean;\n  /** Treat swaps as local-only (no distribution) */\n  localOnly: boolean;\n  /** Allow unsigned bundles when localOnly is true */\n  allowUnsignedLocal: boolean;\n  /** Allowlisted signers for distributed bundles */\n  trustedSigners: HotSwapSignerSchema[];\n  /** Optional manifest URL for test harness workflows */\n  manifestUrl: string | null;\n}\n\n/** Default hot-swap configuration */\nexport const DEFAULT_HOTSWAP_CONFIG: HotSwapConfigSchema = {\n  enabled: false,\n  localOnly: false,\n  allowUnsignedLocal: false,\n  trustedSigners: [],\n  manifestUrl: null,\n};\n", "/**\n * Buffer Pool Config Schema\n *\n * Configuration for GPU buffer pooling, including bucket sizing,\n * pool limits, and alignment settings for efficient buffer reuse.\n *\n * @module config/schema/buffer-pool\n */\n\n// =============================================================================\n// Buffer Pool Config\n// =============================================================================\n\n/**\n * Configuration for GPU buffer pool bucket sizing.\n *\n * Controls how buffers are bucketed by size for efficient reuse.\n * Small buffers use power-of-2 rounding, large buffers use linear steps.\n */\nexport interface BufferPoolBucketConfigSchema {\n  /** Minimum bucket size in bytes (buffers smaller than this round up to this) */\n  minBucketSizeBytes: number;\n\n  /** Threshold in bytes above which large buffer bucketing is used */\n  largeBufferThresholdBytes: number;\n\n  /** Step size in bytes for large buffer buckets (linear rounding) */\n  largeBufferStepBytes: number;\n}\n\n/** Default buffer pool bucket configuration */\nexport const DEFAULT_BUFFER_POOL_BUCKET_CONFIG: BufferPoolBucketConfigSchema = {\n  minBucketSizeBytes: 256, // 256 bytes\n  largeBufferThresholdBytes: 32 * 1024 * 1024, // 32MB\n  largeBufferStepBytes: 16 * 1024 * 1024, // 16MB\n};\n\n// =============================================================================\n// Buffer Pool Limits Config\n// =============================================================================\n\n/**\n * Configuration for buffer pool size limits.\n *\n * Controls how many buffers can be pooled to prevent memory bloat.\n */\nexport interface BufferPoolLimitsConfigSchema {\n  /** Maximum number of buffers per size/usage bucket */\n  maxBuffersPerBucket: number;\n\n  /** Maximum total number of buffers across all pools */\n  maxTotalPooledBuffers: number;\n}\n\n/** Default buffer pool limits configuration */\nexport const DEFAULT_BUFFER_POOL_LIMITS_CONFIG: BufferPoolLimitsConfigSchema = {\n  maxBuffersPerBucket: 8,\n  maxTotalPooledBuffers: 64,\n};\n\n// =============================================================================\n// Buffer Pool Alignment Config\n// =============================================================================\n\n/**\n * Configuration for buffer alignment.\n *\n * Ensures buffers are aligned to WebGPU requirements.\n */\nexport interface BufferPoolAlignmentConfigSchema {\n  /** Alignment boundary in bytes for buffer sizes */\n  alignmentBytes: number;\n}\n\n/** Default buffer pool alignment configuration */\nexport const DEFAULT_BUFFER_POOL_ALIGNMENT_CONFIG: BufferPoolAlignmentConfigSchema = {\n  alignmentBytes: 256, // WebGPU buffer alignment\n};\n\n// =============================================================================\n// Complete Buffer Pool Config\n// =============================================================================\n\n/**\n * Complete buffer pool configuration schema.\n *\n * Combines bucket sizing, pool limits, and alignment settings.\n */\nexport interface BufferPoolConfigSchema {\n  bucket: BufferPoolBucketConfigSchema;\n  limits: BufferPoolLimitsConfigSchema;\n  alignment: BufferPoolAlignmentConfigSchema;\n}\n\n/** Default buffer pool configuration */\nexport const DEFAULT_BUFFER_POOL_CONFIG: BufferPoolConfigSchema = {\n  bucket: DEFAULT_BUFFER_POOL_BUCKET_CONFIG,\n  limits: DEFAULT_BUFFER_POOL_LIMITS_CONFIG,\n  alignment: DEFAULT_BUFFER_POOL_ALIGNMENT_CONFIG,\n};\n", "/**\n * Memory Limits Config Schema\n *\n * Configuration for memory capability detection and heap management.\n * These settings control heap test sizes, segment allocation, and\n * fallback limits for both Memory64 and segmented heap strategies.\n *\n * @module config/schema/memory-limits\n */\n\n// =============================================================================\n// Unit Constants\n// =============================================================================\n\nconst MB = 1024 * 1024;\nconst GB = 1024 * MB;\n\n// =============================================================================\n// Heap Testing Config\n// =============================================================================\n\n/**\n * Configuration for heap size testing.\n *\n * Controls the sizes probed when detecting maximum WASM heap size\n * and the fallback when all probes fail.\n */\nexport interface HeapTestingConfigSchema {\n  /** Sizes to test for maximum heap, in descending order (bytes) */\n  heapTestSizes: number[];\n\n  /** Fallback maximum heap size when all probes fail (bytes) */\n  fallbackMaxHeapBytes: number;\n}\n\n/** Default heap testing configuration */\nexport const DEFAULT_HEAP_TESTING_CONFIG: HeapTestingConfigSchema = {\n  heapTestSizes: [16 * GB, 8 * GB, 4 * GB, 2 * GB, 1 * GB],\n  fallbackMaxHeapBytes: 1 * GB,\n};\n\n// =============================================================================\n// Segment Testing Config\n// =============================================================================\n\n/**\n * Configuration for segment size testing.\n *\n * Controls the sizes probed when detecting maximum ArrayBuffer size\n * for segmented heap mode.\n */\nexport interface SegmentTestingConfigSchema {\n  /** Sizes to test for maximum segment, in descending order (bytes) */\n  segmentTestSizes: number[];\n\n  /** Safe segment size to use as default (bytes) */\n  safeSegmentSizeBytes: number;\n}\n\n/** Default segment testing configuration */\nexport const DEFAULT_SEGMENT_TESTING_CONFIG: SegmentTestingConfigSchema = {\n  segmentTestSizes: [1 * GB, 512 * MB, 256 * MB, 128 * MB],\n  safeSegmentSizeBytes: 256 * MB,\n};\n\n// =============================================================================\n// Address Space Config\n// =============================================================================\n\n/**\n * Configuration for virtual address space.\n *\n * Controls the target address space size used to calculate\n * recommended segment count.\n */\nexport interface AddressSpaceConfigSchema {\n  /** Target virtual address space size (bytes) */\n  targetAddressSpaceBytes: number;\n}\n\n/** Default address space configuration */\nexport const DEFAULT_ADDRESS_SPACE_CONFIG: AddressSpaceConfigSchema = {\n  targetAddressSpaceBytes: 8 * GB,\n};\n\n// =============================================================================\n// Segment Allocation Config\n// =============================================================================\n\n/**\n * Configuration for segment allocation.\n *\n * Controls fallback behavior when segment allocation fails.\n */\nexport interface SegmentAllocationConfigSchema {\n  /** Fallback segment size for Memory64 init failure (bytes) */\n  fallbackSegmentSizeBytes: number;\n\n  /** Fallback sizes to try when segment allocation fails, in descending order (bytes) */\n  segmentFallbackSizes: number[];\n}\n\n/** Default segment allocation configuration */\nexport const DEFAULT_SEGMENT_ALLOCATION_CONFIG: SegmentAllocationConfigSchema = {\n  fallbackSegmentSizeBytes: 4 * GB,\n  segmentFallbackSizes: [512 * MB, 256 * MB, 128 * MB],\n};\n\n// =============================================================================\n// Complete Memory Limits Config\n// =============================================================================\n\n/**\n * Complete memory limits configuration schema.\n *\n * Combines heap testing, segment testing, address space,\n * and segment allocation settings.\n */\nexport interface MemoryLimitsConfigSchema {\n  heapTesting: HeapTestingConfigSchema;\n  segmentTesting: SegmentTestingConfigSchema;\n  addressSpace: AddressSpaceConfigSchema;\n  segmentAllocation: SegmentAllocationConfigSchema;\n}\n\n/** Default memory limits configuration */\nexport const DEFAULT_MEMORY_LIMITS_CONFIG: MemoryLimitsConfigSchema = {\n  heapTesting: DEFAULT_HEAP_TESTING_CONFIG,\n  segmentTesting: DEFAULT_SEGMENT_TESTING_CONFIG,\n  addressSpace: DEFAULT_ADDRESS_SPACE_CONFIG,\n  segmentAllocation: DEFAULT_SEGMENT_ALLOCATION_CONFIG,\n};\n", "/**\n * Bridge Config Schema\n *\n * Configuration for the native messaging bridge between DOPPLER and the\n * Chrome extension. Controls security boundaries and resource limits.\n *\n * @module config/schema/bridge\n */\n\n// =============================================================================\n// Bridge Config\n// =============================================================================\n\n/**\n * Configuration for the native messaging bridge.\n *\n * Controls file access permissions and resource limits for the native host\n * process that provides filesystem access to the browser extension.\n */\nexport interface BridgeConfigSchema {\n  /** Maximum bytes to read per request to prevent OOM (default: 100MB) */\n  maxReadSizeBytes: number;\n\n  /** Colon-separated list of allowed directory paths for file access */\n  allowedDirectories: string;\n}\n\n/** Default bridge configuration */\nexport const DEFAULT_BRIDGE_CONFIG: BridgeConfigSchema = {\n  maxReadSizeBytes: 100 * 1024 * 1024, // 100MB\n  allowedDirectories: '/Users:/home:/tmp:/var/tmp',\n};\n", "/**\n * Quantization Defaults Config Schema\n *\n * Default quantization settings for the model converter.\n * Controls the target precision for different weight groups when not explicitly specified.\n *\n * @module config/schema/quantization-defaults\n */\n\n// =============================================================================\n// Quantization Dtype Types\n// =============================================================================\n\n/** Supported weight quantization types */\nexport type WeightQuantType = 'f16' | 'f32' | 'q4k' | 'q6k' | 'q8_0';\n\n/** Supported embedding quantization types */\nexport type EmbeddingQuantType = 'f16' | 'f32';\n\n// =============================================================================\n// Quantization Defaults Schema\n// =============================================================================\n\n/**\n * Default quantization settings for model conversion.\n *\n * These defaults are used when no explicit quantization is specified\n * for a particular weight group during conversion.\n */\nexport interface QuantizationDefaultsSchema {\n  /** Default dtype for vision encoder weights (default: 'f16') */\n  visionDtype: EmbeddingQuantType;\n\n  /** Default dtype for audio encoder weights (default: 'f16') */\n  audioDtype: EmbeddingQuantType;\n\n  /** Default dtype for projector weights in multimodal models (default: 'f16') */\n  projectorDtype: EmbeddingQuantType;\n}\n\n/** Default quantization configuration */\nexport const DEFAULT_QUANTIZATION_DEFAULTS: QuantizationDefaultsSchema = {\n  visionDtype: 'f16',\n  audioDtype: 'f16',\n  projectorDtype: 'f16',\n};\n", "/**\n * Kernel Thresholds Schema\n *\n * Centralized configuration for kernel selection thresholds and magic numbers.\n * These values control when variant selection switches between kernel implementations.\n *\n * @module config/schema/kernel-thresholds\n */\n\n// =============================================================================\n// Matmul Thresholds\n// =============================================================================\n\n/**\n * Thresholds for matrix multiplication kernel variant selection.\n */\nexport interface MatmulThresholdsSchema {\n  /**\n   * N dimension threshold for selecting multicol GEMV variants.\n   * When N >= threshold, use multicol variant for reduced workgroup count.\n   * @default 256\n   */\n  multicolThreshold: number;\n}\n\nexport const DEFAULT_MATMUL_THRESHOLDS: MatmulThresholdsSchema = {\n  multicolThreshold: 256,\n};\n\n// =============================================================================\n// RMSNorm Thresholds\n// =============================================================================\n\n/**\n * Thresholds for RMSNorm kernel variant selection.\n */\nexport interface RmsnormThresholdsSchema {\n  /**\n   * Hidden size threshold for selecting small vs default variant.\n   * When hiddenSize <= threshold, use small variant (single workgroup).\n   * @default 256\n   */\n  smallThreshold: number;\n}\n\nexport const DEFAULT_RMSNORM_THRESHOLDS: RmsnormThresholdsSchema = {\n  smallThreshold: 256,\n};\n\n// =============================================================================\n// RoPE Thresholds\n// =============================================================================\n\n/**\n * Default values for RoPE (Rotary Position Embedding) kernel.\n */\nexport interface RopeDefaultsSchema {\n  /**\n   * Default theta value for RoPE frequency computation.\n   * Most models use 10000.0; some (Gemma 3) use higher values.\n   * @default 10000.0\n   */\n  defaultTheta: number;\n\n  /**\n   * Default uniform buffer size in bytes for RoPE params.\n   * @default 32\n   */\n  uniformSize: number;\n}\n\nexport const DEFAULT_ROPE_DEFAULTS: RopeDefaultsSchema = {\n  defaultTheta: 10000.0,\n  uniformSize: 32,\n};\n\n// =============================================================================\n// Attention Thresholds\n// =============================================================================\n\n/**\n * Thresholds for attention kernel variant selection.\n */\nexport interface AttentionThresholdsSchema {\n  /**\n   * Maximum KV length before switching from chunked to streaming attention.\n   * Used by decode_chunked_f16kv variant.\n   * @default 2048\n   */\n  chunkedMaxKVLen: number;\n\n  /**\n   * Minimum head dimension for chunked attention kernel eligibility.\n   * Chunked kernels require headDim >= this value.\n   * @default 128\n   */\n  minHeadDimForChunked: number;\n\n  /**\n   * Head dimension thresholds for tier selection.\n   * tier3: headDim <= 64, tier2: headDim <= 128, tier1: headDim <= 256\n   */\n  tierHeadDimLimits: {\n    tier3: number;\n    tier2: number;\n    tier1: number;\n  };\n\n  /**\n   * Minimum shared memory requirements per tier (in bytes).\n   */\n  tierMinSharedMemory: {\n    tier3: number;\n    tier2: number;\n    tier1: number;\n  };\n}\n\nexport const DEFAULT_ATTENTION_THRESHOLDS: AttentionThresholdsSchema = {\n  chunkedMaxKVLen: 2048,\n  minHeadDimForChunked: 128,\n  tierHeadDimLimits: {\n    tier3: 64,\n    tier2: 128,\n    tier1: 256,\n  },\n  tierMinSharedMemory: {\n    tier3: 16384,  // 16KB for small models\n    tier2: 32768,  // 32KB for medium models\n    tier1: 65536,  // 64KB for large models\n  },\n};\n\n// =============================================================================\n// Fused Matmul Thresholds\n// =============================================================================\n\n/**\n * Thresholds for fused matmul+norm kernel variant selection.\n */\nexport interface FusedMatmulThresholdsSchema {\n  /**\n   * Maximum N dimension for \"medium\" (multi-column) fused variant.\n   * Beyond this, fall back to separate kernels or alternative dispatch.\n   * @default 4096\n   */\n  maxMediumN: number;\n\n  /**\n   * Columns per workgroup for multi-column dispatch.\n   * Each workgroup processes this many output columns.\n   * @default 4\n   */\n  colsPerWg: number;\n}\n\nexport const DEFAULT_FUSED_MATMUL_THRESHOLDS: FusedMatmulThresholdsSchema = {\n  maxMediumN: 4096,\n  colsPerWg: 4,\n};\n\n// =============================================================================\n// Cast Thresholds\n// =============================================================================\n\n/**\n * Configuration for cast kernel dispatch.\n */\nexport interface CastThresholdsSchema {\n  /**\n   * Maximum workgroups per dimension before falling back to 2D dispatch.\n   * @default 65535\n   */\n  maxWorkgroupsPerDim: number;\n}\n\nexport const DEFAULT_CAST_THRESHOLDS: CastThresholdsSchema = {\n  maxWorkgroupsPerDim: 65535,\n};\n\n// =============================================================================\n// Dtype Size Constants\n// =============================================================================\n\n/**\n * Bytes per element for each data type.\n */\nexport const DTYPE_SIZES: Record<string, number> = {\n  f32: 4,\n  f16: 2,\n  bf16: 2,\n  i32: 4,\n  u32: 4,\n  i16: 2,\n  u16: 2,\n  i8: 1,\n  u8: 1,\n};\n\n// =============================================================================\n// Combined Kernel Thresholds\n// =============================================================================\n\n/**\n * All kernel thresholds in a single configuration object.\n */\nexport interface KernelThresholdsConfigSchema {\n  matmul: MatmulThresholdsSchema;\n  rmsnorm: RmsnormThresholdsSchema;\n  rope: RopeDefaultsSchema;\n  attention: AttentionThresholdsSchema;\n  fusedMatmul: FusedMatmulThresholdsSchema;\n  cast: CastThresholdsSchema;\n}\n\nexport const DEFAULT_KERNEL_THRESHOLDS: KernelThresholdsConfigSchema = {\n  matmul: DEFAULT_MATMUL_THRESHOLDS,\n  rmsnorm: DEFAULT_RMSNORM_THRESHOLDS,\n  rope: DEFAULT_ROPE_DEFAULTS,\n  attention: DEFAULT_ATTENTION_THRESHOLDS,\n  fusedMatmul: DEFAULT_FUSED_MATMUL_THRESHOLDS,\n  cast: DEFAULT_CAST_THRESHOLDS,\n};\n\n// =============================================================================\n// Runtime Access\n// =============================================================================\n\n/**\n * Current kernel thresholds configuration.\n * Can be overridden at runtime for testing or optimization.\n */\nlet currentThresholds: KernelThresholdsConfigSchema = { ...DEFAULT_KERNEL_THRESHOLDS };\n\n/**\n * Get the current kernel thresholds configuration.\n */\nexport function getKernelThresholds(): KernelThresholdsConfigSchema {\n  return currentThresholds;\n}\n\n/**\n * Override kernel thresholds (merges with current config).\n */\nexport function setKernelThresholds(overrides: Partial<KernelThresholdsConfigSchema>): void {\n  currentThresholds = {\n    ...currentThresholds,\n    ...overrides,\n    matmul: { ...currentThresholds.matmul, ...overrides.matmul },\n    rmsnorm: { ...currentThresholds.rmsnorm, ...overrides.rmsnorm },\n    rope: { ...currentThresholds.rope, ...overrides.rope },\n    attention: { ...currentThresholds.attention, ...overrides.attention },\n    fusedMatmul: { ...currentThresholds.fusedMatmul, ...overrides.fusedMatmul },\n    cast: { ...currentThresholds.cast, ...overrides.cast },\n  };\n}\n\n/**\n * Reset kernel thresholds to defaults.\n */\nexport function resetKernelThresholds(): void {\n  currentThresholds = { ...DEFAULT_KERNEL_THRESHOLDS };\n}\n", "/**\n * Doppler Config Schema\n *\n * Master configuration schema that composes all runtime configs together.\n * This provides a single unified interface for configuring the entire\n * Doppler inference engine.\n *\n * Individual configs remain importable for subsystems that only need\n * their specific domain. This master config is for:\n * - Serializing/restoring full engine state\n * - Configuration management UIs\n * - Debugging/logging full config state\n *\n * @module config/schema/doppler\n */\n\nimport type { ResolvedConfigSchema } from './preset.schema.js';\nimport type { PlatformSchema } from './platform.schema.js';\nimport type { DistributionConfigSchema } from './distribution.schema.js';\nimport type { StorageFullConfigSchema } from './storage.schema.js';\nimport type { LoadingConfigSchema } from './loading.schema.js';\nimport type { InferenceDefaultsConfigSchema } from './inference-defaults.schema.js';\nimport type { KVCacheConfigSchema } from './kvcache.schema.js';\nimport type { MoERuntimeConfigSchema } from './moe.schema.js';\nimport type { BufferPoolConfigSchema } from './buffer-pool.schema.js';\nimport type { GpuCacheConfigSchema } from './gpu-cache.schema.js';\nimport type { TunerConfigSchema } from './tuner.schema.js';\nimport type { MemoryLimitsConfigSchema } from './memory-limits.schema.js';\nimport type { DebugConfigSchema } from './debug.schema.js';\nimport type { HotSwapConfigSchema } from './hotswap.schema.js';\nimport type { BridgeConfigSchema } from './bridge.schema.js';\n\nimport { DEFAULT_DISTRIBUTION_CONFIG } from './distribution.schema.js';\nimport { DEFAULT_STORAGE_FULL_CONFIG } from './storage.schema.js';\nimport { DEFAULT_LOADING_CONFIG } from './loading.schema.js';\nimport { DEFAULT_INFERENCE_DEFAULTS_CONFIG } from './inference-defaults.schema.js';\nimport { DEFAULT_KVCACHE_CONFIG } from './kvcache.schema.js';\nimport { DEFAULT_MOE_RUNTIME_CONFIG } from './moe.schema.js';\nimport { DEFAULT_BUFFER_POOL_CONFIG } from './buffer-pool.schema.js';\nimport { DEFAULT_GPU_CACHE_CONFIG } from './gpu-cache.schema.js';\nimport { DEFAULT_TUNER_CONFIG } from './tuner.schema.js';\nimport { DEFAULT_MEMORY_LIMITS_CONFIG } from './memory-limits.schema.js';\nimport { DEFAULT_DEBUG_CONFIG } from './debug.schema.js';\nimport { DEFAULT_HOTSWAP_CONFIG } from './hotswap.schema.js';\nimport { DEFAULT_BRIDGE_CONFIG } from './bridge.schema.js';\n\n// =============================================================================\n// Runtime Config (all non-model-specific settings)\n// =============================================================================\n\n/**\n * Runtime configuration schema.\n *\n * Contains all configurable settings that are independent of the model.\n * These settings control engine behavior regardless of which model is loaded.\n */\nexport interface RuntimeConfigSchema {\n  /** Network and download settings */\n  distribution: DistributionConfigSchema;\n\n  /** OPFS quota, VRAM estimation, alignment */\n  storage: StorageFullConfigSchema;\n\n  /** OPFS paths, shard cache, memory management */\n  loading: LoadingConfigSchema;\n\n  /** Batching, sampling, tokenizer defaults */\n  inference: InferenceDefaultsConfigSchema;\n\n  /** KV cache dtype and layout */\n  kvcache: KVCacheConfigSchema;\n\n  /** MoE routing and caching */\n  moe: MoERuntimeConfigSchema;\n\n  /** GPU buffer pool sizing */\n  bufferPool: BufferPoolConfigSchema;\n\n  /** Uniform cache limits */\n  gpuCache: GpuCacheConfigSchema;\n\n  /** Kernel autotuning settings */\n  tuner: TunerConfigSchema;\n\n  /** WASM heap and segment limits */\n  memory: MemoryLimitsConfigSchema;\n\n  /** Logging and tracing */\n  debug: DebugConfigSchema;\n\n  /** Hot-swap security policy */\n  hotSwap: HotSwapConfigSchema;\n\n  /** Native bridge settings (Tier 2) */\n  bridge: BridgeConfigSchema;\n}\n\n/** Default runtime configuration */\nexport const DEFAULT_RUNTIME_CONFIG: RuntimeConfigSchema = {\n  distribution: DEFAULT_DISTRIBUTION_CONFIG,\n  storage: DEFAULT_STORAGE_FULL_CONFIG,\n  loading: DEFAULT_LOADING_CONFIG,\n  inference: DEFAULT_INFERENCE_DEFAULTS_CONFIG,\n  kvcache: DEFAULT_KVCACHE_CONFIG,\n  moe: DEFAULT_MOE_RUNTIME_CONFIG,\n  bufferPool: DEFAULT_BUFFER_POOL_CONFIG,\n  gpuCache: DEFAULT_GPU_CACHE_CONFIG,\n  tuner: DEFAULT_TUNER_CONFIG,\n  memory: DEFAULT_MEMORY_LIMITS_CONFIG,\n  debug: DEFAULT_DEBUG_CONFIG,\n  hotSwap: DEFAULT_HOTSWAP_CONFIG,\n  bridge: DEFAULT_BRIDGE_CONFIG,\n};\n\n// =============================================================================\n// Master Doppler Config\n// =============================================================================\n\n/**\n * Master Doppler configuration schema.\n *\n * Combines model-specific configuration (resolved from preset + manifest)\n * with runtime configuration (engine settings) and platform overrides.\n *\n * Usage:\n * - `model`: Resolved config for the loaded model (architecture, layers, etc.)\n * - `runtime`: Engine settings (all domains from Phase 1-3 config extraction)\n * - `platform`: Optional platform-specific overrides (auto-detected if not set)\n *\n * @example\n * ```typescript\n * const config: DopplerConfigSchema = {\n *   model: resolvedModelConfig,\n *   runtime: {\n *     ...DEFAULT_RUNTIME_CONFIG,\n *     debug: { ...DEFAULT_DEBUG_CONFIG, logHistory: { maxEntries: 500 } },\n *   },\n * };\n * ```\n */\nexport interface DopplerConfigSchema {\n  /** Model-specific configuration (from preset + manifest) */\n  model?: ResolvedConfigSchema;\n\n  /** Runtime configuration (engine settings) */\n  runtime: RuntimeConfigSchema;\n\n  /** Platform-specific overrides (auto-detected if not set) */\n  platform?: Partial<PlatformSchema>;\n}\n\nexport interface DopplerConfigOverrides extends Partial<Omit<DopplerConfigSchema, 'runtime'>> {\n  runtime?: Partial<RuntimeConfigSchema>;\n}\n\n/** Default Doppler configuration (no model loaded) */\nexport const DEFAULT_DOPPLER_CONFIG: DopplerConfigSchema = {\n  model: undefined,\n  runtime: DEFAULT_RUNTIME_CONFIG,\n  platform: undefined,\n};\n\n// =============================================================================\n// Factory Function\n// =============================================================================\n\n/**\n * Create a Doppler configuration with optional overrides.\n *\n * Merges provided overrides with defaults, performing a deep merge\n * on nested objects.\n *\n * @param overrides - Partial configuration to merge with defaults\n * @returns Complete Doppler configuration\n *\n * @example\n * ```typescript\n * const config = createDopplerConfig({\n *   runtime: {\n *     debug: { logHistory: { maxEntries: 500 } },\n *   },\n * });\n * ```\n */\nexport function createDopplerConfig(\n  overrides?: DopplerConfigOverrides\n): DopplerConfigSchema {\n  if (!overrides) {\n    return { ...DEFAULT_DOPPLER_CONFIG };\n  }\n\n  return {\n    model: overrides.model ?? DEFAULT_DOPPLER_CONFIG.model,\n    runtime: overrides.runtime\n      ? mergeRuntimeConfig(DEFAULT_RUNTIME_CONFIG, overrides.runtime)\n      : { ...DEFAULT_RUNTIME_CONFIG },\n    platform: overrides.platform,\n  };\n}\n\n/**\n * Deep merge runtime config with overrides.\n *\n * Note: This merge may run twice in the CLI\u2192browser flow:\n * 1. CLI: config-loader.ts deepMerge() processes user config with defaults\n * 2. Browser: setRuntimeConfig() calls this when config arrives via URL\n *\n * This is intentional - the double merge is idempotent for fully-specified\n * configs (CLI passes complete merged config), but allows browser-only\n * overrides to also work correctly.\n *\n * Uses object spread for most fields. Missing nested objects fall back to base.\n */\nfunction mergeRuntimeConfig(\n  base: RuntimeConfigSchema,\n  overrides: Partial<RuntimeConfigSchema>\n): RuntimeConfigSchema {\n  return {\n    distribution: { ...base.distribution, ...overrides.distribution },\n    storage: overrides.storage\n      ? {\n          quota: { ...base.storage.quota, ...overrides.storage.quota },\n          vramEstimation: { ...base.storage.vramEstimation, ...overrides.storage.vramEstimation },\n          alignment: { ...base.storage.alignment, ...overrides.storage.alignment },\n        }\n      : { ...base.storage },\n    loading: overrides.loading\n      ? {\n          shardCache: { ...base.loading.shardCache, ...overrides.loading.shardCache },\n          memoryManagement: { ...base.loading.memoryManagement, ...overrides.loading.memoryManagement },\n          opfsPath: { ...base.loading.opfsPath, ...overrides.loading.opfsPath },\n          expertCache: { ...base.loading.expertCache, ...overrides.loading.expertCache },\n        }\n      : { ...base.loading },\n    inference: overrides.inference\n      ? {\n          batching: { ...base.inference.batching, ...overrides.inference.batching },\n          sampling: { ...base.inference.sampling, ...overrides.inference.sampling },\n          compute: { ...base.inference.compute, ...overrides.inference.compute },\n          tokenizer: { ...base.inference.tokenizer, ...overrides.inference.tokenizer },\n          largeWeights: { ...base.inference.largeWeights, ...overrides.inference.largeWeights },\n          prompt: overrides.inference.prompt ?? base.inference.prompt,\n          pipeline: overrides.inference.pipeline ?? base.inference.pipeline,\n          kernelPath: overrides.inference.kernelPath ?? base.inference.kernelPath,\n          chatTemplate: overrides.inference.chatTemplate\n            ? { ...base.inference.chatTemplate, ...overrides.inference.chatTemplate }\n            : base.inference.chatTemplate,\n          // Model-specific inference overrides (merged with manifest.inference at load time)\n          modelOverrides: overrides.inference.modelOverrides ?? base.inference.modelOverrides,\n        }\n      : { ...base.inference },\n    kvcache: { ...base.kvcache, ...overrides.kvcache },\n    moe: overrides.moe\n      ? {\n          routing: { ...base.moe.routing, ...overrides.moe.routing },\n          cache: { ...base.moe.cache, ...overrides.moe.cache },\n        }\n      : { ...base.moe },\n    bufferPool: overrides.bufferPool\n      ? {\n          bucket: { ...base.bufferPool.bucket, ...overrides.bufferPool.bucket },\n          limits: { ...base.bufferPool.limits, ...overrides.bufferPool.limits },\n          alignment: { ...base.bufferPool.alignment, ...overrides.bufferPool.alignment },\n        }\n      : { ...base.bufferPool },\n    gpuCache: { ...base.gpuCache, ...overrides.gpuCache },\n    tuner: { ...base.tuner, ...overrides.tuner },\n    memory: overrides.memory\n      ? {\n          heapTesting: { ...base.memory.heapTesting, ...overrides.memory.heapTesting },\n          segmentTesting: { ...base.memory.segmentTesting, ...overrides.memory.segmentTesting },\n          addressSpace: { ...base.memory.addressSpace, ...overrides.memory.addressSpace },\n          segmentAllocation: { ...base.memory.segmentAllocation, ...overrides.memory.segmentAllocation },\n        }\n      : { ...base.memory },\n    debug: overrides.debug\n      ? {\n          logOutput: { ...base.debug.logOutput, ...overrides.debug.logOutput },\n          logHistory: { ...base.debug.logHistory, ...overrides.debug.logHistory },\n          logLevel: { ...base.debug.logLevel, ...overrides.debug.logLevel },\n          trace: { ...base.debug.trace, ...overrides.debug.trace },\n          pipeline: { ...base.debug.pipeline, ...overrides.debug.pipeline },\n          probes: overrides.debug.probes ?? base.debug.probes,\n        }\n      : { ...base.debug },\n    hotSwap: overrides.hotSwap\n      ? {\n          ...base.hotSwap,\n          ...overrides.hotSwap,\n          trustedSigners: overrides.hotSwap.trustedSigners ?? base.hotSwap.trustedSigners,\n        }\n      : { ...base.hotSwap },\n    bridge: { ...base.bridge, ...overrides.bridge },\n  };\n}\n", "/**\n * Schema Index\n *\n * Re-exports all schema definitions for easy importing.\n *\n * Naming Convention:\n * - *Schema: Type definitions (interface structure)\n * - *Config: Runtime instances (validated values)\n * - *Raw: Unparsed input (from manifest/file)\n * - *Options: Function parameters\n *\n * @module config/schema\n */\n\n// =============================================================================\n// Manifest Schema\n// =============================================================================\nexport {\n  // Constants\n  RDRR_VERSION,\n  SHARD_SIZE,\n  TENSORS_FILENAME,\n\n  // Types\n  type HashAlgorithm,\n  type ModelType,\n  type ComponentGroupType,\n  type WeightLayout,\n  type QuantizationValue,\n\n  // Schemas\n  type ArchitectureSchema,\n  type ShardSchema,\n  type TensorSpanSchema,\n  type TensorSchema,\n  type TensorMapSchema,\n  type ComponentGroupSchema,\n  type MoEConfigSchema,\n  type TokenizerSchema,\n  type RuntimeOptimizationsSchema,\n  type QuantizationInfoSchema,\n  type ConversionInfoSchema,\n  type ManifestSchema,\n  type AdapterConfigSchema,\n  type ProvenanceSchema,\n\n  // Inference config (embedded in manifest)\n  type ManifestInferenceSchema,\n  type ManifestAttentionSchema,\n  type ManifestNormalizationSchema,\n  type ManifestFFNSchema,\n  type ManifestRoPESchema,\n  type ManifestOutputSchema,\n  type ManifestLayerPatternSchema,\n  DEFAULT_MANIFEST_INFERENCE,\n\n  // Helpers\n  isV1Manifest,\n  hasMoEConfig,\n  validateManifestInference,\n  hasInferenceConfig,\n} from './manifest.schema.js';\n\n// =============================================================================\n// Kernel Path Schema\n// =============================================================================\nexport {\n  type KernelPathSchema,\n  type KernelPathRef,\n  type KernelStepSchema,\n  type LayerKernelPathSchema,\n  type LayerOverrideSchema,\n  type BuiltinKernelPathId,\n  DEFAULT_ENTRY,\n  DEFAULT_INPUT,\n  DEFAULT_OUTPUT,\n} from './kernel-path.schema.js';\n\n// =============================================================================\n// Inference Schema\n// =============================================================================\nexport {\n  // RoPE\n  type RoPEConfigSchema,\n  DEFAULT_ROPE_CONFIG,\n\n  type AttentionSchema,\n  type NormalizationSchema,\n  type FFNSchema,\n  type LayerPipelineOp,\n  type LayerPipelineNormWeight,\n  type LayerPipelineStepSchema,\n  type LayerPipelineOverrideSchema,\n  type LayerPipelineSchema,\n  type OutputSchema,\n  type LayerType,\n  type GlobalLayerPattern,\n  type LayerPatternSchema,\n  type InferenceConfigSchema,\n  type SamplingSchema,\n  type TokenizerConfigSchema,\n  // Functions\n  computeGlobalLayers,\n} from './inference.schema.js';\n\n// =============================================================================\n// Conversion Schema\n// =============================================================================\nexport {\n  // Types\n  type QuantizationType,\n  type ConversionStageType,\n\n  // Constants\n  ConversionStage,\n\n  // Schemas\n  type TensorInfoSchema,\n  type ParsedModelSchema,\n  type RawModelConfigSchema,\n  type ConversionOptionsSchema,\n  type ConversionProgressSchema,\n  type WriterOptionsSchema,\n  type TensorLocationSchema,\n  type WriteResultSchema,\n  type ConversionIOSchema,\n} from './conversion.schema.js';\n\n// =============================================================================\n// Preset Schema\n// =============================================================================\nexport {\n  type PresetSchema,\n  type TensorPatternSchema,\n  type DetectionPatternSchema,\n  type ResolvedConfigSchema,\n} from './preset.schema.js';\n\n// =============================================================================\n// Loading Schema\n// =============================================================================\nexport {\n  // Types\n  type ShardCacheConfigSchema,\n  type MemoryManagementConfigSchema,\n  type OpfsPathConfigSchema,\n  type ExpertCacheConfigSchema,\n  type LoadingConfigSchema,\n\n  // Defaults\n  DEFAULT_SHARD_CACHE_CONFIG,\n  DEFAULT_MEMORY_MANAGEMENT_CONFIG,\n  DEFAULT_OPFS_PATH_CONFIG,\n  DEFAULT_EXPERT_CACHE_CONFIG,\n  DEFAULT_LOADING_CONFIG,\n} from './loading.schema.js';\n\n// =============================================================================\n// Kernel Registry Schema\n// =============================================================================\nexport {\n  // Types\n  type GpuFeature,\n  type BindingType,\n  type BindingSchema,\n  type UniformFieldType,\n  type UniformFieldSchema,\n  type UniformsSchema,\n  type WgslOverridesSchema,\n  type KernelVariantSchema,\n  type OperationSchema,\n  type KernelRegistrySchema,\n  type ResolvedKernelConfig,\n\n  // Functions\n  mergeBindings,\n  resolveKernelConfig,\n} from './kernel-registry.schema.js';\n\n// =============================================================================\n// Platform Schema\n// =============================================================================\nexport {\n  // Types\n  type PlatformDetectionSchema,\n  type KernelOperationOverrideSchema,\n  type KernelOverridesSchema,\n  type MemoryHintsSchema,\n  type PlatformSchema,\n  type RuntimeCapabilities,\n  type ResolvedPlatformConfig,\n  type PlatformRegistrySchema,\n} from './platform.schema.js';\n\n// =============================================================================\n// Storage Schema\n// =============================================================================\nexport {\n  // Types\n  type QuotaConfigSchema,\n  type VramEstimationConfigSchema,\n  type StorageAlignmentConfigSchema,\n  type StorageFullConfigSchema,\n\n  // Defaults\n  DEFAULT_QUOTA_CONFIG,\n  DEFAULT_VRAM_ESTIMATION_CONFIG,\n  DEFAULT_STORAGE_ALIGNMENT_CONFIG,\n  DEFAULT_STORAGE_FULL_CONFIG,\n} from './storage.schema.js';\n\n// =============================================================================\n// Inference Defaults Schema\n// =============================================================================\nexport {\n  // Types\n  type BatchingDefaultsSchema,\n  type ComputeDefaultsSchema,\n  type LargeWeightConfigSchema,\n  type SamplingDefaultsSchema,\n  type TokenizerDefaultsSchema,\n  type InferenceDefaultsConfigSchema,\n  type ModelInferenceOverrides,\n\n  // Defaults\n  DEFAULT_BATCHING_DEFAULTS,\n  DEFAULT_COMPUTE_DEFAULTS,\n  DEFAULT_LARGE_WEIGHT_CONFIG,\n  DEFAULT_SAMPLING_DEFAULTS,\n  DEFAULT_TOKENIZER_DEFAULTS,\n  DEFAULT_INFERENCE_DEFAULTS_CONFIG,\n} from './inference-defaults.schema.js';\n\n// =============================================================================\n// Distribution Schema\n// =============================================================================\nexport {\n  // Types\n  type DistributionConfigSchema,\n\n  // Defaults\n  DEFAULT_DISTRIBUTION_CONFIG,\n} from './distribution.schema.js';\n\n// =============================================================================\n// MoE Runtime Schema\n// =============================================================================\nexport {\n  // Types\n  type RouterDtype,\n  type MoERoutingConfigSchema,\n  type MoECacheConfigSchema,\n  type MoERuntimeConfigSchema,\n\n  // Defaults\n  DEFAULT_MOE_ROUTING_CONFIG,\n  DEFAULT_MOE_CACHE_CONFIG,\n  DEFAULT_MOE_RUNTIME_CONFIG,\n} from './moe.schema.js';\n\n// =============================================================================\n// KV Cache Schema\n// =============================================================================\nexport {\n  // Types\n  type KVDtype,\n  type KVLayout,\n  type KVCacheConfigSchema,\n\n  // Defaults\n  DEFAULT_KVCACHE_CONFIG,\n} from './kvcache.schema.js';\n\n// =============================================================================\n// GPU Cache Schema\n// =============================================================================\nexport {\n  // Types\n  type GpuCacheConfigSchema,\n\n  // Defaults\n  DEFAULT_GPU_CACHE_CONFIG,\n} from './gpu-cache.schema.js';\n\n// =============================================================================\n// Tuner Schema\n// =============================================================================\nexport {\n  // Types\n  type TunerConfigSchema,\n\n  // Defaults\n  DEFAULT_TUNER_CONFIG,\n} from './tuner.schema.js';\n\n// =============================================================================\n// Debug Schema\n// =============================================================================\nexport {\n  // Types\n  type LogOutputConfigSchema,\n  type LogHistoryConfigSchema,\n  type LogLevelConfigSchema,\n  type LogLevel,\n  type TraceCategory,\n  type TraceConfigSchema,\n  type PipelineDebugCategory,\n  type PipelineDebugConfigSchema,\n  type ProbeStage,\n  type ProbeConfigSchema,\n  type DebugConfigSchema,\n\n  // Constants\n  LOG_LEVELS,\n\n  // Defaults\n  DEFAULT_LOG_OUTPUT_CONFIG,\n  DEFAULT_LOG_HISTORY_CONFIG,\n  DEFAULT_LOG_LEVEL_CONFIG,\n  DEFAULT_TRACE_CONFIG,\n  DEFAULT_PIPELINE_DEBUG_CONFIG,\n  DEFAULT_DEBUG_CONFIG,\n} from './debug.schema.js';\n\n// =============================================================================\n// Hot-Swap Schema\n// =============================================================================\nexport {\n  // Types\n  type HotSwapSignerSchema,\n  type HotSwapConfigSchema,\n\n  // Defaults\n  DEFAULT_HOTSWAP_CONFIG,\n} from './hotswap.schema.js';\n\n// =============================================================================\n// Buffer Pool Schema\n// =============================================================================\nexport {\n  // Types\n  type BufferPoolBucketConfigSchema,\n  type BufferPoolLimitsConfigSchema,\n  type BufferPoolAlignmentConfigSchema,\n  type BufferPoolConfigSchema,\n\n  // Defaults\n  DEFAULT_BUFFER_POOL_BUCKET_CONFIG,\n  DEFAULT_BUFFER_POOL_LIMITS_CONFIG,\n  DEFAULT_BUFFER_POOL_ALIGNMENT_CONFIG,\n  DEFAULT_BUFFER_POOL_CONFIG,\n} from './buffer-pool.schema.js';\n\n// =============================================================================\n// Memory Limits Schema\n// =============================================================================\nexport {\n  // Types\n  type HeapTestingConfigSchema,\n  type SegmentTestingConfigSchema,\n  type AddressSpaceConfigSchema,\n  type SegmentAllocationConfigSchema,\n  type MemoryLimitsConfigSchema,\n\n  // Defaults\n  DEFAULT_HEAP_TESTING_CONFIG,\n  DEFAULT_SEGMENT_TESTING_CONFIG,\n  DEFAULT_ADDRESS_SPACE_CONFIG,\n  DEFAULT_SEGMENT_ALLOCATION_CONFIG,\n  DEFAULT_MEMORY_LIMITS_CONFIG,\n} from './memory-limits.schema.js';\n\n// =============================================================================\n// Bridge Schema\n// =============================================================================\nexport {\n  // Types\n  type BridgeConfigSchema,\n\n  // Defaults\n  DEFAULT_BRIDGE_CONFIG,\n} from './bridge.schema.js';\n\n// =============================================================================\n// Quantization Defaults Schema\n// =============================================================================\nexport {\n  // Types\n  type WeightQuantType,\n  type EmbeddingQuantType,\n  type QuantizationDefaultsSchema,\n\n  // Defaults\n  DEFAULT_QUANTIZATION_DEFAULTS,\n} from './quantization-defaults.schema.js';\n\n// =============================================================================\n// Kernel Thresholds Schema\n// =============================================================================\nexport {\n  // Types\n  type MatmulThresholdsSchema,\n  type RmsnormThresholdsSchema,\n  type RopeDefaultsSchema,\n  type AttentionThresholdsSchema,\n  type CastThresholdsSchema,\n  type KernelThresholdsConfigSchema,\n\n  // Constants\n  DTYPE_SIZES,\n\n  // Defaults\n  DEFAULT_MATMUL_THRESHOLDS,\n  DEFAULT_RMSNORM_THRESHOLDS,\n  DEFAULT_ROPE_DEFAULTS,\n  DEFAULT_ATTENTION_THRESHOLDS,\n  DEFAULT_CAST_THRESHOLDS,\n  DEFAULT_KERNEL_THRESHOLDS,\n\n  // Functions\n  getKernelThresholds,\n  setKernelThresholds,\n  resetKernelThresholds,\n} from './kernel-thresholds.schema.js';\n\n// =============================================================================\n// Doppler Master Config\n// =============================================================================\nexport {\n  // Types\n  type RuntimeConfigSchema,\n  type DopplerConfigSchema,\n\n  // Defaults\n  DEFAULT_RUNTIME_CONFIG,\n  DEFAULT_DOPPLER_CONFIG,\n\n  // Factory\n  createDopplerConfig,\n} from './doppler.schema.js';\n", "/**\n * Runtime Config Registry\n *\n * Stores the active RuntimeConfigSchema for the current session.\n * Call setRuntimeConfig() early (before pipeline/loader init) to apply overrides.\n *\n * @module config/runtime\n */\n\nimport type { RuntimeConfigSchema } from './schema/index.js';\nimport { createDopplerConfig, DEFAULT_BATCHING_DEFAULTS } from './schema/index.js';\nimport { log } from '../debug/index.js';\n\nlet runtimeConfig: RuntimeConfigSchema = createDopplerConfig().runtime;\n\n/**\n * Get the active runtime config (merged with defaults).\n */\nexport function getRuntimeConfig(): RuntimeConfigSchema {\n  return runtimeConfig;\n}\n\n/**\n * Set the active runtime config.\n * Accepts partial overrides and merges with defaults.\n */\nexport function setRuntimeConfig(\n  overrides?: Partial<RuntimeConfigSchema> | RuntimeConfigSchema\n): RuntimeConfigSchema {\n  if (!overrides) {\n    runtimeConfig = createDopplerConfig().runtime;\n    return runtimeConfig;\n  }\n\n  const merged = createDopplerConfig({ runtime: overrides }).runtime;\n\n  // Migrate deprecated sampling.maxTokens to batching.maxTokens\n  const sampling = merged.inference.sampling as typeof merged.inference.sampling & { maxTokens?: number };\n  if (sampling.maxTokens !== undefined) {\n    log.warn('Config', 'inference.sampling.maxTokens is deprecated, use inference.batching.maxTokens instead');\n    // Only migrate if batching.maxTokens is still at default (user didn't explicitly set it)\n    if (merged.inference.batching.maxTokens === DEFAULT_BATCHING_DEFAULTS.maxTokens) {\n      merged.inference.batching.maxTokens = sampling.maxTokens;\n      log.debug('Config', `Migrated sampling.maxTokens=${sampling.maxTokens} to batching.maxTokens`);\n    }\n  }\n\n  runtimeConfig = merged;\n  return runtimeConfig;\n}\n\n/**\n * Reset runtime config to defaults.\n */\nexport function resetRuntimeConfig(): RuntimeConfigSchema {\n  runtimeConfig = createDopplerConfig().runtime;\n  return runtimeConfig;\n}\n", "/**\n * DOPPLER Debug Module - Unified Logging and Tracing\n *\n * Single source of truth for all logging and debugging.\n *\n * ## Log Levels (verbosity - how much to show)\n *   silent  - nothing\n *   error   - errors only\n *   warn    - errors + warnings\n *   info    - normal operation (default)\n *   verbose - detailed info\n *   debug   - everything\n *\n * ## Trace Categories (what to show when tracing)\n *   loader  - model loading (shards, weights)\n *   kernels - GPU kernel execution\n *   logits  - logit computation\n *   embed   - embedding layer\n *   attn    - attention computation\n *   ffn     - feed-forward network\n *   kv      - KV cache operations\n *   sample  - token sampling\n *   buffers - GPU buffer stats (expensive!)\n *   perf    - timing info\n *   all     - everything\n *\n * ## Usage\n *   import { log, trace, setLogLevel, setTrace } from '../debug/index.js';\n *\n *   // Log levels (verbosity)\n *   log.info('Pipeline', 'Model loaded');\n *   log.verbose('Loader', 'Shard 0 from OPFS');\n *   log.debug('Attention', `heads=${numHeads}`);\n *\n *   // Trace categories (only logs if category enabled)\n *   trace.loader('Loading shard 0 from OPFS');\n *   trace.kernels('matmul M=1 K=1152 N=1024');\n *   trace.logits({ min: -2.3, max: 15.7 });\n *\n *   // Configure\n *   setLogLevel('verbose');\n *   setTrace('kernels,logits');       // enable specific\n *   setTrace('all,-buffers');         // all except buffers\n *   setTrace(false);                  // disable all\n *\n * ## CLI Flags \u2192 URL Params (auto-mapped)\n *   --verbose, -v     \u2192  ?log=verbose\n *   --debug           \u2192  ?log=debug\n *   --quiet, -q       \u2192  ?log=silent\n *   --trace           \u2192  ?trace=all\n *   --trace kernels   \u2192  ?trace=kernels\n *   --trace all,-buf  \u2192  ?trace=all,-buffers\n *   --layers 0,5      \u2192  ?layers=0,5\n *   --break           \u2192  ?break=1\n *\n * @module debug\n */\n\nimport type { DebugConfigSchema } from '../config/schema/debug.schema.js';\nimport { getRuntimeConfig } from '../config/runtime.js';\n\n// ============================================================================\n// Completion Signals\n// ============================================================================\n\n/**\n * Standard completion signal prefixes for CLI/automation detection.\n *\n * Usage:\n *   console.log(`${SIGNALS.DONE} ${JSON.stringify({status: 'success', elapsed: 1234})}`);\n *   console.log(`${SIGNALS.RESULT} ${JSON.stringify(benchmarkData)}`);\n *   console.log(`${SIGNALS.ERROR} ${JSON.stringify({error: 'message'})}`);\n *\n * Detection (CLI/Puppeteer):\n *   if (text.startsWith('[DOPPLER:DONE]')) { ... }\n */\nexport const SIGNALS = {\n  /** Task completed (success or error) - always emitted at end */\n  DONE: '[DOPPLER:DONE]',\n  /** Full result payload (JSON) - emitted before DONE for data extraction */\n  RESULT: '[DOPPLER:RESULT]',\n  /** Error occurred - can be emitted before DONE */\n  ERROR: '[DOPPLER:ERROR]',\n  /** Progress update (optional) */\n  PROGRESS: '[DOPPLER:PROGRESS]',\n} as const;\n\nexport type SignalType = keyof typeof SIGNALS;\n\n/**\n * Completion payload for DONE signal.\n */\nexport interface DonePayload {\n  status: 'success' | 'error';\n  elapsed: number;\n  tokens?: number;\n  tokensPerSecond?: number;\n  error?: string;\n}\n\n/**\n * Emit a completion signal to console.\n * This is the standard way to signal task completion for CLI detection.\n */\nexport function signalDone(payload: DonePayload): void {\n  console.log(`${SIGNALS.DONE} ${JSON.stringify(payload)}`);\n}\n\n/**\n * Emit a result signal with full data payload.\n */\nexport function signalResult(data: Record<string, unknown>): void {\n  console.log(`${SIGNALS.RESULT} ${JSON.stringify(data)}`);\n}\n\n/**\n * Emit an error signal.\n */\nexport function signalError(error: string, details?: Record<string, unknown>): void {\n  console.log(`${SIGNALS.ERROR} ${JSON.stringify({ error, ...details })}`);\n}\n\n/**\n * Emit a progress signal.\n */\nexport function signalProgress(percent: number, message?: string): void {\n  console.log(`${SIGNALS.PROGRESS} ${JSON.stringify({ percent, message })}`);\n}\n\n// ============================================================================\n// Types and Interfaces\n// ============================================================================\n\n/**\n * Log level values (higher = less verbose)\n */\nexport const LOG_LEVELS = {\n  DEBUG: 0,\n  VERBOSE: 1,\n  INFO: 2,\n  WARN: 3,\n  ERROR: 4,\n  SILENT: 5,\n} as const;\n\n/**\n * Trace categories\n */\nexport const TRACE_CATEGORIES = [\n  'loader',   // Model loading (shards, weights)\n  'kernels',  // GPU kernel execution\n  'logits',   // Logit computation\n  'embed',    // Embedding layer\n  'attn',     // Attention\n  'ffn',      // Feed-forward\n  'kv',       // KV cache\n  'sample',   // Token sampling\n  'buffers',  // GPU buffer stats (expensive!)\n  'perf',     // Timing\n] as const;\n\nexport type TraceCategory = (typeof TRACE_CATEGORIES)[number];\n\nexport type LogLevel = keyof typeof LOG_LEVELS;\nexport type LogLevelValue = (typeof LOG_LEVELS)[LogLevel];\n\n/**\n * Log entry for history\n */\nexport interface LogEntry {\n  time: number;\n  perfTime: number;\n  level: string;\n  module: string;\n  message: string;\n  data?: unknown;\n}\n\n/**\n * Tensor statistics\n */\nexport interface TensorStats {\n  label: string;\n  shape: number[];\n  size: number;\n  isGPU: boolean;\n  min: number;\n  max: number;\n  mean: number;\n  std: number;\n  nanCount: number;\n  infCount: number;\n  zeroCount: number;\n  zeroPercent: string;\n  first: string[];\n  last: string[];\n}\n\n/**\n * Tensor comparison result\n */\nexport interface TensorCompareResult {\n  label: string;\n  match: boolean;\n  maxDiff: number;\n  maxDiffIdx: number;\n  avgDiff: number;\n  mismatchCount: number;\n  mismatchPercent: string;\n  error?: string;\n}\n\n/**\n * Tensor health check result\n */\nexport interface TensorHealthResult {\n  label: string;\n  healthy: boolean;\n  issues: string[];\n}\n\n/**\n * Tensor inspect options\n */\nexport interface TensorInspectOptions {\n  shape?: number[];\n  maxPrint?: number;\n  checkNaN?: boolean;\n}\n\n/**\n * Log history filter\n */\nexport interface LogHistoryFilter {\n  level?: string;\n  module?: string;\n  last?: number;\n}\n\n/**\n * Debug snapshot\n */\nexport interface DebugSnapshot {\n  timestamp: string;\n  logLevel: string | undefined;\n  traceCategories: TraceCategory[];\n  enabledModules: string[];\n  disabledModules: string[];\n  recentLogs: Array<{\n    time: string;\n    level: string;\n    module: string;\n    message: string;\n  }>;\n  errorCount: number;\n  warnCount: number;\n}\n\n// ============================================================================\n// Global State\n// ============================================================================\n\nlet currentLogLevel: LogLevelValue = LOG_LEVELS.INFO;\nlet enabledModules = new Set<string>();\nlet disabledModules = new Set<string>();\nlet logHistory: LogEntry[] = [];\n\n// GPU device reference for tensor inspection\nlet gpuDevice: GPUDevice | null = null;\n\n// Trace categories state\nlet enabledTraceCategories = new Set<TraceCategory>();\nlet traceLayerFilter: number[] = [];  // Empty = all layers\nlet traceDecodeStep = 0;\nlet traceMaxDecodeSteps = 0;  // 0 = unlimited\nlet traceBreakOnAnomaly = false;\n\n// ============================================================================\n// Configuration Functions\n// ============================================================================\n\n/**\n * Set the global log level.\n */\nexport function setLogLevel(level: string): void {\n  const levelMap: Record<string, LogLevelValue> = {\n    debug: LOG_LEVELS.DEBUG,\n    verbose: LOG_LEVELS.VERBOSE,\n    info: LOG_LEVELS.INFO,\n    warn: LOG_LEVELS.WARN,\n    error: LOG_LEVELS.ERROR,\n    silent: LOG_LEVELS.SILENT,\n  };\n  currentLogLevel = levelMap[level.toLowerCase()] ?? LOG_LEVELS.INFO;\n  console.log(`[Doppler] Log level set to: ${level.toUpperCase()}`);\n}\n\n/**\n * Get current log level name.\n */\nexport function getLogLevel(): string {\n  for (const [name, value] of Object.entries(LOG_LEVELS)) {\n    if (value === currentLogLevel) return name.toLowerCase();\n  }\n  return 'info';\n}\n\n/**\n * Set trace categories.\n *\n * @param categories - Comma-separated categories, 'all', false to disable, or array\n *   Examples:\n *   - 'kernels,logits' - enable kernels and logits\n *   - 'all' - enable all categories\n *   - 'all,-buffers' - all except buffers\n *   - false - disable all tracing\n *   - ['kernels', 'logits'] - array form\n */\nexport function setTrace(\n  categories: string | TraceCategory[] | false,\n  options?: { layers?: number[]; maxDecodeSteps?: number; breakOnAnomaly?: boolean }\n): void {\n  // Handle false = disable all\n  if (categories === false) {\n    enabledTraceCategories.clear();\n    console.log('[Doppler] Trace disabled');\n    return;\n  }\n\n  // Parse string into array\n  const catArray = typeof categories === 'string'\n    ? categories.split(',').map(s => s.trim())\n    : categories;\n\n  // Clear and rebuild\n  enabledTraceCategories.clear();\n\n  // Check for 'all' first\n  const hasAll = catArray.includes('all');\n  if (hasAll) {\n    for (const cat of TRACE_CATEGORIES) {\n      enabledTraceCategories.add(cat);\n    }\n  }\n\n  // Add inclusions and handle exclusions (prefixed with -)\n  for (const cat of catArray) {\n    if (cat === 'all') continue;\n\n    if (cat.startsWith('-')) {\n      const exclude = cat.slice(1) as TraceCategory;\n      enabledTraceCategories.delete(exclude);\n    } else if (TRACE_CATEGORIES.includes(cat as TraceCategory)) {\n      enabledTraceCategories.add(cat as TraceCategory);\n    }\n  }\n\n  // Apply options\n  if (options?.layers) {\n    traceLayerFilter = options.layers;\n  }\n  if (options?.maxDecodeSteps !== undefined) {\n    traceMaxDecodeSteps = options.maxDecodeSteps;\n  }\n  if (options?.breakOnAnomaly !== undefined) {\n    traceBreakOnAnomaly = options.breakOnAnomaly;\n  }\n\n  const enabled = [...enabledTraceCategories].join(',') || 'none';\n  console.log(`[Doppler] Trace categories: ${enabled}`);\n}\n\n/**\n * Apply debug config defaults unless URL params already set them.\n */\nexport function applyDebugConfig(\n  config: DebugConfigSchema,\n  options: { respectUrlParams?: boolean } = {}\n): void {\n  const respectUrlParams = options.respectUrlParams !== false;\n  let hasLogParam = false;\n  let hasTraceParam = false;\n\n  if (respectUrlParams && typeof window !== 'undefined') {\n    const params = new URLSearchParams(window.location.search);\n    hasLogParam = params.has('log');\n    hasTraceParam = params.has('trace');\n  }\n\n  if (!hasLogParam && config.logLevel?.defaultLogLevel) {\n    const desired = config.logLevel.defaultLogLevel;\n    if (desired && desired !== getLogLevel()) {\n      setLogLevel(desired);\n    }\n  }\n\n  if (!hasTraceParam) {\n    if (config.trace?.enabled) {\n      const categories = config.trace.categories?.length\n        ? config.trace.categories.join(',')\n        : 'all';\n      setTrace(categories, {\n        layers: config.trace.layers ?? undefined,\n        maxDecodeSteps: config.trace.maxDecodeSteps || undefined,\n      });\n    } else if (getTrace().length > 0) {\n      setTrace(false);\n    }\n  }\n}\n\n/**\n * Get enabled trace categories.\n */\nexport function getTrace(): TraceCategory[] {\n  return [...enabledTraceCategories];\n}\n\n/**\n * Check if a trace category is enabled.\n */\nexport function isTraceEnabled(category: TraceCategory, layerIdx?: number): boolean {\n  if (!enabledTraceCategories.has(category)) return false;\n\n  // Check layer filter\n  if (layerIdx !== undefined && traceLayerFilter.length > 0) {\n    if (!traceLayerFilter.includes(layerIdx)) return false;\n  }\n\n  // Check decode step limit\n  if (traceMaxDecodeSteps > 0 && traceDecodeStep > traceMaxDecodeSteps) {\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Increment decode step counter (call after each decode step).\n */\nexport function incrementDecodeStep(): number {\n  return ++traceDecodeStep;\n}\n\n/**\n * Reset decode step counter (call at start of generation).\n */\nexport function resetDecodeStep(): void {\n  traceDecodeStep = 0;\n}\n\n/**\n * Get current decode step.\n */\nexport function getDecodeStep(): number {\n  return traceDecodeStep;\n}\n\n/**\n * Check if we should break on anomaly.\n */\nexport function shouldBreakOnAnomaly(): boolean {\n  return traceBreakOnAnomaly;\n}\n\n// Benchmark mode state\nlet benchmarkMode = false;\nconst originalConsoleLog = console.log;\nconst originalConsoleDebug = console.debug;\nconst originalConsoleInfo = console.info;\n\n/**\n * Enable benchmark mode - silences all console.log/debug/info calls.\n */\nexport function setBenchmarkMode(enabled: boolean): void {\n  benchmarkMode = enabled;\n  if (enabled) {\n    const noop = () => {};\n    console.log = noop;\n    console.debug = noop;\n    console.info = noop;\n    originalConsoleLog('[Doppler] Benchmark mode enabled - logging silenced');\n  } else {\n    console.log = originalConsoleLog;\n    console.debug = originalConsoleDebug;\n    console.info = originalConsoleInfo;\n    console.log('[Doppler] Benchmark mode disabled - logging restored');\n  }\n}\n\n/**\n * Check if benchmark mode is active.\n */\nexport function isBenchmarkMode(): boolean {\n  return benchmarkMode;\n}\n\n/**\n * Enable logging for specific modules only.\n */\nexport function enableModules(...modules: string[]): void {\n  enabledModules = new Set(modules.map((m) => m.toLowerCase()));\n  console.log(`[Doppler] Enabled modules: ${modules.join(', ')}`);\n}\n\n/**\n * Disable logging for specific modules.\n */\nexport function disableModules(...modules: string[]): void {\n  for (const m of modules) {\n    disabledModules.add(m.toLowerCase());\n  }\n  console.log(`[Doppler] Disabled modules: ${modules.join(', ')}`);\n}\n\n/**\n * Reset module filters.\n */\nexport function resetModuleFilters(): void {\n  enabledModules.clear();\n  disabledModules.clear();\n}\n\n/**\n * Set GPU device for tensor inspection.\n */\nexport function setGPUDevice(device: GPUDevice): void {\n  gpuDevice = device;\n}\n\n// ============================================================================\n// URL Parameter Auto-Detection\n// ============================================================================\n\n/**\n * Initialize logging and tracing from URL parameters.\n * Called automatically in browser environment.\n *\n * Supported params:\n *   ?log=verbose          - Set log level\n *   ?trace=kernels,logits - Enable specific trace categories\n *   ?trace=all,-buffers   - All categories except buffers\n *   ?layers=0,5           - Filter to specific layers\n *   ?break=1              - Break on anomaly (NaN/explosion)\n */\nexport function initFromUrlParams(): void {\n  if (typeof window === 'undefined') return;\n\n  const params = new URLSearchParams(window.location.search);\n\n  // Log level\n  const logLevel = params.get('log');\n  if (logLevel) {\n    setLogLevel(logLevel);\n  }\n\n  // Trace categories\n  const traceParam = params.get('trace');\n  if (traceParam) {\n    const layers = params.get('layers')?.split(',').map(Number).filter(n => !isNaN(n));\n    const breakOn = params.get('break') === '1';\n    setTrace(traceParam, { layers, breakOnAnomaly: breakOn });\n  }\n\n  // Debug mode (legacy param support)\n  const debugParam = params.get('debug');\n  if (debugParam === '1' && !traceParam) {\n    setTrace('all');\n    setLogLevel('verbose');\n  }\n}\n\n// ============================================================================\n// Internal Helpers\n// ============================================================================\n\n/**\n * Check if logging is enabled for a module at a level.\n */\nfunction shouldLog(module: string, level: LogLevelValue): boolean {\n  if (level < currentLogLevel) return false;\n\n  const moduleLower = module.toLowerCase();\n\n  if (enabledModules.size > 0 && !enabledModules.has(moduleLower)) {\n    return false;\n  }\n\n  if (disabledModules.has(moduleLower)) {\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Format a log message with timestamp and module tag.\n */\nfunction formatMessage(module: string, message: string): string {\n  const timestamp = performance.now().toFixed(1);\n  return `[${timestamp}ms][${module}] ${message}`;\n}\n\n/**\n * Format a trace message with category tag.\n */\nfunction formatTraceMessage(category: TraceCategory, message: string, layerIdx?: number): string {\n  const timestamp = performance.now().toFixed(1);\n  const layerTag = layerIdx !== undefined ? `L${layerIdx}:` : '';\n  return `[${timestamp}ms][TRACE:${category}] ${layerTag}${message}`;\n}\n\n/**\n * Store log in history for later retrieval.\n */\nfunction storeLog(level: string, module: string, message: string, data?: unknown): void {\n  logHistory.push({\n    time: Date.now(),\n    perfTime: performance.now(),\n    level,\n    module,\n    message,\n    data,\n  });\n\n  const maxHistory = getRuntimeConfig().debug.logHistory.maxLogHistoryEntries;\n  if (logHistory.length > maxHistory) {\n    logHistory.shift();\n  }\n}\n\n/**\n * F16 to F32 conversion helper.\n */\nfunction f16ToF32(h: number): number {\n  const sign = (h >> 15) & 0x1;\n  const exp = (h >> 10) & 0x1f;\n  const mant = h & 0x3ff;\n\n  if (exp === 0) {\n    return (sign ? -1 : 1) * Math.pow(2, -14) * (mant / 1024);\n  } else if (exp === 31) {\n    return mant === 0 ? (sign ? -Infinity : Infinity) : NaN;\n  }\n\n  return (sign ? -1 : 1) * Math.pow(2, exp - 15) * (1 + mant / 1024);\n}\n\n// ============================================================================\n// Logging Interface\n// ============================================================================\n\n/**\n * Main logging interface.\n */\nexport const log = {\n  /**\n   * Debug level logging (most verbose).\n   */\n  debug(module: string, message: string, data?: unknown): void {\n    if (!shouldLog(module, LOG_LEVELS.DEBUG)) return;\n    const formatted = formatMessage(module, message);\n    storeLog('DEBUG', module, message, data);\n    if (data !== undefined) {\n      console.debug(formatted, data);\n    } else {\n      console.debug(formatted);\n    }\n  },\n\n  /**\n   * Verbose level logging (detailed operational info).\n   */\n  verbose(module: string, message: string, data?: unknown): void {\n    if (!shouldLog(module, LOG_LEVELS.VERBOSE)) return;\n    const formatted = formatMessage(module, message);\n    storeLog('VERBOSE', module, message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Info level logging (normal operations).\n   */\n  info(module: string, message: string, data?: unknown): void {\n    if (!shouldLog(module, LOG_LEVELS.INFO)) return;\n    const formatted = formatMessage(module, message);\n    storeLog('INFO', module, message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Warning level logging.\n   */\n  warn(module: string, message: string, data?: unknown): void {\n    if (!shouldLog(module, LOG_LEVELS.WARN)) return;\n    const formatted = formatMessage(module, message);\n    storeLog('WARN', module, message, data);\n    if (data !== undefined) {\n      console.warn(formatted, data);\n    } else {\n      console.warn(formatted);\n    }\n  },\n\n  /**\n   * Error level logging.\n   */\n  error(module: string, message: string, data?: unknown): void {\n    if (!shouldLog(module, LOG_LEVELS.ERROR)) return;\n    const formatted = formatMessage(module, message);\n    storeLog('ERROR', module, message, data);\n    if (data !== undefined) {\n      console.error(formatted, data);\n    } else {\n      console.error(formatted);\n    }\n  },\n\n  /**\n   * Always log regardless of level (for critical messages).\n   */\n  always(module: string, message: string, data?: unknown): void {\n    const formatted = formatMessage(module, message);\n    storeLog('ALWAYS', module, message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n};\n\n// ============================================================================\n// Trace Interface\n// ============================================================================\n\n/**\n * Trace logging interface - only logs if category is enabled.\n */\nexport const trace = {\n  /**\n   * Trace model loading operations.\n   */\n  loader(message: string, data?: unknown): void {\n    if (!isTraceEnabled('loader')) return;\n    const formatted = formatTraceMessage('loader', message);\n    storeLog('TRACE:loader', 'Loader', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace kernel execution.\n   */\n  kernels(message: string, data?: unknown): void {\n    if (!isTraceEnabled('kernels')) return;\n    const formatted = formatTraceMessage('kernels', message);\n    storeLog('TRACE:kernels', 'Kernels', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace logit computation.\n   */\n  logits(message: string, data?: unknown): void {\n    if (!isTraceEnabled('logits')) return;\n    const formatted = formatTraceMessage('logits', message);\n    storeLog('TRACE:logits', 'Logits', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace embedding layer.\n   */\n  embed(message: string, data?: unknown): void {\n    if (!isTraceEnabled('embed')) return;\n    const formatted = formatTraceMessage('embed', message);\n    storeLog('TRACE:embed', 'Embed', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace attention computation.\n   */\n  attn(layerIdx: number, message: string, data?: unknown): void {\n    if (!isTraceEnabled('attn', layerIdx)) return;\n    const formatted = formatTraceMessage('attn', message, layerIdx);\n    storeLog('TRACE:attn', `Attn:L${layerIdx}`, message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace feed-forward network.\n   */\n  ffn(layerIdx: number, message: string, data?: unknown): void {\n    if (!isTraceEnabled('ffn', layerIdx)) return;\n    const formatted = formatTraceMessage('ffn', message, layerIdx);\n    storeLog('TRACE:ffn', `FFN:L${layerIdx}`, message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace KV cache operations.\n   */\n  kv(layerIdx: number, message: string, data?: unknown): void {\n    if (!isTraceEnabled('kv', layerIdx)) return;\n    const formatted = formatTraceMessage('kv', message, layerIdx);\n    storeLog('TRACE:kv', `KV:L${layerIdx}`, message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace token sampling.\n   */\n  sample(message: string, data?: unknown): void {\n    if (!isTraceEnabled('sample')) return;\n    const formatted = formatTraceMessage('sample', message);\n    storeLog('TRACE:sample', 'Sample', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace buffer stats (expensive - requires GPU readback).\n   */\n  buffers(message: string, data?: unknown): void {\n    if (!isTraceEnabled('buffers')) return;\n    const formatted = formatTraceMessage('buffers', message);\n    storeLog('TRACE:buffers', 'Buffers', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n\n  /**\n   * Trace performance timing.\n   */\n  perf(message: string, data?: unknown): void {\n    if (!isTraceEnabled('perf')) return;\n    const formatted = formatTraceMessage('perf', message);\n    storeLog('TRACE:perf', 'Perf', message, data);\n    if (data !== undefined) {\n      console.log(formatted, data);\n    } else {\n      console.log(formatted);\n    }\n  },\n};\n\n// ============================================================================\n// Tensor Inspection Interface\n// ============================================================================\n\n/**\n * Tensor inspection utilities.\n */\nexport const tensor = {\n  /**\n   * Inspect a GPU or CPU tensor and log statistics.\n   */\n  async inspect(\n    buffer: GPUBuffer | Float32Array | Float64Array | Uint16Array,\n    label: string,\n    options: TensorInspectOptions = {}\n  ): Promise<TensorStats | null> {\n    const { shape = [], maxPrint = 8, checkNaN = true } = options;\n\n    let data: Float32Array;\n    let isGPU = false;\n\n    // Handle GPU buffers\n    if (buffer && typeof (buffer as GPUBuffer).mapAsync === 'function') {\n      const gpuBuffer = buffer as GPUBuffer;\n      await gpuBuffer.mapAsync(GPUMapMode.READ);\n      data = new Float32Array(gpuBuffer.getMappedRange().slice(0));\n      gpuBuffer.unmap();\n    } else if (buffer && (buffer as GPUBuffer).size !== undefined && gpuDevice) {\n      isGPU = true;\n      const gpuBuffer = buffer as GPUBuffer;\n      const readSize = Math.min(gpuBuffer.size, 4096);\n      const staging = gpuDevice.createBuffer({\n        label: `debug_staging_${label}`,\n        size: readSize,\n        usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ,\n      });\n\n      const encoder = gpuDevice.createCommandEncoder();\n      encoder.copyBufferToBuffer(gpuBuffer, 0, staging, 0, readSize);\n      gpuDevice.queue.submit([encoder.finish()]);\n\n      await staging.mapAsync(GPUMapMode.READ);\n      data = new Float32Array(staging.getMappedRange().slice(0));\n      staging.unmap();\n      staging.destroy();\n    } else if (buffer instanceof Float32Array || buffer instanceof Float64Array) {\n      data = buffer instanceof Float32Array ? buffer : new Float32Array(buffer);\n    } else if (buffer instanceof Uint16Array) {\n      data = new Float32Array(buffer.length);\n      for (let i = 0; i < buffer.length; i++) {\n        data[i] = f16ToF32(buffer[i]);\n      }\n    } else {\n      log.warn('Debug', `Cannot inspect tensor \"${label}\": unknown type`);\n      return null;\n    }\n\n    // Compute statistics\n    let min = Infinity,\n      max = -Infinity,\n      sum = 0,\n      sumSq = 0;\n    let nanCount = 0,\n      infCount = 0,\n      zeroCount = 0;\n\n    for (let i = 0; i < data.length; i++) {\n      const v = data[i];\n      if (Number.isNaN(v)) {\n        nanCount++;\n        continue;\n      }\n      if (!Number.isFinite(v)) {\n        infCount++;\n        continue;\n      }\n      if (v === 0) zeroCount++;\n      min = Math.min(min, v);\n      max = Math.max(max, v);\n      sum += v;\n      sumSq += v * v;\n    }\n\n    const validCount = data.length - nanCount - infCount;\n    const mean = validCount > 0 ? sum / validCount : 0;\n    const variance = validCount > 0 ? sumSq / validCount - mean * mean : 0;\n    const std = Math.sqrt(Math.max(0, variance));\n\n    const stats: TensorStats = {\n      label,\n      shape,\n      size: data.length,\n      isGPU,\n      min,\n      max,\n      mean,\n      std,\n      nanCount,\n      infCount,\n      zeroCount,\n      zeroPercent: ((zeroCount / data.length) * 100).toFixed(1),\n      first: Array.from(data.slice(0, maxPrint)).map((v) => v.toFixed(4)),\n      last: Array.from(data.slice(-maxPrint)).map((v) => v.toFixed(4)),\n    };\n\n    const shapeStr = shape.length > 0 ? `[${shape.join('x')}]` : `[${data.length}]`;\n    log.debug(\n      'Tensor',\n      `${label} ${shapeStr}: min=${min.toFixed(4)}, max=${max.toFixed(4)}, mean=${mean.toFixed(4)}, std=${std.toFixed(4)}`\n    );\n\n    if (checkNaN && (nanCount > 0 || infCount > 0)) {\n      log.warn('Tensor', `${label} has ${nanCount} NaN and ${infCount} Inf values!`);\n    }\n\n    return stats;\n  },\n\n  /**\n   * Compare two tensors element-wise.\n   */\n  compare(\n    a: Float32Array,\n    b: Float32Array,\n    label: string,\n    tolerance = 1e-5\n  ): TensorCompareResult {\n    if (a.length !== b.length) {\n      log.error('Tensor', `${label}: size mismatch ${a.length} vs ${b.length}`);\n      return { label, match: false, error: 'size_mismatch', maxDiff: 0, maxDiffIdx: 0, avgDiff: 0, mismatchCount: 0, mismatchPercent: '0' };\n    }\n\n    let maxDiff = 0,\n      maxDiffIdx = 0;\n    let sumDiff = 0;\n    let mismatchCount = 0;\n\n    for (let i = 0; i < a.length; i++) {\n      const diff = Math.abs(a[i] - b[i]);\n      sumDiff += diff;\n      if (diff > maxDiff) {\n        maxDiff = diff;\n        maxDiffIdx = i;\n      }\n      if (diff > tolerance) {\n        mismatchCount++;\n      }\n    }\n\n    const avgDiff = sumDiff / a.length;\n    const match = mismatchCount === 0;\n\n    const result: TensorCompareResult = {\n      label,\n      match,\n      maxDiff,\n      maxDiffIdx,\n      avgDiff,\n      mismatchCount,\n      mismatchPercent: ((mismatchCount / a.length) * 100).toFixed(2),\n    };\n\n    if (match) {\n      log.debug('Tensor', `${label}: MATCH (maxDiff=${maxDiff.toExponential(2)})`);\n    } else {\n      log.warn(\n        'Tensor',\n        `${label}: MISMATCH ${mismatchCount}/${a.length} (${result.mismatchPercent}%) maxDiff=${maxDiff.toFixed(6)} at idx=${maxDiffIdx}`\n      );\n    }\n\n    return result;\n  },\n\n  /**\n   * Check tensor for common issues.\n   */\n  healthCheck(data: Float32Array, label: string): TensorHealthResult {\n    const issues: string[] = [];\n\n    const allZero = data.every((v) => v === 0);\n    if (allZero) {\n      issues.push('ALL_ZEROS');\n    }\n\n    const hasNaN = data.some((v) => Number.isNaN(v));\n    const hasInf = data.some((v) => !Number.isFinite(v) && !Number.isNaN(v));\n    if (hasNaN) issues.push('HAS_NAN');\n    if (hasInf) issues.push('HAS_INF');\n\n    const maxAbs = Math.max(...Array.from(data).map(Math.abs).filter(Number.isFinite));\n    if (maxAbs > 1e6) issues.push(`EXTREME_VALUES (max=${maxAbs.toExponential(2)})`);\n\n    const tinyCount = data.filter((v) => Math.abs(v) > 0 && Math.abs(v) < 1e-30).length;\n    if (tinyCount > data.length * 0.1) {\n      issues.push(`POTENTIAL_UNDERFLOW (${tinyCount} tiny values)`);\n    }\n\n    const healthy = issues.length === 0;\n\n    if (healthy) {\n      log.debug('Tensor', `${label}: healthy`);\n    } else {\n      log.warn('Tensor', `${label}: issues found - ${issues.join(', ')}`);\n    }\n\n    return { label, healthy, issues };\n  },\n};\n\n// ============================================================================\n// Performance Timing Interface\n// ============================================================================\n\n/**\n * Performance timing utilities.\n */\nexport const perf = {\n  marks: new Map<string, number>(),\n\n  /**\n   * Start a timing mark.\n   */\n  mark(label: string): void {\n    this.marks.set(label, performance.now());\n  },\n\n  /**\n   * End a timing mark and log duration.\n   */\n  measure(label: string, module = 'Perf'): number {\n    const start = this.marks.get(label);\n    if (start === undefined) {\n      log.warn(module, `No mark found for \"${label}\"`);\n      return 0;\n    }\n\n    const duration = performance.now() - start;\n    this.marks.delete(label);\n    log.debug(module, `${label}: ${duration.toFixed(2)}ms`);\n    return duration;\n  },\n\n  /**\n   * Time an async operation.\n   */\n  async time<T>(label: string, fn: () => Promise<T>): Promise<{ result: T; durationMs: number }> {\n    const start = performance.now();\n    const result = await fn();\n    const durationMs = performance.now() - start;\n    log.debug('Perf', `${label}: ${durationMs.toFixed(2)}ms`);\n    return { result, durationMs };\n  },\n};\n\n// ============================================================================\n// History Functions\n// ============================================================================\n\n/**\n * Get log history for debugging.\n */\nexport function getLogHistory(filter: LogHistoryFilter = {}): LogEntry[] {\n  let history = [...logHistory];\n\n  if (filter.level) {\n    history = history.filter((h) => h.level === filter.level!.toUpperCase());\n  }\n\n  if (filter.module) {\n    const m = filter.module.toLowerCase();\n    history = history.filter((h) => h.module.toLowerCase().includes(m));\n  }\n\n  if (filter.last) {\n    history = history.slice(-filter.last);\n  }\n\n  return history;\n}\n\n/**\n * Clear log history.\n */\nexport function clearLogHistory(): void {\n  logHistory = [];\n}\n\n/**\n * Print a summary of recent logs.\n */\nexport function printLogSummary(count = 20): void {\n  const recent = logHistory.slice(-count);\n  console.log('=== Recent Logs ===');\n  for (const entry of recent) {\n    const time = entry.perfTime.toFixed(1);\n    console.log(`[${time}ms][${entry.level}][${entry.module}] ${entry.message}`);\n  }\n  console.log('===================');\n}\n\n/**\n * Export a debug snapshot for bug reports.\n */\nexport function getDebugSnapshot(): DebugSnapshot {\n  return {\n    timestamp: new Date().toISOString(),\n    logLevel: Object.keys(LOG_LEVELS).find(\n      (k) => LOG_LEVELS[k as LogLevel] === currentLogLevel\n    ),\n    traceCategories: [...enabledTraceCategories],\n    enabledModules: [...enabledModules],\n    disabledModules: [...disabledModules],\n    recentLogs: logHistory.slice(-50).map((e) => ({\n      time: e.perfTime.toFixed(1),\n      level: e.level,\n      module: e.module,\n      message: e.message,\n    })),\n    errorCount: logHistory.filter((e) => e.level === 'ERROR').length,\n    warnCount: logHistory.filter((e) => e.level === 'WARN').length,\n  };\n}\n\n\n// ============================================================================\n// Browser Console Global API\n// ============================================================================\n\n/**\n * DOPPLER debug API exposed to browser console.\n */\nexport interface DopplerDebugAPI {\n  // Trace categories\n  trace: typeof trace;\n  setTrace: typeof setTrace;\n  getTrace: typeof getTrace;\n  // Log levels\n  log: typeof log;\n  setLogLevel: typeof setLogLevel;\n  getLogLevel: typeof getLogLevel;\n  // Tensor inspection\n  tensor: typeof tensor;\n  inspect: typeof tensor.inspect;\n  // Performance\n  perf: typeof perf;\n  // Other\n  setBenchmarkMode: typeof setBenchmarkMode;\n  isBenchmarkMode: typeof isBenchmarkMode;\n  // History\n  getLogHistory: typeof getLogHistory;\n  printLogSummary: typeof printLogSummary;\n  getDebugSnapshot: typeof getDebugSnapshot;\n  // Completion signals\n  SIGNALS: typeof SIGNALS;\n  signalDone: typeof signalDone;\n  signalResult: typeof signalResult;\n  signalError: typeof signalError;\n  signalProgress: typeof signalProgress;\n}\n\nconst DOPPLER_API: DopplerDebugAPI = {\n  // Trace categories\n  trace,\n  setTrace,\n  getTrace,\n  // Log levels\n  log,\n  setLogLevel,\n  getLogLevel,\n  // Tensor inspection\n  tensor,\n  inspect: tensor.inspect.bind(tensor),\n  // Performance\n  perf,\n  // Other\n  setBenchmarkMode,\n  isBenchmarkMode,\n  // History\n  getLogHistory,\n  printLogSummary,\n  getDebugSnapshot,\n  // Completion signals\n  SIGNALS,\n  signalDone,\n  signalResult,\n  signalError,\n  signalProgress,\n};\n\n// Expose to window in browser environment\nif (typeof window !== 'undefined') {\n  (window as any).DOPPLER = {\n    ...((window as any).DOPPLER || {}),\n    ...DOPPLER_API,\n  };\n\n  // Auto-init from URL params on load\n  if (document.readyState === 'loading') {\n    document.addEventListener('DOMContentLoaded', initFromUrlParams);\n  } else {\n    initFromUrlParams();\n  }\n}\n\n// ============================================================================\n// Default Export\n// ============================================================================\n\nexport default {\n  log,\n  trace,\n  tensor,\n  perf,\n  setLogLevel,\n  getLogLevel,\n  setTrace,\n  getTrace,\n  isTraceEnabled,\n  setBenchmarkMode,\n  isBenchmarkMode,\n  setGPUDevice,\n  enableModules,\n  disableModules,\n  resetModuleFilters,\n  getLogHistory,\n  clearLogHistory,\n  printLogSummary,\n  getDebugSnapshot,\n  initFromUrlParams,\n  LOG_LEVELS,\n  TRACE_CATEGORIES,\n  // Completion signals\n  SIGNALS,\n  signalDone,\n  signalResult,\n  signalError,\n  signalProgress,\n};\n\n// ============================================================================\n// Node-only debug utilities\n// ============================================================================\n// Tensor debug utilities (SafeTensors/RDRR comparison) are Node-only.\n// Import directly from './tensor.js' when needed in Node.js scripts.\n", "/**\n * Performance Guards - Runtime Flags for Expensive Operations\n *\n * Controls performance-critical operations that should be\n * disabled in production or gated behind debug mode.\n */\n\nimport { log, trace } from '../debug/index.js';\n\n/**\n * Performance configuration\n */\nexport interface PerfConfig {\n  /** Allow GPU\u2192CPU readbacks (mapAsync). Disable for production. */\n  allowGPUReadback: boolean;\n\n  /** Count queue.submit() calls per inference pass */\n  trackSubmitCount: boolean;\n\n  /** Count buffer allocations per inference pass */\n  trackAllocations: boolean;\n\n  /** Log expensive operations to console */\n  logExpensiveOps: boolean;\n\n  /** Throw error on disallowed operations (vs silent no-op) */\n  strictMode: boolean;\n}\n\n/**\n * Default configuration\n * - Development: All tracking enabled, readbacks allowed\n * - Production: Tracking disabled, readbacks blocked\n */\nconst DEFAULT_CONFIG: PerfConfig = {\n  allowGPUReadback: true, // Default to allowed for backward compatibility\n  trackSubmitCount: false,\n  trackAllocations: false,\n  logExpensiveOps: false,\n  strictMode: false,\n};\n\n/**\n * Global performance configuration\n */\nlet config: PerfConfig = { ...DEFAULT_CONFIG };\n\n/**\n * Performance counters for current inference pass\n */\ninterface PerfCounters {\n  submits: number;\n  allocations: number;\n  readbacks: number;\n  startTime: number;\n}\n\nlet counters: PerfCounters = {\n  submits: 0,\n  allocations: 0,\n  readbacks: 0,\n  startTime: 0,\n};\n\n/**\n * Configure performance guards\n */\nexport function configurePerfGuards(newConfig: Partial<PerfConfig>): void {\n  config = { ...config, ...newConfig };\n}\n\n/**\n * Get current performance configuration\n */\nexport function getPerfConfig(): Readonly<PerfConfig> {\n  return config;\n}\n\n/**\n * Reset performance counters (call at start of inference pass)\n */\nexport function resetPerfCounters(): void {\n  counters = {\n    submits: 0,\n    allocations: 0,\n    readbacks: 0,\n    startTime: performance.now(),\n  };\n}\n\n/**\n * Get current performance counters\n */\nexport function getPerfCounters(): Readonly<PerfCounters> {\n  return counters;\n}\n\n/**\n * Increment submit counter\n */\nexport function trackSubmit(): void {\n  if (config.trackSubmitCount) {\n    counters.submits++;\n    if (config.logExpensiveOps) {\n      trace.perf(`PerfGuard: Submit #${counters.submits}`);\n    }\n  }\n}\n\n/**\n * Increment allocation counter\n */\nexport function trackAllocation(size: number, label?: string): void {\n  if (config.trackAllocations) {\n    counters.allocations++;\n    if (config.logExpensiveOps) {\n      trace.buffers(`PerfGuard: Allocation #${counters.allocations}: ${size} bytes (${label || 'unlabeled'})`);\n    }\n  }\n}\n\n/**\n * Check if GPU readback is allowed\n * @throws Error if readback is disallowed and strictMode is enabled\n */\nexport function allowReadback(reason?: string): boolean {\n  if (!config.allowGPUReadback) {\n    const message = `PerfGuard: GPU readback blocked: ${reason || 'unknown reason'}`;\n    if (config.strictMode) {\n      throw new Error(message);\n    }\n    if (config.logExpensiveOps) {\n      log.warn('PerfGuard', message);\n    }\n    return false;\n  }\n\n  if (config.trackSubmitCount) {\n    counters.readbacks++;\n    if (config.logExpensiveOps) {\n      trace.perf(`PerfGuard: Readback #${counters.readbacks}: ${reason || 'unknown'}`);\n    }\n  }\n\n  return true;\n}\n\n/**\n * Get performance summary for current pass\n */\nexport function getPerfSummary(): string {\n  const elapsed = performance.now() - counters.startTime;\n  return [\n    `Performance Summary (${elapsed.toFixed(1)}ms):`,\n    `  Submits: ${counters.submits}`,\n    `  Allocations: ${counters.allocations}`,\n    `  Readbacks: ${counters.readbacks}`,\n  ].join('\\n');\n}\n\n/**\n * Log performance summary to console\n */\nexport function logPerfSummary(): void {\n  trace.perf(getPerfSummary());\n}\n\n/**\n * Production preset: Disable all tracking, block readbacks\n */\nexport function enableProductionMode(): void {\n  configurePerfGuards({\n    allowGPUReadback: false,\n    trackSubmitCount: false,\n    trackAllocations: false,\n    logExpensiveOps: false,\n    strictMode: true,\n  });\n}\n\n/**\n * Debug preset: Enable all tracking, allow readbacks, log operations\n */\nexport function enableDebugMode(): void {\n  configurePerfGuards({\n    allowGPUReadback: true,\n    trackSubmitCount: true,\n    trackAllocations: true,\n    logExpensiveOps: true,\n    strictMode: false,\n  });\n}\n\n/**\n * Benchmark preset: Track counters but don't log\n */\nexport function enableBenchmarkMode(): void {\n  configurePerfGuards({\n    allowGPUReadback: true,\n    trackSubmitCount: true,\n    trackAllocations: true,\n    logExpensiveOps: false,\n    strictMode: false,\n  });\n}\n", "/**\n * Submit Tracker - Measures GPU submit overhead for optimization benchmarking.\n *\n * Usage:\n *   // Before forward pass:\n *   resetSubmitStats();\n *\n *   // Run forward pass...\n *\n *   // After forward pass:\n *   const stats = getSubmitStats();\n *   log.info('SubmitTracker', `Submits: ${stats.count}, Total time: ${stats.totalMs.toFixed(2)}ms`);\n *\n * To enable tracking, set TRACK_SUBMITS = true and wrap queue.submit calls.\n *\n * @module gpu/submit-tracker\n */\n\nimport { trackSubmit } from './perf-guards.js';\nimport { log, trace } from '../debug/index.js';\n\n/** Whether to track submits (disable in production for perf) */\nexport let TRACK_SUBMITS = false;\n\n/** Submit statistics */\nexport interface SubmitStats {\n  /** Number of queue.submit() calls */\n  count: number;\n  /** Total time spent in submit calls (ms) */\n  totalMs: number;\n  /** Average time per submit (ms) */\n  avgMs: number;\n  /** Max time for a single submit (ms) */\n  maxMs: number;\n  /** Min time for a single submit (ms) */\n  minMs: number;\n  /** Submit timestamps for detailed analysis */\n  timestamps: number[];\n  /** Submit counts by source */\n  bySource?: Map<string, number>;\n}\n\n/** Phase-based submit statistics */\nexport interface PhaseSubmitStats {\n  prefill: SubmitStats;\n  decode: SubmitStats;\n  other: SubmitStats;\n}\n\n/** Current phase for submit tracking */\nexport type SubmitPhase = 'prefill' | 'decode' | 'other';\n\n/** Internal tracking state */\nlet submitCount = 0;\nlet submitTimes: number[] = [];\nlet totalSubmitMs = 0;\nlet maxSubmitMs = 0;\nlet minSubmitMs = Infinity;\nlet submitSources = new Map<string, number>();\n\n/** Phase-based tracking state */\nlet currentPhase: SubmitPhase = 'other';\nconst phaseStats: Record<SubmitPhase, { count: number; times: number[]; totalMs: number; maxMs: number; minMs: number; sources: Map<string, number> }> = {\n  prefill: { count: 0, times: [], totalMs: 0, maxMs: 0, minMs: Infinity, sources: new Map() },\n  decode: { count: 0, times: [], totalMs: 0, maxMs: 0, minMs: Infinity, sources: new Map() },\n  other: { count: 0, times: [], totalMs: 0, maxMs: 0, minMs: Infinity, sources: new Map() },\n};\n\n/**\n * Enable/disable submit tracking.\n * @param enabled - Whether to track submits\n */\nexport function setTrackSubmits(enabled: boolean): void {\n  TRACK_SUBMITS = enabled;\n  if (enabled) {\n    resetSubmitStats();\n    log.debug('SubmitTracker', 'Enabled');\n  } else {\n    log.debug('SubmitTracker', 'Disabled');\n  }\n}\n\n/**\n * Reset submit statistics.\n * Call before starting a new measurement.\n */\nexport function resetSubmitStats(): void {\n  submitCount = 0;\n  submitTimes = [];\n  totalSubmitMs = 0;\n  maxSubmitMs = 0;\n  minSubmitMs = Infinity;\n  submitSources = new Map();\n  currentPhase = 'other';\n\n  // Reset phase stats\n  for (const phase of ['prefill', 'decode', 'other'] as const) {\n    phaseStats[phase] = { count: 0, times: [], totalMs: 0, maxMs: 0, minMs: Infinity, sources: new Map() };\n  }\n}\n\n/**\n * Set the current phase for submit tracking.\n * @param phase - The phase to track ('prefill', 'decode', or 'other')\n */\nexport function setSubmitPhase(phase: SubmitPhase): void {\n  currentPhase = phase;\n}\n\n/**\n * Record a submit call.\n * Call this from a wrapper around queue.submit().\n * @param durationMs - Time spent in this submit call\n * @param source - Optional source identifier (e.g., \"pipeline.ts:prefill\", \"layer.ts:attention\")\n */\nexport function recordSubmit(durationMs: number, source?: string): void {\n  if (!TRACK_SUBMITS) return;\n\n  // Global stats\n  submitCount++;\n  submitTimes.push(durationMs);\n  totalSubmitMs += durationMs;\n  maxSubmitMs = Math.max(maxSubmitMs, durationMs);\n  minSubmitMs = Math.min(minSubmitMs, durationMs);\n\n  // Track by source\n  if (source) {\n    submitSources.set(source, (submitSources.get(source) || 0) + 1);\n  }\n\n  // Phase-specific stats\n  const ps = phaseStats[currentPhase];\n  ps.count++;\n  ps.times.push(durationMs);\n  ps.totalMs += durationMs;\n  ps.maxMs = Math.max(ps.maxMs, durationMs);\n  ps.minMs = Math.min(ps.minMs, durationMs);\n\n  // Track source in phase stats\n  if (source) {\n    ps.sources.set(source, (ps.sources.get(source) || 0) + 1);\n  }\n}\n\n/**\n * Get current submit statistics.\n * @returns Submit statistics\n */\nexport function getSubmitStats(): SubmitStats {\n  return {\n    count: submitCount,\n    totalMs: totalSubmitMs,\n    avgMs: submitCount > 0 ? totalSubmitMs / submitCount : 0,\n    maxMs: maxSubmitMs,\n    minMs: minSubmitMs === Infinity ? 0 : minSubmitMs,\n    timestamps: [...submitTimes],\n    bySource: new Map(submitSources),\n  };\n}\n\n/**\n * Get submit statistics for a specific phase.\n * @param phase - The phase to get stats for\n * @returns Submit statistics for the phase\n */\nexport function getPhaseSubmitStats(phase: SubmitPhase): SubmitStats {\n  const ps = phaseStats[phase];\n  return {\n    count: ps.count,\n    totalMs: ps.totalMs,\n    avgMs: ps.count > 0 ? ps.totalMs / ps.count : 0,\n    maxMs: ps.maxMs,\n    minMs: ps.minMs === Infinity ? 0 : ps.minMs,\n    timestamps: [...ps.times],\n    bySource: new Map(ps.sources),\n  };\n}\n\n/**\n * Get submit statistics for all phases.\n * @returns Submit statistics by phase\n */\nexport function getAllPhaseSubmitStats(): PhaseSubmitStats {\n  return {\n    prefill: getPhaseSubmitStats('prefill'),\n    decode: getPhaseSubmitStats('decode'),\n    other: getPhaseSubmitStats('other'),\n  };\n}\n\n/**\n * Log submit statistics summary.\n * @param label - Label for the log output\n */\nexport function logSubmitStats(label: string = 'Forward pass'): void {\n  const stats = getSubmitStats();\n  trace.perf(\n    `SubmitTracker ${label}: ${stats.count} submits, ` +\n    `total=${stats.totalMs.toFixed(2)}ms, ` +\n    `avg=${stats.avgMs.toFixed(3)}ms, ` +\n    `range=[${stats.minMs.toFixed(3)}-${stats.maxMs.toFixed(3)}ms]`\n  );\n\n  // Log by source if available\n  if (stats.bySource && stats.bySource.size > 0) {\n    trace.perf('SubmitTracker: Submits by source:');\n    const sorted = Array.from(stats.bySource.entries()).sort((a, b) => b[1] - a[1]);\n    for (const [source, count] of sorted) {\n      const pct = ((count / stats.count) * 100).toFixed(1);\n      trace.perf(`  ${source}: ${count} (${pct}%)`);\n    }\n  }\n}\n\n/**\n * Log submit statistics for all phases.\n * @param label - Label for the log output\n */\nexport function logAllPhaseSubmitStats(label: string = 'All phases'): void {\n  const allStats = getAllPhaseSubmitStats();\n  trace.perf(`SubmitTracker ${label}:`);\n\n  for (const phase of ['prefill', 'decode', 'other'] as const) {\n    const stats = allStats[phase];\n    if (stats.count === 0) continue;\n\n    trace.perf(\n      `  ${phase}: ${stats.count} submits, ` +\n      `total=${stats.totalMs.toFixed(2)}ms, ` +\n      `avg=${stats.avgMs.toFixed(3)}ms`\n    );\n\n    // Log by source for this phase\n    if (stats.bySource && stats.bySource.size > 0) {\n      const sorted = Array.from(stats.bySource.entries()).sort((a, b) => b[1] - a[1]);\n      for (const [source, count] of sorted) {\n        const pct = ((count / stats.count) * 100).toFixed(1);\n        trace.perf(`    ${source}: ${count} (${pct}%)`);\n      }\n    }\n  }\n}\n\n/**\n * Extract source from stack trace.\n * @returns Source identifier (e.g., \"pipeline.ts:456\" or \"unknown\")\n */\nfunction extractSourceFromStack(): string {\n  const stack = new Error().stack;\n  if (!stack) return 'unknown';\n\n  const lines = stack.split('\\n');\n  // Skip first 3 lines: Error, extractSourceFromStack, queue.submit wrapper\n  for (let i = 3; i < lines.length; i++) {\n    const line = lines[i];\n    // Match file:line pattern in stack trace\n    // Example: \"at functionName (http://localhost:8080/path/to/file.ts:123:45)\"\n    const match = line.match(/\\/([^\\/]+\\.ts):(\\d+):/);\n    if (match) {\n      return `${match[1]}:${match[2]}`;\n    }\n  }\n  return 'unknown';\n}\n\n/**\n * Wrap a GPU queue to track submit calls.\n * @param queue - GPU queue to wrap\n * @returns Wrapped queue with tracking\n */\nexport function wrapQueueForTracking(queue: GPUQueue): GPUQueue {\n  const originalSubmit = queue.submit.bind(queue);\n\n  (queue as any).submit = function(commandBuffers: Iterable<GPUCommandBuffer>): undefined {\n    const start = TRACK_SUBMITS ? performance.now() : 0;\n    const result = originalSubmit(commandBuffers);\n    trackSubmit();\n\n    if (!TRACK_SUBMITS) {\n      return result;\n    }\n\n    const duration = performance.now() - start;\n    recordSubmit(duration, extractSourceFromStack());\n    return result;\n  };\n\n  return queue;\n}\n\n/**\n * Estimate submit overhead savings from batching.\n * @param currentStats - Current submit stats (unbatched)\n * @param targetSubmits - Target number of submits after batching\n * @returns Estimated time savings in ms\n */\nexport function estimateBatchingSavings(\n  currentStats: SubmitStats,\n  targetSubmits: number = 1\n): { savedSubmits: number; estimatedSavingsMs: number } {\n  const savedSubmits = Math.max(0, currentStats.count - targetSubmits);\n  // Each submit has overhead, estimate savings based on average submit time\n  const estimatedSavingsMs = savedSubmits * currentStats.avgMs;\n\n  return {\n    savedSubmits,\n    estimatedSavingsMs,\n  };\n}\n", "/**\n * Platform Loader\n *\n * Detects the current GPU platform and loads appropriate configs.\n * Provides platform-specific kernel overrides and memory hints.\n *\n * @module config/platforms/loader\n */\n\n/** @type {import('../schema/platform.schema.js').PlatformSchema | null} */\nlet currentPlatform = null;\n\n/** @type {import('../schema/platform.schema.js').RuntimeCapabilities | null} */\nlet currentCapabilities = null;\n\n/** @type {Map<string, import('../schema/platform.schema.js').PlatformSchema>} */\nconst platformCache = new Map();\n\n/** @type {string | null} */\nlet platformsBaseUrl = null;\n\n/**\n * Known platform IDs and their config file names.\n * Order matters for detection priority.\n */\nconst PLATFORM_FILES = [\n  'apple-m3',\n  'apple-m2',\n  'apple-m1',\n  'nvidia-rtx40',\n  'nvidia-rtx30',\n  'amd-rdna3',\n  'generic', // Fallback\n];\n\n/**\n * Set the base URL for loading platform configs.\n * @param {string} baseUrl\n */\nexport function setPlatformsBaseUrl(baseUrl) {\n  platformsBaseUrl = baseUrl;\n  platformCache.clear();\n  currentPlatform = null;\n}\n\n/**\n * Load a platform config by ID.\n * @param {string} platformId\n * @returns {Promise<import('../schema/platform.schema.js').PlatformSchema | null>}\n */\nasync function loadPlatformConfig(platformId) {\n  if (platformCache.has(platformId)) {\n    return platformCache.get(platformId) || null;\n  }\n\n  const baseUrl = platformsBaseUrl || new URL('./', import.meta.url).href;\n  const url = `${baseUrl}${platformId}.json`;\n\n  try {\n    const response = await fetch(url);\n    if (!response.ok) {\n      return null;\n    }\n    const config = await response.json();\n    platformCache.set(platformId, config);\n    return config;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Detect platform from WebGPU adapter info.\n * @param {GPUAdapterInfo} adapterInfo\n * @returns {Promise<import('../schema/platform.schema.js').PlatformSchema>}\n */\nexport async function detectPlatform(adapterInfo) {\n  const vendor = adapterInfo.vendor?.toLowerCase() || '';\n  const architecture = adapterInfo.architecture?.toLowerCase() || '';\n  const device = adapterInfo.device?.toLowerCase() || '';\n  const description = adapterInfo.description?.toLowerCase() || '';\n\n  // Try each platform in priority order\n  for (const platformId of PLATFORM_FILES) {\n    const config = await loadPlatformConfig(platformId);\n    if (!config) continue;\n\n    const detection = config.detection;\n    let matches = true;\n\n    if (detection.vendor && !vendor.includes(detection.vendor.toLowerCase())) {\n      matches = false;\n    }\n    if (detection.architecture && !architecture.includes(detection.architecture.toLowerCase())) {\n      matches = false;\n    }\n    if (detection.device && !device.includes(detection.device.toLowerCase())) {\n      matches = false;\n    }\n    if (detection.description && !description.includes(detection.description.toLowerCase())) {\n      matches = false;\n    }\n\n    if (matches && !config.isGeneric) {\n      currentPlatform = config;\n      return config;\n    }\n  }\n\n  // Fall back to generic\n  const genericConfig = await loadPlatformConfig('generic');\n  if (genericConfig) {\n    currentPlatform = genericConfig;\n    return genericConfig;\n  }\n\n  // Absolute fallback if no config files available\n  const fallback = {\n    id: 'unknown',\n    name: 'Unknown Platform',\n    detection: {},\n    isGeneric: true,\n  };\n  currentPlatform = fallback;\n  return fallback;\n}\n\n/**\n * Initialize platform detection with a WebGPU adapter.\n * @param {GPUAdapter} adapter\n * @returns {Promise<import('../schema/platform.schema.js').ResolvedPlatformConfig>}\n */\nexport async function initializePlatform(adapter) {\n  const adapterInfo = adapter.info;\n  const platform = await detectPlatform(adapterInfo);\n\n  // Detect runtime capabilities\n  const features = adapter.features;\n  currentCapabilities = {\n    hasF16: features.has('shader-f16'),\n    hasSubgroups: features.has('subgroups'),\n    subgroupSize: features.has('subgroups') ? 32 : undefined, // TODO: detect actual size\n    maxWorkgroupSize: adapter.limits.maxComputeWorkgroupSizeX,\n    maxSharedMemory: adapter.limits.maxComputeWorkgroupStorageSize,\n    maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n    maxBufferSize: adapter.limits.maxBufferSize,\n  };\n\n  return {\n    platform,\n    capabilities: currentCapabilities,\n  };\n}\n\n/**\n * Get the current platform (throws if not initialized).\n * @returns {import('../schema/platform.schema.js').PlatformSchema}\n */\nexport function getPlatform() {\n  if (!currentPlatform) {\n    throw new Error('Platform not initialized. Call initializePlatform() first.');\n  }\n  return currentPlatform;\n}\n\n/**\n * Get the current runtime capabilities (throws if not initialized).\n * @returns {import('../schema/platform.schema.js').RuntimeCapabilities}\n */\nexport function getCapabilities() {\n  if (!currentCapabilities) {\n    throw new Error('Platform not initialized. Call initializePlatform() first.');\n  }\n  return currentCapabilities;\n}\n\n/**\n * Get kernel override for an operation on current platform.\n * @param {string} operation\n * @returns {import('../schema/platform.schema.js').KernelOperationOverrideSchema | undefined}\n */\nexport function getKernelOverride(operation) {\n  const platform = getPlatform();\n  return platform.kernelOverrides?.[operation];\n}\n\n/**\n * Get preferred variant for an operation, if platform specifies one.\n * @param {string} operation\n * @returns {string | undefined}\n */\nexport function getPreferredVariant(operation) {\n  return getKernelOverride(operation)?.preferred;\n}\n\n/**\n * Check if a variant should be avoided on current platform.\n * @param {string} operation\n * @param {string} variant\n * @returns {boolean}\n */\nexport function shouldAvoidVariant(operation, variant) {\n  const override = getKernelOverride(operation);\n  return override?.avoid?.includes(variant) ?? false;\n}\n\n/**\n * Get workgroup size override for a variant, if platform specifies one.\n * @param {string} operation\n * @param {string} variant\n * @returns {[number, number, number] | undefined}\n */\nexport function getWorkgroupOverride(operation, variant) {\n  const override = getKernelOverride(operation);\n  return override?.workgroupOverrides?.[variant];\n}\n\n/**\n * Get WGSL override constants for a variant, if platform specifies any.\n * @param {string} operation\n * @param {string} variant\n * @returns {Record<string, number> | undefined}\n */\nexport function getWgslOverrides(operation, variant) {\n  const override = getKernelOverride(operation);\n  return override?.wgslOverrides?.[variant];\n}\n\n/**\n * Get memory hints for current platform.\n * @returns {import('../schema/platform.schema.js').MemoryHintsSchema | undefined}\n */\nexport function getMemoryHints() {\n  return getPlatform().memoryHints;\n}\n\n/**\n * Check if current platform prefers unified memory strategies.\n * @returns {boolean}\n */\nexport function prefersUnifiedMemory() {\n  return getMemoryHints()?.preferUnifiedMemory ?? false;\n}\n\n/**\n * Get optimal buffer alignment for current platform.\n * @returns {number}\n */\nexport function getBufferAlignment() {\n  return getMemoryHints()?.bufferAlignment ?? 256;\n}\n\n/**\n * Clear all cached platform data. Useful for hot-reloading.\n */\nexport function clearPlatformCache() {\n  platformCache.clear();\n  currentPlatform = null;\n  currentCapabilities = null;\n}\n\n/**\n * Get resolved platform config with capabilities.\n * @returns {import('../schema/platform.schema.js').ResolvedPlatformConfig}\n */\nexport function getResolvedPlatformConfig() {\n  return {\n    platform: getPlatform(),\n    capabilities: getCapabilities(),\n  };\n}\n", "/**\n * Kernel Registry Loader\n *\n * Loads and caches the kernel registry from JSON.\n * Provides resolved kernel configs with base + variant merged.\n *\n * @module config/kernels/registry\n */\n\n/** @type {import('../schema/kernel-registry.schema.js').KernelRegistrySchema | null} */\nlet cachedRegistry = null;\n\n/** @type {string | null} */\nlet registryUrl = null;\n\n/**\n * Set the URL for loading the registry.\n * Must be called before getRegistry() if not using default.\n * @param {string} url\n */\nexport function setRegistryUrl(url) {\n  registryUrl = url;\n  cachedRegistry = null; // Clear cache when URL changes\n}\n\n/**\n * Get the kernel registry, loading it if needed.\n * @returns {Promise<import('../schema/kernel-registry.schema.js').KernelRegistrySchema>}\n */\nexport async function getRegistry() {\n  if (cachedRegistry) {\n    return cachedRegistry;\n  }\n\n  const url = registryUrl || new URL('./registry.json', import.meta.url).href;\n  const response = await fetch(url);\n  if (!response.ok) {\n    throw new Error(`Failed to load kernel registry from ${url}: ${response.status}`);\n  }\n\n  cachedRegistry = await response.json();\n  return cachedRegistry;\n}\n\n/**\n * Get registry synchronously (throws if not loaded).\n * Use after awaiting getRegistry() at startup.\n * @returns {import('../schema/kernel-registry.schema.js').KernelRegistrySchema}\n */\nexport function getRegistrySync() {\n  if (!cachedRegistry) {\n    throw new Error('Kernel registry not loaded. Call await getRegistry() first.');\n  }\n  return cachedRegistry;\n}\n\n/**\n * Clear the cached registry. Useful for hot-reloading.\n */\nexport function clearRegistryCache() {\n  cachedRegistry = null;\n}\n\n/**\n * Get an operation schema by name.\n * @param {string} operation\n * @returns {import('../schema/kernel-registry.schema.js').OperationSchema | undefined}\n */\nexport function getOperation(operation) {\n  const registry = getRegistrySync();\n  return registry.operations[operation];\n}\n\n/**\n * Get a variant schema by operation and variant name.\n * @param {string} operation\n * @param {string} variant\n * @returns {import('../schema/kernel-registry.schema.js').KernelVariantSchema | undefined}\n */\nexport function getVariant(operation, variant) {\n  const op = getOperation(operation);\n  return op?.variants[variant];\n}\n\n/**\n * Get all variant names for an operation.\n * @param {string} operation\n * @returns {string[]}\n */\nexport function getVariantNames(operation) {\n  const op = getOperation(operation);\n  return op ? Object.keys(op.variants) : [];\n}\n\n/**\n * Check if a variant's requirements are met by capabilities.\n * @param {string} operation\n * @param {string} variant\n * @param {import('../schema/platform.schema.js').RuntimeCapabilities} capabilities\n * @returns {boolean}\n */\nexport function isVariantAvailable(operation, variant, capabilities) {\n  const variantSchema = getVariant(operation, variant);\n  if (!variantSchema) return false;\n\n  const requires = variantSchema.requires || [];\n  for (const req of requires) {\n    if (req === 'shader-f16' && !capabilities.hasF16) return false;\n    if (req === 'subgroups' && !capabilities.hasSubgroups) return false;\n    if (req === 'subgroups-f16' && (!capabilities.hasSubgroups || !capabilities.hasF16)) return false;\n  }\n  return true;\n}\n\n/**\n * Get all available variants for an operation given capabilities.\n * @param {string} operation\n * @param {import('../schema/platform.schema.js').RuntimeCapabilities} capabilities\n * @returns {string[]}\n */\nexport function getAvailableVariants(operation, capabilities) {\n  return getVariantNames(operation).filter(v => isVariantAvailable(operation, v, capabilities));\n}\n\n/**\n * Merge base and variant bindings.\n * Variant bindings with matching indices override base bindings.\n * @param {import('../schema/kernel-registry.schema.js').BindingSchema[]} base\n * @param {import('../schema/kernel-registry.schema.js').BindingSchema[] | undefined} override\n * @returns {import('../schema/kernel-registry.schema.js').BindingSchema[]}\n */\nexport function mergeBindings(base, override) {\n  if (!override || override.length === 0) {\n    return [...base];\n  }\n\n  const result = [...base];\n  for (const binding of override) {\n    const existingIdx = result.findIndex(b => b.index === binding.index);\n    if (existingIdx >= 0) {\n      result[existingIdx] = binding;\n    } else {\n      result.push(binding);\n    }\n  }\n\n  return result.sort((a, b) => a.index - b.index);\n}\n\n/**\n * Resolve a kernel variant to a complete configuration.\n * Merges base operation config with variant-specific overrides.\n * @param {string} operation\n * @param {string} variant\n * @returns {import('../schema/kernel-registry.schema.js').ResolvedKernelConfig | null}\n */\nexport function resolveKernelConfig(operation, variant) {\n  const opSchema = getOperation(operation);\n  const variantSchema = getVariant(operation, variant);\n\n  if (!opSchema || !variantSchema) {\n    return null;\n  }\n\n  return {\n    operation,\n    variant,\n    wgsl: variantSchema.wgsl,\n    entryPoint: variantSchema.entryPoint,\n    workgroup: variantSchema.workgroup,\n    requires: variantSchema.requires ?? [],\n    bindings: mergeBindings(opSchema.baseBindings, variantSchema.bindingsOverride),\n    uniforms: variantSchema.uniformsOverride ?? opSchema.baseUniforms,\n    wgslOverrides: variantSchema.wgslOverrides ?? {},\n    sharedMemory: variantSchema.sharedMemory ?? 0,\n  };\n}\n", "/**\n * WebGPU Device Initialization and Feature Probing\n *\n * Handles WebGPU adapter/device setup with comprehensive feature detection\n * for optimal kernel selection.\n *\n * Also initializes the platform loader and kernel registry for config-as-code\n * kernel selection based on detected GPU hardware.\n */\n\nimport type { GpuCapabilities, GpuLimits } from '../types/gpu.js';\nimport { wrapQueueForTracking, TRACK_SUBMITS, setTrackSubmits } from './submit-tracker.js';\nimport { log } from '../debug/index.js';\n\n// Platform and kernel registry types (dynamic import to avoid circular deps)\nimport type { ResolvedPlatformConfig, RuntimeCapabilities } from '../config/schema/platform.schema.js';\n\n// Re-export types for convenience\nexport type { GpuCapabilities, GpuLimits };\n\n// Re-export submit tracker for convenience\nexport { setTrackSubmits };\n\n/**\n * GPU adapter information\n */\nexport interface AdapterInfo {\n  vendor: string;\n  architecture: string;\n  device: string;\n  description: string;\n}\n\n/**\n * Extended kernel capabilities with adapter info\n */\nexport interface KernelCapabilities {\n  hasSubgroups: boolean;\n  hasSubgroupsF16: boolean;\n  hasF16: boolean;\n  hasTimestampQuery: boolean;\n  maxBufferSize: number;\n  maxWorkgroupSize: number;\n  maxWorkgroupStorageSize: number;\n  adapterInfo: AdapterInfo;\n  features?: string[];  // GPU feature strings from adapter\n}\n\n/**\n * WebGPU adapter request options\n */\ninterface AdapterRequestOptions {\n  powerPreference?: 'low-power' | 'high-performance';\n  forceFallbackAdapter?: boolean;\n}\n\n/**\n * GPU device limits for initialization\n */\nexport interface DeviceLimits {\n  maxStorageBufferBindingSize: number;\n  maxBufferSize: number;\n  maxComputeWorkgroupSizeX: number;\n  maxComputeWorkgroupSizeY: number;\n  maxComputeWorkgroupSizeZ: number;\n  maxComputeInvocationsPerWorkgroup: number;\n  maxComputeWorkgroupStorageSize: number;\n  maxStorageBuffersPerShaderStage: number;\n  maxUniformBufferBindingSize: number;\n  maxComputeWorkgroupsPerDimension: number;\n}\n\n// Cached device and capabilities\nlet gpuDevice: GPUDevice | null = null;\nlet kernelCapabilities: KernelCapabilities | null = null;\n\n// Cached platform config (set during initDevice)\nlet resolvedPlatformConfig: ResolvedPlatformConfig | null = null;\n\n// Track whether platform/registry initialization has been attempted\nlet platformInitialized = false;\n\n/**\n * Feature flags detected during initialization\n */\nconst FEATURES = {\n  SHADER_F16: 'shader-f16',\n  SUBGROUPS: 'subgroups',\n  SUBGROUPS_F16: 'subgroups-f16',\n  TIMESTAMP_QUERY: 'timestamp-query',\n} as const;\n\ntype FeatureKey = keyof typeof FEATURES;\n\n/**\n * Probe for WebGPU availability\n */\nexport function isWebGPUAvailable(): boolean {\n  return typeof navigator !== 'undefined' && 'gpu' in navigator;\n}\n\n/**\n * Request WebGPU adapter with fallback options\n * @param options - Adapter request options\n * @returns GPU adapter or null if unavailable\n */\nasync function requestAdapter(options: AdapterRequestOptions = {}): Promise<GPUAdapter | null> {\n  if (!isWebGPUAvailable()) {\n    return null;\n  }\n\n  // Try high-performance first, then fallback\n  const adapterOptions: GPURequestAdapterOptions[] = [\n    { powerPreference: 'high-performance', ...options },\n    { powerPreference: 'low-power', ...options },\n    { ...options }, // Default\n  ];\n\n  for (const opts of adapterOptions) {\n    try {\n      const adapter = await navigator.gpu.requestAdapter(opts);\n      if (adapter) {\n        return adapter;\n      }\n    } catch (e) {\n      // Continue to next option\n    }\n  }\n\n  return null;\n}\n\n/**\n * Detect available features from adapter\n * @param adapter - GPU adapter\n * @returns Set of available feature names\n */\nfunction detectFeatures(adapter: GPUAdapter): Set<string> {\n  const available = new Set<string>();\n\n  for (const feature of adapter.features) {\n    available.add(feature);\n  }\n\n  return available;\n}\n\n/**\n * Build list of features to request based on availability\n * @param available - Available features\n * @returns Array of feature names to request\n */\nfunction buildFeatureRequests(available: Set<string>): GPUFeatureName[] {\n  const requested: GPUFeatureName[] = [];\n\n  // Request shader-f16 for FP16 matmul kernels\n  if (available.has(FEATURES.SHADER_F16)) {\n    requested.push(FEATURES.SHADER_F16 as GPUFeatureName);\n  }\n\n  // Request subgroups for efficient dequantization\n  if (available.has(FEATURES.SUBGROUPS)) {\n    requested.push(FEATURES.SUBGROUPS as GPUFeatureName);\n  }\n\n  // Request subgroups-f16 if available (for combined f16 + subgroup ops)\n  if (available.has(FEATURES.SUBGROUPS_F16)) {\n    requested.push(FEATURES.SUBGROUPS_F16 as GPUFeatureName);\n  }\n\n  // Request timestamp query for profiling (optional)\n  if (available.has(FEATURES.TIMESTAMP_QUERY)) {\n    requested.push(FEATURES.TIMESTAMP_QUERY as GPUFeatureName);\n  }\n\n  return requested;\n}\n\n/**\n * Build device limits based on adapter capabilities\n * @param adapter - GPU adapter\n * @returns Device limits object\n */\nfunction buildLimits(adapter: GPUAdapter): Record<string, GPUSize64> {\n  const adapterLimits = adapter.limits;\n\n  return {\n    // Request maximum available storage buffer size (critical for large weight tensors)\n    maxStorageBufferBindingSize: adapterLimits.maxStorageBufferBindingSize,\n    // Request maximum buffer size\n    maxBufferSize: adapterLimits.maxBufferSize,\n    // Request maximum compute workgroup sizes\n    maxComputeWorkgroupSizeX: adapterLimits.maxComputeWorkgroupSizeX,\n    maxComputeWorkgroupSizeY: adapterLimits.maxComputeWorkgroupSizeY,\n    maxComputeWorkgroupSizeZ: adapterLimits.maxComputeWorkgroupSizeZ,\n    maxComputeInvocationsPerWorkgroup: adapterLimits.maxComputeInvocationsPerWorkgroup,\n    maxComputeWorkgroupStorageSize: adapterLimits.maxComputeWorkgroupStorageSize,\n    // Binding limits\n    maxStorageBuffersPerShaderStage: adapterLimits.maxStorageBuffersPerShaderStage,\n    maxUniformBufferBindingSize: adapterLimits.maxUniformBufferBindingSize,\n  };\n}\n\n/**\n * Initialize platform loader and kernel registry.\n * Called automatically during initDevice() after adapter is obtained.\n *\n * @param adapter - GPU adapter for platform detection\n */\nasync function initializePlatformAndRegistry(adapter: GPUAdapter): Promise<void> {\n  if (platformInitialized) {\n    return;\n  }\n\n  platformInitialized = true;\n\n  try {\n    // Dynamic import to avoid circular dependencies and enable hotswap\n    const [platformLoader, kernelRegistry] = await Promise.all([\n      import('../config/platforms/loader.js'),\n      import('../config/kernels/registry.js'),\n    ]);\n\n    // Initialize platform detection with the adapter\n    resolvedPlatformConfig = await platformLoader.initializePlatform(adapter);\n\n    // Preload kernel registry (cached for subsequent calls)\n    await kernelRegistry.getRegistry();\n\n    log.debug('GPU', 'Platform: ' + resolvedPlatformConfig.platform.name + ' (' + resolvedPlatformConfig.platform.id + ')');\n    log.debug('GPU', 'Capabilities: f16=' + resolvedPlatformConfig.capabilities.hasF16 + ', subgroups=' + resolvedPlatformConfig.capabilities.hasSubgroups);\n  } catch (e) {\n    // Platform/registry init is optional - kernel selection will use fallbacks\n    log.warn('GPU', 'Platform/registry init failed (non-fatal): ' + (e as Error).message);\n    resolvedPlatformConfig = null;\n  }\n}\n\n/**\n * Initialize WebGPU device with optimal features\n * @returns GPU device\n * @throws Error if WebGPU is unavailable or device creation fails\n */\nexport async function initDevice(): Promise<GPUDevice> {\n  // Return cached device if available\n  if (gpuDevice) {\n    return gpuDevice;\n  }\n\n  if (!isWebGPUAvailable()) {\n    throw new Error('WebGPU is not available in this browser');\n  }\n\n  const adapter = await requestAdapter();\n  if (!adapter) {\n    throw new Error('Failed to get WebGPU adapter');\n  }\n\n  // Initialize platform loader and kernel registry early (before device creation)\n  // This allows platform-specific config to be available for kernel selection\n  await initializePlatformAndRegistry(adapter);\n\n  // Detect available features\n  const availableFeatures = detectFeatures(adapter);\n  const requestedFeatures = buildFeatureRequests(availableFeatures);\n  const limits = buildLimits(adapter);\n\n  // Get adapter info (adapter.info is synchronous in modern WebGPU)\n  const adapterInfo = adapter.info || { vendor: 'unknown', architecture: 'unknown', device: 'unknown', description: '' };\n\n  try {\n    gpuDevice = await adapter.requestDevice({\n      requiredFeatures: requestedFeatures,\n      requiredLimits: limits,\n    });\n  } catch (e) {\n    // Fallback: request device without optional features\n    log.warn('GPU', 'Failed to request device with features, trying minimal config: ' + (e as Error).message);\n    gpuDevice = await adapter.requestDevice();\n  }\n\n  if (!gpuDevice) {\n    throw new Error('Failed to create WebGPU device');\n  }\n\n  // Set up device lost handler\n  gpuDevice.lost.then((info) => {\n    log.error('GPU', 'Device lost: ' + info.message + ', Reason: ' + info.reason);\n    gpuDevice = null;\n    kernelCapabilities = null;\n    resolvedPlatformConfig = null;\n    platformInitialized = false;\n  });\n\n  // Wrap queue for submit tracking (when enabled)\n  wrapQueueForTracking(gpuDevice.queue);\n\n  // Cache kernel capabilities\n  kernelCapabilities = {\n    hasSubgroups: gpuDevice.features.has(FEATURES.SUBGROUPS),\n    hasSubgroupsF16: gpuDevice.features.has(FEATURES.SUBGROUPS_F16),\n    hasF16: gpuDevice.features.has(FEATURES.SHADER_F16),\n    hasTimestampQuery: gpuDevice.features.has(FEATURES.TIMESTAMP_QUERY),\n    maxBufferSize: gpuDevice.limits.maxStorageBufferBindingSize,\n    maxWorkgroupSize: gpuDevice.limits.maxComputeInvocationsPerWorkgroup,\n    maxWorkgroupStorageSize: gpuDevice.limits.maxComputeWorkgroupStorageSize,\n    adapterInfo: {\n      vendor: adapterInfo.vendor || 'unknown',\n      architecture: adapterInfo.architecture || 'unknown',\n      device: adapterInfo.device || 'unknown',\n      description: adapterInfo.description || '',\n    },\n  };\n\n  const features = [\n    kernelCapabilities.hasF16 && 'f16',\n    kernelCapabilities.hasSubgroups && 'subgroups',\n  ].filter(Boolean).join('/') || 'basic';\n  console.log('[GPU] ' + (adapterInfo.vendor || 'unknown') + ' ' + (adapterInfo.architecture || adapterInfo.device || '') + ', ' + features + ', ' + (kernelCapabilities.maxBufferSize / (1024 * 1024 * 1024)).toFixed(1) + 'GB');\n\n  return gpuDevice;\n}\n\n/**\n * Get kernel capabilities (call after initDevice)\n * @returns Capability flags for kernel selection\n * @throws Error if device not initialized\n */\nexport function getKernelCapabilities(): KernelCapabilities {\n  if (!kernelCapabilities) {\n    throw new Error('Device not initialized. Call initDevice() first.');\n  }\n  return { ...kernelCapabilities };\n}\n\n/**\n * Get the current GPU device (call after initDevice)\n * @returns GPU device or null if not initialized\n */\nexport function getDevice(): GPUDevice | null {\n  return gpuDevice;\n}\n\n/**\n * Get the resolved platform configuration (call after initDevice)\n * @returns Platform config with capabilities, or null if not initialized or detection failed\n */\nexport function getPlatformConfig(): ResolvedPlatformConfig | null {\n  return resolvedPlatformConfig;\n}\n\n/**\n * Check if platform and registry are initialized\n * @returns True if platform detection succeeded\n */\nexport function isPlatformInitialized(): boolean {\n  return platformInitialized && resolvedPlatformConfig !== null;\n}\n\n/**\n * Destroy the device and clear cache\n */\nexport function destroyDevice(): void {\n  if (gpuDevice) {\n    gpuDevice.destroy();\n    gpuDevice = null;\n    kernelCapabilities = null;\n    resolvedPlatformConfig = null;\n    platformInitialized = false;\n  }\n}\n\n/**\n * Check if a specific feature is available\n * @param feature - Feature name to check\n * @returns True if feature is available\n */\nexport function hasFeature(feature: string): boolean {\n  if (!gpuDevice) {\n    return false;\n  }\n  return gpuDevice.features.has(feature as GPUFeatureName);\n}\n\n/**\n * Get device limits\n * @returns Device limits or null if device not initialized\n */\nexport function getDeviceLimits(): DeviceLimits | null {\n  if (!gpuDevice) {\n    return null;\n  }\n  return {\n    maxStorageBufferBindingSize: gpuDevice.limits.maxStorageBufferBindingSize,\n    maxBufferSize: gpuDevice.limits.maxBufferSize,\n    maxComputeWorkgroupSizeX: gpuDevice.limits.maxComputeWorkgroupSizeX,\n    maxComputeWorkgroupSizeY: gpuDevice.limits.maxComputeWorkgroupSizeY,\n    maxComputeWorkgroupSizeZ: gpuDevice.limits.maxComputeWorkgroupSizeZ,\n    maxComputeInvocationsPerWorkgroup: gpuDevice.limits.maxComputeInvocationsPerWorkgroup,\n    maxComputeWorkgroupStorageSize: gpuDevice.limits.maxComputeWorkgroupStorageSize,\n    maxStorageBuffersPerShaderStage: gpuDevice.limits.maxStorageBuffersPerShaderStage,\n    maxUniformBufferBindingSize: gpuDevice.limits.maxUniformBufferBindingSize,\n    maxComputeWorkgroupsPerDimension: gpuDevice.limits.maxComputeWorkgroupsPerDimension,\n  };\n}\n\n// Feature constants for external use\nexport { FEATURES };\n", "/**\n * Tensor Abstraction\n *\n * Wraps GPUBuffer with explicit dtype and shape metadata.\n * Ensures dtype flows through the pipeline structurally rather than\n * being tracked in a separate WeakMap.\n */\n\nexport type TensorDtype = 'f16' | 'f32';\n\n/**\n * A tensor with explicit dtype and shape.\n * Use this instead of raw GPUBuffer for dtype-sensitive operations.\n */\nexport interface Tensor {\n  readonly buffer: GPUBuffer;\n  readonly dtype: TensorDtype;\n  readonly shape: readonly number[];\n  readonly label?: string;\n}\n\n/**\n * Create a tensor from a buffer with explicit dtype.\n */\nexport function createTensor(\n  buffer: GPUBuffer,\n  dtype: TensorDtype,\n  shape: number[],\n  label?: string\n): Tensor {\n  return {\n    buffer,\n    dtype,\n    shape: Object.freeze([...shape]),\n    label,\n  };\n}\n\n/**\n * Assert tensor has expected dtype, throw if mismatch.\n */\nexport function assertDtype(\n  tensor: Tensor,\n  expected: TensorDtype,\n  operation: string\n): void {\n  if (tensor.dtype !== expected) {\n    throw new Error(\n      `${operation}: expected ${expected} tensor, got ${tensor.dtype}` +\n      (tensor.label ? ` (${tensor.label})` : '')\n    );\n  }\n}\n\n/**\n * Assert tensor has expected shape, throw if mismatch.\n */\nexport function assertShape(\n  tensor: Tensor,\n  expected: readonly number[],\n  operation: string\n): void {\n  if (tensor.shape.length !== expected.length) {\n    throw new Error(\n      `${operation}: expected ${expected.length}D tensor, got ${tensor.shape.length}D` +\n      (tensor.label ? ` (${tensor.label})` : '')\n    );\n  }\n  for (let i = 0; i < expected.length; i++) {\n    if (expected[i] !== -1 && tensor.shape[i] !== expected[i]) {\n      throw new Error(\n        `${operation}: shape mismatch at dim ${i}: expected ${expected[i]}, got ${tensor.shape[i]}` +\n        (tensor.label ? ` (${tensor.label})` : '')\n      );\n    }\n  }\n}\n\n/**\n * Get bytes per element for dtype.\n */\nexport function dtypeBytes(dtype: TensorDtype): number {\n  return dtype === 'f16' ? 2 : 4;\n}\n\n/**\n * Compute total byte size for a tensor.\n */\nexport function tensorBytes(shape: readonly number[], dtype: TensorDtype): number {\n  return shape.reduce((a, b) => a * b, 1) * dtypeBytes(dtype);\n}\n\n/**\n * Check if two tensors have compatible dtypes for an operation.\n */\nexport function dtypesMatch(a: Tensor, b: Tensor): boolean {\n  return a.dtype === b.dtype;\n}\n\n/**\n * Determine output dtype for a binary operation.\n * F16 only if both inputs are F16.\n */\nexport function inferOutputDtype(a: Tensor, b: Tensor): TensorDtype {\n  return (a.dtype === 'f16' && b.dtype === 'f16') ? 'f16' : 'f32';\n}\n", "/**\n * GPU Profiler - Timestamp-based Performance Profiling\n *\n * Provides GPU-side timing using WebGPU timestamp queries.\n * Falls back to CPU timing when timestamp queries unavailable.\n *\n * Usage:\n *   const profiler = new GPUProfiler(device);\n *   profiler.begin('matmul');\n *   // ... dispatch compute pass ...\n *   profiler.end('matmul');\n *   await profiler.resolve();\n *   log.info('GPUProfiler', 'Results', profiler.getResults());\n */\n\nimport { getDevice, hasFeature, FEATURES } from './device.js';\nimport { allowReadback } from './perf-guards.js';\nimport type { ProfileEvent, ProfileSession } from '../types/gpu.js';\nimport { log } from '../debug/index.js';\n\n/**\n * Profiling result for a single label\n */\nexport interface ProfileResult {\n  /** Average time in milliseconds */\n  avg: number;\n  /** Minimum time in milliseconds */\n  min: number;\n  /** Maximum time in milliseconds */\n  max: number;\n  /** Number of samples */\n  count: number;\n  /** Total time in milliseconds */\n  total: number;\n}\n\n/**\n * Internal tracking state for active measurements\n */\ninterface ActiveMeasurement {\n  startQueryIndex: number;\n  cpuStartTime: number;\n}\n\n/**\n * Internal tracking state for CPU-only measurements\n */\ninterface CpuMeasurement {\n  cpuStartTime: number;\n}\n\n/**\n * Pending timestamp query resolution\n */\ninterface PendingResolve {\n  label: string;\n  startIndex: number;\n  endIndex: number;\n  cpuStartTime: number;\n  cpuEndTime: number;\n}\n\n/**\n * Internal result storage\n */\ninterface ResultData {\n  times: number[];\n  min: number;\n  max: number;\n  sum: number;\n  count: number;\n}\n\n/**\n * GPU Profiler using timestamp queries\n */\nexport class GPUProfiler {\n  private device: GPUDevice | null;\n  private hasTimestampQuery: boolean;\n\n  // Query set for timestamp queries (if supported)\n  private querySet: GPUQuerySet | null = null;\n  private queryBuffer: GPUBuffer | null = null;\n  private readbackBuffer: GPUBuffer | null = null;\n  private queryCapacity = 256; // Max number of timestamp pairs\n\n  // Tracking state\n  private activeLabels: Map<string, ActiveMeasurement | CpuMeasurement> = new Map();\n  private nextQueryIndex = 0;\n  private pendingResolves: PendingResolve[] = [];\n\n  // Results storage\n  private results: Map<string, ResultData> = new Map();\n\n  // CPU fallback timing\n  private cpuTimings: Map<string, number> = new Map();\n\n  /**\n   * @param device - WebGPU device (uses global if not provided)\n   */\n  constructor(device: GPUDevice | null = null) {\n    this.device = device || getDevice();\n    this.hasTimestampQuery = this.device?.features?.has(FEATURES.TIMESTAMP_QUERY) ?? false;\n\n    // Initialize query resources if timestamp queries available\n    if (this.hasTimestampQuery && this.device) {\n      this._initQueryResources();\n    }\n  }\n\n  /**\n   * Initialize GPU query resources\n   * @private\n   */\n  private _initQueryResources(): void {\n    if (!this.device) return;\n\n    try {\n      this.querySet = this.device.createQuerySet({\n        type: 'timestamp',\n        count: this.queryCapacity * 2, // Start and end for each measurement\n      });\n\n      // Buffer to hold query results (8 bytes per timestamp)\n      this.queryBuffer = this.device.createBuffer({\n        size: this.queryCapacity * 2 * 8,\n        usage: GPUBufferUsage.QUERY_RESOLVE | GPUBufferUsage.COPY_SRC,\n      });\n\n      // Readback buffer\n      this.readbackBuffer = this.device.createBuffer({\n        size: this.queryCapacity * 2 * 8,\n        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,\n      });\n    } catch (e) {\n      log.warn('GPUProfiler', `Failed to create timestamp query resources: ${e}`);\n      this.hasTimestampQuery = false;\n    }\n  }\n\n  /**\n   * Begin timing a labeled region.\n   * Uses CPU timing; use writeTimestamp() inside passes for GPU timestamps.\n   * @param label - Unique label for this measurement\n   */\n  begin(label: string): void {\n    if (this.activeLabels.has(label)) {\n      log.warn('GPUProfiler', `Label \"${label}\" already active`);\n      return;\n    }\n\n    const startTime = performance.now();\n\n    // CPU timing for begin/end; GPU timestamps require writeTimestamp() in a pass.\n    this.activeLabels.set(label, {\n      cpuStartTime: startTime,\n    });\n  }\n\n  /**\n   * End timing a labeled region\n   * @param label - Label started with begin()\n   */\n  end(label: string): void {\n    const active = this.activeLabels.get(label);\n    if (!active) {\n      log.warn('GPUProfiler', `No active measurement for label \"${label}\"`);\n      return;\n    }\n\n    const endTime = performance.now();\n    this.activeLabels.delete(label);\n\n    if (this.hasTimestampQuery && 'startQueryIndex' in active) {\n      // GPU timing will be resolved later\n      this.pendingResolves.push({\n        label,\n        startIndex: active.startQueryIndex,\n        endIndex: active.startQueryIndex + 1,\n        cpuStartTime: active.cpuStartTime,\n        cpuEndTime: endTime,\n      });\n    } else {\n      // CPU fallback - record immediately\n      this._recordResult(label, endTime - active.cpuStartTime);\n    }\n  }\n\n  /**\n   * Write timestamp to query set within a compute pass\n   * Call this instead of begin/end when inside a pass\n   * @param pass - Compute pass encoder\n   * @param label - Label for this measurement\n   * @param isEnd - true for end timestamp\n   */\n  writeTimestamp(pass: GPUComputePassEncoder, label: string, isEnd = false): void {\n    if (!this.hasTimestampQuery || !this.querySet) return;\n\n    let queryIndex: number;\n    if (!isEnd) {\n      // Start timestamp\n      queryIndex = this.nextQueryIndex;\n      this.nextQueryIndex += 2;\n      this.activeLabels.set(label, {\n        startQueryIndex: queryIndex,\n        cpuStartTime: performance.now(),\n      });\n    } else {\n      // End timestamp\n      const active = this.activeLabels.get(label);\n      if (!active || !('startQueryIndex' in active)) return;\n      queryIndex = active.startQueryIndex + 1;\n      this.activeLabels.delete(label);\n      this.pendingResolves.push({\n        label,\n        startIndex: active.startQueryIndex,\n        endIndex: queryIndex,\n        cpuStartTime: active.cpuStartTime,\n        cpuEndTime: performance.now(),\n      });\n    }\n\n    // Note: writeTimestamp is deprecated in modern WebGPU spec but still works in Chrome\n    // Future: migrate to timestampWrites in GPUComputePassDescriptor\n    (pass as any).writeTimestamp(this.querySet, queryIndex);\n  }\n\n  /**\n   * Resolve pending timestamp queries and update results\n   * Call this after command buffer submission\n   */\n  async resolve(): Promise<void> {\n    if (!this.hasTimestampQuery || this.pendingResolves.length === 0) {\n      return;\n    }\n\n    if (!this.device || !this.querySet || !this.queryBuffer || !this.readbackBuffer) {\n      log.warn('GPUProfiler', 'Missing required resources for resolve');\n      return;\n    }\n\n    const encoder = this.device.createCommandEncoder();\n\n    // Resolve all timestamps to buffer\n    const maxIndex = Math.max(...this.pendingResolves.map(p => p.endIndex)) + 1;\n    encoder.resolveQuerySet(this.querySet, 0, maxIndex, this.queryBuffer, 0);\n\n    // Copy to readback buffer\n    encoder.copyBufferToBuffer(\n      this.queryBuffer,\n      0,\n      this.readbackBuffer,\n      0,\n      maxIndex * 8\n    );\n\n    this.device.queue.submit([encoder.finish()]);\n\n    if (!allowReadback('GPUProfiler.resolve')) {\n      return;\n    }\n\n    // Read back timestamps\n    await this.readbackBuffer.mapAsync(GPUMapMode.READ);\n    const timestamps = new BigUint64Array(this.readbackBuffer.getMappedRange());\n\n    // Process pending resolves\n    for (const pending of this.pendingResolves) {\n      const startNs = timestamps[pending.startIndex];\n      const endNs = timestamps[pending.endIndex];\n\n      // Convert nanoseconds to milliseconds\n      const durationMs = Number(endNs - startNs) / 1_000_000;\n\n      // Sanity check - use CPU timing if GPU timing seems wrong\n      if (durationMs < 0 || durationMs > 60000) {\n        // Fallback to CPU timing\n        this._recordResult(pending.label, pending.cpuEndTime - pending.cpuStartTime);\n      } else {\n        this._recordResult(pending.label, durationMs);\n      }\n    }\n\n    this.readbackBuffer.unmap();\n    this.pendingResolves = [];\n    this.nextQueryIndex = 0;\n  }\n\n  /**\n   * Record a timing result\n   * @private\n   */\n  private _recordResult(label: string, timeMs: number): void {\n    if (!this.results.has(label)) {\n      this.results.set(label, {\n        times: [],\n        min: Infinity,\n        max: -Infinity,\n        sum: 0,\n        count: 0,\n      });\n    }\n\n    const result = this.results.get(label)!;\n    result.times.push(timeMs);\n    result.min = Math.min(result.min, timeMs);\n    result.max = Math.max(result.max, timeMs);\n    result.sum += timeMs;\n    result.count++;\n\n    // Keep only last 100 samples for running average\n    if (result.times.length > 100) {\n      const removed = result.times.shift()!;\n      result.sum -= removed;\n      result.count--;\n      // Recalculate min/max if needed (expensive, so only do occasionally)\n      if (result.times.length % 20 === 0) {\n        result.min = Math.min(...result.times);\n        result.max = Math.max(...result.times);\n      }\n    }\n  }\n\n  /**\n   * Get profiling results\n   */\n  getResults(): Record<string, ProfileResult> {\n    const output: Record<string, ProfileResult> = {};\n\n    for (const [label, data] of this.results) {\n      output[label] = {\n        avg: data.sum / data.count,\n        min: data.min,\n        max: data.max,\n        count: data.count,\n        total: data.sum,\n      };\n    }\n\n    return output;\n  }\n\n  /**\n   * Get result for a specific label\n   * @param label - Label to get result for\n   */\n  getResult(label: string): ProfileResult | null {\n    const data = this.results.get(label);\n    if (!data) return null;\n\n    return {\n      avg: data.sum / data.count,\n      min: data.min,\n      max: data.max,\n      count: data.count,\n      total: data.sum,\n    };\n  }\n\n  /**\n   * Reset all profiling data\n   */\n  reset(): void {\n    this.results.clear();\n    this.activeLabels.clear();\n    this.pendingResolves = [];\n    this.nextQueryIndex = 0;\n  }\n\n  /**\n   * Get formatted report string\n   */\n  getReport(): string {\n    const results = this.getResults();\n    const labels = Object.keys(results).sort();\n\n    if (labels.length === 0) {\n      return 'No profiling data collected';\n    }\n\n    let report = 'GPU Profiler Results\\n';\n    report += '\u2500'.repeat(60) + '\\n';\n    report += 'Label'.padEnd(30) + 'Avg (ms)'.padStart(10) + 'Min'.padStart(10) + 'Max'.padStart(10) + '\\n';\n    report += '\u2500'.repeat(60) + '\\n';\n\n    for (const label of labels) {\n      const r = results[label];\n      report += label.padEnd(30);\n      report += r.avg.toFixed(3).padStart(10);\n      report += r.min.toFixed(3).padStart(10);\n      report += r.max.toFixed(3).padStart(10);\n      report += '\\n';\n    }\n\n    return report;\n  }\n\n  /**\n   * Check if timestamp queries are available\n   */\n  isGPUTimingAvailable(): boolean {\n    return this.hasTimestampQuery;\n  }\n\n  /**\n   * Destroy profiler resources\n   */\n  destroy(): void {\n    if (this.querySet) {\n      this.querySet.destroy();\n      this.querySet = null;\n    }\n    if (this.queryBuffer) {\n      this.queryBuffer.destroy();\n      this.queryBuffer = null;\n    }\n    if (this.readbackBuffer) {\n      this.readbackBuffer.destroy();\n      this.readbackBuffer = null;\n    }\n    this.results.clear();\n    this.activeLabels.clear();\n  }\n}\n\n// Global profiler instance\nlet globalProfiler: GPUProfiler | null = null;\n\n/**\n * Get the global profiler instance\n */\nexport function getProfiler(): GPUProfiler {\n  if (!globalProfiler) {\n    globalProfiler = new GPUProfiler();\n  }\n  return globalProfiler;\n}\n\n/**\n * Create a new profiler instance\n * @param device - Optional GPU device\n */\nexport function createProfiler(device?: GPUDevice | null): GPUProfiler {\n  return new GPUProfiler(device);\n}\n\n/**\n * Convenience function to time a single operation\n * @param label - Label for the operation\n * @param fn - Async function to time\n */\nexport async function timeOperation<T>(\n  label: string,\n  fn: () => Promise<T>\n): Promise<{ result: T; timeMs: number }> {\n  const profiler = getProfiler();\n  profiler.begin(label);\n  const result = await fn();\n  profiler.end(label);\n  await profiler.resolve();\n\n  const timing = profiler.getResult(label);\n  return {\n    result,\n    timeMs: timing?.avg ?? 0,\n  };\n}\n\nexport default GPUProfiler;\n", "/**\n * Kernel Auto-Tuner - Optimal Workgroup Size Selection\n *\n * Automatically finds optimal workgroup sizes for different kernels\n * by running benchmarks with various configurations.\n *\n * Results are cached in localStorage for persistence across sessions.\n */\n\nimport { getDevice, getKernelCapabilities, getDeviceLimits } from './device.js';\nimport { GPUProfiler } from './profiler.js';\nimport { log } from '../debug/index.js';\nimport { getRuntimeConfig } from '../config/runtime.js';\n\nfunction getTunerConfig() {\n  return getRuntimeConfig().tuner;\n}\n\n/**\n * Device information for cache keys\n */\ninterface DeviceInfo {\n  vendor: string;\n  architecture: string;\n  device: string;\n  description?: string;\n}\n\n/**\n * Tuning result for a kernel\n */\ninterface TuneResult {\n  optimalWorkgroupSize: [number, number, number];\n  optimalTileSize: number;\n  throughput: number;\n  timeMs: number;\n  deviceInfo: DeviceInfo | undefined;\n}\n\n/**\n * Tuning record stored in cache\n */\ninterface TuneRecord {\n  optimalWorkgroupSize: [number, number, number];\n  optimalTileSize: number;\n  throughput: number;\n  timeMs: number;\n  deviceInfo: DeviceInfo | undefined;\n}\n\n/**\n * Tuning configuration options\n */\ninterface TuneConfig {\n  warmup?: number;\n  iterations?: number;\n  forceRetune?: boolean;\n}\n\n/**\n * Input sizes for kernel tuning\n */\ninterface InputSizes {\n  M?: number;\n  N?: number;\n  K?: number;\n  seqLen?: number;\n  numHeads?: number;\n  headDim?: number;\n  innerSize?: number;\n  outerSize?: number;\n  hiddenSize?: number;\n  numTokens?: number;\n  numBlocks?: number;\n}\n\n/**\n * Workgroup size candidate\n */\ntype WorkgroupSize = [number, number, number];\n\n/**\n * Device limits from GPU\n */\ninterface DeviceLimits {\n  maxStorageBufferBindingSize: number;\n  maxBufferSize: number;\n  maxComputeWorkgroupSizeX: number;\n  maxComputeWorkgroupSizeY: number;\n  maxComputeWorkgroupSizeZ: number;\n  maxComputeInvocationsPerWorkgroup: number;\n  maxComputeWorkgroupStorageSize: number;\n  maxStorageBuffersPerShaderStage: number;\n}\n\n/**\n * Kernel capabilities from GPU\n */\ninterface KernelCapabilities {\n  hasSubgroups: boolean;\n  hasSubgroupsF16: boolean;\n  hasF16: boolean;\n  hasTimestampQuery: boolean;\n  maxBufferSize: number;\n  maxWorkgroupSize: number;\n  maxWorkgroupStorageSize: number;\n  adapterInfo: DeviceInfo;\n}\n\n/**\n * Cache storage key type\n */\ntype CacheKey = string;\n\n/**\n * Kernel Tuner class\n */\nexport class KernelTuner {\n  private device: GPUDevice | null;\n  private profiler: GPUProfiler | null;\n  private limits: DeviceLimits | null;\n  private capabilities: KernelCapabilities | null;\n  private cache: Map<CacheKey, TuneRecord>;\n\n  constructor() {\n    this.device = null;\n    this.profiler = null;\n    this.limits = null;\n    this.capabilities = null;\n    this.cache = new Map();\n  }\n\n  /**\n   * Initialize the tuner\n   */\n  async init(): Promise<void> {\n    this.device = getDevice();\n    if (!this.device) {\n      throw new Error('GPU device not initialized');\n    }\n\n    this.profiler = new GPUProfiler(this.device);\n    this.limits = getDeviceLimits();\n    this.capabilities = getKernelCapabilities();\n\n    // Load cached results\n    this._loadCache();\n  }\n\n  /**\n   * Get device signature for cache key\n   * @private\n   */\n  private _getDeviceSignature(): string {\n    const info: DeviceInfo = this.capabilities?.adapterInfo || { vendor: '', architecture: '', device: '' };\n    return `${info.vendor}_${info.architecture}_${info.device}`.replace(/[^a-zA-Z0-9]/g, '_');\n  }\n\n  /**\n   * Load cached tuning results from localStorage\n   * @private\n   */\n  private _loadCache(): void {\n    if (typeof localStorage === 'undefined') return;\n\n    const signature = this._getDeviceSignature();\n    const cacheKey = getTunerConfig().cacheKeyPrefix + signature;\n\n    try {\n      const cached = localStorage.getItem(cacheKey);\n      if (cached) {\n        const data = JSON.parse(cached);\n        this.cache = new Map(Object.entries(data));\n      }\n    } catch (e) {\n      log.warn('KernelTuner', `Failed to load cache: ${e}`);\n    }\n  }\n\n  /**\n   * Save cached results to localStorage\n   * @private\n   */\n  private _saveCache(): void {\n    if (typeof localStorage === 'undefined') return;\n\n    const signature = this._getDeviceSignature();\n    const cacheKey = getTunerConfig().cacheKeyPrefix + signature;\n\n    try {\n      const data = Object.fromEntries(this.cache);\n      localStorage.setItem(cacheKey, JSON.stringify(data));\n    } catch (e) {\n      log.warn('KernelTuner', `Failed to save cache: ${e}`);\n    }\n  }\n\n  /**\n   * Generate workgroup size candidates based on device limits\n   * @private\n   */\n  private _generateWorkgroupCandidates(): WorkgroupSize[] {\n    const maxX = this.limits?.maxComputeWorkgroupSizeX || 256;\n    const maxY = this.limits?.maxComputeWorkgroupSizeY || 256;\n    const maxInvocations = this.limits?.maxComputeInvocationsPerWorkgroup || 256;\n\n    const candidates: WorkgroupSize[] = [];\n\n    // 1D workgroups\n    for (const x of [64, 128, 256, 512]) {\n      if (x <= maxX && x <= maxInvocations) {\n        candidates.push([x, 1, 1]);\n      }\n    }\n\n    // 2D workgroups (for matrix operations)\n    for (const x of [8, 16, 32]) {\n      for (const y of [8, 16, 32]) {\n        if (x <= maxX && y <= maxY && x * y <= maxInvocations) {\n          candidates.push([x, y, 1]);\n        }\n      }\n    }\n\n    return candidates;\n  }\n\n  /**\n   * Tune a kernel by running benchmarks\n   * @param kernelName - Name of kernel to tune\n   * @param inputSizes - Input dimensions for tuning\n   * @param options - Tuning options\n   * @returns Promise resolving to tuning result\n   */\n  async tuneKernel(\n    kernelName: string,\n    inputSizes: InputSizes,\n    options: TuneConfig = {}\n  ): Promise<TuneResult> {\n    const {\n      warmup = getTunerConfig().defaultWarmupIterations,\n      iterations = getTunerConfig().defaultTimedIterations,\n      forceRetune = false,\n    } = options;\n\n    // Check cache\n    const cacheKey: CacheKey = `${kernelName}_${JSON.stringify(inputSizes)}`;\n    if (!forceRetune && this.cache.has(cacheKey)) {\n      return this.cache.get(cacheKey)!;\n    }\n\n    // Get candidates to test\n    const candidates = this._generateWorkgroupCandidates();\n\n    // Run tuning based on kernel type\n    let bestResult: TuneResult;\n\n    switch (kernelName) {\n      case 'matmul':\n        bestResult = await this._tuneMatmul(inputSizes, candidates, warmup, iterations);\n        break;\n      case 'attention':\n        bestResult = await this._tuneAttention(inputSizes, candidates, warmup, iterations);\n        break;\n      case 'softmax':\n        bestResult = await this._tuneSoftmax(inputSizes, candidates, warmup, iterations);\n        break;\n      case 'rmsnorm':\n        bestResult = await this._tuneRMSNorm(inputSizes, candidates, warmup, iterations);\n        break;\n      case 'dequant':\n        bestResult = await this._tuneDequant(inputSizes, candidates, warmup, iterations);\n        break;\n      default:\n        bestResult = await this._tuneGeneric(kernelName, inputSizes, candidates, warmup, iterations);\n    }\n\n    // Cache result\n    this.cache.set(cacheKey, bestResult);\n    this._saveCache();\n\n    return bestResult;\n  }\n\n  /**\n   * Tune matmul kernel\n   * @private\n   */\n  private async _tuneMatmul(\n    inputSizes: InputSizes,\n    candidates: WorkgroupSize[],\n    warmup: number,\n    iterations: number\n  ): Promise<TuneResult> {\n    const { M = 1024, N = 1024, K = 1024 } = inputSizes;\n\n    // Filter to 2D candidates for matmul\n    const matmulCandidates = candidates.filter(c => c[1] > 1);\n\n    let best: TuneResult = {\n      optimalWorkgroupSize: [16, 16, 1],\n      optimalTileSize: 16,\n      throughput: 0,\n      timeMs: Infinity,\n      deviceInfo: this.capabilities?.adapterInfo,\n    };\n\n    if (!this.device) {\n      return best;\n    }\n\n    // Create test buffers\n    const bufferA = this.device.createBuffer({\n      size: M * K * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferB = this.device.createBuffer({\n      size: K * N * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferC = this.device.createBuffer({\n      size: M * N * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,\n    });\n\n    // Initialize with random data\n    const dataA = new Float32Array(M * K);\n    const dataB = new Float32Array(K * N);\n    for (let i = 0; i < dataA.length; i++) dataA[i] = Math.random();\n    for (let i = 0; i < dataB.length; i++) dataB[i] = Math.random();\n    this.device.queue.writeBuffer(bufferA, 0, dataA);\n    this.device.queue.writeBuffer(bufferB, 0, dataB);\n\n    for (const [wgX, wgY] of matmulCandidates) {\n      try {\n        // Create shader with this workgroup size\n        const shader = this._createMatmulShader(wgX, wgY);\n        const pipeline = await this._createComputePipeline(shader, 'main');\n\n        // Create bind group\n        const uniformBuffer = this.device.createBuffer({\n          size: 16,\n          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n        });\n        const uniformData = new Uint32Array([M, N, K, 0]);\n        this.device.queue.writeBuffer(uniformBuffer, 0, uniformData);\n\n        const bindGroup = this.device.createBindGroup({\n          layout: pipeline.getBindGroupLayout(0),\n          entries: [\n            { binding: 0, resource: { buffer: uniformBuffer } },\n            { binding: 1, resource: { buffer: bufferA } },\n            { binding: 2, resource: { buffer: bufferB } },\n            { binding: 3, resource: { buffer: bufferC } },\n          ],\n        });\n\n        // Warmup\n        for (let i = 0; i < warmup; i++) {\n          const encoder = this.device.createCommandEncoder();\n          const pass = encoder.beginComputePass();\n          pass.setPipeline(pipeline);\n          pass.setBindGroup(0, bindGroup);\n          pass.dispatchWorkgroups(Math.ceil(M / wgX), Math.ceil(N / wgY));\n          pass.end();\n          this.device.queue.submit([encoder.finish()]);\n        }\n        await this.device.queue.onSubmittedWorkDone();\n\n        // Benchmark\n        const times: number[] = [];\n        for (let i = 0; i < iterations; i++) {\n          const start = performance.now();\n          const encoder = this.device.createCommandEncoder();\n          const pass = encoder.beginComputePass();\n          pass.setPipeline(pipeline);\n          pass.setBindGroup(0, bindGroup);\n          pass.dispatchWorkgroups(Math.ceil(M / wgX), Math.ceil(N / wgY));\n          pass.end();\n          this.device.queue.submit([encoder.finish()]);\n          await this.device.queue.onSubmittedWorkDone();\n          times.push(performance.now() - start);\n        }\n\n        const avgTime = times.reduce((a, b) => a + b, 0) / times.length;\n        const flops = 2 * M * N * K; // multiply-add = 2 ops\n        const gflops = (flops / avgTime) / 1e6; // GFLOPS\n\n        if (avgTime < best.timeMs) {\n          best = {\n            optimalWorkgroupSize: [wgX, wgY, 1],\n            optimalTileSize: wgX,\n            throughput: gflops,\n            timeMs: avgTime,\n            deviceInfo: this.capabilities?.adapterInfo,\n          };\n        }\n\n        uniformBuffer.destroy();\n      } catch (e) {\n        // Skip invalid configurations\n        continue;\n      }\n    }\n\n    // Cleanup\n    bufferA.destroy();\n    bufferB.destroy();\n    bufferC.destroy();\n\n    return best;\n  }\n\n  /**\n   * Create matmul shader with specified workgroup size\n   * @private\n   */\n  private _createMatmulShader(wgX: number, wgY: number): string {\n    return `\nstruct Uniforms {\n    M: u32, N: u32, K: u32, _pad: u32,\n}\n@group(0) @binding(0) var<uniform> uniforms: Uniforms;\n@group(0) @binding(1) var<storage, read> A: array<f32>;\n@group(0) @binding(2) var<storage, read> B: array<f32>;\n@group(0) @binding(3) var<storage, read_write> C: array<f32>;\n\n@compute @workgroup_size(${wgX}, ${wgY}, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    let row = gid.x;\n    let col = gid.y;\n    if (row >= uniforms.M || col >= uniforms.N) { return; }\n\n    var sum: f32 = 0.0;\n    for (var k: u32 = 0u; k < uniforms.K; k = k + 1u) {\n        sum = sum + A[row * uniforms.K + k] * B[k * uniforms.N + col];\n    }\n    C[row * uniforms.N + col] = sum;\n}`;\n  }\n\n  /**\n   * Tune attention kernel\n   * @private\n   */\n  private async _tuneAttention(\n    inputSizes: InputSizes,\n    candidates: WorkgroupSize[],\n    warmup: number,\n    iterations: number\n  ): Promise<TuneResult> {\n    // For attention, test 1D workgroups\n    const { seqLen = 2048, numHeads = 32, headDim = 128 } = inputSizes;\n\n    let best: TuneResult = {\n      optimalWorkgroupSize: [64, 1, 1],\n      optimalTileSize: 64,\n      throughput: 0,\n      timeMs: Infinity,\n      deviceInfo: this.capabilities?.adapterInfo,\n    };\n\n    if (!this.device) {\n      return best;\n    }\n\n    const attentionCandidates = candidates.filter(c => c[1] === 1);\n    if (attentionCandidates.length === 0) {\n      return best;\n    }\n\n    const maxElements = 2_000_000;\n    const totalHeadsRaw = Math.max(1, seqLen * numHeads);\n    let benchSeqLen = seqLen;\n    let totalHeads = totalHeadsRaw;\n    let totalElements = totalHeads * headDim;\n\n    if (totalElements > maxElements) {\n      benchSeqLen = Math.max(1, Math.floor(maxElements / (numHeads * headDim)));\n      totalHeads = Math.max(1, benchSeqLen * numHeads);\n      totalElements = totalHeads * headDim;\n    }\n\n    const bufferQ = this.device.createBuffer({\n      size: totalElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferK = this.device.createBuffer({\n      size: totalElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferOut = this.device.createBuffer({\n      size: totalHeads * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,\n    });\n\n    const dataQ = new Float32Array(totalElements);\n    const dataK = new Float32Array(totalElements);\n    for (let i = 0; i < totalElements; i++) {\n      dataQ[i] = Math.random();\n      dataK[i] = Math.random();\n    }\n    this.device.queue.writeBuffer(bufferQ, 0, dataQ);\n    this.device.queue.writeBuffer(bufferK, 0, dataK);\n\n    for (const [wgX] of attentionCandidates) {\n      try {\n        const shader = this._createAttentionShader(wgX);\n        const pipeline = await this._createComputePipeline(shader, 'main');\n\n        const uniformBuffer = this.device.createBuffer({\n          size: 16,\n          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n        });\n        const uniformData = new Uint32Array([headDim, numHeads, benchSeqLen, 0]);\n        this.device.queue.writeBuffer(uniformBuffer, 0, uniformData);\n\n        const bindGroup = this.device.createBindGroup({\n          layout: pipeline.getBindGroupLayout(0),\n          entries: [\n            { binding: 0, resource: { buffer: uniformBuffer } },\n            { binding: 1, resource: { buffer: bufferQ } },\n            { binding: 2, resource: { buffer: bufferK } },\n            { binding: 3, resource: { buffer: bufferOut } },\n          ],\n        });\n\n        const avgTime = await this._benchmarkPipeline(\n          pipeline,\n          bindGroup,\n          [totalHeads, 1, 1],\n          warmup,\n          iterations\n        );\n\n        const flops = 2 * totalHeads * headDim;\n        const gflops = avgTime > 0 ? (flops / avgTime) / 1e6 : 0;\n\n        if (avgTime < best.timeMs) {\n          best = {\n            optimalWorkgroupSize: [wgX, 1, 1],\n            optimalTileSize: wgX,\n            throughput: gflops,\n            timeMs: avgTime,\n            deviceInfo: this.capabilities?.adapterInfo,\n          };\n        }\n\n        uniformBuffer.destroy();\n      } catch (e) {\n        continue;\n      }\n    }\n\n    bufferQ.destroy();\n    bufferK.destroy();\n    bufferOut.destroy();\n\n    return best;\n  }\n\n  /**\n   * Tune softmax kernel\n   * @private\n   */\n  private async _tuneSoftmax(\n    inputSizes: InputSizes,\n    candidates: WorkgroupSize[],\n    warmup: number,\n    iterations: number\n  ): Promise<TuneResult> {\n    const { innerSize = 32000, outerSize = 1 } = inputSizes;\n\n    let best: TuneResult = {\n      optimalWorkgroupSize: [256, 1, 1],\n      optimalTileSize: 256,\n      throughput: 0,\n      timeMs: Infinity,\n      deviceInfo: this.capabilities?.adapterInfo,\n    };\n\n    if (!this.device) {\n      return best;\n    }\n\n    const softmaxCandidates = candidates.filter(c => c[1] === 1);\n    if (softmaxCandidates.length === 0) {\n      return best;\n    }\n\n    const totalElements = Math.max(1, innerSize * outerSize);\n\n    const bufferIn = this.device.createBuffer({\n      size: totalElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferOut = this.device.createBuffer({\n      size: totalElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,\n    });\n\n    const dataIn = new Float32Array(totalElements);\n    for (let i = 0; i < totalElements; i++) {\n      dataIn[i] = Math.random();\n    }\n    this.device.queue.writeBuffer(bufferIn, 0, dataIn);\n\n    for (const [wgX] of softmaxCandidates) {\n      try {\n        const shader = this._createSoftmaxShader(wgX);\n        const pipeline = await this._createComputePipeline(shader, 'main');\n\n        const uniformBuffer = this.device.createBuffer({\n          size: 16,\n          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n        });\n        const uniformData = new Uint32Array([innerSize, outerSize, 0, 0]);\n        this.device.queue.writeBuffer(uniformBuffer, 0, uniformData);\n\n        const bindGroup = this.device.createBindGroup({\n          layout: pipeline.getBindGroupLayout(0),\n          entries: [\n            { binding: 0, resource: { buffer: uniformBuffer } },\n            { binding: 1, resource: { buffer: bufferIn } },\n            { binding: 2, resource: { buffer: bufferOut } },\n          ],\n        });\n\n        const avgTime = await this._benchmarkPipeline(\n          pipeline,\n          bindGroup,\n          [outerSize, 1, 1],\n          warmup,\n          iterations\n        );\n\n        const ops = 2 * totalElements;\n        const gops = avgTime > 0 ? (ops / avgTime) / 1e6 : 0;\n\n        if (avgTime < best.timeMs) {\n          best = {\n            optimalWorkgroupSize: [wgX, 1, 1],\n            optimalTileSize: wgX,\n            throughput: gops,\n            timeMs: avgTime,\n            deviceInfo: this.capabilities?.adapterInfo,\n          };\n        }\n\n        uniformBuffer.destroy();\n      } catch (e) {\n        continue;\n      }\n    }\n\n    bufferIn.destroy();\n    bufferOut.destroy();\n\n    return best;\n  }\n\n  /**\n   * Tune RMSNorm kernel\n   * @private\n   */\n  private async _tuneRMSNorm(\n    inputSizes: InputSizes,\n    candidates: WorkgroupSize[],\n    warmup: number,\n    iterations: number\n  ): Promise<TuneResult> {\n    const { hiddenSize = 4096, numTokens = 1 } = inputSizes;\n\n    let best: TuneResult = {\n      optimalWorkgroupSize: [256, 1, 1],\n      optimalTileSize: 256,\n      throughput: 0,\n      timeMs: Infinity,\n      deviceInfo: this.capabilities?.adapterInfo,\n    };\n\n    if (!this.device) {\n      return best;\n    }\n\n    const rmsCandidates = candidates.filter(c => c[1] === 1);\n    if (rmsCandidates.length === 0) {\n      return best;\n    }\n\n    const totalElements = Math.max(1, hiddenSize * numTokens);\n\n    const bufferIn = this.device.createBuffer({\n      size: totalElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferWeight = this.device.createBuffer({\n      size: hiddenSize * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferOut = this.device.createBuffer({\n      size: totalElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,\n    });\n\n    const dataIn = new Float32Array(totalElements);\n    const dataWeight = new Float32Array(hiddenSize);\n    for (let i = 0; i < totalElements; i++) {\n      dataIn[i] = Math.random();\n    }\n    for (let i = 0; i < hiddenSize; i++) {\n      dataWeight[i] = Math.random();\n    }\n    this.device.queue.writeBuffer(bufferIn, 0, dataIn);\n    this.device.queue.writeBuffer(bufferWeight, 0, dataWeight);\n\n    for (const [wgX] of rmsCandidates) {\n      try {\n        const shader = this._createRMSNormShader(wgX);\n        const pipeline = await this._createComputePipeline(shader, 'main');\n\n        const uniformBuffer = this.device.createBuffer({\n          size: 16,\n          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n        });\n        const uniformData = new ArrayBuffer(16);\n        const uniformView = new DataView(uniformData);\n        uniformView.setUint32(0, hiddenSize, true);\n        uniformView.setUint32(4, numTokens, true);\n        uniformView.setFloat32(8, 1e-5, true);\n        uniformView.setUint32(12, 0, true);\n        this.device.queue.writeBuffer(uniformBuffer, 0, uniformData);\n\n        const bindGroup = this.device.createBindGroup({\n          layout: pipeline.getBindGroupLayout(0),\n          entries: [\n            { binding: 0, resource: { buffer: uniformBuffer } },\n            { binding: 1, resource: { buffer: bufferIn } },\n            { binding: 2, resource: { buffer: bufferWeight } },\n            { binding: 3, resource: { buffer: bufferOut } },\n          ],\n        });\n\n        const avgTime = await this._benchmarkPipeline(\n          pipeline,\n          bindGroup,\n          [numTokens, 1, 1],\n          warmup,\n          iterations\n        );\n\n        const ops = 2 * totalElements;\n        const gops = avgTime > 0 ? (ops / avgTime) / 1e6 : 0;\n\n        if (avgTime < best.timeMs) {\n          best = {\n            optimalWorkgroupSize: [wgX, 1, 1],\n            optimalTileSize: wgX,\n            throughput: gops,\n            timeMs: avgTime,\n            deviceInfo: this.capabilities?.adapterInfo,\n          };\n        }\n\n        uniformBuffer.destroy();\n      } catch (e) {\n        continue;\n      }\n    }\n\n    bufferIn.destroy();\n    bufferWeight.destroy();\n    bufferOut.destroy();\n\n    return best;\n  }\n\n  /**\n   * Tune dequantization kernel\n   * @private\n   */\n  private async _tuneDequant(\n    inputSizes: InputSizes,\n    candidates: WorkgroupSize[],\n    warmup: number,\n    iterations: number\n  ): Promise<TuneResult> {\n    const { numBlocks = 1000 } = inputSizes;\n\n    let best: TuneResult = {\n      optimalWorkgroupSize: [64, 1, 1],\n      optimalTileSize: 64,\n      throughput: 0,\n      timeMs: Infinity,\n      deviceInfo: this.capabilities?.adapterInfo,\n    };\n\n    if (!this.device) {\n      return best;\n    }\n\n    const dequantCandidates = candidates.filter(c => c[1] === 1);\n    if (dequantCandidates.length === 0) {\n      return best;\n    }\n\n    const numElements = Math.max(1, numBlocks * 256);\n\n    const bufferIn = this.device.createBuffer({\n      size: numElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    const bufferOut = this.device.createBuffer({\n      size: numElements * 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,\n    });\n\n    const dataIn = new Uint32Array(numElements);\n    for (let i = 0; i < numElements; i++) {\n      dataIn[i] = i & 0xffff;\n    }\n    this.device.queue.writeBuffer(bufferIn, 0, dataIn);\n\n    for (const [wgX] of dequantCandidates) {\n      try {\n        const shader = this._createDequantShader(wgX);\n        const pipeline = await this._createComputePipeline(shader, 'main');\n\n        const uniformBuffer = this.device.createBuffer({\n          size: 16,\n          usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n        });\n        const uniformData = new ArrayBuffer(16);\n        const uniformView = new DataView(uniformData);\n        uniformView.setUint32(0, numElements, true);\n        uniformView.setFloat32(4, 0.01, true);\n        uniformView.setUint32(8, 0, true);\n        uniformView.setUint32(12, 0, true);\n        this.device.queue.writeBuffer(uniformBuffer, 0, uniformData);\n\n        const bindGroup = this.device.createBindGroup({\n          layout: pipeline.getBindGroupLayout(0),\n          entries: [\n            { binding: 0, resource: { buffer: uniformBuffer } },\n            { binding: 1, resource: { buffer: bufferIn } },\n            { binding: 2, resource: { buffer: bufferOut } },\n          ],\n        });\n\n        const workgroups = Math.ceil(numElements / wgX);\n        const avgTime = await this._benchmarkPipeline(\n          pipeline,\n          bindGroup,\n          [workgroups, 1, 1],\n          warmup,\n          iterations\n        );\n\n        const ops = numElements;\n        const gops = avgTime > 0 ? (ops / avgTime) / 1e6 : 0;\n\n        if (avgTime < best.timeMs) {\n          best = {\n            optimalWorkgroupSize: [wgX, 1, 1],\n            optimalTileSize: wgX,\n            throughput: gops,\n            timeMs: avgTime,\n            deviceInfo: this.capabilities?.adapterInfo,\n          };\n        }\n\n        uniformBuffer.destroy();\n      } catch (e) {\n        continue;\n      }\n    }\n\n    bufferIn.destroy();\n    bufferOut.destroy();\n\n    return best;\n  }\n\n  /**\n   * Generic tuning for unknown kernels\n   * @private\n   */\n  private async _tuneGeneric(\n    kernelName: string,\n    inputSizes: InputSizes,\n    candidates: WorkgroupSize[],\n    warmup: number,\n    iterations: number\n  ): Promise<TuneResult> {\n    // Return sensible defaults\n    return {\n      optimalWorkgroupSize: [256, 1, 1],\n      optimalTileSize: 256,\n      throughput: 0,\n      timeMs: 0,\n      deviceInfo: this.capabilities?.adapterInfo,\n    };\n  }\n\n  private async _benchmarkPipeline(\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: [number, number, number],\n    warmup: number,\n    iterations: number\n  ): Promise<number> {\n    if (!this.device) {\n      return Infinity;\n    }\n\n    const [wgX, wgY, wgZ] = workgroups;\n    if (wgX === 0 || wgY === 0 || wgZ === 0) {\n      return Infinity;\n    }\n\n    for (let i = 0; i < warmup; i++) {\n      const encoder = this.device.createCommandEncoder();\n      const pass = encoder.beginComputePass();\n      pass.setPipeline(pipeline);\n      pass.setBindGroup(0, bindGroup);\n      pass.dispatchWorkgroups(wgX, wgY, wgZ);\n      pass.end();\n      this.device.queue.submit([encoder.finish()]);\n    }\n    await this.device.queue.onSubmittedWorkDone();\n\n    const times: number[] = [];\n    for (let i = 0; i < iterations; i++) {\n      const start = performance.now();\n      const encoder = this.device.createCommandEncoder();\n      const pass = encoder.beginComputePass();\n      pass.setPipeline(pipeline);\n      pass.setBindGroup(0, bindGroup);\n      pass.dispatchWorkgroups(wgX, wgY, wgZ);\n      pass.end();\n      this.device.queue.submit([encoder.finish()]);\n      await this.device.queue.onSubmittedWorkDone();\n      times.push(performance.now() - start);\n    }\n\n    return times.reduce((a, b) => a + b, 0) / times.length;\n  }\n\n  /**\n   * Create compute pipeline from shader source\n   * @private\n   */\n  private async _createComputePipeline(\n    shaderSource: string,\n    entryPoint: string\n  ): Promise<GPUComputePipeline> {\n    if (!this.device) {\n      throw new Error('Device not initialized');\n    }\n    const module = this.device.createShaderModule({ code: shaderSource });\n    return await this.device.createComputePipelineAsync({\n      layout: 'auto',\n      compute: { module, entryPoint },\n    });\n  }\n\n  private _createAttentionShader(wgSize: number): string {\n    return `\nconst WG_SIZE: u32 = ${wgSize}u;\n\nstruct Uniforms {\n  headDim: u32,\n  numHeads: u32,\n  seqLen: u32,\n  _pad: u32,\n}\n\n@group(0) @binding(0) var<uniform> uniforms: Uniforms;\n@group(0) @binding(1) var<storage, read> Q: array<f32>;\n@group(0) @binding(2) var<storage, read> K: array<f32>;\n@group(0) @binding(3) var<storage, read_write> Out: array<f32>;\n\nvar<workgroup> shared: array<f32, WG_SIZE>;\n\n@compute @workgroup_size(${wgSize}, 1, 1)\nfn main(\n  @builtin(workgroup_id) wg_id: vec3<u32>,\n  @builtin(local_invocation_id) local_id: vec3<u32>\n) {\n  let totalHeads = uniforms.numHeads * uniforms.seqLen;\n  let idx = wg_id.x;\n  if (idx >= totalHeads) { return; }\n\n  let headDim = uniforms.headDim;\n  let offset = idx * headDim;\n  let lane = local_id.x;\n\n  var sum: f32 = 0.0;\n  var i: u32 = lane;\n  loop {\n    if (i >= headDim) { break; }\n    sum = sum + Q[offset + i] * K[offset + i];\n    i = i + WG_SIZE;\n  }\n\n  shared[lane] = sum;\n  workgroupBarrier();\n\n  var stride: u32 = WG_SIZE / 2u;\n  loop {\n    if (stride == 0u) { break; }\n    if (lane < stride) {\n      shared[lane] = shared[lane] + shared[lane + stride];\n    }\n    workgroupBarrier();\n    stride = stride / 2u;\n  }\n\n  if (lane == 0u) {\n    Out[idx] = shared[0];\n  }\n}`;\n  }\n\n  private _createSoftmaxShader(wgSize: number): string {\n    return `\nconst WG_SIZE: u32 = ${wgSize}u;\n\nstruct Uniforms {\n  innerSize: u32,\n  outerSize: u32,\n  _pad0: u32,\n  _pad1: u32,\n}\n\n@group(0) @binding(0) var<uniform> uniforms: Uniforms;\n@group(0) @binding(1) var<storage, read> input: array<f32>;\n@group(0) @binding(2) var<storage, read_write> output: array<f32>;\n\nvar<workgroup> shared: array<f32, WG_SIZE>;\n\n@compute @workgroup_size(${wgSize}, 1, 1)\nfn main(\n  @builtin(workgroup_id) wg_id: vec3<u32>,\n  @builtin(local_invocation_id) local_id: vec3<u32>\n) {\n  let row = wg_id.x;\n  if (row >= uniforms.outerSize) { return; }\n\n  let inner = uniforms.innerSize;\n  let lane = local_id.x;\n  let offset = row * inner;\n\n  var localMax: f32 = -3.402823e+38;\n  var i: u32 = lane;\n  loop {\n    if (i >= inner) { break; }\n    localMax = max(localMax, input[offset + i]);\n    i = i + WG_SIZE;\n  }\n\n  shared[lane] = localMax;\n  workgroupBarrier();\n\n  var stride: u32 = WG_SIZE / 2u;\n  loop {\n    if (stride == 0u) { break; }\n    if (lane < stride) {\n      shared[lane] = max(shared[lane], shared[lane + stride]);\n    }\n    workgroupBarrier();\n    stride = stride / 2u;\n  }\n\n  let rowMax = shared[0];\n  var localSum: f32 = 0.0;\n  i = lane;\n  loop {\n    if (i >= inner) { break; }\n    localSum = localSum + exp(input[offset + i] - rowMax);\n    i = i + WG_SIZE;\n  }\n\n  shared[lane] = localSum;\n  workgroupBarrier();\n\n  stride = WG_SIZE / 2u;\n  loop {\n    if (stride == 0u) { break; }\n    if (lane < stride) {\n      shared[lane] = shared[lane] + shared[lane + stride];\n    }\n    workgroupBarrier();\n    stride = stride / 2u;\n  }\n\n  let denom = shared[0];\n  i = lane;\n  loop {\n    if (i >= inner) { break; }\n    output[offset + i] = exp(input[offset + i] - rowMax) / denom;\n    i = i + WG_SIZE;\n  }\n}`;\n  }\n\n  private _createRMSNormShader(wgSize: number): string {\n    return `\nconst WG_SIZE: u32 = ${wgSize}u;\n\nstruct Uniforms {\n  hiddenSize: u32,\n  numTokens: u32,\n  eps: f32,\n  _pad0: u32,\n}\n\n@group(0) @binding(0) var<uniform> uniforms: Uniforms;\n@group(0) @binding(1) var<storage, read> input: array<f32>;\n@group(0) @binding(2) var<storage, read> weight: array<f32>;\n@group(0) @binding(3) var<storage, read_write> output: array<f32>;\n\nvar<workgroup> shared: array<f32, WG_SIZE>;\n\n@compute @workgroup_size(${wgSize}, 1, 1)\nfn main(\n  @builtin(workgroup_id) wg_id: vec3<u32>,\n  @builtin(local_invocation_id) local_id: vec3<u32>\n) {\n  let tokenIdx = wg_id.x;\n  if (tokenIdx >= uniforms.numTokens) { return; }\n\n  let size = uniforms.hiddenSize;\n  let base = tokenIdx * size;\n  let lane = local_id.x;\n\n  var localSumSq: f32 = 0.0;\n  var i: u32 = lane;\n  loop {\n    if (i >= size) { break; }\n    let x = input[base + i];\n    localSumSq = localSumSq + x * x;\n    i = i + WG_SIZE;\n  }\n\n  shared[lane] = localSumSq;\n  workgroupBarrier();\n\n  var stride: u32 = WG_SIZE / 2u;\n  loop {\n    if (stride == 0u) { break; }\n    if (lane < stride) {\n      shared[lane] = shared[lane] + shared[lane + stride];\n    }\n    workgroupBarrier();\n    stride = stride / 2u;\n  }\n\n  let invRms = 1.0 / sqrt(shared[0] / f32(size) + uniforms.eps);\n  i = lane;\n  loop {\n    if (i >= size) { break; }\n    output[base + i] = input[base + i] * invRms * weight[i];\n    i = i + WG_SIZE;\n  }\n}`;\n  }\n\n  private _createDequantShader(wgSize: number): string {\n    return `\nconst WG_SIZE: u32 = ${wgSize}u;\n\nstruct Uniforms {\n  count: u32,\n  scale: f32,\n  _pad0: u32,\n  _pad1: u32,\n}\n\n@group(0) @binding(0) var<uniform> uniforms: Uniforms;\n@group(0) @binding(1) var<storage, read> input: array<u32>;\n@group(0) @binding(2) var<storage, read_write> output: array<f32>;\n\n@compute @workgroup_size(${wgSize}, 1, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n  let idx = gid.x;\n  if (idx >= uniforms.count) { return; }\n  output[idx] = f32(input[idx]) * uniforms.scale;\n}`;\n  }\n\n  /**\n   * Get cached tuning result\n   * @param kernelName - Kernel name\n   * @param inputSizes - Input sizes\n   * @returns Cached result or null\n   */\n  getCachedResult(kernelName: string, inputSizes: InputSizes): TuneResult | null {\n    const cacheKey: CacheKey = `${kernelName}_${JSON.stringify(inputSizes)}`;\n    return this.cache.get(cacheKey) || null;\n  }\n\n  /**\n   * Clear all cached results\n   */\n  clearCache(): void {\n    this.cache.clear();\n    if (typeof localStorage !== 'undefined') {\n      const signature = this._getDeviceSignature();\n      localStorage.removeItem(getTunerConfig().cacheKeyPrefix + signature);\n    }\n  }\n\n  /**\n   * Get all cached results\n   * @returns Object with all cached results\n   */\n  getAllCachedResults(): Record<string, TuneRecord> {\n    return Object.fromEntries(this.cache);\n  }\n\n  /**\n   * Destroy tuner resources\n   */\n  destroy(): void {\n    if (this.profiler) {\n      this.profiler.destroy();\n    }\n  }\n}\n\n// Global tuner instance\nlet globalTuner: KernelTuner | null = null;\n\n/**\n * Get the global kernel tuner\n * @returns Promise resolving to kernel tuner instance\n */\nexport async function getKernelTuner(): Promise<KernelTuner> {\n  if (!globalTuner) {\n    globalTuner = new KernelTuner();\n    await globalTuner.init();\n  }\n  return globalTuner;\n}\n\n/**\n * Convenience function to tune a kernel\n * @param kernelName - Kernel name\n * @param inputSizes - Input sizes\n * @returns Promise resolving to tuning result\n */\nexport async function tuneKernel(\n  kernelName: string,\n  inputSizes: InputSizes\n): Promise<TuneResult> {\n  const tuner = await getKernelTuner();\n  return tuner.tuneKernel(kernelName, inputSizes);\n}\n\nexport default KernelTuner;\n", "/**\n * Uniform Buffer Cache\n *\n * Caches small uniform buffers by content hash to avoid repeated allocations.\n * WebLLM-inspired optimization: uniform buffers with identical contents are reused\n * across kernel dispatches instead of being created fresh and destroyed each time.\n */\n\nimport { getDevice } from './device.js';\nimport { getRuntimeConfig } from '../config/runtime.js';\n\ninterface UniformCacheEntry {\n  buffer: GPUBuffer;\n  lastUsed: number;\n  refCount: number;\n}\n\ninterface UniformCacheStats {\n  hits: number;\n  misses: number;\n  evictions: number;\n  currentSize: number;\n}\n\n/**\n * Fast hash for small ArrayBuffers (uniform buffers are typically 16-64 bytes)\n * Uses FNV-1a variant for speed on small inputs\n */\nfunction hashArrayBuffer(data: ArrayBuffer | SharedArrayBuffer): string {\n  const view = new Uint8Array(data);\n  let hash = 2166136261; // FNV offset basis\n\n  for (let i = 0; i < view.length; i++) {\n    hash ^= view[i];\n    hash = Math.imul(hash, 16777619); // FNV prime\n  }\n\n  // Convert to hex string for Map key\n  return (hash >>> 0).toString(16).padStart(8, '0');\n}\n\n/**\n * Uniform Buffer Cache\n *\n * Provides content-addressed caching for uniform buffers. Buffers with\n * identical contents share the same GPU buffer, reducing allocation overhead.\n *\n * IMPORTANT: Evicted buffers are NOT destroyed immediately. They are queued\n * for deferred destruction to avoid use-after-destroy bugs when command\n * buffers reference cached uniforms that get evicted before submit.\n * Call flushPendingDestruction() after GPU work completes.\n */\nexport class UniformBufferCache {\n  private cache: Map<string, UniformCacheEntry> = new Map();\n  private stats: UniformCacheStats = {\n    hits: 0,\n    misses: 0,\n    evictions: 0,\n    currentSize: 0,\n  };\n\n  /** Buffers evicted from cache, awaiting destruction after GPU work completes */\n  private pendingDestruction: GPUBuffer[] = [];\n\n  private readonly maxEntries: number;\n  private readonly maxAgeMs: number;\n\n  constructor(\n    maxEntries: number = getRuntimeConfig().gpuCache.uniformCacheMaxEntries,\n    maxAgeMs: number = getRuntimeConfig().gpuCache.uniformCacheMaxAgeMs\n  ) {\n    this.maxEntries = maxEntries;\n    this.maxAgeMs = maxAgeMs;\n  }\n\n  /**\n   * Get or create a uniform buffer with the given contents.\n   * Returns a cached buffer if one exists with identical data.\n   */\n  getOrCreate(data: ArrayBuffer | SharedArrayBuffer, label: string): GPUBuffer {\n    const hash = hashArrayBuffer(data);\n    const existing = this.cache.get(hash);\n\n    if (existing) {\n      existing.lastUsed = performance.now();\n      existing.refCount++;\n      this.stats.hits++;\n      return existing.buffer;\n    }\n\n    // Cache miss - create new buffer\n    this.stats.misses++;\n\n    const device = getDevice();\n    if (!device) {\n      throw new Error('GPU device not initialized');\n    }\n\n    const buffer = device.createBuffer({\n      label: `${label}_cached`,\n      size: data.byteLength,\n      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n    });\n    device.queue.writeBuffer(buffer, 0, data);\n\n    // Evict if at capacity\n    if (this.cache.size >= this.maxEntries) {\n      this.evictLRU();\n    }\n\n    this.cache.set(hash, {\n      buffer,\n      lastUsed: performance.now(),\n      refCount: 1,\n    });\n    this.stats.currentSize = this.cache.size;\n\n    return buffer;\n  }\n\n  /**\n   * Release a reference to a cached buffer.\n   * Buffer is NOT destroyed - it stays in cache for reuse.\n   * Call this instead of buffer.destroy() for cached uniforms.\n   */\n  release(buffer: GPUBuffer): void {\n    // Find entry by buffer reference\n    for (const [hash, entry] of this.cache) {\n      if (entry.buffer === buffer) {\n        entry.refCount = Math.max(0, entry.refCount - 1);\n        return;\n      }\n    }\n    // Buffer not in cache - it may have been created outside the cache\n    // Don't destroy it here; caller is responsible\n  }\n\n  /**\n   * Evict least recently used entry.\n   * IMPORTANT: Buffer is NOT destroyed immediately - it's queued for deferred\n   * destruction to avoid use-after-destroy bugs with pending command buffers.\n   */\n  private evictLRU(): void {\n    let oldestHash: string | null = null;\n    let oldestTime = Infinity;\n\n    for (const [hash, entry] of this.cache) {\n      // Prefer evicting entries with refCount 0\n      if (entry.refCount === 0 && entry.lastUsed < oldestTime) {\n        oldestTime = entry.lastUsed;\n        oldestHash = hash;\n      }\n    }\n\n    // If all entries are in use, evict oldest anyway\n    if (oldestHash === null) {\n      for (const [hash, entry] of this.cache) {\n        if (entry.lastUsed < oldestTime) {\n          oldestTime = entry.lastUsed;\n          oldestHash = hash;\n        }\n      }\n    }\n\n    if (oldestHash) {\n      const entry = this.cache.get(oldestHash);\n      if (entry) {\n        // DON'T destroy immediately - defer until GPU work completes\n        this.pendingDestruction.push(entry.buffer);\n        this.cache.delete(oldestHash);\n        this.stats.evictions++;\n        this.stats.currentSize = this.cache.size;\n      }\n    }\n  }\n\n  /**\n   * Evict stale entries (older than maxAgeMs).\n   * Buffers are queued for deferred destruction.\n   */\n  evictStale(): number {\n    const now = performance.now();\n    let evicted = 0;\n\n    for (const [hash, entry] of this.cache) {\n      if (entry.refCount === 0 && now - entry.lastUsed > this.maxAgeMs) {\n        // DON'T destroy immediately - defer until GPU work completes\n        this.pendingDestruction.push(entry.buffer);\n        this.cache.delete(hash);\n        evicted++;\n      }\n    }\n\n    this.stats.evictions += evicted;\n    this.stats.currentSize = this.cache.size;\n    return evicted;\n  }\n\n  /**\n   * Clear all cached buffers.\n   * Also flushes any pending destruction queue.\n   */\n  clear(): void {\n    // Flush pending destruction first\n    this.flushPendingDestruction();\n\n    // Destroy all cached buffers\n    for (const entry of this.cache.values()) {\n      entry.buffer.destroy();\n    }\n    this.cache.clear();\n    this.stats.currentSize = 0;\n  }\n\n  /**\n   * Destroy all buffers in the pending destruction queue.\n   * Call this after GPU work completes (e.g., after onSubmittedWorkDone).\n   *\n   * This is critical for avoiding use-after-destroy bugs: when the uniform\n   * cache evicts a buffer that's still referenced by a pending command buffer,\n   * the buffer is queued here instead of being destroyed immediately.\n   */\n  flushPendingDestruction(): number {\n    const count = this.pendingDestruction.length;\n    for (const buffer of this.pendingDestruction) {\n      buffer.destroy();\n    }\n    this.pendingDestruction = [];\n    return count;\n  }\n\n  /**\n   * Get the number of buffers pending destruction.\n   */\n  getPendingDestructionCount(): number {\n    return this.pendingDestruction.length;\n  }\n\n  /**\n   * Check if a buffer is managed by this cache\n   */\n  isCached(buffer: GPUBuffer): boolean {\n    for (const entry of this.cache.values()) {\n      if (entry.buffer === buffer) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * Get cache statistics\n   */\n  getStats(): UniformCacheStats & { hitRate: string; pendingDestruction: number } {\n    const total = this.stats.hits + this.stats.misses;\n    const hitRate = total > 0 ? ((this.stats.hits / total) * 100).toFixed(1) + '%' : '0%';\n    return { ...this.stats, hitRate, pendingDestruction: this.pendingDestruction.length };\n  }\n}\n\n/**\n * Release or destroy a uniform buffer appropriately.\n * If the buffer is cached, releases it back to the cache.\n * If not cached, destroys it directly.\n */\nexport function releaseUniformBuffer(buffer: GPUBuffer): void {\n  const cache = getUniformCache();\n  if (cache.isCached(buffer)) {\n    cache.release(buffer);\n  } else {\n    buffer.destroy();\n  }\n}\n\n// Global singleton instance\nlet globalUniformCache: UniformBufferCache | null = null;\n\n/**\n * Get the global uniform buffer cache instance\n */\nexport function getUniformCache(): UniformBufferCache {\n  if (!globalUniformCache) {\n    globalUniformCache = new UniformBufferCache();\n  }\n  return globalUniformCache;\n}\n\n/**\n * Reset the global uniform cache (useful for testing or device loss)\n */\nexport function resetUniformCache(): void {\n  if (globalUniformCache) {\n    globalUniformCache.clear();\n    globalUniformCache = null;\n  }\n}\n", "/**\n * Kernel Utilities - Shared utilities for kernel management\n *\n * Provides shader loading, compilation, caching, and device capability checking.\n */\n\nimport { getDevice, getKernelCapabilities, getDeviceLimits } from '../device.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { getKernelTuner } from '../kernel-tuner.js';\nimport { getUniformCache } from '../uniform-cache.js';\nimport { log, trace } from '../../debug/index.js';\n\n/** Shader source cache (loaded via fetch) */\nconst shaderSourceCache = new Map<string, string>();\n\n/** Compiled shader module cache */\nconst shaderModuleCache = new Map<string, Promise<GPUShaderModule>>();\n\n/** Compiled pipeline cache */\nconst pipelineCache = new Map<string, GPUComputePipeline>();\n\n/** Bind group layout cache */\nconst bindGroupLayoutCache = new Map<string, GPUBindGroupLayout>();\n\n/** Pipeline layout cache */\nconst pipelineLayoutCache = new Map<string, GPUPipelineLayout>();\n\n/**\n * Base path for kernel files\n * Detects if running under /doppler/ (replo.id deployment) or standalone\n */\nfunction getKernelBasePath(): string {\n  // Check if we're running from /doppler/ path (replo.id deployment)\n  if (typeof location !== 'undefined') {\n    const path = location.pathname;\n    if (path.startsWith('/d') || path.startsWith('/doppler/') || location.host.includes('replo')) {\n      return '/doppler/gpu/kernels';\n    }\n  }\n  return '/gpu/kernels';\n}\n\nconst KERNEL_BASE_PATH = getKernelBasePath();\n\n/** Variant-specific metadata for table-driven kernel configuration */\nexport interface VariantMetadata {\n  /** Columns processed per workgroup (matmul multicol variants) */\n  colsPerWg?: number;\n  /** Tile size for M dimension (batched matmul variants) */\n  tileM?: number;\n  /** Output buffer binding index (gather F16 output variants) */\n  outputBinding?: number;\n  /** Maximum KV length for chunked attention */\n  maxKVLen?: number;\n}\n\n/** Kernel configuration */\nexport interface KernelConfig {\n  shaderFile: string;\n  entryPoint: string;\n  workgroupSize: [number, number, number];\n  requires: string[];\n  validate?: (seqLen: number, numHeads: number, headDim: number) => void;\n  /** Output dtype for variants that output to specific precision */\n  outputDtype?: 'f16' | 'f32';\n  /** Tile size for attention/matmul kernels */\n  tileSize?: number;\n  /** Additional variant-specific configuration */\n  variantMetadata?: VariantMetadata;\n}\n\n/** All kernel configurations by operation and variant */\nexport const KERNEL_CONFIGS: Record<string, Record<string, KernelConfig>> = {\n  matmul: {\n    f16: {\n      shaderFile: 'matmul_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [16, 16, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n    },\n    f16_vec4: {\n      shaderFile: 'matmul_f16.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [16, 16, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n    },\n    f16w_f32a: {\n      shaderFile: 'matmul_f16w_f32a.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [16, 16, 1],\n      requires: ['shader-f16'],\n    },\n    // Optimized GEMV for M=1 decode: uses shared memory for A vector\n    gemv: {\n      shaderFile: 'matmul_gemv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    // Subgroup-optimized GEMV - 1.5x faster using subgroupAdd\n    gemv_subgroup: {\n      shaderFile: 'matmul_gemv_subgroup.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16', 'subgroups'],\n    },\n    gemv_subgroup_vec4: {\n      shaderFile: 'matmul_gemv_subgroup.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16', 'subgroups'],\n    },\n    // Multi-column GEMV for large vocab (LM head F16) - 32 columns per workgroup\n    // Reduces workgroups from 65K to 8K for vocab=262144\n    gemv_subgroup_multicol: {\n      shaderFile: 'matmul_gemv_subgroup.wgsl',\n      entryPoint: 'main_multicol',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16', 'subgroups'],\n      variantMetadata: { colsPerWg: 32 },\n    },\n    // Fused Q4_K dequant + matmul - 2-3x faster (no separate dequant pass)\n    q4_fused: {\n      shaderFile: 'fused_matmul_q4.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    q4_fused_batched: {\n      shaderFile: 'fused_matmul_q4_batched.wgsl',\n      entryPoint: 'main_batched',\n      workgroupSize: [64, 4, 1],\n      requires: ['subgroups'],\n      variantMetadata: { tileM: 4 },\n    },\n    // Multi-column GEMV for large vocab (LM head) - 32 columns per workgroup\n    q4_fused_multicol: {\n      shaderFile: 'fused_matmul_q4.wgsl',\n      entryPoint: 'main_multicol',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n      variantMetadata: { colsPerWg: 32 },\n    },\n    // F16 output variants - same as above but output to f16 buffer\n    q4_fused_multicol_f16: {\n      shaderFile: 'fused_matmul_q4_multicol_f16.wgsl',\n      entryPoint: 'main_multicol_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16', 'subgroups'],\n      outputDtype: 'f16',\n      variantMetadata: { colsPerWg: 32 },\n    },\n    q4_fused_batched_f16: {\n      shaderFile: 'fused_matmul_q4_batched_f16.wgsl',\n      entryPoint: 'main_batched_f16',\n      workgroupSize: [64, 4, 1],\n      requires: ['shader-f16', 'subgroups'],\n      outputDtype: 'f16',\n      variantMetadata: { tileM: 4 },\n    },\n    f32: {\n      shaderFile: 'matmul_f32.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [16, 16, 1],\n      requires: [],\n    },\n  },\n  // Fused FFN kernels (Tier 2 P0)\n  fused_ffn: {\n    default: {\n      shaderFile: 'fused_ffn.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    multi: {\n      shaderFile: 'fused_ffn.wgsl',\n      entryPoint: 'main_multi',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    f16: {\n      shaderFile: 'fused_ffn.wgsl',\n      entryPoint: 'main_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    batched: {\n      shaderFile: 'fused_ffn.wgsl',\n      entryPoint: 'main_batched',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    q4k: {\n      shaderFile: 'fused_ffn_q4k.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    q4k_batched: {\n      shaderFile: 'fused_ffn_q4k.wgsl',\n      entryPoint: 'main_batched',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n  },\n  // Optimized attention decode (Tier 2 P0)\n  attention_decode_optimized: {\n    default: {\n      shaderFile: 'attention_decode_optimized.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    multihead: {\n      shaderFile: 'attention_decode_optimized.wgsl',\n      entryPoint: 'main_multihead',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    f16kv: {\n      shaderFile: 'attention_decode_optimized.wgsl',\n      entryPoint: 'main_f16kv',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n  },\n  dequant: {\n    subgroup: {\n      shaderFile: 'dequant_subgroup.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [64, 1, 1],\n      requires: ['subgroups'],\n    },\n    subgroup_vec4: {\n      shaderFile: 'dequant_subgroup.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: ['subgroups'],\n    },\n    subgroup_f16out: {\n      shaderFile: 'dequant_f16_out.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    subgroup_vec4_f16out: {\n      shaderFile: 'dequant_f16_out_vec4.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n    },\n    shared: {\n      shaderFile: 'dequant_shared.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    shared_vec4: {\n      shaderFile: 'dequant_shared_vec4.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n    },\n    shared_f16out: {\n      shaderFile: 'dequant_f16_out.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    shared_vec4_f16out: {\n      shaderFile: 'dequant_f16_out_vec4.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n    },\n    // MXFP4 dequantization (GPT-OSS)\n    mxfp4: {\n      shaderFile: 'dequant_mxfp4.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    mxfp4_vec4: {\n      shaderFile: 'dequant_mxfp4_vec4.wgsl',\n      entryPoint: 'main_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n    },\n    mxfp4_expert: {\n      shaderFile: 'dequant_mxfp4_expert.wgsl',\n      entryPoint: 'main_expert',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    // Q6_K dequantization (GGUF 6-bit quantization)\n    q6k_f16out: {\n      shaderFile: 'dequant_q6k.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    // Q8_0 dequantization (GGUF 8-bit quantization)\n    q8_0_f16out: {\n      shaderFile: 'dequant_q8_0.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [32, 1, 1],\n      requires: ['shader-f16'],\n    },\n  },\n  attention: {\n    prefill: {\n      shaderFile: 'attention.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n      validate: validateAttentionLimits,\n    },\n    decode: {\n      shaderFile: 'attention_decode.wgsl',\n      entryPoint: 'attention_decode',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    prefill_small: {\n      shaderFile: 'attention_small.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [32, 1, 1],\n      requires: [],\n      validate: validateAttentionLimits,\n    },\n    decode_small: {\n      shaderFile: 'attention_small.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [32, 1, 1],\n      requires: [],\n    },\n    prefill_streaming: {\n      shaderFile: 'attention_streaming.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [1, 1, 1],\n      requires: [],\n      validate: validateAttentionLimits,\n    },\n    decode_streaming: {\n      shaderFile: 'attention_streaming.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [1, 1, 1],\n      requires: [],\n    },\n    prefill_f16kv: {\n      shaderFile: 'attention_f16kv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n      validate: validateAttentionLimits,\n    },\n    decode_f16kv: {\n      shaderFile: 'attention_decode_f16kv.wgsl',\n      entryPoint: 'attention_decode',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    prefill_small_f16kv: {\n      shaderFile: 'attention_small_f16kv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [32, 1, 1],\n      requires: ['shader-f16'],\n      validate: validateAttentionLimits,\n    },\n    decode_small_f16kv: {\n      shaderFile: 'attention_small_f16kv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [32, 1, 1],\n      requires: ['shader-f16'],\n    },\n    prefill_streaming_f16kv: {\n      shaderFile: 'attention_streaming_f16kv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [1, 1, 1],\n      requires: ['shader-f16'],\n      validate: validateAttentionLimits,\n    },\n    decode_streaming_f16kv: {\n      shaderFile: 'attention_streaming_f16kv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [1, 1, 1],\n      requires: ['shader-f16'],\n    },\n    // Chunked decode kernel - parallelizes headDim for models with few heads (e.g., Gemma 3)\n    decode_chunked_f16kv: {\n      shaderFile: 'attention_decode_chunked_f16kv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n      variantMetadata: { maxKVLen: 2048 },\n    },\n    // Subgroup-optimized decode kernel - 4 barriers (vs 80), 100% thread utilization\n    decode_subgroup: {\n      shaderFile: 'attention_decode_subgroup.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],  // headDim threads per workgroup\n      requires: ['subgroups'],\n    },\n  },\n  rmsnorm: {\n    default: {\n      shaderFile: 'rmsnorm.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    small: {\n      shaderFile: 'rmsnorm.wgsl',\n      entryPoint: 'main_small',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    cached: {\n      shaderFile: 'rmsnorm.wgsl',\n      entryPoint: 'main_cached',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    // Legacy alias for residual (now uses main_cached)\n    residual: {\n      shaderFile: 'rmsnorm.wgsl',\n      entryPoint: 'main_cached',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    // Subgroup-accelerated variants (3-5x faster reductions)\n    subgroup: {\n      shaderFile: 'rmsnorm.wgsl',\n      entryPoint: 'main_subgroup',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    small_subgroup: {\n      shaderFile: 'rmsnorm.wgsl',\n      entryPoint: 'main_small_subgroup',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    // F16 variants for reduced memory bandwidth\n    default_f16: {\n      shaderFile: 'rmsnorm_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    small_f16: {\n      shaderFile: 'rmsnorm_f16.wgsl',\n      entryPoint: 'rmsnorm_small_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n  },\n  // Fused GEMV + RMSNorm for decode (M=1)\n  // Combines down projection matmul with RMSNorm in single kernel\n  fused_matmul_rmsnorm: {\n    default: {\n      shaderFile: 'fused_matmul_rmsnorm.wgsl',\n      entryPoint: 'gemv_rmsnorm_medium',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    small: {\n      shaderFile: 'fused_matmul_rmsnorm.wgsl',\n      entryPoint: 'gemv_rmsnorm_small',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    // Medium variant for N up to ~4096 (covers Gemma 3's hiddenSize=1152)\n    medium: {\n      shaderFile: 'fused_matmul_rmsnorm.wgsl',\n      entryPoint: 'gemv_rmsnorm_medium',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    phase1: {\n      shaderFile: 'fused_matmul_rmsnorm.wgsl',\n      entryPoint: 'gemv_rmsnorm_phase1',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  // Fused GEMV + Residual for decode (M=1)\n  // Combines output projection matmul with residual add in single kernel\n  fused_matmul_residual: {\n    default: {\n      shaderFile: 'matmul_gemv_residual.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  softmax: {\n    default: {\n      shaderFile: 'softmax.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    small: {\n      shaderFile: 'softmax.wgsl',\n      entryPoint: 'softmax_small',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    online: {\n      shaderFile: 'softmax.wgsl',\n      entryPoint: 'softmax_online',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    // Subgroup-accelerated variants (3-5x faster reductions)\n    subgroup: {\n      shaderFile: 'softmax.wgsl',\n      entryPoint: 'main_subgroup',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n    small_subgroup: {\n      shaderFile: 'softmax.wgsl',\n      entryPoint: 'softmax_small_subgroup',\n      workgroupSize: [256, 1, 1],\n      requires: ['subgroups'],\n    },\n  },\n  rope: {\n    default: {\n      shaderFile: 'rope.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    compute_freqs: {\n      shaderFile: 'rope.wgsl',\n      entryPoint: 'rope_compute_freqs',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    qk: {\n      shaderFile: 'rope.wgsl',\n      entryPoint: 'rope_qk',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    ntk: {\n      shaderFile: 'rope.wgsl',\n      entryPoint: 'rope_ntk_scaled',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    yarn: {\n      shaderFile: 'rope.wgsl',\n      entryPoint: 'rope_yarn',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  silu: {\n    default: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    gate: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'silu_gate',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    gate_split: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'silu_gate_split',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    vec4: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'silu_vec4',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    gelu: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'gelu',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    geglu: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'geglu',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    gate_rowsplit: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'silu_gate_rowsplit',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    geglu_rowsplit: {\n      shaderFile: 'silu.wgsl',\n      entryPoint: 'geglu_rowsplit',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    // F16 variants for reduced memory bandwidth\n    default_f16: {\n      shaderFile: 'silu_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    gate_f16: {\n      shaderFile: 'silu_f16.wgsl',\n      entryPoint: 'silu_gate_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    vec4_f16: {\n      shaderFile: 'silu_f16.wgsl',\n      entryPoint: 'silu_vec4_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    gate_rowsplit_f16: {\n      shaderFile: 'silu_f16.wgsl',\n      entryPoint: 'silu_gate_rowsplit_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    geglu_rowsplit_f16: {\n      shaderFile: 'silu_f16.wgsl',\n      entryPoint: 'geglu_rowsplit_f16',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n  },\n  scale: {\n    default: {\n      shaderFile: 'scale.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    inplace: {\n      shaderFile: 'scale.wgsl',\n      entryPoint: 'main_inplace',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  gather: {\n    default: {\n      shaderFile: 'gather.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    vec4: {\n      shaderFile: 'gather_vec4.wgsl',\n      entryPoint: 'gather_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n    },\n    // F16 embeddings \u2192 F32 output (for weight-tied lm_head optimization)\n    f16: {\n      shaderFile: 'gather_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    f16_vec4: {\n      shaderFile: 'gather_f16_vec4.wgsl',\n      entryPoint: 'gather_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n    },\n    // F32 embeddings \u2192 F16 output (for F16 activation mode)\n    f16_out: {\n      shaderFile: 'gather_f16_out.wgsl',\n      entryPoint: 'gather_f16_out',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n      variantMetadata: { outputBinding: 4 },\n    },\n    vec4_f16_out: {\n      shaderFile: 'gather_vec4_f16_out.wgsl',\n      entryPoint: 'gather_vec4_f16_out',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n      variantMetadata: { outputBinding: 4 },\n    },\n    // F16 embeddings \u2192 F16 output (for F16 activation mode with F16 embeddings)\n    f16_f16_out: {\n      shaderFile: 'gather_f16_f16_out.wgsl',\n      entryPoint: 'gather_f16_out',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n      variantMetadata: { outputBinding: 4 },\n    },\n    f16_vec4_f16_out: {\n      shaderFile: 'gather_f16_vec4_f16_out.wgsl',\n      entryPoint: 'gather_vec4_f16_out',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n      variantMetadata: { outputBinding: 4 },\n    },\n  },\n  residual: {\n    default: {\n      shaderFile: 'residual.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    vec4: {\n      shaderFile: 'residual_vec4.wgsl',\n      entryPoint: 'add_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n    },\n    default_f16: {\n      shaderFile: 'residual_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n    },\n    vec4_f16: {\n      shaderFile: 'residual_f16_vec4.wgsl',\n      entryPoint: 'add_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: ['shader-f16'],\n      outputDtype: 'f16',\n    },\n  },\n  topk: {\n    default: {\n      shaderFile: 'topk.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [32, 1, 1],\n      requires: [],\n    },\n    small: {\n      shaderFile: 'topk.wgsl',\n      entryPoint: 'topk_2_small',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    fused: {\n      shaderFile: 'topk.wgsl',\n      entryPoint: 'softmax_topk',\n      workgroupSize: [32, 1, 1],\n      requires: [],\n    },\n  },\n  scatter_add: {\n    default: {\n      shaderFile: 'scatter_add.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    vec4: {\n      shaderFile: 'scatter_add_vec4.wgsl',\n      entryPoint: 'scatter_add_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n    },\n    dynamic: {\n      shaderFile: 'scatter_add_dynamic.wgsl',\n      entryPoint: 'scatter_add_dynamic',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    accumulate: {\n      shaderFile: 'scatter_add.wgsl',\n      entryPoint: 'scatter_add_accumulate',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  moe_gather: {\n    count: {\n      shaderFile: 'moe_gather.wgsl',\n      entryPoint: 'count_and_map',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    gather: {\n      shaderFile: 'moe_gather.wgsl',\n      entryPoint: 'gather_tokens',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    gather_vec4: {\n      shaderFile: 'moe_gather_vec4.wgsl',\n      entryPoint: 'gather_tokens_vec4',\n      workgroupSize: [64, 1, 1],\n      requires: [],\n    },\n    single_pass: {\n      shaderFile: 'moe_gather.wgsl',\n      entryPoint: 'gather_single_pass',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    sparse: {\n      shaderFile: 'moe_gather.wgsl',\n      entryPoint: 'count_and_map',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  swiglu: {\n    rowsplit_bias: {\n      shaderFile: 'fused_swiglu.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  bias_add: {\n    default: {\n      shaderFile: 'bias_add.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    f16: {\n      shaderFile: 'bias_add_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n  },\n  cast: {\n    f32_to_f16: {\n      shaderFile: 'cast_f32_to_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n    f16_to_f32: {\n      shaderFile: 'cast_f16_to_f32.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n  },\n  // Split fused QKV output into separate Q, K, V buffers\n  split_qkv: {\n    default: {\n      shaderFile: 'split_qkv.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  sample: {\n    argmax: {\n      shaderFile: 'sample.wgsl',\n      entryPoint: 'argmax',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    argmax_reduce: {\n      shaderFile: 'sample.wgsl',\n      entryPoint: 'argmax_reduce',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    find_topk_phase1: {\n      shaderFile: 'sample.wgsl',\n      entryPoint: 'find_topk_phase1',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    find_topk_phase2: {\n      shaderFile: 'sample.wgsl',\n      entryPoint: 'find_topk_phase2',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    softmax_and_sample: {\n      shaderFile: 'sample.wgsl',\n      entryPoint: 'softmax_and_sample',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n    single_pass: {\n      shaderFile: 'sample.wgsl',\n      entryPoint: 'sample_single_pass',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  bf16_to_f32: {\n    default: {\n      shaderFile: 'bf16_to_f32.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: [],\n    },\n  },\n  bf16_to_f16: {\n    default: {\n      shaderFile: 'bf16_to_f16.wgsl',\n      entryPoint: 'main',\n      workgroupSize: [256, 1, 1],\n      requires: ['shader-f16'],\n    },\n  },\n};\n\n/**\n * Validate that attention parameters are within device limits\n */\nexport function validateAttentionLimits(seqLen: number, numHeads: number, headDim: number): void {\n  const limits = getDeviceLimits();\n  if (!limits) return; // No device, validation will fail later\n\n  // Check workgroup invocations limit\n  const workgroupInvocations = seqLen * numHeads;\n  if (workgroupInvocations > limits.maxComputeWorkgroupsPerDimension) {\n    throw new Error(\n      `Attention parameters exceed device limits: ${workgroupInvocations} workgroups ` +\n      `> ${limits.maxComputeWorkgroupsPerDimension} max per dimension. ` +\n      `Try reducing seqLen (${seqLen}) or numHeads (${numHeads}).`\n    );\n  }\n\n  // Check buffer size limits for KV cache\n  const kvCacheSize = seqLen * numHeads * headDim * 4; // float32\n  if (kvCacheSize > limits.maxStorageBufferBindingSize) {\n    throw new Error(\n      `KV cache size ${(kvCacheSize / 1e9).toFixed(2)}GB exceeds device limit ` +\n      `${(limits.maxStorageBufferBindingSize / 1e9).toFixed(2)}GB. ` +\n      `Reduce sequence length or use paged attention.`\n    );\n  }\n\n  // Check shared memory requirements for attention tile\n  const tileSize = 64; // TILE_SIZE in attention.wgsl\n  const sharedMemRequired = tileSize * headDim * 4 * 2; // K and V tiles\n  if (sharedMemRequired > limits.maxComputeWorkgroupStorageSize) {\n    log.warn('KernelSelector', `Attention may be slow: tile requires ${sharedMemRequired} bytes but device has ${limits.maxComputeWorkgroupStorageSize} bytes shared memory.`);\n  }\n}\n\n/**\n * Load a WGSL shader file via fetch\n */\nexport async function loadShaderSource(filename: string): Promise<string> {\n  if (shaderSourceCache.has(filename)) {\n    return shaderSourceCache.get(filename)!;\n  }\n\n  const url = `${KERNEL_BASE_PATH}/${filename}`;\n  try {\n    const response = await fetch(url, { cache: 'no-cache' });\n    if (!response.ok) {\n      throw new Error(`Failed to load shader ${filename}: ${response.status}`);\n    }\n    const source = await response.text();\n    shaderSourceCache.set(filename, source);\n    return source;\n  } catch (error) {\n    log.error('KernelSelector', `Failed to load shader ${filename}: ${error}`);\n    throw error;\n  }\n}\n\n/** Minimum capabilities interface for feature checking */\ninterface FeatureCapabilities {\n  hasF16: boolean;\n  hasSubgroups: boolean;\n}\n\n/**\n * Check if all required features are available\n */\nexport function hasRequiredFeatures(required: string[], capabilities: FeatureCapabilities): boolean {\n  for (const feature of required) {\n    if (feature === 'shader-f16' && !capabilities.hasF16) return false;\n    if (feature === 'subgroups' && !capabilities.hasSubgroups) return false;\n    if (feature === 'subgroups-f16' && !capabilities.hasSubgroups) return false;\n  }\n  return true;\n}\n\n/**\n * Get kernel configuration\n */\nexport function getKernelConfig(operation: string, variant: string): KernelConfig {\n  const config = KERNEL_CONFIGS[operation]?.[variant];\n  if (!config) {\n    throw new Error(`Unknown kernel: ${operation}/${variant}`);\n  }\n  return config;\n}\n\n/**\n * Compile a shader module\n */\nexport async function compileShader(device: GPUDevice, source: string, label: string): Promise<GPUShaderModule> {\n  const module = device.createShaderModule({\n    label,\n    code: source,\n  });\n\n  // Check for compilation errors\n  const compilationInfo = await module.getCompilationInfo();\n  if (compilationInfo.messages.length > 0) {\n    for (const msg of compilationInfo.messages) {\n      if (msg.type === 'error') {\n        log.error('compileShader', `${label}: ${msg.message} (line ${msg.lineNum}:${msg.linePos})`);\n      } else if (msg.type === 'warning') {\n        log.warn('compileShader', `${label}: ${msg.message} (line ${msg.lineNum}:${msg.linePos})`);\n      } else {\n        log.debug('compileShader', `${label}: ${msg.message} (line ${msg.lineNum}:${msg.linePos})`);\n      }\n    }\n    if (compilationInfo.messages.some(m => m.type === 'error')) {\n      throw new Error(`Shader compilation failed for ${label}`);\n    }\n  }\n\n  return module;\n}\n\n/**\n * Get or create a cached shader module for a shader file.\n */\nasync function getShaderModule(\n  device: GPUDevice,\n  shaderFile: string,\n  label: string\n): Promise<GPUShaderModule> {\n  const cacheKey = shaderFile;\n  const cached = shaderModuleCache.get(cacheKey);\n  if (cached) {\n    return cached;\n  }\n\n  const compilePromise = (async () => {\n    const shaderSource = await loadShaderSource(shaderFile);\n    return compileShader(device, shaderSource, label);\n  })();\n\n  shaderModuleCache.set(cacheKey, compilePromise);\n\n  try {\n    return await compilePromise;\n  } catch (err) {\n    shaderModuleCache.delete(cacheKey);\n    throw err;\n  }\n}\n\n/**\n * Get or create a cached bind group layout.\n */\nexport function getOrCreateBindGroupLayout(\n  label: string,\n  entries: GPUBindGroupLayoutEntry[],\n  deviceOverride: GPUDevice | null = null\n): GPUBindGroupLayout {\n  const cached = bindGroupLayoutCache.get(label);\n  if (cached) {\n    return cached;\n  }\n\n  const device = deviceOverride || getDevice();\n  if (!device) {\n    throw new Error('Device not initialized');\n  }\n\n  const layout = device.createBindGroupLayout({ label, entries });\n  bindGroupLayoutCache.set(label, layout);\n  return layout;\n}\n\n/**\n * Get or create a cached pipeline layout.\n */\nexport function getOrCreatePipelineLayout(\n  label: string,\n  bindGroupLayouts: GPUBindGroupLayout[],\n  deviceOverride: GPUDevice | null = null\n): GPUPipelineLayout {\n  const cached = pipelineLayoutCache.get(label);\n  if (cached) {\n    return cached;\n  }\n\n  const device = deviceOverride || getDevice();\n  if (!device) {\n    throw new Error('Device not initialized');\n  }\n\n  const layout = device.createPipelineLayout({\n    label,\n    bindGroupLayouts,\n  });\n\n  pipelineLayoutCache.set(label, layout);\n  return layout;\n}\n\n/**\n * Synchronously get a cached pipeline, or null if not cached.\n * Use this for fast path when you know the pipeline should be warm.\n */\nexport function getCachedPipeline(\n  operation: string,\n  variant: string\n): GPUComputePipeline | null {\n  const cacheKey = `${operation}:${variant}`;\n  return pipelineCache.get(cacheKey) || null;\n}\n\n/**\n * Get a pipeline, using synchronous cache lookup when available.\n * Falls back to async compilation if not cached.\n * This is the preferred way to get pipelines in hot paths.\n */\nexport async function getPipelineFast(\n  operation: string,\n  variant: string,\n  bindGroupLayout: GPUBindGroupLayout | null = null\n): Promise<GPUComputePipeline> {\n  const cached = getCachedPipeline(operation, variant);\n  if (cached) {\n    return cached;\n  }\n  return createPipeline(operation, variant, bindGroupLayout);\n}\n\n/**\n * Create a compute pipeline for a kernel\n */\nexport async function createPipeline(\n  operation: string,\n  variant: string,\n  bindGroupLayout: GPUBindGroupLayout | null = null\n): Promise<GPUComputePipeline> {\n  const cacheKey = `${operation}:${variant}`;\n\n  // Return cached pipeline if available\n  if (pipelineCache.has(cacheKey)) {\n    return pipelineCache.get(cacheKey)!;\n  }\n\n  const device = getDevice();\n  if (!device) {\n    throw new Error('Device not initialized');\n  }\n\n  const config = getKernelConfig(operation, variant);\n  const capabilities = getKernelCapabilities();\n\n  // Verify requirements\n  if (!hasRequiredFeatures(config.requires, capabilities)) {\n    throw new Error(\n      `Kernel ${operation}/${variant} requires features: ${config.requires.join(', ')}`\n    );\n  }\n\n  trace.kernels(\n    `KernelLayout: ${operation}/${variant} file=${config.shaderFile} entry=${config.entryPoint} ` +\n      `workgroup=[${config.workgroupSize.join(',')}] requires=` +\n      `${config.requires.length > 0 ? config.requires.join('|') : 'none'}`\n  );\n\n  // Compile or reuse shader module\n  const shaderModule = await getShaderModule(device, config.shaderFile, `${operation}_${variant}`);\n\n  // Create pipeline\n  const layoutLabel = bindGroupLayout?.label || `${operation}_${variant}_layout`;\n  const pipelineDescriptor: GPUComputePipelineDescriptor = {\n    label: `${operation}_${variant}_pipeline`,\n    layout: bindGroupLayout\n      ? getOrCreatePipelineLayout(layoutLabel, [bindGroupLayout], device)\n      : 'auto',\n    compute: {\n      module: shaderModule,\n      entryPoint: config.entryPoint,\n    },\n  };\n\n  const pipeline = await device.createComputePipelineAsync(pipelineDescriptor);\n  pipelineCache.set(cacheKey, pipeline);\n\n  return pipeline;\n}\n\n/**\n * Clear the pipeline cache\n */\nexport function clearKernelCaches(): void {\n  pipelineCache.clear();\n  shaderSourceCache.clear();\n  shaderModuleCache.clear();\n  bindGroupLayoutCache.clear();\n  pipelineLayoutCache.clear();\n}\n\nexport function clearPipelineCache(): void {\n  clearKernelCaches();\n}\n\n/**\n * Get cache statistics\n */\nexport function getCacheStats(): {\n  pipelines: number;\n  shaders: number;\n  shaderModules: number;\n  bindGroupLayouts: number;\n  pipelineLayouts: number;\n} {\n  return {\n    pipelines: pipelineCache.size,\n    shaders: shaderSourceCache.size,\n    shaderModules: shaderModuleCache.size,\n    bindGroupLayouts: bindGroupLayoutCache.size,\n    pipelineLayouts: pipelineLayoutCache.size,\n  };\n}\n\n/**\n * Get tuned workgroup size for an operation\n */\nexport async function getTunedWorkgroupSize(\n  operation: string,\n  inputSizes: Record<string, number> = {}\n): Promise<[number, number, number]> {\n  try {\n    const tuner = await getKernelTuner();\n    const result = tuner.getCachedResult(operation, inputSizes);\n\n    if (result) {\n      return result.optimalWorkgroupSize;\n    }\n\n    // Run tuning if not cached\n    const tuneResult = await tuner.tuneKernel(operation, inputSizes);\n    return tuneResult.optimalWorkgroupSize;\n  } catch (e: any) {\n    log.warn('KernelSelector', `Tuning failed for ${operation}, using defaults: ${e.message}`);\n    // Return defaults based on operation\n    switch (operation) {\n      case 'matmul':\n        return [16, 16, 1];\n      case 'attention':\n      case 'rmsnorm':\n      case 'softmax':\n        return [256, 1, 1];\n      case 'dequant':\n        return [64, 1, 1];\n      default:\n        return [256, 1, 1];\n    }\n  }\n}\n\n/**\n * Run auto-tuning for all kernels with given model config\n */\nexport async function autoTuneKernels(modelConfig: Record<string, number> = {}): Promise<Record<string, any>> {\n  const {\n    hiddenSize = 4096,\n    intermediateSize = 14336,\n    numHeads = 32,\n    headDim = 128,\n    maxSeqLen = 4096,\n    vocabSize = 32000,\n  } = modelConfig;\n\n  const tuner = await getKernelTuner();\n  const results: Record<string, any> = {};\n\n  // Tune matmul for common sizes\n  results.matmul_hidden = await tuner.tuneKernel('matmul', {\n    M: 1, N: hiddenSize, K: hiddenSize,\n  });\n  results.matmul_ffn = await tuner.tuneKernel('matmul', {\n    M: 1, N: intermediateSize, K: hiddenSize,\n  });\n\n  // Tune attention\n  results.attention = await tuner.tuneKernel('attention', {\n    seqLen: 1, numHeads, headDim,\n  });\n\n  // Tune softmax (LM head output)\n  results.softmax = await tuner.tuneKernel('softmax', {\n    innerSize: vocabSize, outerSize: 1,\n  });\n\n  // Tune RMSNorm\n  results.rmsnorm = await tuner.tuneKernel('rmsnorm', {\n    hiddenSize, numTokens: 1,\n  });\n\n  // Tune dequant\n  results.dequant = await tuner.tuneKernel('dequant', {\n    numBlocks: 1000,\n  });\n\n  log.debug('KernelSelector', `Auto-tuning complete: ${JSON.stringify(results)}`);\n  return results;\n}\n\n/**\n * Prewarm all supported kernel pipelines\n */\nexport async function prewarmKernels(\n  options: { mode?: 'parallel' | 'sequential' } = {}\n): Promise<void> {\n  const caps = getKernelCapabilities();\n  const mode = options.mode ?? 'parallel';\n  const entries = Object.entries(KERNEL_CONFIGS)\n    .sort(([a], [b]) => a.localeCompare(b))\n    .map(([operation, variants]) => [operation, Object.entries(variants).sort(([a], [b]) => a.localeCompare(b))] as const);\n\n  if (mode === 'sequential') {\n    let count = 0;\n    for (const [operation, variants] of entries) {\n      for (const [variant, cfg] of variants) {\n        if (cfg.requires && !hasRequiredFeatures(cfg.requires, caps)) {\n          continue;\n        }\n        try {\n          await createPipeline(operation, variant);\n          count += 1;\n        } catch (e: any) {\n          log.warn('KernelSelector', `Prewarm failed for ${operation}/${variant}: ${e.message}`);\n        }\n      }\n    }\n    log.debug('KernelSelector', `Prewarmed ${count} kernel pipelines`);\n    return;\n  }\n\n  const jobs: Promise<void>[] = [];\n  for (const [operation, variants] of entries) {\n    for (const [variant, cfg] of variants) {\n      if (cfg.requires && !hasRequiredFeatures(cfg.requires, caps)) {\n        continue;\n      }\n      jobs.push(\n        createPipeline(operation, variant)\n          .then(() => {}) // Ignore the pipeline result\n          .catch((e) => {\n            log.warn('KernelSelector', `Prewarm failed for ${operation}/${variant}: ${e.message}`);\n          })\n      );\n    }\n  }\n\n  await Promise.all(jobs);\n  log.debug('KernelSelector', `Prewarmed ${jobs.length} kernel pipelines`);\n}\n\n/** Options for uniform buffer creation */\nexport interface UniformBufferOptions {\n  /** Use content-addressed cache for reuse (default: true) */\n  useCache?: boolean;\n}\n\nexport function createUniformBufferFromData(\n  label: string,\n  data: ArrayBuffer | ArrayBufferView,\n  recorder?: CommandRecorder | null,\n  deviceOverride?: GPUDevice | null,\n  options?: UniformBufferOptions\n): GPUBuffer {\n  if (recorder) {\n    return recorder.createUniformBuffer(data, label);\n  }\n\n  // Convert ArrayBufferView to ArrayBuffer for caching\n  const arrayBuffer = data instanceof ArrayBuffer\n    ? data\n    : data.buffer.slice(data.byteOffset, data.byteOffset + data.byteLength);\n\n  // Use cache by default for non-recorder paths\n  const useCache = options?.useCache ?? true;\n  if (useCache && !deviceOverride) {\n    return getUniformCache().getOrCreate(arrayBuffer, label);\n  }\n\n  // Fallback to direct creation (for custom device or explicit no-cache)\n  const device = deviceOverride ?? getDevice();\n  if (!device) {\n    throw new Error('GPU device not initialized');\n  }\n\n  const byteLength = arrayBuffer.byteLength;\n  const buffer = device.createBuffer({\n    label,\n    size: byteLength,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n  device.queue.writeBuffer(buffer, 0, arrayBuffer);\n  return buffer;\n}\n\nexport function createUniformBufferWithView(\n  label: string,\n  byteLength: number,\n  writer: (view: DataView) => void,\n  recorder?: CommandRecorder | null,\n  deviceOverride?: GPUDevice | null\n): GPUBuffer {\n  const data = new ArrayBuffer(byteLength);\n  const view = new DataView(data);\n  writer(view);\n  return createUniformBufferFromData(label, data, recorder, deviceOverride);\n}\n", "/**\n * Weight Buffer Abstraction\n *\n * Wraps GPUBuffer with weight-specific metadata (dtype, layout).\n * Parallel to Tensor but for weights which have:\n * - Quantized dtypes (q4k, q8, bf16)\n * - Layout metadata (row/column for transposeB)\n *\n * Use Tensor for activations (f16/f32 flowing through pipeline).\n * Use WeightBuffer for model weights (static, may be quantized).\n */\n\nexport type WeightDtype = 'f16' | 'f32' | 'bf16' | 'q4k' | 'q8';\nexport type WeightLayout = 'row' | 'column';\n\n/**\n * CPU-resident weight buffer with layout metadata.\n * Used for oversized weights that cannot be bound as a single GPU buffer.\n */\nexport interface CpuWeightBuffer {\n  readonly data: Float32Array;\n  readonly dtype: WeightDtype;\n  readonly layout: WeightLayout;\n  readonly shape: readonly number[];\n  readonly label?: string;\n}\n\n/**\n * A weight buffer with explicit dtype and layout.\n * Use this instead of raw GPUBuffer for weight matrices.\n */\nexport interface WeightBuffer {\n  readonly buffer: GPUBuffer;\n  readonly dtype: WeightDtype;\n  readonly layout: WeightLayout;\n  readonly shape: readonly number[];\n  readonly label?: string;\n}\n\n/**\n * Create a weight buffer from a GPU buffer with explicit metadata.\n */\nexport function createWeightBuffer(\n  buffer: GPUBuffer,\n  dtype: WeightDtype,\n  layout: WeightLayout,\n  shape: number[],\n  label?: string\n): WeightBuffer {\n  return {\n    buffer,\n    dtype,\n    layout,\n    shape: Object.freeze([...shape]),\n    label,\n  };\n}\n\n/**\n * Create a CPU-resident weight buffer with explicit metadata.\n */\nexport function createCpuWeightBuffer(\n  data: Float32Array,\n  dtype: WeightDtype,\n  layout: WeightLayout,\n  shape: number[],\n  label?: string\n): CpuWeightBuffer {\n  return {\n    data,\n    dtype,\n    layout,\n    shape: Object.freeze([...shape]),\n    label,\n  };\n}\n\n/**\n * Check if weight is stored in column-major (pre-transposed) format.\n * Column-major weights use transposeB=false in matmul.\n */\nexport function isColumnMajor(weight: WeightBuffer): boolean {\n  return weight.layout === 'column';\n}\n\n/**\n * Check if weight buffer is a specific type for type guards.\n */\nexport function isWeightBuffer(value: unknown): value is WeightBuffer {\n  return (\n    typeof value === 'object' &&\n    value !== null &&\n    'buffer' in value &&\n    'dtype' in value &&\n    'layout' in value &&\n    'shape' in value\n  );\n}\n\n/**\n * Check if value is a CPU-resident weight buffer.\n */\nexport function isCpuWeightBuffer(value: unknown): value is CpuWeightBuffer {\n  return (\n    typeof value === 'object' &&\n    value !== null &&\n    'data' in value &&\n    'dtype' in value &&\n    'layout' in value &&\n    'shape' in value\n  );\n}\n\n/**\n * Extract the raw GPUBuffer from either a WeightBuffer or raw GPUBuffer.\n * Used for backwards compatibility during migration.\n */\nexport function getBuffer(weight: GPUBuffer | WeightBuffer): GPUBuffer {\n  return isWeightBuffer(weight) ? weight.buffer : weight;\n}\n\n/**\n * Get layout from WeightBuffer, or null for raw GPUBuffer.\n * Used for auto-resolving transposeB in matmul.\n */\nexport function getLayout(weight: GPUBuffer | WeightBuffer): WeightLayout | null {\n  return isWeightBuffer(weight) ? weight.layout : null;\n}\n\n/**\n * Get dtype from WeightBuffer, or null for raw GPUBuffer.\n */\nexport function getWeightDtype(weight: GPUBuffer | WeightBuffer): WeightDtype | null {\n  return isWeightBuffer(weight) ? weight.dtype : null;\n}\n", "/**\n * GPU Buffer Pool - Efficient Buffer Allocation and Reuse\n *\n * Manages GPU buffer allocation with pooling for reuse,\n * reducing allocation overhead during inference.\n */\n\nimport { getDevice, getDeviceLimits } from './device.js';\nimport { allowReadback, trackAllocation } from './perf-guards.js';\nimport type { GpuBufferHandle, BufferRequest } from '../types/gpu.js';\nimport { log, trace } from '../debug/index.js';\nimport type { BufferPoolConfigSchema } from '../config/schema/index.js';\nimport { getRuntimeConfig } from '../config/runtime.js';\n\n/**\n * Pool statistics\n */\nexport interface PoolStats {\n  allocations: number;\n  reuses: number;\n  totalBytesAllocated: number;\n  peakBytesAllocated: number;\n  currentBytesAllocated: number;\n  activeBuffers: number;\n  pooledBuffers: number;\n  hitRate: string;\n}\n\n/**\n * Pool configuration\n */\nexport interface PoolConfig {\n  maxPoolSizePerBucket: number;\n  maxTotalPooledBuffers: number;\n  enablePooling: boolean;\n  alignmentBytes: number;\n}\n\n/**\n * Internal buffer stats for tracking\n */\ninterface InternalStats {\n  allocations: number;\n  reuses: number;\n  totalBytesAllocated: number;\n  peakBytesAllocated: number;\n  currentBytesAllocated: number;\n}\n\n/**\n * Tracked buffer metadata for leak detection\n */\ninterface BufferMetadata {\n  size: number;\n  usage: GPUBufferUsageFlags;\n  label?: string;\n  acquiredAt: number;\n  stackTrace?: string;\n}\n\n/**\n * Buffer usage flags for different operations\n */\nexport const BufferUsage = {\n  STORAGE: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST | GPUBufferUsage.COPY_SRC,\n  STORAGE_READ: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n  UNIFORM: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  STAGING_READ: GPUMapMode.READ | GPUBufferUsage.COPY_DST,\n  STAGING_WRITE: GPUMapMode.WRITE | GPUBufferUsage.COPY_SRC,\n} as const;\n\n/**\n * Round size up to alignment boundary\n */\nfunction alignTo(size: number, alignment: number): number {\n  return Math.ceil(size / alignment) * alignment;\n}\n\n/**\n * Get size bucket for pooling (power of 2 rounding)\n */\nfunction getSizeBucket(\n  size: number,\n  maxAllowedSize: number = Infinity,\n  bucketConfig = getRuntimeConfig().bufferPool.bucket\n): number {\n  // Minimum bucket from config\n  const minBucket = bucketConfig.minBucketSizeBytes;\n  if (size <= minBucket) return minBucket;\n\n  // Avoid power-of-two rounding for very large buffers.\n  // For weights and large activations, rounding 600MB \u2192 1GB can cause OOM even when the\n  // exact-sized buffer would fit. Use coarse-grained bucketing to retain most pooling\n  // benefits without 2x blowups.\n  const largeThreshold = bucketConfig.largeBufferThresholdBytes;\n  if (size >= largeThreshold) {\n    const largeStep = bucketConfig.largeBufferStepBytes;\n    const bucket = Math.ceil(size / largeStep) * largeStep;\n    if (bucket > maxAllowedSize) {\n      return alignTo(size, minBucket);\n    }\n    return bucket;\n  }\n\n  // Round up to next power of 2\n  // Use Math.pow instead of bit shift to avoid 32-bit signed integer overflow\n  // (1 << 31 = -2147483648 in JavaScript due to signed 32-bit arithmetic)\n  const bits = 32 - Math.clz32(size - 1);\n  const bucket = Math.pow(2, bits);\n\n  // If bucket exceeds device limit, fall back to aligned size\n  if (bucket > maxAllowedSize) {\n    return alignTo(size, minBucket);\n  }\n  return bucket;\n}\n\n/**\n * Buffer Pool for efficient GPU memory reuse\n */\nexport class BufferPool {\n  // Pools organized by usage and size bucket\n  // Map<usage, Map<sizeBucket, GPUBuffer[]>>\n  private pools: Map<GPUBufferUsageFlags, Map<number, GPUBuffer[]>>;\n\n  // Active buffers (currently in use)\n  private activeBuffers: Set<GPUBuffer>;\n\n  // Buffer metadata for leak detection (debug mode)\n  private bufferMetadata: Map<GPUBuffer, BufferMetadata>;\n\n  // Deferred destruction queue (buffers destroyed after GPU work completes)\n  private pendingDestruction: Set<GPUBuffer>;\n  private destructionScheduled: boolean;\n\n  // Statistics\n  private stats: InternalStats;\n\n  // Configuration\n  private config: PoolConfig;\n\n  // Schema-based configuration\n  private schemaConfig: BufferPoolConfigSchema;\n\n  // Debug mode flag\n  private debugMode: boolean;\n\n  constructor(debugMode: boolean = false, schemaConfig?: BufferPoolConfigSchema) {\n    this.pools = new Map();\n    this.activeBuffers = new Set();\n    this.bufferMetadata = new Map();\n    this.debugMode = debugMode;\n    this.schemaConfig = schemaConfig ?? getRuntimeConfig().bufferPool;\n    this.pendingDestruction = new Set();\n    this.destructionScheduled = false;\n\n    this.stats = {\n      allocations: 0,\n      reuses: 0,\n      totalBytesAllocated: 0,\n      peakBytesAllocated: 0,\n      currentBytesAllocated: 0,\n    };\n\n    // Initialize from schema config\n    this.config = {\n      maxPoolSizePerBucket: this.schemaConfig.limits.maxBuffersPerBucket,\n      maxTotalPooledBuffers: this.schemaConfig.limits.maxTotalPooledBuffers,\n      enablePooling: true,\n      alignmentBytes: this.schemaConfig.alignment.alignmentBytes,\n    };\n  }\n\n  /**\n   * Get or create a buffer of the specified size\n   */\n  acquire(size: number, usage: GPUBufferUsageFlags = BufferUsage.STORAGE, label: string = 'pooled_buffer'): GPUBuffer {\n    const device = getDevice();\n    if (!device) {\n      throw new Error('Device not initialized');\n    }\n\n    // Check device limits before allocation\n    const limits = getDeviceLimits();\n    const maxSize = limits?.maxBufferSize || Infinity;\n    const maxStorageSize = limits?.maxStorageBufferBindingSize || Infinity;\n    const isStorageBuffer = (usage & GPUBufferUsage.STORAGE) !== 0;\n\n    // Align size and compute bucket, respecting device limits\n    const alignedSize = alignTo(size, this.config.alignmentBytes);\n    const maxAllowedBucket = isStorageBuffer ? Math.min(maxSize, maxStorageSize) : maxSize;\n    const bucket = getSizeBucket(alignedSize, maxAllowedBucket, this.schemaConfig.bucket);\n\n    if (bucket > maxSize) {\n      throw new Error(\n        `Buffer size ${bucket} exceeds device maxBufferSize (${maxSize}). ` +\n        `Requested: ${size} bytes, bucketed to: ${bucket} bytes.`\n      );\n    }\n\n    if (isStorageBuffer && bucket > maxStorageSize) {\n      throw new Error(\n        `Storage buffer size ${bucket} exceeds device maxStorageBufferBindingSize (${maxStorageSize}). ` +\n        `Consider splitting into smaller buffers or using a different strategy.`\n      );\n    }\n\n    // Try to get from pool\n    if (this.config.enablePooling) {\n      const pooled = this._getFromPool(bucket, usage);\n      if (pooled) {\n        this.activeBuffers.add(pooled);\n        this.stats.reuses++;\n\n        // Track metadata in debug mode\n        if (this.debugMode) {\n          this._trackBuffer(pooled, bucket, usage, label);\n        }\n\n        return pooled;\n      }\n    }\n\n    // Allocate new buffer\n    const buffer = device.createBuffer({\n      label: `${label}_${bucket}`,\n      size: bucket,\n      usage,\n    });\n\n    this.activeBuffers.add(buffer);\n    this.stats.allocations++;\n    this.stats.totalBytesAllocated += bucket;\n    this.stats.currentBytesAllocated += bucket;\n    this.stats.peakBytesAllocated = Math.max(\n      this.stats.peakBytesAllocated,\n      this.stats.currentBytesAllocated\n    );\n    trackAllocation(bucket, label);\n\n    // Track metadata in debug mode\n    if (this.debugMode) {\n      this._trackBuffer(buffer, bucket, usage, label);\n    }\n\n    return buffer;\n  }\n\n  /**\n   * Release a buffer back to the pool\n   */\n  release(buffer: GPUBuffer): void {\n    if (!this.activeBuffers.has(buffer)) {\n      log.warn('BufferPool', 'Releasing buffer not tracked as active');\n      return;\n    }\n\n    this.activeBuffers.delete(buffer);\n\n    // Remove metadata in debug mode\n    if (this.debugMode) {\n      this.bufferMetadata.delete(buffer);\n    }\n\n    if (!this.config.enablePooling) {\n      this.deferDestroy(buffer);\n      this.stats.currentBytesAllocated -= buffer.size;\n      return;\n    }\n\n    // Return to pool if there's room\n    const bucket = buffer.size;\n    const usage = buffer.usage;\n\n    if (!this.pools.has(usage)) {\n      this.pools.set(usage, new Map());\n    }\n    const usagePool = this.pools.get(usage)!;\n\n    if (!usagePool.has(bucket)) {\n      usagePool.set(bucket, []);\n    }\n    const bucketPool = usagePool.get(bucket)!;\n\n    if (bucketPool.length < this.config.maxPoolSizePerBucket &&\n        this._getTotalPooledCount() < this.config.maxTotalPooledBuffers) {\n      bucketPool.push(buffer);\n    } else {\n      // Pool is full; defer destruction until GPU work completes.\n      this.deferDestroy(buffer);\n      this.stats.currentBytesAllocated -= buffer.size;\n    }\n  }\n\n  /**\n   * Defer buffer destruction until all submitted GPU work completes.\n   * This avoids destroying buffers still referenced by in-flight command buffers.\n   */\n  private deferDestroy(buffer: GPUBuffer): void {\n    this.pendingDestruction.add(buffer);\n    if (this.destructionScheduled) {\n      return;\n    }\n    const device = getDevice();\n    if (!device) {\n      // No device context; destroy immediately as a fallback.\n      for (const pending of this.pendingDestruction) {\n        pending.destroy();\n      }\n      this.pendingDestruction.clear();\n      this.destructionScheduled = false;\n      return;\n    }\n\n    this.destructionScheduled = true;\n    device.queue.onSubmittedWorkDone()\n      .then(() => {\n        for (const pending of this.pendingDestruction) {\n          pending.destroy();\n        }\n        this.pendingDestruction.clear();\n        this.destructionScheduled = false;\n      })\n      .catch((err) => {\n        log.warn('BufferPool', `Deferred destruction failed: ${(err as Error).message}`);\n        this.pendingDestruction.clear();\n        this.destructionScheduled = false;\n      });\n  }\n\n  /**\n   * Get a buffer from the pool if available\n   */\n  private _getFromPool(bucket: number, usage: GPUBufferUsageFlags): GPUBuffer | null {\n    const usagePool = this.pools.get(usage);\n    if (!usagePool) return null;\n\n    const bucketPool = usagePool.get(bucket);\n    if (!bucketPool || bucketPool.length === 0) return null;\n\n    return bucketPool.pop()!;\n  }\n\n  /**\n   * Get total count of pooled buffers\n   */\n  private _getTotalPooledCount(): number {\n    let count = 0;\n    for (const usagePool of this.pools.values()) {\n      for (const bucketPool of usagePool.values()) {\n        count += bucketPool.length;\n      }\n    }\n    return count;\n  }\n\n  /**\n   * Track buffer metadata for leak detection (debug mode)\n   */\n  private _trackBuffer(buffer: GPUBuffer, size: number, usage: GPUBufferUsageFlags, label?: string): void {\n    const metadata: BufferMetadata = {\n      size,\n      usage,\n      label,\n      acquiredAt: Date.now(),\n    };\n\n    // Capture stack trace for leak detection\n    if (Error.captureStackTrace) {\n      const obj = {};\n      Error.captureStackTrace(obj);\n      metadata.stackTrace = (obj as any).stack;\n    }\n\n    this.bufferMetadata.set(buffer, metadata);\n  }\n\n  /**\n   * Detect leaked buffers (debug mode)\n   */\n  detectLeaks(thresholdMs: number = 60000): BufferMetadata[] {\n    if (!this.debugMode) {\n      log.warn('BufferPool', 'Leak detection requires debug mode');\n      return [];\n    }\n\n    const now = Date.now();\n    const leaks: BufferMetadata[] = [];\n\n    for (const [buffer, metadata] of this.bufferMetadata.entries()) {\n      if (this.activeBuffers.has(buffer)) {\n        const age = now - metadata.acquiredAt;\n        if (age > thresholdMs) {\n          leaks.push(metadata);\n        }\n      }\n    }\n\n    return leaks;\n  }\n\n  /**\n   * Create a staging buffer for CPU readback\n   */\n  createStagingBuffer(size: number): GPUBuffer {\n    return this.acquire(size, BufferUsage.STAGING_READ, 'staging_read');\n  }\n\n  /**\n   * Create a staging buffer for CPU upload\n   */\n  createUploadBuffer(size: number): GPUBuffer {\n    return this.acquire(size, BufferUsage.STAGING_WRITE, 'staging_write');\n  }\n\n  /**\n   * Create a uniform buffer\n   */\n  createUniformBuffer(size: number): GPUBuffer {\n    // Uniform buffers have stricter alignment (256 bytes typically)\n    const alignedSize = alignTo(size, 256);\n    return this.acquire(alignedSize, BufferUsage.UNIFORM, 'uniform');\n  }\n\n  /**\n   * Upload data to GPU buffer\n   */\n  uploadData(buffer: GPUBuffer, data: ArrayBuffer | ArrayBufferView, offset: number = 0): void {\n    const device = getDevice();\n    if (!device) {\n      throw new Error('Device not initialized');\n    }\n    device.queue.writeBuffer(buffer, offset, data as GPUAllowSharedBufferSource);\n  }\n\n  /**\n   * Read data from GPU buffer\n   * NOTE: GPU readbacks are expensive (0.5-2ms overhead per call). Use sparingly.\n   */\n  async readBuffer(buffer: GPUBuffer, size: number = buffer.size): Promise<ArrayBuffer> {\n    if (!allowReadback('BufferPool.readBuffer')) {\n      return new ArrayBuffer(0);\n    }\n\n    const device = getDevice();\n    if (!device) {\n      throw new Error('Device not initialized');\n    }\n\n    // Create staging buffer\n    const staging = this.createStagingBuffer(size);\n\n    // Copy to staging\n    const encoder = device.createCommandEncoder({ label: 'readback_encoder' });\n    encoder.copyBufferToBuffer(buffer, 0, staging, 0, size);\n    device.queue.submit([encoder.finish()]);\n\n    // Map and read\n    await staging.mapAsync(GPUMapMode.READ);\n    const data = staging.getMappedRange(0, size).slice(0);\n    staging.unmap();\n\n    // Release staging buffer\n    this.release(staging);\n\n    return data;\n  }\n\n  /**\n   * Clear all pooled buffers\n   */\n  clearPool(): void {\n    for (const usagePool of this.pools.values()) {\n      for (const bucketPool of usagePool.values()) {\n        for (const buffer of bucketPool) {\n          buffer.destroy();\n          this.stats.currentBytesAllocated -= buffer.size;\n        }\n        bucketPool.length = 0;\n      }\n    }\n    this.pools.clear();\n    for (const buffer of this.pendingDestruction) {\n      buffer.destroy();\n    }\n    this.pendingDestruction.clear();\n    this.destructionScheduled = false;\n  }\n\n  /**\n   * Destroy all buffers (active and pooled)\n   */\n  destroy(): void {\n    // Destroy active buffers\n    for (const buffer of this.activeBuffers) {\n      buffer.destroy();\n    }\n    this.activeBuffers.clear();\n    this.bufferMetadata.clear();\n\n    // Clear pools\n    this.clearPool();\n\n    this.stats.currentBytesAllocated = 0;\n  }\n\n  /**\n   * Get pool statistics\n   */\n  getStats(): PoolStats {\n    return {\n      ...this.stats,\n      activeBuffers: this.activeBuffers.size,\n      pooledBuffers: this._getTotalPooledCount(),\n      hitRate: this.stats.allocations > 0\n        ? (this.stats.reuses / (this.stats.allocations + this.stats.reuses) * 100).toFixed(1) + '%'\n        : '0%',\n    };\n  }\n\n  /**\n   * Configure pool settings\n   */\n  configure(config: Partial<PoolConfig>): void {\n    Object.assign(this.config, config);\n  }\n}\n\n// Global buffer pool instance\nlet globalPool: BufferPool | null = null;\n\n/**\n * Get the global buffer pool\n */\nexport function getBufferPool(): BufferPool {\n  if (!globalPool) {\n    globalPool = new BufferPool();\n  }\n  return globalPool;\n}\n\n/**\n * Create a standalone buffer pool\n */\nexport function createBufferPool(debugMode?: boolean, schemaConfig?: BufferPoolConfigSchema): BufferPool {\n  return new BufferPool(debugMode, schemaConfig);\n}\n\n/**\n * Destroy the global buffer pool\n */\nexport function destroyBufferPool(): void {\n  if (globalPool) {\n    globalPool.destroy();\n    globalPool = null;\n  }\n}\n\n// Convenience exports for common operations\nexport const createStagingBuffer = (size: number): GPUBuffer => getBufferPool().createStagingBuffer(size);\nexport const createUploadBuffer = (size: number): GPUBuffer => getBufferPool().createUploadBuffer(size);\nexport const createUniformBuffer = (size: number): GPUBuffer => getBufferPool().createUniformBuffer(size);\nexport const acquireBuffer = (size: number, usage?: GPUBufferUsageFlags, label?: string): GPUBuffer =>\n  getBufferPool().acquire(size, usage, label);\nexport const releaseBuffer = (buffer: GPUBuffer): void => getBufferPool().release(buffer);\nexport const uploadData = (buffer: GPUBuffer, data: ArrayBuffer | ArrayBufferView, offset?: number): void =>\n  getBufferPool().uploadData(buffer, data, offset);\nexport const readBuffer = (buffer: GPUBuffer, size?: number): Promise<ArrayBuffer> =>\n  getBufferPool().readBuffer(buffer, size);\n\n/**\n * Scoped buffer helper - automatically releases buffer when done\n */\nexport async function withBuffer<T>(\n  size: number,\n  usage: GPUBufferUsageFlags,\n  fn: (buffer: GPUBuffer) => Promise<T>\n): Promise<T> {\n  const pool = getBufferPool();\n  const buffer = pool.acquire(size, usage);\n  try {\n    return await fn(buffer);\n  } finally {\n    pool.release(buffer);\n  }\n}\n", "/**\n * Dispatch Helpers - Simplified GPU kernel dispatch\n *\n * Provides helpers to reduce boilerplate for common dispatch patterns:\n * - Single submit dispatch\n * - CommandRecorder dispatch (batched)\n * - Multi-dimensional dispatch\n */\n\nimport type { CommandRecorder } from '../command-recorder.js';\n\n/**\n * Dispatch a single compute pass and submit immediately\n * Use for standalone kernels that don't participate in batching\n */\nexport function dispatch(\n  device: GPUDevice,\n  pipeline: GPUComputePipeline,\n  bindGroup: GPUBindGroup,\n  workgroups: number | [number, number, number],\n  label: string = 'compute'\n): void {\n  const encoder = device.createCommandEncoder({ label: `${label}_encoder` });\n  const pass = encoder.beginComputePass({ label: `${label}_pass` });\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n\n  if (typeof workgroups === 'number') {\n    pass.dispatchWorkgroups(workgroups);\n  } else {\n    pass.dispatchWorkgroups(workgroups[0], workgroups[1], workgroups[2]);\n  }\n\n  pass.end();\n  device.queue.submit([encoder.finish()]);\n}\n\n/**\n * Record a compute pass to a CommandRecorder (no submit)\n * Use for kernels in the batched pipeline path\n */\nexport function recordDispatch(\n  recorder: CommandRecorder,\n  pipeline: GPUComputePipeline,\n  bindGroup: GPUBindGroup,\n  workgroups: number | [number, number, number],\n  label: string = 'compute'\n): void {\n  const pass = recorder.beginComputePass(label);\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n\n  if (typeof workgroups === 'number') {\n    pass.dispatchWorkgroups(workgroups);\n  } else {\n    pass.dispatchWorkgroups(workgroups[0], workgroups[1], workgroups[2]);\n  }\n\n  pass.end();\n}\n\n/**\n * Dispatch a single compute pass using an indirect dispatch buffer\n * Use when workgroup counts are produced on GPU\n */\nexport function dispatchIndirect(\n  device: GPUDevice,\n  pipeline: GPUComputePipeline,\n  bindGroup: GPUBindGroup,\n  indirectBuffer: GPUBuffer,\n  indirectOffset: number = 0,\n  label: string = 'compute'\n): void {\n  const encoder = device.createCommandEncoder({ label: `${label}_encoder` });\n  const pass = encoder.beginComputePass({ label: `${label}_pass` });\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n  pass.dispatchWorkgroupsIndirect(indirectBuffer, indirectOffset);\n  pass.end();\n  device.queue.submit([encoder.finish()]);\n}\n\n/**\n * Record an indirect dispatch into a CommandRecorder (no submit)\n */\nexport function recordDispatchIndirect(\n  recorder: CommandRecorder,\n  pipeline: GPUComputePipeline,\n  bindGroup: GPUBindGroup,\n  indirectBuffer: GPUBuffer,\n  indirectOffset: number = 0,\n  label: string = 'compute'\n): void {\n  const pass = recorder.beginComputePass(label);\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n  pass.dispatchWorkgroupsIndirect(indirectBuffer, indirectOffset);\n  pass.end();\n}\n\n/**\n * Dispatch with multiple bind groups\n * For kernels that use multiple bind group sets\n */\nexport function dispatchMultiBindGroup(\n  device: GPUDevice,\n  pipeline: GPUComputePipeline,\n  bindGroups: GPUBindGroup[],\n  workgroups: number | [number, number, number],\n  label: string = 'compute'\n): void {\n  const encoder = device.createCommandEncoder({ label: `${label}_encoder` });\n  const pass = encoder.beginComputePass({ label: `${label}_pass` });\n  pass.setPipeline(pipeline);\n\n  for (let i = 0; i < bindGroups.length; i++) {\n    pass.setBindGroup(i, bindGroups[i]);\n  }\n\n  if (typeof workgroups === 'number') {\n    pass.dispatchWorkgroups(workgroups);\n  } else {\n    pass.dispatchWorkgroups(workgroups[0], workgroups[1], workgroups[2]);\n  }\n\n  pass.end();\n  device.queue.submit([encoder.finish()]);\n}\n\n/**\n * Calculate workgroup count for 1D dispatch\n * @param totalThreads - Total number of threads needed\n * @param workgroupSize - Threads per workgroup (default: 256)\n * @returns Number of workgroups (rounded up)\n */\nexport function calculateWorkgroups1D(\n  totalThreads: number,\n  workgroupSize: number = 256\n): number {\n  return Math.ceil(totalThreads / workgroupSize);\n}\n\n/**\n * Calculate workgroup count for 2D dispatch\n * @param width - Width dimension (e.g., matrix columns)\n * @param height - Height dimension (e.g., matrix rows)\n * @param tileSize - Tile size per workgroup (default: 16)\n * @returns [workgroupsX, workgroupsY]\n */\nexport function calculateWorkgroups2D(\n  width: number,\n  height: number,\n  tileSize: number = 16\n): [number, number] {\n  return [\n    Math.ceil(width / tileSize),\n    Math.ceil(height / tileSize),\n  ];\n}\n\n/**\n * Calculate workgroup count for 3D dispatch\n * @param width - Width dimension\n * @param height - Height dimension\n * @param depth - Depth dimension\n * @param tileSizeX - Tile size in X (default: 16)\n * @param tileSizeY - Tile size in Y (default: 16)\n * @param tileSizeZ - Tile size in Z (default: 1)\n * @returns [workgroupsX, workgroupsY, workgroupsZ]\n */\nexport function calculateWorkgroups3D(\n  width: number,\n  height: number,\n  depth: number,\n  tileSizeX: number = 16,\n  tileSizeY: number = 16,\n  tileSizeZ: number = 1\n): [number, number, number] {\n  return [\n    Math.ceil(width / tileSizeX),\n    Math.ceil(height / tileSizeY),\n    Math.ceil(depth / tileSizeZ),\n  ];\n}\n\n/**\n * Dispatch options for advanced use cases\n */\nexport interface DispatchOptions {\n  /** Custom label for encoder and pass */\n  label?: string;\n\n  /** Bind groups (default: single group at index 0) */\n  bindGroups?: GPUBindGroup[];\n\n  /** Push constants (if supported) */\n  pushConstants?: ArrayBuffer;\n\n  /** Timestamp queries (if available) */\n  timestampWrites?: GPUComputePassTimestampWrites;\n}\n\n/**\n * Advanced dispatch with full control\n * Supports push constants, timestamps, and multiple bind groups\n */\nexport function dispatchAdvanced(\n  device: GPUDevice,\n  pipeline: GPUComputePipeline,\n  workgroups: number | [number, number, number],\n  options: DispatchOptions = {}\n): void {\n  const {\n    label = 'compute',\n    bindGroups = [],\n    timestampWrites,\n  } = options;\n\n  const encoder = device.createCommandEncoder({ label: `${label}_encoder` });\n  const passDescriptor: GPUComputePassDescriptor = {\n    label: `${label}_pass`,\n  };\n\n  if (timestampWrites) {\n    passDescriptor.timestampWrites = timestampWrites;\n  }\n\n  const pass = encoder.beginComputePass(passDescriptor);\n  pass.setPipeline(pipeline);\n\n  // Set bind groups\n  for (let i = 0; i < bindGroups.length; i++) {\n    pass.setBindGroup(i, bindGroups[i]);\n  }\n\n  // Dispatch\n  if (typeof workgroups === 'number') {\n    pass.dispatchWorkgroups(workgroups);\n  } else {\n    pass.dispatchWorkgroups(workgroups[0], workgroups[1], workgroups[2]);\n  }\n\n  pass.end();\n  device.queue.submit([encoder.finish()]);\n}\n\n/**\n * Batch multiple dispatches in a single command buffer\n * Useful for multi-kernel operations that should be submitted together\n */\nexport function dispatchBatch(\n  device: GPUDevice,\n  batches: Array<{\n    pipeline: GPUComputePipeline;\n    bindGroup: GPUBindGroup;\n    workgroups: number | [number, number, number];\n    label?: string;\n  }>,\n  label: string = 'batch'\n): void {\n  const encoder = device.createCommandEncoder({ label: `${label}_encoder` });\n\n  for (const batch of batches) {\n    const pass = encoder.beginComputePass({ label: batch.label || `${label}_pass` });\n    pass.setPipeline(batch.pipeline);\n    pass.setBindGroup(0, batch.bindGroup);\n\n    if (typeof batch.workgroups === 'number') {\n      pass.dispatchWorkgroups(batch.workgroups);\n    } else {\n      pass.dispatchWorkgroups(batch.workgroups[0], batch.workgroups[1], batch.workgroups[2]);\n    }\n\n    pass.end();\n  }\n\n  device.queue.submit([encoder.finish()]);\n}\n", "/**\n * Kernel Constants - Shared constants for GPU kernels\n *\n * Centralized constants to eliminate magic numbers and improve\n * maintainability across kernel implementations.\n */\n\n/**\n * Workgroup sizes for different kernel types\n */\nexport const WORKGROUP_SIZES = {\n  /** Default workgroup size for most kernels */\n  DEFAULT: 256,\n\n  /** Vec4 workgroup thread count (64 threads \u00D7 4 elements = 256 elements) */\n  VEC4_THREADS: 64,\n\n  /** Attention kernels (large blocks) */\n  ATTENTION_LARGE_BLOCK: 64,\n\n  /** Attention kernels (small blocks) */\n  ATTENTION_SMALL_BLOCK: 32,\n\n  /** Subgroup size (typical for modern GPUs) */\n  SUBGROUP: 32,\n\n  /** RMSNorm workgroup size */\n  RMSNORM: 256,\n\n  /** Softmax workgroup size */\n  SOFTMAX: 256,\n\n  /** Matmul tile sizes */\n  MATMUL_TILE_M: 16,\n  MATMUL_TILE_N: 16,\n  MATMUL_TILE_K: 16,\n\n  /** MoE workgroup size */\n  MOE: 256,\n} as const;\n\n/** Derived: Vec4 elements per workgroup (VEC4_THREADS \u00D7 4) */\nexport const VEC4_ELEMENTS_PER_WG = WORKGROUP_SIZES.VEC4_THREADS * 4;  // 256\n\n/**\n * WebGPU limits (spec-level defaults)\n */\nexport const GPU_LIMITS = {\n  /** Max workgroups per dimension (WebGPU minimum) */\n  MAX_WORKGROUPS: 65535,\n} as const;\n\n/**\n * Memory thresholds for kernel selection (in bytes)\n */\nexport const MEMORY_THRESHOLDS = {\n  /** Large attention tier shared memory requirement */\n  ATTENTION_LARGE_SHARED: 49152, // 48KB\n\n  /** Small attention tier shared memory requirement (F32) */\n  ATTENTION_SMALL_SHARED_F32: 8192, // 8KB (2 * 32 * 32 * 4)\n\n  /** Small attention tier shared memory requirement (F16) */\n  ATTENTION_SMALL_SHARED_F16: 4096, // 4KB (2 * 32 * 32 * 2)\n\n  /** Subgroup attention tier shared memory requirement */\n  ATTENTION_SUBGROUP_SHARED: 8192, // 2048 * 4 bytes for scores array\n\n  /** Minimum shared memory for any GPU */\n  MIN_SHARED_MEMORY: 16384, // 16KB (WebGPU minimum spec)\n} as const;\n\n/**\n * Dimension limits for kernel tier selection\n */\nexport const DIMENSION_LIMITS = {\n  /** Maximum head dimension for large attention tier */\n  ATTENTION_LARGE_MAX_HEAD_DIM: 64,\n\n  /** Maximum head dimension for small attention tier */\n  ATTENTION_SMALL_MAX_HEAD_DIM: 256,\n\n  /** Maximum head dimension for subgroup attention tier */\n  ATTENTION_SUBGROUP_MAX_HEAD_DIM: 256,\n\n  /** Maximum sequence length for practical inference */\n  MAX_SEQ_LEN: 32768,\n\n  /** Maximum vocab size for typical models */\n  MAX_VOCAB_SIZE: 262144, // Gemma 3\n\n  /** Maximum batch size for prefill */\n  MAX_BATCH_SIZE: 128,\n} as const;\n\n/**\n * Tile sizes for different operations\n */\nexport const TILE_SIZES = {\n  /** Attention tile sizes (large) */\n  ATTENTION_LARGE_BLOCK_SIZE: 64,\n  ATTENTION_LARGE_HEAD_TILE: 64,\n\n  /** Attention tile sizes (small) */\n  ATTENTION_SMALL_BLOCK_SIZE: 32,\n  ATTENTION_SMALL_HEAD_TILE: 32,\n\n  /** Matmul tile sizes */\n  MATMUL_M: 16,\n  MATMUL_N: 16,\n  MATMUL_K: 16,\n\n  /** Q4K dequant tile sizes */\n  Q4K_BLOCK_SIZE: 32,\n  Q4K_SUPER_BLOCK_SIZE: 256,\n} as const;\n\n/**\n * Quantization constants\n */\nexport const QUANTIZATION = {\n  /** Q4K_M bits per weight */\n  Q4K_BITS: 4.5,\n  /** Q4K block bytes per 256-element super-block */\n  Q4K_BLOCK_BYTES: 144,\n\n  /** Q8_0 bits per weight */\n  Q8_BITS: 8.5,\n\n  /** F16 bits per weight */\n  F16_BITS: 16,\n\n  /** BF16 bits per weight */\n  BF16_BITS: 16,\n\n  /** F32 bits per weight */\n  F32_BITS: 32,\n\n  /** MXFP4 bits per weight (including shared exponent) */\n  MXFP4_BITS: 4,\n} as const;\n\n/**\n * Buffer alignment requirements\n */\nexport const ALIGNMENT = {\n  /** WebGPU buffer alignment */\n  BUFFER: 256,\n\n  /** Uniform buffer alignment */\n  UNIFORM: 256,\n\n  /** Storage buffer alignment */\n  STORAGE: 256,\n\n  /** Vertex buffer alignment */\n  VERTEX: 4,\n} as const;\n\n/**\n * Performance tuning constants\n */\nexport const PERFORMANCE = {\n  /** Number of warmup runs for benchmarks */\n  WARMUP_RUNS: 5,\n\n  /** Number of timed runs for benchmarks */\n  TIMED_RUNS: 20,\n\n  /** Default timeout for operations (ms) */\n  DEFAULT_TIMEOUT: 120000,\n\n  /** Max buffer pool size per bucket */\n  MAX_POOL_SIZE_PER_BUCKET: 8,\n\n  /** Max total pooled buffers */\n  MAX_TOTAL_POOLED_BUFFERS: 64,\n} as const;\n\n/**\n * Dtype size mappings (in bytes)\n */\nexport const DTYPE_SIZES = {\n  u8: 1,\n  i8: 1,\n  u16: 2,\n  i16: 2,\n  f16: 2,\n  bf16: 2,\n  u32: 4,\n  i32: 4,\n  f32: 4,\n  f64: 8,\n} as const;\n\nexport type DType = keyof typeof DTYPE_SIZES;\n\n/**\n * Get dtype size in bytes\n */\nexport function getDtypeSize(dtype: DType): number {\n  return DTYPE_SIZES[dtype];\n}\n\n/**\n * Calculate buffer size for tensor\n */\nexport function calculateBufferSize(shape: number[], dtype: DType): number {\n  const elements = shape.reduce((a, b) => a * b, 1);\n  return elements * getDtypeSize(dtype);\n}\n\n/**\n * Round size up to alignment boundary\n */\nexport function alignSize(size: number, alignment: number = ALIGNMENT.BUFFER): number {\n  return Math.ceil(size / alignment) * alignment;\n}\n", "/**\n * Fused GEMV + RMSNorm Kernel\n *\n * For decode (M=1), combines the down projection matmul with RMSNorm in a single kernel:\n * 1. Compute GEMV: C[1, N] = A[1, K] \u00D7 B[K, N]  (down projection)\n * 2. Compute RMSNorm on C: output = C / sqrt(mean(C^2) + eps) * weight\n * 3. Optional residual: output = output + residual\n *\n * Benefits:\n * - Single GPU dispatch instead of 2\n * - No intermediate buffer for matmul output\n * - Better cache locality\n *\n * Expected speedup: 1.2-1.5x for post-FFN normalization path\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { createTensor, type Tensor } from '../tensor.js';\nimport { type WeightBuffer, getBuffer } from '../weight-buffer.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { getKernelThresholds } from '../../config/schema/kernel-thresholds.schema.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\n\n/** Fused MatmulRMSNorm kernel options */\nexport interface MatmulRMSNormFusedOptions extends OutputBufferOptions {\n  /** Output dimension N (hiddenSize) */\n  N: number;\n  /** Input dimension K (intermediateSize) */\n  K: number;\n  /** RMSNorm epsilon (default: 1e-5) */\n  eps?: number;\n  /** Optional residual buffer to add to output */\n  residual?: GPUBuffer | null;\n  /**\n   * Whether weight matrix is stored transposed.\n   * - true: weight is [N,K] (row-major/SafeTensors), needs transpose access\n   * - false: weight is [K,N] (column-major/pre-transposed), direct access\n   * Default: true (matches GGUF convention)\n   */\n  transposeB?: boolean;\n}\n\n/**\n * Select fused kernel variant based on output size\n *\n * - small: N <= WORKGROUP_SIZES.DEFAULT (one element per thread)\n * - medium: N > WORKGROUP_SIZES.DEFAULT (multiple elements per thread, single workgroup)\n */\nexport function selectMatmulRMSNormFusedVariant(N: number): string {\n  if (N <= WORKGROUP_SIZES.DEFAULT) {\n    return 'small';\n  }\n  return 'medium';\n}\n\n/**\n * Run fused GEMV + RMSNorm\n *\n * Combines down projection matmul (M=1) with RMSNorm in a single kernel.\n * Use this for the post-FFN normalization path during decode.\n *\n * @param input - Input activation tensor [1, K]\n * @param weight - Down projection weight buffer (GPUBuffer or WeightBuffer)\n * @param normWeight - RMSNorm weight buffer [N]\n * @param options - Kernel options including N, K dimensions\n * @returns Output tensor [1, N] with normalized result\n */\nexport async function runMatmulRMSNormFused(\n  input: Tensor,\n  weight: GPUBuffer | WeightBuffer,\n  normWeight: GPUBuffer,\n  options: MatmulRMSNormFusedOptions\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    N,\n    K,\n    eps = 1e-5,\n    residual = null,\n    outputBuffer = null,\n    transposeB = true,  // Default: GGUF row-major weights\n  } = options;\n\n  const { colsPerWg } = getKernelThresholds().fusedMatmul;\n  if (N > colsPerWg) {\n    throw new Error(`[MatmulRMSNormFused] N=${N} exceeds colsPerWg=${colsPerWg}; kernel only supports single-workgroup RMSNorm.`);\n  }\n\n  const weightBuffer = getBuffer(weight);\n\n  // Select variant based on output size\n  const variant = selectMatmulRMSNormFusedVariant(N);\n\n  trace.kernels(`MatmulRMSNormFused: N=${N}, K=${K}, variant=${variant}, hasResidual=${!!residual}, transposeB=${transposeB}`);\n\n  const pipeline = await getPipelineFast('fused_matmul_rmsnorm', variant);\n\n  // Output buffer: [1, N] floats\n  const outputSize = N * 4;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'matmul_rmsnorm_fused_output');\n\n  // Create uniform buffer (8 u32/f32 = 32 bytes, padded for alignment)\n  const uniformBuffer = createUniformBufferWithView(\n    'matmul_rmsnorm_fused_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, N, true);\n      view.setUint32(4, K, true);\n      view.setFloat32(8, eps, true);\n      view.setUint32(12, residual ? 1 : 0, true);\n      view.setUint32(16, transposeB ? 1 : 0, true);\n      // Padding bytes 20-31 are zero-initialized\n    },\n    null,\n    device\n  );\n\n  // Create placeholder for residual if not provided\n  const residualBuffer = residual || device.createBuffer({\n    label: 'matmul_rmsnorm_residual_placeholder',\n    size: 4,\n    usage: GPUBufferUsage.STORAGE,\n  });\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'matmul_rmsnorm_fused_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: weightBuffer } },\n      { binding: 3, resource: { buffer: normWeight } },\n      { binding: 4, resource: { buffer: output } },\n      { binding: 5, resource: { buffer: residualBuffer } },\n    ],\n  });\n\n  // Calculate workgroups\n  let workgroups: number;\n  if (variant === 'small' || variant === 'medium') {\n    workgroups = 1;  // Single workgroup for small/medium N\n  } else {\n    workgroups = Math.ceil(N / getKernelThresholds().fusedMatmul.colsPerWg);\n  }\n\n  dispatch(device, pipeline, bindGroup, workgroups, 'matmul_rmsnorm_fused');\n\n  // Cleanup\n  uniformBuffer.destroy();\n  if (!residual) residualBuffer.destroy();\n\n  // Output dtype matches input dtype\n  return createTensor(output, input.dtype, [1, N], 'matmul_rmsnorm_fused_output');\n}\n\n/**\n * Record fused GEMV + RMSNorm (batched, no submit)\n *\n * Use this for the command recording path in the inference pipeline.\n */\nexport async function recordMatmulRMSNormFused(\n  recorder: CommandRecorder,\n  input: Tensor,\n  weight: GPUBuffer | WeightBuffer,\n  normWeight: GPUBuffer,\n  options: MatmulRMSNormFusedOptions\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    N,\n    K,\n    eps = 1e-5,\n    residual = null,\n    outputBuffer = null,\n    transposeB = true,  // Default: GGUF row-major weights\n  } = options;\n\n  const { colsPerWg } = getKernelThresholds().fusedMatmul;\n  if (N > colsPerWg) {\n    throw new Error(`[MatmulRMSNormFused] N=${N} exceeds colsPerWg=${colsPerWg}; kernel only supports single-workgroup RMSNorm.`);\n  }\n\n  const weightBuffer = getBuffer(weight);\n\n  // Select variant\n  const variant = selectMatmulRMSNormFusedVariant(N);\n\n  trace.kernels(`recordMatmulRMSNormFused: N=${N}, K=${K}, variant=${variant}, hasResidual=${!!residual}, transposeB=${transposeB}`);\n\n  const pipeline = await getPipelineFast('fused_matmul_rmsnorm', variant);\n\n  // Output buffer\n  const outputSize = N * 4;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'matmul_rmsnorm_fused_output');\n\n  // Uniform buffer via recorder (8 u32/f32 = 32 bytes, padded for alignment)\n  const uniformBuffer = createUniformBufferWithView(\n    'matmul_rmsnorm_fused_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, N, true);\n      view.setUint32(4, K, true);\n      view.setFloat32(8, eps, true);\n      view.setUint32(12, residual ? 1 : 0, true);\n      view.setUint32(16, transposeB ? 1 : 0, true);\n      // Padding bytes 20-31 are zero-initialized\n    },\n    recorder\n  );\n\n  // Placeholder for residual\n  const residualBuffer = residual || device.createBuffer({\n    label: 'matmul_rmsnorm_residual_placeholder',\n    size: 4,\n    usage: GPUBufferUsage.STORAGE,\n  });\n\n  // Bind group\n  const bindGroup = device.createBindGroup({\n    label: 'matmul_rmsnorm_fused_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: weightBuffer } },\n      { binding: 3, resource: { buffer: normWeight } },\n      { binding: 4, resource: { buffer: output } },\n      { binding: 5, resource: { buffer: residualBuffer } },\n    ],\n  });\n\n  // Calculate workgroups\n  let workgroups: number;\n  if (variant === 'small' || variant === 'medium') {\n    workgroups = 1;  // Single workgroup for small/medium N\n  } else {\n    workgroups = Math.ceil(N / getKernelThresholds().fusedMatmul.colsPerWg);\n  }\n\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'matmul_rmsnorm_fused');\n\n  // Track placeholder for cleanup\n  if (!residual) {\n    recorder.trackTemporaryBuffer(residualBuffer);\n  }\n\n  // Output dtype matches input dtype\n  return createTensor(output, input.dtype, [1, N], 'matmul_rmsnorm_fused_output');\n}\n\n/**\n * Check if fused kernel should be used for given dimensions\n *\n * The fused kernel is beneficial when:\n * - M = 1 (decode, not prefill)\n * - N <= colsPerWg (current WGSL RMSNorm reduction only valid for single workgroup)\n *\n * For N > 256, the parallelism loss from single-workgroup execution\n * outweighs the dispatch reduction benefit of fusion.\n */\nexport function shouldUseFusedMatmulRMSNorm(M: number, N: number): boolean {\n  // Only beneficial for decode (M=1)\n  if (M !== 1) {\n    return false;\n  }\n\n  const { colsPerWg } = getKernelThresholds().fusedMatmul;\n  if (N > colsPerWg) {\n    return false;\n  }\n\n  return true;\n}\n", "/**\n * Browser Test Page - Initializes GPU and exposes test functions to Playwright\n */\n\n// Import from main doppler repo (relative path from kernel-tests/browser/)\n// When served from doppler/, paths are relative to that root\nimport { initDevice, getKernelCapabilities, getDeviceLimits, destroyDevice } from '../../src/gpu/device.js';\n\n// Import tensor abstraction for Tensor-based kernels\nimport { createTensor, type Tensor } from '../../src/gpu/tensor.js';\n\n// Ensure platform/registry lookups resolve to the main config paths when bundled\nimport { setPlatformsBaseUrl } from '../../src/config/platforms/loader.js';\nimport { setRegistryUrl } from '../../src/config/kernels/registry.js';\n\n// Import kernel path to enable fused Q4K path for testing\nimport { resolveKernelPath, setActiveKernelPath } from '../../src/config/kernel-path-loader.js';\n\n// Import kernel functions - some may not exist, so we import what's available\nimport * as kernelSelector from '../../src/gpu/kernel-selector.js';\n\n// Destructure available functions with defaults\nconst {\n  runMatmul = null,\n  runSoftmax = null,\n  runTopK = null,\n  runSoftmaxTopK = null,\n  runScatterAdd = null,\n  runMoEGather = null,\n  runRMSNorm = null,\n  runRoPE = null,\n  runSiLU = null,\n  runSwiGLURowsplitBias = null,\n  runScale = null,\n  runGather = null,\n  runResidualAdd = null,\n  runBiasAdd = null,\n  runAttention = null,\n  dequantize = null,\n  dequantizeQ6K = null,\n  runBF16ToF32 = null,\n  runBF16ToF16 = null,\n  castF32ToF16 = null,\n} = kernelSelector;\n\n// Import sample kernel\nimport * as sampleKernel from '../../src/gpu/kernels/sample.js';\n\n// Optional buffer pool\nlet bufferPool: any = null;\ntry {\n  bufferPool = await import('../../src/gpu/buffer-pool.js');\n} catch (e) {\n  console.warn('Buffer pool not available:', (e as Error).message);\n}\n\n// Import reference implementations\nimport * as references from '../src/reference/index.js';\nimport { compareArrays, generateTestData, KERNEL_TOLERANCES } from '../src/harness/tolerance.js';\nimport { createBuffer, readGPUBuffer, readAsFloat32, readAsUint32 } from '../src/harness/buffer-utils.js';\nimport { KernelBenchmark, computeMetrics } from '../src/harness/benchmark.js';\n\n// Global state\nlet device: GPUDevice | null = null;\nlet initialized = false;\n\n/**\n * Convert f16 (IEEE 754 half-precision) to f32\n */\nfunction f16ToF32(h: number): number {\n  const sign = (h & 0x8000) >> 15;\n  const exponent = (h & 0x7C00) >> 10;\n  const mantissa = h & 0x03FF;\n\n  if (exponent === 0) {\n    // Denormalized or zero\n    if (mantissa === 0) return sign ? -0 : 0;\n    return (sign ? -1 : 1) * Math.pow(2, -14) * (mantissa / 1024);\n  } else if (exponent === 31) {\n    // Infinity or NaN\n    return mantissa === 0 ? (sign ? -Infinity : Infinity) : NaN;\n  }\n\n  // Normalized\n  return (sign ? -1 : 1) * Math.pow(2, exponent - 15) * (1 + mantissa / 1024);\n}\n\n/**\n * Initialize WebGPU device\n */\nasync function initGPU(): Promise<GPUDevice> {\n  if (device) return device;\n\n  setPlatformsBaseUrl('/config/platforms/');\n  setRegistryUrl('/config/kernels/registry.json');\n\n  device = await initDevice();\n  if (!device) {\n    throw new Error('WebGPU not available');\n  }\n\n  // Set kernel path to use fused Q4K path for testing\n  setActiveKernelPath(resolveKernelPath('q4k-fused'), 'runtime');\n\n  initialized = true;\n  return device;\n}\n\n/**\n * Get GPU device (initializes if needed)\n */\nasync function getGPU(): Promise<{ device: GPUDevice; queue: GPUQueue }> {\n  if (!device) {\n    await initGPU();\n  }\n  return { device: device!, queue: device!.queue };\n}\n\n/**\n * Wrapper to create GPU buffer from typed array\n */\nfunction makeBuffer(\n  data: Float32Array | Uint32Array | Int32Array | Uint16Array | Uint8Array | ArrayBuffer,\n  usage: number = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC\n): GPUBuffer {\n  const byteLength = data instanceof ArrayBuffer ? data.byteLength : data.byteLength;\n  const buffer = device!.createBuffer({\n    size: byteLength,\n    usage: usage | GPUBufferUsage.COPY_DST,\n    mappedAtCreation: true,\n  });\n\n  const mappedRange = buffer.getMappedRange();\n  if (data instanceof Float32Array) {\n    new Float32Array(mappedRange).set(data);\n  } else if (data instanceof Uint32Array) {\n    new Uint32Array(mappedRange).set(data);\n  } else if (data instanceof Int32Array) {\n    new Int32Array(mappedRange).set(data);\n  } else if (data instanceof Uint16Array) {\n    new Uint16Array(mappedRange).set(data);\n  } else if (data instanceof Uint8Array) {\n    new Uint8Array(mappedRange).set(data);\n  } else {\n    new Uint8Array(mappedRange).set(new Uint8Array(data));\n  }\n  buffer.unmap();\n\n  return buffer;\n}\n\n/**\n * Read GPU buffer back to CPU\n */\nasync function readBufferData(buffer: GPUBuffer, size: number): Promise<ArrayBuffer> {\n  const stagingBuffer = device!.createBuffer({\n    size,\n    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,\n  });\n\n  const encoder = device!.createCommandEncoder();\n  encoder.copyBufferToBuffer(buffer, 0, stagingBuffer, 0, size);\n  device!.queue.submit([encoder.finish()]);\n\n  await stagingBuffer.mapAsync(GPUMapMode.READ);\n  const data = new Uint8Array(stagingBuffer.getMappedRange()).slice();\n  stagingBuffer.unmap();\n  stagingBuffer.destroy();\n\n  return data.buffer;\n}\n\n// ============================================================================\n// Test Harness - Exposed to window for Playwright\n// ============================================================================\n\ninterface TopKResult {\n  indices: Uint32Array;\n  weights: Float32Array;\n}\n\ninterface MoEGatherResult {\n  gatheredTokens: Float32Array;\n  tokenCounts: Uint32Array;\n}\n\ninterface TestHarnessImpl {\n  // Core\n  getGPU: typeof getGPU;\n  device: () => GPUDevice | null;\n\n  // Reference implementations\n  references: typeof references;\n  softmax: typeof references.softmaxRef;\n  topkRef: typeof references.topkRef;\n  softmaxTopkRef: typeof references.softmaxTopkRef;\n  matmulRef: typeof references.matmulRef;\n  scatterAddRef: typeof references.scatterAddRef;\n\n  // Utilities\n  generateTestData: typeof generateTestData;\n  compareArrays: typeof compareArrays;\n  makeBuffer: typeof makeBuffer;\n  readBufferData: typeof readBufferData;\n  KERNEL_TOLERANCES: typeof KERNEL_TOLERANCES;\n\n  // Kernel Runners\n  runMatmul(\n    dev: GPUDevice,\n    A: Float32Array,\n    B: Float32Array,\n    M: number,\n    N: number,\n    K: number,\n    alpha?: number\n  ): Promise<Float32Array>;\n\n  runBatchMatmul(\n    dev: GPUDevice,\n    A: Float32Array,\n    B: Float32Array,\n    batch: number,\n    M: number,\n    N: number,\n    K: number\n  ): Promise<Float32Array>;\n\n  runMatvec(\n    dev: GPUDevice,\n    A: Float32Array,\n    x: Float32Array,\n    M: number,\n    K: number\n  ): Promise<Float32Array>;\n\n  runMatmulQ4K(\n    dev: GPUDevice,\n    A: Float32Array,\n    B_q4k: Uint8Array,\n    M: number,\n    N: number,\n    K: number,\n    alpha?: number\n  ): Promise<Float32Array>;\n\n  runSoftmax(\n    dev: GPUDevice,\n    input: Float32Array,\n    innerSize: number,\n    outerSize: number,\n    temperature?: number\n  ): Promise<Float32Array>;\n\n  runSoftmaxTopK(\n    dev: GPUDevice,\n    logits: Float32Array,\n    numTokens: number,\n    numExperts: number,\n    topK: number,\n    options?: { normalize?: boolean }\n  ): Promise<TopKResult>;\n\n  runTopK(\n    dev: GPUDevice,\n    probs: Float32Array,\n    numTokens: number,\n    numExperts: number,\n    topK: number,\n    options?: { normalize?: boolean }\n  ): Promise<TopKResult>;\n\n  runScatterAdd(\n    dev: GPUDevice,\n    expertOutputs: Float32Array,\n    indices: Uint32Array,\n    weights: Float32Array,\n    numTokens: number,\n    hiddenSize: number,\n    numExperts: number,\n    topK: number\n  ): Promise<Float32Array>;\n\n  runRMSNorm(\n    dev: GPUDevice,\n    input: Float32Array,\n    weight: Float32Array,\n    numTokens: number,\n    hiddenSize: number,\n    eps?: number\n  ): Promise<Float32Array>;\n\n  runRoPE(\n    dev: GPUDevice,\n    input: Float32Array,\n    seqLen: number,\n    numHeads: number,\n    headDim: number,\n    startPos?: number\n  ): Promise<Float32Array>;\n\n  runSiLU(dev: GPUDevice, input: Float32Array): Promise<Float32Array>;\n\n  runSiLUGated(dev: GPUDevice, gate: Float32Array, up: Float32Array): Promise<Float32Array>;\n\n  runGather(\n    dev: GPUDevice,\n    embeddings: Float32Array,\n    indices: Uint32Array,\n    vocabSize: number,\n    embedDim: number\n  ): Promise<Float32Array>;\n\n  runResidual(dev: GPUDevice, x: Float32Array, residual: Float32Array): Promise<Float32Array>;\n  runBiasAdd(\n    dev: GPUDevice,\n    data: Float32Array,\n    bias: Float32Array,\n    numTokens: number,\n    dim: number\n  ): Promise<Float32Array>;\n\n  runDequantQ4K(\n    dev: GPUDevice,\n    quantized: Uint8Array,\n    numBlocks: number\n  ): Promise<Float32Array>;\n\n  runAttention(\n    dev: GPUDevice,\n    Q: Float32Array,\n    K: Float32Array,\n    V: Float32Array,\n    seqLen: number,\n    kvLen: number,\n    numHeads: number,\n    numKVHeads: number,\n    headDim: number,\n    mask?: Float32Array | null\n  ): Promise<Float32Array>;\n\n  runMoEGather(\n    dev: GPUDevice,\n    tokens: Float32Array,\n    expertIndices: Uint32Array,\n    numTokens: number,\n    hiddenSize: number,\n    numExperts: number,\n    topK: number\n  ): Promise<MoEGatherResult>;\n\n  runArgmax(dev: GPUDevice, logits: Float32Array): Promise<number>;\n\n  runSampleTopK(\n    dev: GPUDevice,\n    logits: Float32Array,\n    temperature: number,\n    topK: number,\n    randomValue: number\n  ): Promise<number>;\n\n  runSwiGLU(\n    dev: GPUDevice,\n    gate: Float32Array,\n    up: Float32Array,\n    gateBias: Float32Array,\n    upBias: Float32Array\n  ): Promise<Float32Array>;\n\n  runScale(\n    dev: GPUDevice,\n    input: Float32Array,\n    scale: number\n  ): Promise<Float32Array>;\n\n  runBF16ToF32(dev: GPUDevice, input: Uint16Array): Promise<Float32Array>;\n\n  runF32ToF16(dev: GPUDevice, input: Float32Array): Promise<Uint16Array>;\n\n  runBF16ToF16(dev: GPUDevice, input: Uint16Array): Promise<Uint16Array>;\n\n  runDequantQ6K(\n    dev: GPUDevice,\n    quantized: Uint8Array,\n    numBlocks: number\n  ): Promise<Float32Array>;\n}\n\nconst testHarness: TestHarnessImpl = {\n  // Core\n  getGPU,\n  device: () => device,\n\n  // Reference implementations\n  references,\n  softmax: references.softmaxRef,\n  topkRef: references.topkRef,\n  softmaxTopkRef: references.softmaxTopkRef,\n  matmulRef: references.matmulRef,\n  scatterAddRef: references.scatterAddRef,\n\n  // Utilities\n  generateTestData,\n  compareArrays,\n  makeBuffer,\n  readBufferData,\n  KERNEL_TOLERANCES,\n\n  // ============================================================================\n  // Kernel Runners (match expected interface from tests)\n  // ============================================================================\n\n  /**\n   * Run matmul kernel\n   */\n  async runMatmul(dev, A, B, M, N, K, alpha = 1.0) {\n    if (!runMatmul) {\n      // Fallback to reference implementation\n      return references.matmulRef(A, B, M, N, K, alpha);\n    }\n\n    const bufA = makeBuffer(A);\n    const tensorA = createTensor(bufA, 'f32', [M, K], 'matmul_a');\n    const bufB = makeBuffer(B);\n\n    // Test uses standard layout B [K, N], so transposeB = false\n    // (GPU kernel defaults to transposeB=true for SafeTensors [N, K] layout)\n    const resultTensor = await runMatmul(tensorA, bufB, M, N, K, { alpha, transposeB: false });\n\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, M * N * 4));\n\n    bufA.destroy();\n    bufB.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run batched matmul kernel\n   */\n  async runBatchMatmul(dev, A, B, batch, M, N, K) {\n    // Always use reference - batch matmul kernel may not be implemented\n    return references.batchMatmulRef(A, B, batch, M, N, K);\n  },\n\n  /**\n   * Run matrix-vector multiplication\n   */\n  async runMatvec(dev, A, x, M, K) {\n    // Always use reference - matvec kernel may not be implemented\n    return references.matvecRef(A, x, M, K);\n  },\n\n  /**\n   * Run Q4_K fused matmul kernel (tests q4_fused/q4_fused_batched)\n   * C = A[M,K] @ dequant(B_q4k[N,K])^T = C[M,N]\n   */\n  async runMatmulQ4K(dev, A, B_q4k, M, N, K, alpha = 1.0) {\n    if (!runMatmul) {\n      throw new Error('runMatmul kernel not available');\n    }\n\n    // Create A buffer (activations)\n    const bufA = makeBuffer(A);\n    const tensorA = createTensor(bufA, 'f32', [M, K], 'matmul_q4k_a');\n\n    // Create B buffer and pass q4k dtype to trigger fused Q4K selection\n    const bufB = makeBuffer(B_q4k, GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC);\n\n    // Run matmul - kernel auto-detects q4k and uses fused variant\n    // transposeB is implicit for Q4K (weight matrix stored as [N, K])\n    const resultTensor = await runMatmul(tensorA, bufB, M, N, K, { alpha, bDtype: 'q4k' });\n\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, M * N * 4));\n\n    bufA.destroy();\n    bufB.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run softmax kernel\n   */\n  async runSoftmax(dev, input, innerSize, outerSize, temperature = 1.0) {\n    if (!runSoftmax) {\n      return references.softmaxRef(input, innerSize, outerSize, temperature);\n    }\n\n    const inputBuf = makeBuffer(input);\n    const inputTensor = createTensor(inputBuf, 'f32', [outerSize, innerSize], 'softmax_input');\n\n    const resultTensor = await runSoftmax(inputTensor, -1, {\n      batchSize: outerSize,\n      size: innerSize,\n      temperature,\n    });\n\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, input.length * 4));\n\n    inputBuf.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run fused softmax + top-k kernel\n   */\n  async runSoftmaxTopK(dev, logits, numTokens, numExperts, topK, options = {}) {\n    if (!runSoftmaxTopK) {\n      return references.softmaxTopkRef(logits, numTokens, numExperts, topK, options.normalize !== false);\n    }\n\n    const inputBuf = makeBuffer(logits);\n\n    const { indices: indicesBuf, weights: weightsBuf } = await runSoftmaxTopK(\n      inputBuf,\n      numTokens,\n      numExperts,\n      topK,\n      { normalize: options.normalize !== false }\n    );\n\n    const indices = new Uint32Array(await readBufferData(indicesBuf, numTokens * topK * 4));\n    const weights = new Float32Array(await readBufferData(weightsBuf, numTokens * topK * 4));\n\n    inputBuf.destroy();\n    indicesBuf.destroy();\n    weightsBuf.destroy();\n\n    return { indices, weights };\n  },\n\n  /**\n   * Run top-k selection (without softmax)\n   */\n  async runTopK(dev, probs, numTokens, numExperts, topK, options = {}) {\n    const inputBuf = makeBuffer(probs);\n\n    const { indices: indicesBuf, weights: weightsBuf } = await runTopK(\n      inputBuf,\n      numTokens,\n      numExperts,\n      topK,\n      { normalize: options.normalize !== false }\n    );\n\n    const indices = new Uint32Array(await readBufferData(indicesBuf, numTokens * topK * 4));\n    const weights = new Float32Array(await readBufferData(weightsBuf, numTokens * topK * 4));\n\n    inputBuf.destroy();\n    indicesBuf.destroy();\n    weightsBuf.destroy();\n\n    return { indices, weights };\n  },\n\n  /**\n   * Run scatter-add kernel\n   */\n  async runScatterAdd(dev, expertOutputs, indices, weights, numTokens, hiddenSize, numExperts, topK) {\n    if (!runScatterAdd) {\n      return references.scatterAddRef(expertOutputs, indices, weights, numTokens, hiddenSize, numExperts, topK);\n    }\n\n    const expertBuf = makeBuffer(expertOutputs);\n    const indicesBuf = makeBuffer(indices);\n    const weightsBuf = makeBuffer(weights);\n\n    // Wrap expertBuf in Tensor (MoE kernels now use Tensor abstraction)\n    const expertTensor = createTensor(expertBuf, 'f32', [numExperts, numTokens, hiddenSize], 'expert_outputs');\n    const resultTensor = await runScatterAdd(\n      expertTensor,\n      indicesBuf,\n      weightsBuf,\n      numTokens,\n      hiddenSize,\n      numExperts,\n      topK\n    );\n\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, numTokens * hiddenSize * 4));\n\n    expertBuf.destroy();\n    indicesBuf.destroy();\n    weightsBuf.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run RMSNorm kernel\n   * kernel-selector API: runRMSNorm(input, weight, eps, options)\n   * options: { batchSize, hiddenSize }\n   */\n  async runRMSNorm(dev, input, weight, numTokens, hiddenSize, eps = 1e-6) {\n    if (!runRMSNorm) {\n      return references.rmsNormRef(input, weight, numTokens, hiddenSize, eps);\n    }\n\n    const inputBuf = makeBuffer(input);\n    const weightBuf = makeBuffer(weight);\n    const inputTensor = createTensor(inputBuf, 'f32', [numTokens, hiddenSize], 'rmsnorm_input');\n\n    const resultTensor = await runRMSNorm(inputTensor, weightBuf, eps, {\n      batchSize: numTokens,\n      hiddenSize,\n    });\n\n    let result: Float32Array;\n    if (resultTensor.dtype === 'f16') {\n      const rawData = await readBufferData(resultTensor.buffer, numTokens * hiddenSize * 2);\n      const u16View = new Uint16Array(rawData);\n      result = new Float32Array(u16View.length);\n      for (let i = 0; i < u16View.length; i++) {\n        result[i] = f16ToF32(u16View[i]);\n      }\n    } else {\n      result = new Float32Array(\n        await readBufferData(resultTensor.buffer, numTokens * hiddenSize * 4)\n      );\n    }\n\n    inputBuf.destroy();\n    weightBuf.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run RoPE kernel\n   */\n  async runRoPE(dev, input, seqLen, numHeads, headDim, startPos = 0) {\n    const { cos, sin } = references.computeRopeFreqs(headDim, seqLen + startPos);\n\n    if (!runRoPE) {\n      return references.ropeRef(input, cos, sin, seqLen, numHeads, headDim, startPos);\n    }\n\n    const inputBuf = makeBuffer(input);\n    const cosBuf = makeBuffer(cos);\n    const sinBuf = makeBuffer(sin);\n\n    await runRoPE(inputBuf, cosBuf, sinBuf, seqLen, {\n      numHeads,\n      headDim,\n      startPos,\n    });\n\n    const result = new Float32Array(\n      await readBufferData(inputBuf, seqLen * numHeads * headDim * 4)\n    );\n\n    inputBuf.destroy();\n    cosBuf.destroy();\n    sinBuf.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run SiLU kernel\n   */\n  async runSiLU(dev, input) {\n    if (!runSiLU) {\n      return references.siluRef(input);\n    }\n\n    const inputBuf = makeBuffer(input);\n    const resultBuf = await runSiLU(inputBuf, { size: input.length });\n    const result = new Float32Array(await readBufferData(resultBuf, input.length * 4));\n\n    inputBuf.destroy();\n    resultBuf.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run SiLU with gating\n   */\n  async runSiLUGated(dev, gate, up) {\n    if (!runSiLU) {\n      return references.siluGatedRef(gate, up);\n    }\n\n    const gateBuf = makeBuffer(gate);\n    const upBuf = makeBuffer(up);\n\n    const resultBuf = await runSiLU(upBuf, { size: up.length, gate: gateBuf });\n    const result = new Float32Array(await readBufferData(resultBuf, up.length * 4));\n\n    gateBuf.destroy();\n    upBuf.destroy();\n    resultBuf.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run gather/embedding lookup\n   * kernel-selector API: runGather(indices, embeddings, numTokens, hiddenSize, vocabSize, options)\n   */\n  async runGather(dev, embeddings, indices, vocabSize, embedDim) {\n    if (!runGather) {\n      return references.gatherRef(embeddings, indices, vocabSize, embedDim);\n    }\n\n    const embBuf = makeBuffer(embeddings);\n    const idxBuf = makeBuffer(indices);\n    const numTokens = indices.length;\n    // Test data uses standard [vocab_size, hidden_size] layout, not GGUF [hidden_size, vocab_size]\n    const resultTensor = await runGather(idxBuf, embBuf, numTokens, embedDim, vocabSize, { transpose: false });\n    let result: Float32Array;\n    if (resultTensor.dtype === 'f16') {\n      const rawData = await readBufferData(resultTensor.buffer, numTokens * embedDim * 2);\n      const u16View = new Uint16Array(rawData);\n      result = new Float32Array(u16View.length);\n      for (let i = 0; i < u16View.length; i++) {\n        result[i] = f16ToF32(u16View[i]);\n      }\n    } else {\n      result = new Float32Array(\n        await readBufferData(resultTensor.buffer, numTokens * embedDim * 4)\n      );\n    }\n\n    embBuf.destroy();\n    idxBuf.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run residual add\n   * kernel-selector API: runResidualAdd(a, b, size, options)\n   */\n  async runResidual(dev, x, residual) {\n    if (!runResidualAdd) {\n      return references.residualAddRef(x, residual);\n    }\n\n    const xBuf = makeBuffer(x);\n    const resBuf = makeBuffer(residual);\n    const size = x.length;\n    const resultBuf = await runResidualAdd(xBuf, resBuf, size);\n    const result = new Float32Array(await readBufferData(resultBuf, size * 4));\n\n    xBuf.destroy();\n    resBuf.destroy();\n    resultBuf.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run bias add (row-wise)\n   */\n  async runBiasAdd(dev, data, bias, numTokens, dim) {\n    if (!runBiasAdd) {\n      const result = new Float32Array(data);\n      for (let t = 0; t < numTokens; t++) {\n        const rowOffset = t * dim;\n        for (let d = 0; d < dim; d++) {\n          result[rowOffset + d] += bias[d];\n        }\n      }\n      return result;\n    }\n\n    const dataBuf = makeBuffer(data);\n    const biasBuf = makeBuffer(bias);\n    const dataTensor = createTensor(dataBuf, 'f32', [numTokens, dim], 'bias_add_data');\n    const biasTensor = createTensor(biasBuf, 'f32', [dim], 'bias_add_bias');\n\n    const resultTensor = await runBiasAdd(dataTensor, biasTensor, numTokens, dim);\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, numTokens * dim * 4));\n\n    dataBuf.destroy();\n    biasBuf.destroy();\n    if (resultTensor.buffer !== dataBuf) {\n      resultTensor.buffer.destroy();\n    }\n\n    return result;\n  },\n\n  /**\n   * Run Q4_K dequantization (Q4_K_M) on GPU\n   * kernel-selector API: dequantize(quantized, numBlocks, options)\n   */\n  async runDequantQ4K(dev, quantized, numBlocks) {\n    if (!dequantize) {\n      throw new Error('dequantize kernel not available');\n    }\n\n    const qBuf = makeBuffer(quantized, GPUBufferUsage.STORAGE);\n    const outTensor = await dequantize(qBuf, numBlocks, { outputDtype: 'f32', useVec4: false });\n    const out = new Float32Array(await readBufferData(outTensor.buffer, numBlocks * 256 * 4));\n\n    qBuf.destroy();\n    outTensor.buffer.destroy();\n\n    return out;\n  },\n\n  /**\n   * Run Q4_K dequantization to F16 output (production path)\n   * This matches what the loader uses during model loading\n   */\n  async runDequantQ4K_F16(dev, quantized, numBlocks) {\n    if (!dequantize) {\n      throw new Error('dequantize kernel not available');\n    }\n\n    const qBuf = makeBuffer(quantized, GPUBufferUsage.STORAGE);\n    // Use F16 output and vec4=true (default) to match production loader path\n    const outTensor = await dequantize(qBuf, numBlocks, { outputDtype: 'f16', useVec4: true });\n\n    // Read back F16 data and convert to F32 for comparison\n    const f16Bytes = numBlocks * 256 * 2; // F16 = 2 bytes per element\n    const rawData = await readBufferData(outTensor.buffer, f16Bytes);\n    const u16 = new Uint16Array(rawData);\n    const out = new Float32Array(numBlocks * 256);\n\n    // Convert F16 to F32\n    for (let i = 0; i < u16.length; i++) {\n      const h = u16[i];\n      const sign = (h >> 15) & 1;\n      const exp = (h >> 10) & 0x1F;\n      const mant = h & 0x3FF;\n      let f: number;\n      if (exp === 0) {\n        f = mant === 0 ? 0 : Math.pow(2, -14) * (mant / 1024);\n      } else if (exp === 31) {\n        f = mant === 0 ? Infinity : NaN;\n      } else {\n        f = Math.pow(2, exp - 15) * (1 + mant / 1024);\n      }\n      out[i] = sign ? -f : f;\n    }\n\n    qBuf.destroy();\n    outTensor.buffer.destroy();\n\n    return out;\n  },\n\n  /**\n   * Run attention kernel\n   * kernel-selector API: runAttention(Q, K, V, mask, numHeads, headDim, options)\n   * options: { seqLen, kvLen, numKVHeads, scale, causal }\n   *\n   * Uses production kernel selector which automatically chooses appropriate tier\n   * (subgroup, tiled_small, streaming) based on device capabilities.\n   */\n  async runAttention(dev, Q, K, V, seqLen, kvLen, numHeads, numKVHeads, headDim, mask = null) {\n    if (!runAttention) {\n      // Fallback to reference if kernel not available\n      return references.attentionRef(Q, K, V, seqLen, kvLen, numHeads, numKVHeads, headDim, mask);\n    }\n\n    // Create GPU buffers\n    const qBuf = makeBuffer(Q);\n    const kBuf = makeBuffer(K);\n    const vBuf = makeBuffer(V);\n    const maskBuf = mask ? makeBuffer(mask) : null;\n    const isCausal = !!mask;\n\n    // Run attention via kernel selector (handles tier selection automatically)\n    const outBuf = await runAttention(qBuf, kBuf, vBuf, maskBuf, numHeads, headDim, {\n      seqLen,\n      kvLen,\n      numKVHeads,\n      scale: 1 / Math.sqrt(headDim),\n      causal: isCausal,\n    });\n\n    // Read back result\n    const out = new Float32Array(await readBufferData(outBuf, seqLen * numHeads * headDim * 4));\n    qBuf.destroy();\n    kBuf.destroy();\n    vBuf.destroy();\n    maskBuf?.destroy();\n    outBuf.destroy();\n    return out;\n  },\n\n  /**\n   * Run MoE gather - dispatches tokens to experts\n   * Now uses the fixed two-phase GPU kernel (count_and_map + gather_tokens)\n   */\n  async runMoEGather(dev, tokens, expertIndices, numTokens, hiddenSize, numExperts, topK) {\n    if (!runMoEGather) {\n      // Fallback to reference if kernel not available\n      const result = references.moeGatherRef(tokens, expertIndices, numTokens, hiddenSize, numExperts, topK);\n      return {\n        gatheredTokens: result.gatheredTokens,\n        tokenCounts: result.tokenCounts,\n      };\n    }\n\n    // Create GPU buffers\n    const tokensBuf = makeBuffer(tokens);\n    const indicesBuf = makeBuffer(expertIndices);\n\n    // Wrap tokensBuf in Tensor (MoE kernels now use Tensor abstraction)\n    const tokensTensor = createTensor(tokensBuf, 'f32', [numTokens, hiddenSize], 'moe_input');\n\n    // Run MoE gather via kernel selector\n    const result = await runMoEGather(tokensTensor, indicesBuf, numTokens, hiddenSize, numExperts, topK);\n\n    // Read back results (result.gathered is now a Tensor)\n    const maxTokensPerExpert = result.maxTokensPerExpert;\n    const gatheredTokens = new Float32Array(await readBufferData(result.gathered.buffer, numExperts * maxTokensPerExpert * hiddenSize * 4));\n    const tokenCounts = new Uint32Array(await readBufferData(result.tokenCounts, numExperts * 4));\n\n    tokensBuf.destroy();\n    indicesBuf.destroy();\n    result.gathered.buffer.destroy();\n    result.tokenCounts.destroy();\n    result.tokenMap.destroy();\n\n    return {\n      gatheredTokens,\n      tokenCounts,\n    };\n  },\n\n  /**\n   * Run GPU argmax (greedy decoding)\n   */\n  async runArgmax(dev, logits) {\n    const logitsBuf = makeBuffer(logits);\n    const tokenId = await sampleKernel.runArgmax(logitsBuf, logits.length);\n    logitsBuf.destroy();\n    return tokenId;\n  },\n\n  /**\n   * Run GPU top-k sampling with temperature\n   */\n  async runSampleTopK(dev, logits, temperature, topK, randomValue) {\n    const logitsBuf = makeBuffer(logits);\n    const tokenId = await sampleKernel.runGPUSample(logitsBuf, logits.length, {\n      temperature,\n      topK,\n      randomSeed: randomValue * 10000, // Convert to seed\n    });\n    logitsBuf.destroy();\n    return tokenId;\n  },\n\n  /**\n   * Run SwiGLU activation: output = SiLU(gate) * up\n   * Tests the gated SiLU variant from the silu kernel\n   */\n  async runSwiGLU(dev, gate, up, gateBias, upBias) {\n    // For testing, we pre-add bias to gate and up, then use SiLU with gating\n    const size = gate.length;\n\n    // Add biases\n    const gateWithBias = new Float32Array(size);\n    const upWithBias = new Float32Array(size);\n    for (let i = 0; i < size; i++) {\n      gateWithBias[i] = gate[i] + gateBias[i];\n      upWithBias[i] = up[i] + upBias[i];\n    }\n\n    if (!runSiLU) {\n      // Fallback to reference implementation\n      const result = new Float32Array(size);\n      for (let i = 0; i < size; i++) {\n        const silu = gateWithBias[i] / (1 + Math.exp(-gateWithBias[i]));\n        result[i] = silu * upWithBias[i];\n      }\n      return result;\n    }\n\n    const gateBuf = makeBuffer(gateWithBias);\n    const upBuf = makeBuffer(upWithBias);\n\n    // runSiLU with gate option: output = silu(gate) * up\n    const resultBuf = await runSiLU(upBuf, { size, gate: gateBuf });\n\n    const result = new Float32Array(await readBufferData(resultBuf, size * 4));\n\n    gateBuf.destroy();\n    upBuf.destroy();\n    resultBuf.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run scale kernel: output[i] = input[i] * scale\n   */\n  async runScale(dev, input, scale) {\n    if (!runScale) {\n      // Fallback to reference implementation\n      const result = new Float32Array(input.length);\n      for (let i = 0; i < input.length; i++) {\n        result[i] = input[i] * scale;\n      }\n      return result;\n    }\n\n    const inputBuf = makeBuffer(input);\n    const resultBuf = await runScale(inputBuf, scale, { count: input.length });\n    const result = new Float32Array(await readBufferData(resultBuf, input.length * 4));\n\n    inputBuf.destroy();\n    resultBuf.destroy();\n\n    return result;\n  },\n\n  /**\n   * Run BF16 \u2192 F32 cast\n   */\n  async runBF16ToF32(dev, input) {\n    if (!runBF16ToF32) {\n      const out = new Float32Array(input.length);\n      for (let i = 0; i < input.length; i++) {\n        const view = new DataView(new ArrayBuffer(4));\n        view.setUint32(0, input[i] << 16, true);\n        out[i] = view.getFloat32(0, true);\n      }\n      return out;\n    }\n\n    const inputBuf = makeBuffer(input, GPUBufferUsage.STORAGE);\n    const outTensor = await runBF16ToF32(inputBuf, [input.length], 'bf16_to_f32_test');\n    const out = new Float32Array(await readBufferData(outTensor.buffer, input.length * 4));\n\n    inputBuf.destroy();\n    outTensor.buffer.destroy();\n\n    return out;\n  },\n\n  /**\n   * Run F32 \u2192 F16 cast\n   */\n  async runF32ToF16(dev, input) {\n    if (!castF32ToF16) {\n      const out = new Uint16Array(input.length);\n      for (let i = 0; i < input.length; i++) {\n        const view = new DataView(new ArrayBuffer(4));\n        view.setFloat32(0, input[i], true);\n        const bits = view.getUint32(0, true);\n        const sign = (bits >> 31) & 0x1;\n        const exp = (bits >> 23) & 0xff;\n        const mant = bits & 0x7fffff;\n\n        let hExp = 0;\n        let hMant = 0;\n        if (exp === 0xff) {\n          hExp = 0x1f;\n          hMant = mant ? 0x200 : 0;\n        } else if (exp !== 0) {\n          const newExp = exp - 127 + 15;\n          if (newExp >= 0x1f) {\n            hExp = 0x1f;\n          } else if (newExp > 0) {\n            hExp = newExp;\n            hMant = mant >> 13;\n          }\n        }\n        out[i] = (sign << 15) | (hExp << 10) | hMant;\n      }\n      return out;\n    }\n\n    const inputBuf = makeBuffer(input);\n    const inputTensor = createTensor(inputBuf, 'f32', [input.length], 'f32_to_f16_input');\n    const outTensor = await castF32ToF16(inputTensor);\n    const out = new Uint16Array(await readBufferData(outTensor.buffer, input.length * 2));\n\n    inputBuf.destroy();\n    outTensor.buffer.destroy();\n\n    return out;\n  },\n\n  /**\n   * Run BF16 \u2192 F16 cast\n   */\n  async runBF16ToF16(dev, input) {\n    if (!runBF16ToF16) {\n      const out = new Uint16Array(input.length);\n      for (let i = 0; i < input.length; i++) {\n        const view = new DataView(new ArrayBuffer(4));\n        view.setUint32(0, input[i] << 16, true);\n        const bits = view.getUint32(0, true);\n        const sign = (bits >> 31) & 0x1;\n        const exp = (bits >> 23) & 0xff;\n        const mant = bits & 0x7fffff;\n\n        let hExp = 0;\n        let hMant = 0;\n        if (exp === 0xff) {\n          hExp = 0x1f;\n          hMant = mant ? 0x200 : 0;\n        } else if (exp !== 0) {\n          const newExp = exp - 127 + 15;\n          if (newExp >= 0x1f) {\n            hExp = 0x1f;\n          } else if (newExp > 0) {\n            hExp = newExp;\n            hMant = mant >> 13;\n          }\n        }\n        out[i] = (sign << 15) | (hExp << 10) | hMant;\n      }\n      return out;\n    }\n\n    const inputBuf = makeBuffer(input, GPUBufferUsage.STORAGE);\n    const outTensor = await runBF16ToF16(inputBuf, [input.length], 'bf16_to_f16_test');\n    const out = new Uint16Array(await readBufferData(outTensor.buffer, input.length * 2));\n\n    inputBuf.destroy();\n    outTensor.buffer.destroy();\n\n    return out;\n  },\n\n  /**\n   * Run Q6_K dequantization\n   * Note: Q6K outputs f16, which we read as f16 and convert to f32\n   */\n  async runDequantQ6K(dev, quantized, numBlocks) {\n    if (!dequantizeQ6K) {\n      throw new Error('dequantizeQ6K kernel not available');\n    }\n\n    const blockSize = 256;  // Q6_K: 256 elements per block\n    const qBuf = makeBuffer(quantized, GPUBufferUsage.STORAGE);\n    const outBuf = await dequantizeQ6K(qBuf, numBlocks, { outputOffset: 0 });\n\n    // Q6K outputs f16 - read raw bytes and convert\n    const rawData = await readBufferData(outBuf, numBlocks * blockSize * 2);  // f16 = 2 bytes\n    const u16View = new Uint16Array(rawData);\n    const out = new Float32Array(u16View.length);\n\n    // Convert f16 to f32\n    for (let i = 0; i < u16View.length; i++) {\n      out[i] = f16ToF32(u16View[i]);\n    }\n\n    qBuf.destroy();\n    outBuf.destroy();\n\n    return out;\n  },\n\n  /**\n   * Run F16 weights matmul (f16w_f32a kernel)\n   * Takes F32 activations and F16 weights (as Uint16Array)\n   * This tests the exact same kernel path as production\n   * C = A[M,K] @ B[N,K]^T = C[M,N]\n   */\n  async runMatmulF16W(dev, A: Float32Array, B_f16: Uint16Array, M: number, N: number, K: number) {\n    if (!runMatmul) {\n      throw new Error('runMatmul kernel not available');\n    }\n\n    // Create A buffer (F32 activations)\n    const bufA = makeBuffer(A);\n    const tensorA = createTensor(bufA, 'f32', [M, K], 'matmul_f16w_a');\n\n    // Create B buffer (F16 weights) - pass raw Uint16Array\n    const bufB = makeBuffer(B_f16, GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC);\n\n    // Run matmul with bDtype='f16' and preferF16=true to trigger f16w_f32a kernel\n    // transposeB=true because B is [N, K] format (weight matrix layout)\n    const resultTensor = await runMatmul(tensorA, bufB, M, N, K, {\n      bDtype: 'f16',\n      preferF16: true,\n      transposeB: true,\n    });\n\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, M * N * 4));\n\n    bufA.destroy();\n    bufB.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n\n  /**\n   * Combined Q4K dequant + F16 matmul (production path)\n   * Does dequant to F16 then matmul, all on GPU without CPU round-trip\n   * C = A[M,K] @ dequant(B_q4k[N,K])^T = C[M,N]\n   */\n  async runDequantAndMatmulF16W(dev, A: Float32Array, B_q4k: Uint8Array, M: number, N: number, K: number, numBlocks: number) {\n    if (!runMatmul || !dequantize) {\n      throw new Error('runMatmul or dequantize kernel not available');\n    }\n\n    // Dequant Q4K \u2192 F16 on GPU\n    const qBuf = makeBuffer(B_q4k, GPUBufferUsage.STORAGE);\n    const dequantTensor = await dequantize(qBuf, numBlocks, { outputDtype: 'f16', useVec4: true });\n\n    // Create A buffer (F32 activations)\n    const bufA = makeBuffer(A);\n    const tensorA = createTensor(bufA, 'f32', [M, K], 'dequant_matmul_a');\n\n    // Run matmul with F16 weights (stays on GPU, no CPU round-trip)\n    // transposeB=true because dequanted weights are [N, K] format\n    const resultTensor = await runMatmul(tensorA, dequantTensor.buffer, M, N, K, {\n      bDtype: 'f16',\n      preferF16: true,\n      transposeB: true,\n    });\n\n    const result = new Float32Array(await readBufferData(resultTensor.buffer, M * N * 4));\n\n    qBuf.destroy();\n    bufA.destroy();\n    dequantTensor.buffer.destroy();\n    resultTensor.buffer.destroy();\n\n    return result;\n  },\n};\n\n// Expose to window for Playwright (type declared in tests/correctness/setup.ts)\n(window as any).testHarness = testHarness;\n(window as any).gpuReady = false;\n(window as any).gpuError = undefined;\n\n// Auto-initialize on load\nwindow.addEventListener('DOMContentLoaded', async () => {\n  try {\n    await initGPU();\n    console.log('WebGPU initialized successfully');\n    (window as any).gpuReady = true;\n\n    // Display status\n    const status = document.getElementById('status');\n    if (status) {\n      const caps = getKernelCapabilities();\n      status.innerHTML = `\n        <strong>WebGPU Ready</strong><br>\n        Adapter: ${caps?.adapterInfo || 'Unknown'}<br>\n        F16 Support: ${caps?.hasF16 ? 'Yes' : 'No'}<br>\n        Subgroups: ${caps?.hasSubgroups ? 'Yes' : 'No'}\n      `;\n      status.style.color = 'green';\n    }\n  } catch (e) {\n    console.error('Failed to initialize WebGPU:', e);\n    (window as any).gpuReady = false;\n    (window as any).gpuError = (e as Error).message;\n\n    const status = document.getElementById('status');\n    if (status) {\n      status.innerHTML = `<strong>WebGPU Error:</strong> ${(e as Error).message}`;\n      status.style.color = 'red';\n    }\n  }\n});\n\n// Export for module usage\nexport { testHarness, initGPU, getGPU };\n", "/**\n * Kernel Path Loader\n *\n * Loads and resolves kernel path configurations.\n *\n * @module config/kernel-path-loader\n */\n\nimport type {\n  KernelPathSchema,\n  KernelPathRef,\n  BuiltinKernelPathId,\n  KernelStepSchema,\n  LayerKernelPathSchema,\n} from './schema/kernel-path.schema.js';\nimport { DEFAULT_ENTRY } from './schema/kernel-path.schema.js';\nimport { KERNEL_CONFIGS } from '../gpu/kernels/utils.js';\n\n// =============================================================================\n// Built-in Kernel Paths (imported at build time)\n// =============================================================================\n\nimport gemma2Q4kFused from './presets/kernel-paths/gemma2-q4k-fused.json' with { type: 'json' };\nimport gemma2Q4kDequantF32 from './presets/kernel-paths/gemma2-q4k-dequant-f32.json' with { type: 'json' };\nimport gemma2Q4kDequantF16 from './presets/kernel-paths/gemma2-q4k-dequant-f16.json' with { type: 'json' };\nimport gemma2F16Native from './presets/kernel-paths/gemma2-f16-native.json' with { type: 'json' };\n\n/** Registry of built-in kernel paths */\nconst KERNEL_PATH_REGISTRY: Record<string, KernelPathSchema> = {\n  // Gemma 2 Q4K variants\n  'gemma2-q4k-fused': gemma2Q4kFused as KernelPathSchema,\n  'gemma2-q4k-dequant-f32': gemma2Q4kDequantF32 as KernelPathSchema,\n  'gemma2-q4k-dequant-f16': gemma2Q4kDequantF16 as KernelPathSchema,\n\n  // Gemma 2 F16 native\n  'gemma2-f16-native': gemma2F16Native as KernelPathSchema,\n\n  // Aliases for generic access (model-agnostic)\n  'q4k-fused': gemma2Q4kFused as KernelPathSchema,\n  'q4k-dequant-f32': gemma2Q4kDequantF32 as KernelPathSchema,\n  'q4k-dequant-f16': gemma2Q4kDequantF16 as KernelPathSchema,\n  'f16-native': gemma2F16Native as KernelPathSchema,\n\n  // Semantic aliases\n  'q4k-safe': gemma2Q4kDequantF32 as KernelPathSchema, // Max compatibility, no fusion\n  'q4k-fast': gemma2Q4kFused as KernelPathSchema, // Best throughput\n  'q4k-balanced': gemma2Q4kDequantF16 as KernelPathSchema, // Good speed/accuracy tradeoff\n};\n\n// =============================================================================\n// Public API\n// =============================================================================\n\n/**\n * Get a kernel path by ID.\n */\nexport function getKernelPath(id: string): KernelPathSchema | null {\n  return KERNEL_PATH_REGISTRY[id] ?? null;\n}\n\n/**\n * List all available kernel path IDs.\n */\nexport function listKernelPaths(): string[] {\n  return Object.keys(KERNEL_PATH_REGISTRY);\n}\n\n/**\n * Resolve a kernel path reference to a full schema.\n */\nexport function resolveKernelPath(ref: KernelPathRef): KernelPathSchema {\n  if (typeof ref === 'string') {\n    const path = getKernelPath(ref);\n    if (!path) {\n      throw new Error(`Unknown kernel path: ${ref}. Available: ${listKernelPaths().join(', ')}`);\n    }\n    return path;\n  }\n  return ref;\n}\n\n/**\n * Auto-select kernel path based on model quantization and capabilities.\n *\n * Selection priority:\n * - F16/BF16 models: use f16-native\n * - Q4K with subgroups: use fused path (best throughput)\n * - Q4K with F16 support: use dequant-f16 (balanced)\n * - Q4K fallback: use dequant-f32 (max compatibility)\n */\nexport function autoSelectKernelPath(\n  quantization: string | null,\n  modelFamily: string,\n  capabilities: { hasSubgroups?: boolean; hasF16?: boolean } = {}\n): KernelPathSchema {\n  const family = modelFamily.toLowerCase();\n  const familyPrefix =\n    family.includes('gemma3') ? 'gemma3' :\n      family.includes('gemma') ? 'gemma2' :\n        null;\n\n  const resolveAutoPath = (suffix: string): KernelPathSchema => {\n    if (familyPrefix) {\n      const prefixed = getKernelPath(`${familyPrefix}-${suffix}`);\n      if (prefixed) return prefixed;\n    }\n    return resolveKernelPath(suffix);\n  };\n\n  const quantLower = quantization?.toLowerCase() ?? '';\n  if (!quantization || quantLower === 'f16' || quantLower === 'bf16') {\n    return resolveAutoPath('f16-native');\n  }\n\n  if (quantization.toLowerCase().includes('q4')) {\n    // Prefer fused if subgroups available\n    if (capabilities.hasSubgroups) {\n      return resolveAutoPath('q4k-fused');\n    }\n    // Use F16 dequant if F16 math is available\n    if (capabilities.hasF16) {\n      return resolveAutoPath('q4k-dequant-f16');\n    }\n    // Fallback to F32 (safest, most compatible)\n    return resolveAutoPath('q4k-dequant-f32');\n  }\n\n  // Default fallback\n  return resolveAutoPath('q4k-dequant-f32');\n}\n\n// =============================================================================\n// Step Resolution\n// =============================================================================\n\n/**\n * Resolve layer index template in weight references.\n * Replaces {L} with the actual layer index.\n */\nexport function resolveWeightRef(template: string, layerIndex: number): string {\n  return template.replace(/\\{L\\}/g, String(layerIndex));\n}\n\n/**\n * Get steps for a specific layer, applying any overrides.\n */\nexport function getLayerSteps(\n  path: KernelPathSchema,\n  layerIndex: number,\n  phase: 'prefill' | 'decode'\n): KernelStepSchema[] {\n  // Check for layer-specific overrides\n  if (path.layerOverrides) {\n    for (const override of path.layerOverrides) {\n      if (override.layers.includes(layerIndex)) {\n        return override.steps;\n      }\n    }\n  }\n\n  // Use phase-specific or decode as fallback\n  const layerPath = phase === 'prefill' && path.prefill ? path.prefill : path.decode;\n  return layerPath.steps;\n}\n\n/**\n * Validate a kernel path schema.\n */\nexport function validateKernelPath(path: KernelPathSchema): string[] {\n  const errors: string[] = [];\n\n  if (!path.id) errors.push('Missing path id');\n  if (!path.name) errors.push('Missing path name');\n  if (!path.decode?.steps?.length) errors.push('Missing decode steps');\n\n  // Validate each step\n  const validateSteps = (steps: KernelStepSchema[], context: string) => {\n    for (let i = 0; i < steps.length; i++) {\n      const step = steps[i];\n      if (!step.op) errors.push(`${context}[${i}]: missing op`);\n      if (!step.kernel) errors.push(`${context}[${i}]: missing kernel`);\n    }\n  };\n\n  if (path.decode?.steps) validateSteps(path.decode.steps, 'decode');\n  if (path.prefill?.steps) validateSteps(path.prefill.steps, 'prefill');\n  if (path.preLayer) validateSteps(path.preLayer, 'preLayer');\n  if (path.postLayer) validateSteps(path.postLayer, 'postLayer');\n  if (path.sampling) validateSteps(path.sampling, 'sampling');\n\n  return errors;\n}\n\n// =============================================================================\n// Kernel Path Variant Resolution\n// =============================================================================\n\nexport type KernelPathPhase = 'prefill' | 'decode';\nexport type KernelPathSection = 'layer' | 'preLayer' | 'postLayer' | 'sampling';\nexport type KernelPathSource = 'runtime' | 'config' | 'model' | 'manifest' | 'auto' | 'none';\n\nconst MATMUL_ROLE_ALIASES: Record<string, { section: KernelPathSection; ops: string[] }> = {\n  q_proj: { section: 'layer', ops: ['q_proj'] },\n  k_proj: { section: 'layer', ops: ['k_proj'] },\n  v_proj: { section: 'layer', ops: ['v_proj'] },\n  qkv_proj: { section: 'layer', ops: ['qkv_proj', 'q_proj'] },\n  o_proj: { section: 'layer', ops: ['o_proj'] },\n  ffn_gate: { section: 'layer', ops: ['ffn_gate', 'gate_proj'] },\n  ffn_up: { section: 'layer', ops: ['ffn_up', 'up_proj'] },\n  ffn_down: { section: 'layer', ops: ['ffn_down', 'down_proj'] },\n  ffn_gate_up: { section: 'layer', ops: ['ffn_gate_up'] },\n  lm_head: { section: 'postLayer', ops: ['lm_head'] },\n};\n\nfunction normalizeKernelFile(kernel: string): string {\n  const trimmed = kernel.trim();\n  if (!trimmed) return trimmed;\n  const parts = trimmed.split('/');\n  return parts[parts.length - 1] ?? trimmed;\n}\n\nfunction getKernelPathStepsForSection(\n  path: KernelPathSchema,\n  section: KernelPathSection,\n  phase: KernelPathPhase,\n  layerIndex: number\n): KernelStepSchema[] {\n  switch (section) {\n    case 'preLayer':\n      return path.preLayer ?? [];\n    case 'postLayer':\n      return path.postLayer ?? [];\n    case 'sampling':\n      return path.sampling ?? [];\n    case 'layer':\n    default:\n      return getLayerSteps(path, layerIndex, phase);\n  }\n}\n\nfunction findStepByOp(steps: KernelStepSchema[], op: string): KernelStepSchema | null {\n  return steps.find((step) => step.op === op) ?? null;\n}\n\nfunction findKernelVariant(\n  operation: keyof typeof KERNEL_CONFIGS,\n  kernel: string,\n  entry: string | undefined\n): string | null {\n  const variants = KERNEL_CONFIGS[operation];\n  if (!variants) return null;\n  const normalizedKernel = normalizeKernelFile(kernel);\n  const normalizedEntry = entry ?? DEFAULT_ENTRY;\n\n  let fallbackVariant: string | null = null;\n  let fallbackCount = 0;\n\n  for (const [variant, config] of Object.entries(variants)) {\n    if (config.shaderFile !== normalizedKernel) continue;\n    fallbackVariant = variant;\n    fallbackCount += 1;\n    if (config.entryPoint === normalizedEntry) {\n      return variant;\n    }\n  }\n\n  if (fallbackCount === 1) {\n    return fallbackVariant;\n  }\n  return null;\n}\n\nexport function getKernelPathMatmulVariant(\n  role: string | undefined,\n  phase: KernelPathPhase,\n  layerIndex?: number\n): string | null {\n  if (!activeKernelPath || !role) return null;\n  const alias = MATMUL_ROLE_ALIASES[role] ?? { section: 'layer', ops: [role] };\n  const steps = getKernelPathStepsForSection(activeKernelPath, alias.section, phase, layerIndex ?? 0);\n  for (const op of alias.ops) {\n    const step = findStepByOp(steps, op);\n    if (!step) continue;\n    const variant = findKernelVariant('matmul', step.kernel, step.entry);\n    if (variant) {\n      return variant;\n    }\n  }\n  return null;\n}\n\nexport function getKernelPathAttentionVariant(\n  phase: KernelPathPhase,\n  layerIndex?: number\n): string | null {\n  if (!activeKernelPath) return null;\n  const steps = getKernelPathStepsForSection(activeKernelPath, 'layer', phase, layerIndex ?? 0);\n  const step = findStepByOp(steps, 'attention');\n  if (!step) return null;\n  return findKernelVariant('attention', step.kernel, step.entry);\n}\n\n// =============================================================================\n// Active Kernel Path Registry\n// =============================================================================\n\nlet activeKernelPath: KernelPathSchema | null = null;\nlet activeKernelPathSource: KernelPathSource = 'none';\n\n/**\n * Set the active kernel path for the current pipeline.\n * Called by Pipeline when resolving kernel path.\n */\nexport function setActiveKernelPath(path: KernelPathSchema | null, source: KernelPathSource = 'none'): void {\n  activeKernelPath = path;\n  activeKernelPathSource = path ? source : 'none';\n}\n\n/**\n * Get the active kernel path.\n */\nexport function getActiveKernelPath(): KernelPathSchema | null {\n  return activeKernelPath;\n}\n\nexport function getActiveKernelPathSource(): KernelPathSource {\n  return activeKernelPathSource;\n}\n\nexport function getKernelPathStrict(): boolean {\n  return activeKernelPathSource !== 'auto' && activeKernelPathSource !== 'none';\n}\n\n/**\n * Check if the active kernel path uses fused Q4K matmul.\n * Returns false if no kernel path is set (auto-selection will apply).\n */\nexport function isActiveKernelPathFusedQ4K(): boolean {\n  if (!activeKernelPath) return true; // Default to auto-selection (which prefers fused)\n  const kernelSteps: KernelStepSchema[] = [\n    ...(activeKernelPath.decode?.steps ?? []),\n    ...(activeKernelPath.prefill?.steps ?? []),\n    ...(activeKernelPath.preLayer ?? []),\n    ...(activeKernelPath.postLayer ?? []),\n    ...(activeKernelPath.layerOverrides?.flatMap((override) => override.steps) ?? []),\n  ];\n  return kernelSteps.some((step) => step.kernel.includes('fused_matmul_q4'));\n}\n\n/**\n * Check if the active kernel path uses dequant (non-fused) Q4K matmul.\n */\nexport function isActiveKernelPathDequant(): boolean {\n  if (!activeKernelPath) return false;\n  const kernelSteps: KernelStepSchema[] = [\n    ...(activeKernelPath.decode?.steps ?? []),\n    ...(activeKernelPath.prefill?.steps ?? []),\n    ...(activeKernelPath.preLayer ?? []),\n    ...(activeKernelPath.postLayer ?? []),\n    ...(activeKernelPath.layerOverrides?.flatMap((override) => override.steps) ?? []),\n  ];\n  return kernelSteps.some((step) => step.kernel.startsWith('matmul_'));\n}\n\n// =============================================================================\n// Debug/Logging\n// =============================================================================\n\n/**\n * Format kernel path for logging.\n */\nexport function formatKernelPath(path: KernelPathSchema): string {\n  const decodeOps = path.decode.steps.map(s => s.op).join(' \u2192 ');\n  return `${path.id}: ${decodeOps}`;\n}\n\n/**\n * Get summary statistics for a kernel path.\n */\nexport function getKernelPathStats(path: KernelPathSchema): {\n  decodeSteps: number;\n  prefillSteps: number;\n  uniqueKernels: number;\n  hasLayerOverrides: boolean;\n} {\n  const allKernels = new Set<string>();\n\n  const collectKernels = (steps: KernelStepSchema[]) => {\n    for (const step of steps) {\n      allKernels.add(step.kernel);\n    }\n  };\n\n  collectKernels(path.decode.steps);\n  if (path.prefill) collectKernels(path.prefill.steps);\n  if (path.preLayer) collectKernels(path.preLayer);\n  if (path.postLayer) collectKernels(path.postLayer);\n  if (path.sampling) collectKernels(path.sampling);\n\n  return {\n    decodeSteps: path.decode.steps.length,\n    prefillSteps: path.prefill?.steps.length ?? path.decode.steps.length,\n    uniqueKernels: allKernels.size,\n    hasLayerOverrides: !!path.layerOverrides?.length,\n  };\n}\n", "{\n  \"id\": \"gemma2-q4k-fused\",\n  \"name\": \"Gemma 2 Q4K Fused\",\n  \"description\": \"Q4K weights with fused dequant+matmul and fused FFN. Best throughput for Q4K.\",\n\n  \"decode\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",           \"entry\": \"main\",         \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"fused_matmul_q4.wgsl\",   \"entry\": \"main_multicol\", \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"fused_matmul_q4.wgsl\",   \"entry\": \"main_multicol\", \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"fused_matmul_q4.wgsl\",   \"entry\": \"main_multicol\", \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",              \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",              \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention_decode.wgsl\",  \"entry\": \"attention_decode\",         \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"fused_matmul_q4.wgsl\",   \"entry\": \"main_multicol\", \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",          \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",          \"entry\": \"main\",         \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"ffn_gate_up\",  \"kernel\": \"fused_ffn_q4k.wgsl\",     \"entry\": \"main\",         \"weights\": \"layer.{L}.mlp\", \"constants\": { \"ACTIVATION\": 1 } },\n      { \"op\": \"down_proj\",    \"kernel\": \"fused_matmul_q4.wgsl\",   \"entry\": \"main_multicol\", \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",          \"entry\": \"main\" }\n    ]\n  },\n\n  \"prefill\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",              \"entry\": \"main\",      \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"fused_matmul_q4_batched.wgsl\", \"entry\": \"main_batched\",   \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"fused_matmul_q4_batched.wgsl\", \"entry\": \"main_batched\",   \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"fused_matmul_q4_batched.wgsl\", \"entry\": \"main_batched\",   \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",                 \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",                 \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention.wgsl\",            \"entry\": \"main\",      \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"fused_matmul_q4_batched.wgsl\", \"entry\": \"main_batched\",   \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",             \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",             \"entry\": \"main\",      \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"ffn_gate_up\",  \"kernel\": \"fused_ffn_q4k.wgsl\",        \"entry\": \"main_batched\", \"weights\": \"layer.{L}.mlp\", \"constants\": { \"ACTIVATION\": 1 } },\n      { \"op\": \"down_proj\",    \"kernel\": \"fused_matmul_q4_batched.wgsl\", \"entry\": \"main_batched\",   \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",             \"entry\": \"main\" }\n    ]\n  },\n\n  \"preLayer\": [\n    { \"op\": \"embed\",        \"kernel\": \"gather.wgsl\",             \"entry\": \"main\",         \"weights\": \"embed_tokens\" }\n  ],\n\n  \"postLayer\": [\n    { \"op\": \"final_norm\",   \"kernel\": \"rmsnorm.wgsl\",            \"entry\": \"main\",         \"constants\": { \"RMS_NORM_OFFSET\": true } },\n    { \"op\": \"lm_head\",      \"kernel\": \"fused_matmul_q4.wgsl\",    \"entry\": \"main_multicol\", \"weights\": \"lm_head\" }\n  ],\n\n  \"sampling\": [\n    { \"op\": \"softcap\",      \"kernel\": \"sample.wgsl\",             \"entry\": \"apply_softcap\", \"constants\": { \"SOFTCAP\": 30.0 } },\n    { \"op\": \"sample\",       \"kernel\": \"sample.wgsl\",             \"entry\": \"sample_single_pass\" }\n  ]\n}\n", "{\n  \"id\": \"gemma2-q4k-dequant-f32\",\n  \"name\": \"Gemma 2 Q4K Dequant F32\",\n  \"description\": \"Q4K weights dequantized to F32 at load time. Best accuracy, slower throughput.\",\n\n  \"decode\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",      \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention_decode.wgsl\", \"entry\": \"attention_decode\", \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",     \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",     \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"gate_proj\",    \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.gate_proj\" },\n      { \"op\": \"up_proj\",      \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.up_proj\" },\n      { \"op\": \"activation\",   \"kernel\": \"silu.wgsl\",         \"entry\": \"geglu\" },\n      { \"op\": \"down_proj\",    \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",     \"entry\": \"main\" }\n    ]\n  },\n\n  \"prefill\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",      \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention.wgsl\",    \"entry\": \"main\",  \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",     \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",     \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"gate_proj\",    \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.mlp.gate_proj\" },\n      { \"op\": \"up_proj\",      \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.mlp.up_proj\" },\n      { \"op\": \"activation\",   \"kernel\": \"silu.wgsl\",         \"entry\": \"geglu\" },\n      { \"op\": \"down_proj\",    \"kernel\": \"matmul_f32.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",     \"entry\": \"main\" }\n    ]\n  },\n\n  \"preLayer\": [\n    { \"op\": \"embed\",        \"kernel\": \"gather.wgsl\",         \"entry\": \"main\",  \"weights\": \"embed_tokens\" }\n  ],\n\n  \"postLayer\": [\n    { \"op\": \"final_norm\",   \"kernel\": \"rmsnorm.wgsl\",        \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n    { \"op\": \"lm_head\",      \"kernel\": \"matmul_f32.wgsl\",     \"entry\": \"main\",  \"weights\": \"lm_head\" }\n  ],\n\n  \"sampling\": [\n    { \"op\": \"softcap\",      \"kernel\": \"sample.wgsl\",         \"entry\": \"apply_softcap\", \"constants\": { \"SOFTCAP\": 30.0 } },\n    { \"op\": \"sample\",       \"kernel\": \"sample.wgsl\",         \"entry\": \"sample_single_pass\" }\n  ]\n}\n", "{\n  \"id\": \"gemma2-q4k-dequant-f16\",\n  \"name\": \"Gemma 2 Q4K Dequant F16\",\n  \"description\": \"Q4K weights dequantized to F16. Balanced speed/accuracy, lower VRAM than F32.\",\n\n  \"decode\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",      \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention_decode.wgsl\", \"entry\": \"attention_decode\", \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",     \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",     \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"gate_proj\",    \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.gate_proj\" },\n      { \"op\": \"up_proj\",      \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.up_proj\" },\n      { \"op\": \"activation\",   \"kernel\": \"silu.wgsl\",         \"entry\": \"geglu\" },\n      { \"op\": \"down_proj\",    \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",     \"entry\": \"main\" }\n    ]\n  },\n\n  \"prefill\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",      \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",         \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention.wgsl\",    \"entry\": \"main\",  \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",     \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",     \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"gate_proj\",    \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.mlp.gate_proj\" },\n      { \"op\": \"up_proj\",      \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.mlp.up_proj\" },\n      { \"op\": \"activation\",   \"kernel\": \"silu.wgsl\",         \"entry\": \"geglu\" },\n      { \"op\": \"down_proj\",    \"kernel\": \"matmul_f16.wgsl\",   \"entry\": \"main\", \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",     \"entry\": \"main\" }\n    ]\n  },\n\n  \"preLayer\": [\n    { \"op\": \"embed\",        \"kernel\": \"gather.wgsl\",         \"entry\": \"main\",  \"weights\": \"embed_tokens\" }\n  ],\n\n  \"postLayer\": [\n    { \"op\": \"final_norm\",   \"kernel\": \"rmsnorm.wgsl\",        \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n    { \"op\": \"lm_head\",      \"kernel\": \"matmul_f16.wgsl\",     \"entry\": \"main\",  \"weights\": \"lm_head\" }\n  ],\n\n  \"sampling\": [\n    { \"op\": \"softcap\",      \"kernel\": \"sample.wgsl\",         \"entry\": \"apply_softcap\", \"constants\": { \"SOFTCAP\": 30.0 } },\n    { \"op\": \"sample\",       \"kernel\": \"sample.wgsl\",         \"entry\": \"sample_single_pass\" }\n  ]\n}\n", "{\n  \"id\": \"gemma2-f16-native\",\n  \"name\": \"Gemma 2 F16 Native\",\n  \"description\": \"Native F16 weights, no dequantization. Baseline accuracy.\",\n\n  \"decode\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",         \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",            \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",            \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention_decode.wgsl\",\"entry\": \"attention_decode\",  \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",        \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",        \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"gate_proj\",    \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.gate_proj\" },\n      { \"op\": \"up_proj\",      \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.up_proj\" },\n      { \"op\": \"activation\",   \"kernel\": \"silu.wgsl\",            \"entry\": \"geglu\" },\n      { \"op\": \"down_proj\",    \"kernel\": \"matmul_f16w_f32a.wgsl\",\"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",        \"entry\": \"main\" }\n    ]\n  },\n\n  \"prefill\": {\n    \"steps\": [\n      { \"op\": \"input_norm\",   \"kernel\": \"rmsnorm.wgsl\",         \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"q_proj\",       \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.q_proj\" },\n      { \"op\": \"k_proj\",       \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.k_proj\" },\n      { \"op\": \"v_proj\",       \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.v_proj\" },\n      { \"op\": \"rope_q\",       \"kernel\": \"rope.wgsl\",            \"entry\": \"main\" },\n      { \"op\": \"rope_k\",       \"kernel\": \"rope.wgsl\",            \"entry\": \"main\" },\n      { \"op\": \"attention\",    \"kernel\": \"attention.wgsl\",       \"entry\": \"main\",  \"constants\": { \"SOFTCAP\": 50.0 } },\n      { \"op\": \"o_proj\",       \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.self_attn.o_proj\" },\n      { \"op\": \"attn_residual\",\"kernel\": \"residual.wgsl\",        \"entry\": \"main\" },\n      { \"op\": \"post_attn_norm\",\"kernel\": \"rmsnorm.wgsl\",        \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n      { \"op\": \"gate_proj\",    \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.gate_proj\" },\n      { \"op\": \"up_proj\",      \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.up_proj\" },\n      { \"op\": \"activation\",   \"kernel\": \"silu.wgsl\",            \"entry\": \"geglu\" },\n      { \"op\": \"down_proj\",    \"kernel\": \"matmul_f16.wgsl\",      \"entry\": \"main\",  \"weights\": \"layer.{L}.mlp.down_proj\" },\n      { \"op\": \"ffn_residual\", \"kernel\": \"residual.wgsl\",        \"entry\": \"main\" }\n    ]\n  },\n\n  \"preLayer\": [\n    { \"op\": \"embed\",        \"kernel\": \"gather_f16.wgsl\",       \"entry\": \"main\",  \"weights\": \"embed_tokens\" }\n  ],\n\n  \"postLayer\": [\n    { \"op\": \"final_norm\",   \"kernel\": \"rmsnorm.wgsl\",          \"entry\": \"main\",  \"constants\": { \"RMS_NORM_OFFSET\": true } },\n    { \"op\": \"lm_head\",      \"kernel\": \"matmul_f16w_f32a.wgsl\", \"entry\": \"main\",  \"weights\": \"lm_head\" }\n  ],\n\n  \"sampling\": [\n    { \"op\": \"softcap\",      \"kernel\": \"sample.wgsl\",           \"entry\": \"apply_softcap\", \"constants\": { \"SOFTCAP\": 30.0 } },\n    { \"op\": \"sample\",       \"kernel\": \"sample.wgsl\",           \"entry\": \"sample_single_pass\" }\n  ]\n}\n", "/**\n * Kernel Selector - Backward Compatibility Wrapper\n *\n * This file has been refactored into separate kernel modules in gpu/kernels/.\n * It now serves as a thin re-export wrapper for backward compatibility.\n *\n * For new code, prefer importing from gpu/kernels/index.ts directly.\n *\n * Migration completed: kernel-selector.js (3428 lines) split into:\n * - utils.ts - Shared utilities, pipeline cache, KERNEL_CONFIGS\n * - matmul.ts - Matrix multiplication kernels\n * - dequant.ts - Dequantization kernels\n * - attention.ts - Attention kernels\n * - rmsnorm.ts - RMSNorm kernels\n * - softmax.ts - Softmax kernels\n * - rope.ts - RoPE kernels\n * - silu.ts - SiLU activation kernels\n * - gelu.ts - GeLU activation kernels\n * - gather.ts - Gather/embedding lookup kernels\n * - residual.ts - Residual connection kernels\n * - moe.ts - Mixture of Experts kernels\n * - cast.ts - Type casting kernels\n * - index.ts - Barrel export\n */\n\n// Re-export everything from the new kernel modules for backward compatibility\nexport * from './kernels/index.js';\n", "/**\n * GPU Kernels - Barrel Export\n *\n * Central export point for all GPU kernel modules.\n * This allows backward compatibility with the original kernel-selector.js\n */\n\n// Utilities\nexport {\n  KERNEL_CONFIGS,\n  validateAttentionLimits,\n  loadShaderSource,\n  hasRequiredFeatures,\n  getKernelConfig,\n  compileShader,\n  getOrCreateBindGroupLayout,\n  getOrCreatePipelineLayout,\n  createPipeline,\n  clearKernelCaches,\n  clearPipelineCache,\n  getCacheStats,\n  getTunedWorkgroupSize,\n  autoTuneKernels,\n  prewarmKernels,\n  type KernelConfig,\n} from './utils.js';\n\nexport type {\n  OutputBufferOptions,\n  OutputOffsetOptions,\n  OutputDtypeOptions,\n  Vec4Options,\n} from './types.js';\n\n// Matrix Multiplication\nexport {\n  selectMatmulKernel,\n  createMatmulBindGroupLayout,\n  runMatmul,\n  recordMatmul,\n  isFusedQ4KDisabled,\n  type MatmulOptions,\n} from './matmul.js';\n\n// Dequantization\nexport {\n  selectDequantKernel,\n  createDequantBindGroupLayout,\n  dequantize,\n  dequantizeQ6K,\n  dequantizeQ8_0,\n  dequantizeMXFP4,\n  dequantizeMXFP4Expert,\n  recordDequantize,\n  type DequantOptions,\n} from './dequant.js';\n\n// Attention\nexport {\n  runAttention,\n  recordAttention,\n  type AttentionOptions,\n} from './attention.js';\n\n// RMSNorm\nexport {\n  selectRMSNormKernel,\n  runRMSNorm,\n  recordRMSNorm,\n  type RMSNormOptions,\n} from './rmsnorm.js';\n\n// Softmax\nexport {\n  runSoftmax,\n  runSoftmaxTopK,\n  recordSoftmax,\n  type SoftmaxOptions,\n} from './softmax.js';\n\n// RoPE\nexport {\n  runRoPE,\n  recordRoPE,\n  type RoPEOptions,\n} from './rope.js';\n\n// SiLU Activation\nexport {\n  runSiLU,\n  runSwiGLURowsplitBias,\n  runSiLURowSplit,\n  recordSiLU,\n  recordSiLURowSplit,\n  type SiLUOptions,\n  type SiLURowSplitOptions,\n} from './silu.js';\n\n// GeLU Activation\nexport {\n  runGeLU,\n  recordGeLU,\n  type GeLUOptions,\n} from './gelu.js';\n\n// Scale (Element-wise Multiply by Scalar)\nexport {\n  runScale,\n  recordScale,\n  type ScaleOptions,\n} from './scale.js';\n\n// Gather (Embedding Lookup)\nexport {\n  runGather,\n  recordGather,\n  type GatherOptions,\n} from './gather.js';\n\n// Residual Connections\nexport {\n  runResidualAdd,\n  runBiasAdd,\n  recordResidualAdd,\n  recordBiasAdd,\n  type ResidualOptions,\n} from './residual.js';\n\n// Mixture of Experts\nexport {\n  runTopK,\n  runMoEGather,\n  runScatterAdd,\n  runScatterAddDynamic,\n  type MoEOptions,\n} from './moe.js';\n\n// Type Casting\nexport {\n  castF32ToF16,\n  recordCastF32ToF16,\n  castF16ToF32,\n  recordCastF16ToF32,\n  runBF16ToF32,\n  runBF16ToF16,\n  type CastOptions,\n} from './cast.js';\n\n// GPU-Side Sampling\nexport {\n  runArgmax,\n  runGPUSample,\n  recordArgmax,\n  isGPUSamplingAvailable,\n  type SampleOptions,\n  type SampleResult,\n} from './sample.js';\n\n// Fused FFN (Tier 2 P0)\nexport {\n  runFusedFFN,\n  recordFusedFFN,\n  calculateFusedFFNSavings,\n  type FusedFFNOptions,\n  type FFNActivation,\n} from './fused_ffn.js';\n\n// Fused Matmul + RMSNorm (P0 - 1.2-1.5x decode speedup)\nexport {\n  selectMatmulRMSNormFusedVariant,\n  runMatmulRMSNormFused,\n  recordMatmulRMSNormFused,\n  shouldUseFusedMatmulRMSNorm,\n  type MatmulRMSNormFusedOptions,\n} from './fused_matmul_rmsnorm.js';\n\n// Re-export for convenience in layer.ts integration\nexport { recordMatmulRMSNormFused as doRecordMatmulRMSNormFused } from './fused_matmul_rmsnorm.js';\n\n// Fused Matmul + Residual (P1 - eliminates 1 dispatch per layer for attention output)\nexport {\n  runMatmulResidualFused,\n  recordMatmulResidualFused,\n  shouldUseFusedMatmulResidual,\n  type MatmulResidualFusedOptions,\n} from './fused_matmul_residual.js';\n\n// Re-export CommandRecorder types for convenience\nexport {\n  CommandRecorder,\n  createCommandRecorder,\n  createProfilingRecorder,\n  type RecorderOptions,\n  type ProfileTimings,\n} from '../command-recorder.js';\n\n// Re-export benchmark utilities\nexport {\n  benchmarkMatmul,\n  benchmarkAttentionDecode,\n  benchmarkRMSNorm,\n  benchmarkSiLU,\n  benchmarkMatmulRMSNormFused,\n  benchmarkDecodePass,\n  compareBenchmarks,\n  exportBenchmarkJSON,\n  printBenchmarkReport,\n  type KernelBenchmarkResult,\n  type BenchmarkComparison,\n  type BenchmarkReport,\n  type BenchmarkConfig,\n} from '../kernel-benchmark.js';\n\n// Split QKV\nexport {\n  runSplitQKV,\n  recordSplitQKV,\n  type SplitQKVOptions,\n  type SplitQKVResult,\n} from './split_qkv.js';\n\n// Re-export profiling utilities\nexport {\n  isProfilingEnabled,\n  setProfilingEnabled,\n  clearProfile,\n  startProfileSession,\n  recordProfileEntry,\n  profileAsync,\n  profileSync,\n  profileKernel,\n  getProfileReport,\n  printProfileReport,\n  exportProfileJSON,\n  analyzeDecodePerformance,\n  type ProfileEntry,\n  type ProfileReport,\n} from '../perf-profiler.js';\n", "/**\n * Matrix Multiplication Kernels\n *\n * Provides optimized matmul operations with support for:\n * - F16/F32 inputs and outputs\n * - Mixed precision (F16 weights, F32 activations)\n * - Tiled and naive variants\n * - Command recording for batched execution\n */\n\nimport { getDevice, getKernelCapabilities } from '../device.js';\nimport { Tensor, createTensor, type TensorDtype } from '../tensor.js';\nimport { type WeightBuffer, getBuffer, getLayout, getWeightDtype } from '../weight-buffer.js';\nimport { log, trace, isTraceEnabled } from '../../debug/index.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { KernelBase } from './kernel-base.js';\nimport { ALIGNMENT, GPU_LIMITS, QUANTIZATION, TILE_SIZES } from './constants.js';\nimport { getKernelConfig, createUniformBufferWithView, getOrCreateBindGroupLayout, getCachedPipeline, createPipeline, getPipelineFast, hasRequiredFeatures } from './utils.js';\nimport { releaseUniformBuffer } from '../uniform-cache.js';\nimport type { OutputBufferOptions, OutputDtypeOptions, Vec4Options } from './types.js';\nimport { getKernelThresholds } from '../../config/schema/index.js';\nimport { getKernelPathMatmulVariant, getKernelPathStrict, isActiveKernelPathFusedQ4K } from '../../config/kernel-path-loader.js';\n\n// =============================================================================\n// Q4K Variant Lookup Tables\n// =============================================================================\n\n/**\n * Q4K fused variant lookup table keyed by \"${m1}/${f16out}\".\n * Replaces duplicated if-else chains in selectMatmulVariantAndFlags.\n */\nconst Q4K_FUSED_VARIANTS: Record<string, string> = {\n  'true/true': 'q4_fused_multicol_f16',\n  'true/false': 'q4_fused_multicol',\n  'false/true': 'q4_fused_batched_f16',\n  'false/false': 'q4_fused_batched',\n};\n\n/**\n * Select Q4K fused variant based on M dimension and output dtype.\n */\nfunction selectQ4KFusedVariant(isM1: boolean, wantF16Output: boolean): string {\n  const key = `${isM1}/${wantF16Output}`;\n  return Q4K_FUSED_VARIANTS[key] ?? 'q4_fused_batched';\n}\n\n/**\n * Check if fused Q4K kernels are disabled.\n * Returns true (disabled) when:\n * 1. Debug flag DOPPLER_DISABLE_FUSED_Q4K is set\n * 2. Active kernel path uses dequant (not fused)\n */\nexport function isFusedQ4KDisabled(): boolean {\n  // Check window override first (debug flag)\n  const debugFlags = typeof window !== 'undefined'\n    ? (window as unknown as { DOPPLER_DISABLE_FUSED_Q4K?: boolean })\n    : null;\n  if (debugFlags?.DOPPLER_DISABLE_FUSED_Q4K) return true;\n\n  // Check active kernel path - if explicitly set to dequant, disable fused\n  if (!isActiveKernelPathFusedQ4K()) return true;\n\n  return false;\n}\n\n/** Matmul-supported buffer types (includes q4k for fused W4A16) */\ntype MatmulDtype = 'f16' | 'f32' | 'q4k';\n\n/** Helper to narrow TensorDtype to matmul-supported types */\nfunction toMatmulDtype(dtype: TensorDtype | 'q4k' | 'bf16' | 'q8' | null | undefined): MatmulDtype {\n  if (dtype === 'f16' || dtype === 'bf16') return 'f16';  // bf16 weights use f16 kernel\n  if (dtype === 'q4k') return 'q4k';\n  return 'f32';\n}\n\n/** Matmul kernel options */\nexport interface MatmulOptions extends OutputBufferOptions, OutputDtypeOptions, Vec4Options {\n  alpha?: number;\n  /** Optional matmul role for kernel path overrides (e.g., 'q_proj', 'ffn_gate', 'lm_head') */\n  role?: string;\n  /** Layer index for kernel path layer overrides */\n  layerIdx?: number;\n  /**\n   * Whether B matrix is stored transposed.\n   * - true: B is [N,K] (SafeTensors/row-major), needs transpose\n   * - false: B is [K,N] (column-major/pre-transposed), direct access\n   * - 'auto': Auto-detect from buffer layout metadata (default)\n   */\n  transposeB?: boolean | 'auto';\n  aOffset?: number;\n  bOffset?: number;\n  cOffset?: number;\n  aDtype?: 'f16' | 'f32' | null;\n  bDtype?: 'f16' | 'f32' | 'q4k' | null;\n  preferF16?: boolean;\n}\n\n/**\n * Select the best matmul kernel variant\n */\nexport function selectMatmulKernel(options: MatmulOptions = {}): string {\n  const capabilities = getKernelCapabilities();\n  const {\n    preferF16 = true,\n    useVec4 = false,\n    outputDtype = 'f32',\n    aDtype = null,\n    bDtype = null,\n  } = options;\n\n  const inputsAreF16 = aDtype === 'f16' && bDtype === 'f16';\n  const weightsAreF16 = bDtype === 'f16' && aDtype !== 'f16';\n\n  // Full f16 matmul only when both inputs are f16 and caller wants f16 output.\n  if (outputDtype === 'f16' && preferF16 && inputsAreF16 && capabilities.hasF16) {\n    return useVec4 ? 'f16_vec4' : 'f16';\n  }\n\n  // Mixed precision: f32 activations, f16 weights.\n  // Use f16w_f32a kernel regardless of output dtype - it will produce f32 output,\n  // and cast to f16 if needed afterwards. This is better than using f32 kernel\n  // which can't read f16 weights at all!\n  if (preferF16 && weightsAreF16 && capabilities.hasF16) {\n    return 'f16w_f32a';\n  }\n\n  return 'f32';\n}\n\nclass MatmulKernel extends KernelBase {\n  async getPipeline(variant: string): Promise<GPUComputePipeline> {\n    return this.getPipelineFor('matmul', variant);\n  }\n\n  dispatch(\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: [number, number, number]\n  ): void {\n    this.dispatchKernel(pipeline, bindGroup, workgroups, 'matmul');\n  }\n\n  record(\n    recorder: CommandRecorder,\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: [number, number, number]\n  ): void {\n    this.recordKernel(recorder, pipeline, bindGroup, workgroups, 'matmul');\n  }\n}\n\ntype MatmulSelectionMode = 'run' | 'record';\n\n// Debug counter to limit logging\nlet _transposeDebugCount = 0;\n\nfunction resolveTransposeB(B: GPUBuffer | WeightBuffer, transposeBOption: boolean | 'auto'): boolean {\n  if (transposeBOption === 'auto') {\n    // Get layout from WeightBuffer (buffer-dtypes WeakMap removed)\n    const weightLayout = getLayout(B);\n    const buffer = getBuffer(B);\n    // WeightBuffer has explicit layout; raw GPUBuffer defaults to row-major\n    const isColMajor = weightLayout === 'column';\n    const result = !isColMajor;\n    // Log first 50 calls to avoid flooding\n    if (isTraceEnabled('kernels') && _transposeDebugCount < 50) {\n      _transposeDebugCount++;\n      trace.kernels(`resolveTransposeB: layout=${weightLayout}, isColumnMajor=${isColMajor}, transposeB=${result}, bufSize=${buffer.size}`);\n    }\n    return result;\n  }\n  return transposeBOption;\n}\n\nfunction validateMatmulDimensions(label: string, M: number, N: number, K: number): void {\n  if (!Number.isFinite(M) || !Number.isFinite(N) || !Number.isFinite(K)) {\n    throw new Error(`[${label}] Invalid dimensions: M=${M}, N=${N}, K=${K}`);\n  }\n  if (M <= 0 || N <= 0 || K <= 0) {\n    throw new Error(`[${label}] Dimensions must be positive: M=${M}, N=${N}, K=${K}`);\n  }\n}\n\nfunction validateMatmulOffsets(\n  label: string,\n  aOffset: number,\n  bOffset: number,\n  cOffset: number\n): void {\n  if (!Number.isFinite(aOffset) || aOffset < 0 ||\n      !Number.isFinite(bOffset) || bOffset < 0 ||\n      !Number.isFinite(cOffset) || cOffset < 0) {\n    throw new Error(`[${label}] Invalid buffer offsets: aOffset=${aOffset}, bOffset=${bOffset}, cOffset=${cOffset}`);\n  }\n\n  const storageAlignment = ALIGNMENT.STORAGE;\n  if (aOffset % storageAlignment !== 0 ||\n      bOffset % storageAlignment !== 0 ||\n      cOffset % storageAlignment !== 0) {\n    throw new Error(\n      `[${label}] Buffer offsets must be ${storageAlignment}-byte aligned: ` +\n      `aOffset=${aOffset}, bOffset=${bOffset}, cOffset=${cOffset}`\n    );\n  }\n}\n\nfunction getMatmulBindingSizes(\n  label: string,\n  A: GPUBuffer,\n  B: GPUBuffer,\n  M: number,\n  N: number,\n  K: number,\n  aDtype: MatmulDtype,\n  bDtype: MatmulDtype,\n  transposeB: boolean,\n  aOffset: number,\n  bOffset: number\n): { aBindingSize: number; bBindingSize: number } {\n  const aBytesPerElem = aDtype === 'f16' ? 2 : 4;\n  const aBindingSize = Math.ceil((M * K * aBytesPerElem) / 4) * 4;\n  const aRequired = aOffset + aBindingSize;\n  if (A.size < aRequired) {\n    throw new Error(`[${label}] A buffer too small: ${A.size} < ${aRequired} (M=${M}, K=${K}, aDtype=${aDtype})`);\n  }\n\n  const QK_K = TILE_SIZES.Q4K_SUPER_BLOCK_SIZE;\n  const Q4K_BLOCK_BYTES = QUANTIZATION.Q4K_BLOCK_BYTES;\n  let bBindingSize: number;\n  let bRequired: number;\n\n  if (bDtype === 'q4k') {\n    const numBlocksPerRow = Math.ceil(K / QK_K);\n    bBindingSize = Math.ceil((N * numBlocksPerRow * Q4K_BLOCK_BYTES) / 4) * 4;\n    bRequired = bOffset + bBindingSize;\n  } else {\n    const bBytesPerElem = bDtype === 'f16' ? 2 : 4;\n    const bElements = transposeB ? N * K : K * N;\n    bBindingSize = Math.ceil((bElements * bBytesPerElem) / 4) * 4;\n    bRequired = bOffset + bBindingSize;\n  }\n\n  if (B.size < bRequired) {\n    throw new Error(\n      `[${label}] B buffer too small: ${B.size} < ${bRequired} ` +\n      `(N=${N}, K=${K}, bDtype=${bDtype}, transposeB=${transposeB})`\n    );\n  }\n\n  return { aBindingSize, bBindingSize };\n}\n\nfunction isQ4KFusedVariant(variant: string): boolean {\n  return variant.startsWith('q4_fused');\n}\n\nfunction isGemvVariant(variant: string): boolean {\n  return variant.startsWith('gemv');\n}\n\nfunction resolveMatmulOverride(\n  variantOverride: string,\n  M: number,\n  aDtype: MatmulDtype,\n  bDtype: MatmulDtype,\n  capabilities: ReturnType<typeof getKernelCapabilities>,\n  strict: boolean\n): { variant: string; useQ4KFused: boolean; useGemv: boolean } | null {\n  const override = variantOverride.trim();\n  if (!override) return null;\n\n  const failOrWarn = (message: string): { variant: string; useQ4KFused: boolean; useGemv: boolean } | null => {\n    if (strict) {\n      throw new Error(message);\n    }\n    log.warn('Matmul', message);\n    return null;\n  };\n\n  let config;\n  try {\n    config = getKernelConfig('matmul', override);\n  } catch {\n    return failOrWarn(`Unknown matmul kernel variant \"${variantOverride}\".`);\n  }\n\n  if (!hasRequiredFeatures(config.requires, capabilities)) {\n    return failOrWarn(`Matmul kernel \"${variantOverride}\" requires unsupported GPU features.`);\n  }\n\n  const useQ4KFused = isQ4KFusedVariant(override);\n  if (useQ4KFused) {\n    if (bDtype !== 'q4k') {\n      return failOrWarn(`Matmul kernel \"${variantOverride}\" requires Q4K weights but B dtype is ${bDtype}.`);\n    }\n    if (isFusedQ4KDisabled()) {\n      return failOrWarn(`Matmul kernel \"${variantOverride}\" blocked by DOPPLER_DISABLE_FUSED_Q4K.`);\n    }\n  }\n\n  const useGemv = isGemvVariant(override);\n  if (useGemv && M !== 1) {\n    return failOrWarn(`Matmul kernel \"${variantOverride}\" requires M=1 but got M=${M}.`);\n  }\n\n  return { variant: override, useQ4KFused, useGemv };\n}\n\nfunction selectMatmulVariantAndFlags(\n  mode: MatmulSelectionMode,\n  M: number,\n  N: number,\n  K: number,\n  aDtype: MatmulDtype,\n  bDtype: MatmulDtype,\n  transposeB: boolean,\n  requestedOutputDtype: 'f16' | 'f32',\n  options: MatmulOptions\n): { variant: string; useQ4KFused: boolean; useGemv: boolean } {\n  const capabilities = getKernelCapabilities();\n  const strict = getKernelPathStrict();\n  const phase = M === 1 ? 'decode' : 'prefill';\n  const pathVariant = getKernelPathMatmulVariant(options.role, phase, options.layerIdx);\n\n  if (pathVariant) {\n    const override = resolveMatmulOverride(pathVariant, M, aDtype, bDtype, capabilities, strict);\n    if (override) {\n      return override;\n    }\n  }\n\n  let variant = 'f32';\n  let useQ4KFused = false;\n  let useGemv = false;\n\n  // For Q4K weights, prefer fused path if available\n  if (bDtype === 'q4k') {\n    const allowFused = !isFusedQ4KDisabled();\n    const canFused = capabilities.hasSubgroups && allowFused;\n\n    if (canFused) {\n      useQ4KFused = true;\n      const wantF16Output = requestedOutputDtype === 'f16' && capabilities.hasF16;\n      variant = selectQ4KFusedVariant(M === 1, wantF16Output);\n    }\n  }\n\n  if (!useQ4KFused) {\n    const effectiveBDtype = bDtype === 'q4k' ? 'f32' : bDtype;\n    variant = selectMatmulKernel({\n      ...options,\n      aDtype: aDtype === 'q4k' ? 'f32' : aDtype,\n      bDtype: effectiveBDtype,\n      outputDtype: requestedOutputDtype,\n    });\n\n    useGemv = M === 1 && effectiveBDtype === 'f16' && aDtype === 'f32';\n    if (useGemv) {\n      if (capabilities.hasSubgroups) {\n        // Use configurable threshold from schema\n        const { multicolThreshold } = getKernelThresholds().matmul;\n        if (N > multicolThreshold) {\n          variant = 'gemv_subgroup_multicol';\n        } else {\n          variant = 'gemv_subgroup';\n        }\n      } else {\n        variant = 'gemv';\n      }\n    }\n  }\n\n  return { variant, useQ4KFused, useGemv };\n}\n\nfunction resolveMatmulOutput(\n  variant: string,\n  M: number,\n  N: number,\n  outputBuffer: GPUBuffer | null\n): { output: GPUBuffer; outputSize: number; cBindingSize: number; actualOutputDtype: 'f16' | 'f32' } {\n  // Use kernel config's outputDtype instead of string matching\n  const config = getKernelConfig('matmul', variant);\n  const outputsF16 = config.outputDtype === 'f16';\n  const elementSize = outputsF16 ? 2 : 4;\n  const actualOutputDtype: 'f16' | 'f32' = outputsF16 ? 'f16' : 'f32';\n  const outputSize = M * N * elementSize;\n  const cBindingSize = Math.ceil(outputSize / 4) * 4;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'matmul_output');\n  return { output, outputSize, cBindingSize, actualOutputDtype };\n}\n\nfunction calculateMatmulDispatch(\n  variant: string,\n  useQ4KFused: boolean,\n  useGemv: boolean,\n  M: number,\n  N: number,\n  config: { workgroupSize: [number, number, number]; variantMetadata?: { colsPerWg?: number; tileM?: number } }\n): { workgroups: [number, number, number]; uniformWorkgroupsX?: number } {\n  const maxWorkgroups = GPU_LIMITS.MAX_WORKGROUPS;\n  const [wgX, wgY] = config.workgroupSize;\n  let workgroupsX = 1;\n  let workgroupsY = 1;\n  let uniformWorkgroupsX: number | undefined;\n\n  // Get colsPerWg from variantMetadata (default 4 for non-multicol GEMV)\n  const colsPerWg = config.variantMetadata?.colsPerWg ?? 4;\n  // Get tileM from variantMetadata (default 4 for batched variants)\n  const tileM = config.variantMetadata?.tileM ?? 4;\n\n  if (useGemv && (variant === 'gemv_subgroup' || variant === 'gemv_subgroup_multicol')) {\n    const gemvWorkgroupsX = Math.ceil(N / colsPerWg);\n    if (gemvWorkgroupsX > maxWorkgroups) {\n      workgroupsX = maxWorkgroups;\n      workgroupsY = Math.ceil(gemvWorkgroupsX / maxWorkgroups);\n    } else {\n      workgroupsX = gemvWorkgroupsX;\n      workgroupsY = 1;\n    }\n    uniformWorkgroupsX = workgroupsX;\n    return { workgroups: [workgroupsX, workgroupsY, 1], uniformWorkgroupsX };\n  }\n\n  if (useQ4KFused) {\n    if (variant === 'q4_fused') {\n      workgroupsX = N;\n      workgroupsY = 1;\n    } else if (config.variantMetadata?.colsPerWg) {\n      // Multicol variants: q4_fused_multicol, q4_fused_multicol_f16\n      workgroupsX = Math.ceil(N / colsPerWg);\n      workgroupsY = 1;\n    } else if (config.variantMetadata?.tileM) {\n      // Batched variants: q4_fused_batched, q4_fused_batched_f16\n      workgroupsX = N;\n      workgroupsY = Math.ceil(M / tileM);\n    } else {\n      // Fallback for q4_fused (1 col per workgroup)\n      workgroupsX = N;\n      workgroupsY = 1;\n    }\n  } else if (useGemv) {\n    workgroupsX = N;\n    workgroupsY = 1;\n  } else {\n    const colsPerThread = variant === 'f16_vec4' ? 4 : 1;\n    workgroupsX = Math.ceil(M / wgX);\n    workgroupsY = Math.ceil(N / (wgY * colsPerThread));\n  }\n\n  return { workgroups: [workgroupsX, workgroupsY, 1], uniformWorkgroupsX };\n}\n\nfunction createMatmulUniformBuffer(\n  label: string,\n  M: number,\n  N: number,\n  K: number,\n  alpha: number,\n  useQ4KFused: boolean,\n  transposeB: boolean,\n  uniformWorkgroupsX: number | undefined,\n  recorder: CommandRecorder | null,\n  device: GPUDevice\n): GPUBuffer {\n  // Shader struct is 32 bytes: M, N, K, alpha, transpose_b/num_blocks, workgroups_x/_pad0, _pad1, _pad2\n  const uniformSize = 32;\n\n  return createUniformBufferWithView(\n    label,\n    uniformSize,\n    (view) => {\n      view.setUint32(0, M, true);\n      view.setUint32(4, N, true);\n      view.setUint32(8, K, true);\n      view.setFloat32(12, alpha, true);\n      if (useQ4KFused) {\n        const numBlocksPerRow = Math.ceil(K / TILE_SIZES.Q4K_SUPER_BLOCK_SIZE);\n        view.setUint32(16, numBlocksPerRow, true);\n      } else {\n        view.setUint32(16, transposeB ? 1 : 0, true);\n      }\n      // workgroups_x (or _pad0 if not needed)\n      view.setUint32(20, uniformWorkgroupsX ?? 0, true);\n      // _pad1, _pad2 - leave as zeros (already zero-initialized)\n    },\n    recorder,\n    device\n  );\n}\n\n/**\n * Create bind group layout for matmul operation\n */\nexport function createMatmulBindGroupLayout(): GPUBindGroupLayout {\n  return getOrCreateBindGroupLayout('matmul_bind_group_layout', [\n    {\n      binding: 0,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'uniform' },\n    },\n    {\n      binding: 1,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'read-only-storage' },\n    },\n    {\n      binding: 2,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'read-only-storage' },\n    },\n    {\n      binding: 3,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'storage' },\n    },\n  ]);\n}\n\n// Debug counter for runMatmul\nlet _runMatmulDebugCount = 0;\n\n/**\n * Run matrix multiplication\n *\n * @param A - Activation tensor (Tensor with explicit dtype)\n * @param B - Weight buffer (GPUBuffer or WeightBuffer)\n * @returns Output tensor with computed dtype\n */\nexport async function runMatmul(\n  A: Tensor,\n  B: GPUBuffer | WeightBuffer,\n  M: number,\n  N: number,\n  K: number,\n  options: MatmulOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    alpha = 1.0,\n    outputBuffer = null,\n    transposeB: transposeBOption = true,  // Default: assume row-major (SafeTensors)\n    aOffset = 0,\n    bOffset = 0,\n    cOffset = 0,\n  } = options;\n\n  // Extract underlying GPUBuffer from WeightBuffer if needed\n  const bBuffer = getBuffer(B);\n  const weightDtype = getWeightDtype(B);\n\n  // Debug: log what options are being passed\n  if (isTraceEnabled('kernels') && _runMatmulDebugCount < 20) {\n    _runMatmulDebugCount++;\n    const weightLayout = getLayout(B);\n    trace.kernels(`runMatmul: M=${M}, N=${N}, K=${K}, transposeBOption=${transposeBOption}, weightLayout=${weightLayout}, weightDtype=${weightDtype}`);\n  }\n\n  const transposeB = resolveTransposeB(B, transposeBOption);\n\n  validateMatmulDimensions('runMatmul', M, N, K);\n\n  // Get activation dtype from Tensor, weight dtype from WeightBuffer or options\n  const aDtype = toMatmulDtype(A.dtype);\n  // Prefer WeightBuffer dtype, fall back to options.bDtype\n  const bDtype = toMatmulDtype(weightDtype ?? options.bDtype);\n  const requestedOutputDtype = options.outputDtype || A.dtype;\n\n  // Warn if B buffer dtype is unknown - this can cause wrong kernel selection\n  if (isTraceEnabled('kernels') && !weightDtype && !options.bDtype && M <= 2) {\n    log.warn('Matmul', `runMatmul: B buffer dtype unknown! size=${bBuffer.size}, M=${M}, N=${N}, K=${K}. Assuming f32.`);\n  }\n\n  validateMatmulOffsets('runMatmul', aOffset, bOffset, cOffset);\n  const { aBindingSize, bBindingSize } = getMatmulBindingSizes(\n    'runMatmul',\n    A.buffer,\n    bBuffer,\n    M,\n    N,\n    K,\n    aDtype,\n    bDtype,\n    transposeB,\n    aOffset,\n    bOffset\n  );\n\n  const { variant, useQ4KFused, useGemv } = selectMatmulVariantAndFlags(\n    'run',\n    M,\n    N,\n    K,\n    aDtype,\n    bDtype,\n    transposeB,\n    requestedOutputDtype,\n    options\n  );\n\n  if (isTraceEnabled('kernels') && bDtype === 'q4k') {\n    if (useQ4KFused) {\n      trace.kernels(`Q4K FUSED: M=${M}, N=${N}, K=${K}, variant=${variant} (WARNING: 2.3x slower than dequant)`);\n    } else {\n      trace.kernels(`Q4K DEQUANT: M=${M}, N=${N}, K=${K}, will dequant first then matmul with variant=${variant}`);\n    }\n  }\n\n  // Debug: Log kernel selection for large matmuls (lm_head projection)\n  if (isTraceEnabled('kernels') && N > 100000) {\n    trace.kernels(`MATMUL_LARGE: N=${N}, variant=${variant}, aDtype=${aDtype}, bDtype=${bDtype}, transposeB=${transposeB}`);\n  }\n\n  const config = getKernelConfig('matmul', variant);\n  const kernel = new MatmulKernel(device);\n\n  // Fast path: use synchronously cached pipeline if available\n  let pipeline = getCachedPipeline('matmul', variant);\n  if (!pipeline) {\n    pipeline = await createPipeline('matmul', variant);\n  }\n\n  const { output: C, outputSize, cBindingSize, actualOutputDtype } = resolveMatmulOutput(\n    variant,\n    M,\n    N,\n    outputBuffer\n  );\n\n  if (!Number.isFinite(outputSize) || outputSize <= 0) {\n    throw new Error(`[runMatmul] Invalid output size: ${outputSize} (M=${M}, N=${N})`);\n  }\n\n  const cRequired = cOffset + cBindingSize;\n  if (C.size < cRequired) {\n    throw new Error(`[runMatmul] Output buffer too small: ${C.size} < ${cRequired} (M=${M}, N=${N})`);\n  }\n\n  const dispatchPlan = calculateMatmulDispatch(variant, useQ4KFused, useGemv, M, N, config);\n  const uniformBuffer = createMatmulUniformBuffer(\n    'matmul_uniforms',\n    M,\n    N,\n    K,\n    alpha,\n    useQ4KFused,\n    transposeB,\n    dispatchPlan.uniformWorkgroupsX,\n    null,\n    device\n  );\n\n  // Q4K F16 variants use binding 4 for output (F16), all other variants use binding 3\n  const isQ4KF16 = variant === 'q4_fused_multicol_f16' || variant === 'q4_fused_batched_f16';\n  const entries: GPUBindGroupEntry[] = [\n    { binding: 0, resource: { buffer: uniformBuffer } },\n    { binding: 1, resource: { buffer: A.buffer, offset: aOffset, size: aBindingSize } },\n    { binding: 2, resource: { buffer: bBuffer, offset: bOffset, size: bBindingSize } },\n  ];\n\n  if (isQ4KF16) {\n    entries.push({ binding: 4, resource: { buffer: C, offset: cOffset, size: cBindingSize } });\n  } else {\n    entries.push({ binding: 3, resource: { buffer: C, offset: cOffset, size: cBindingSize } });\n  }\n\n  const bindGroup = device.createBindGroup({\n    label: 'matmul_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  kernel.dispatch(pipeline, bindGroup, dispatchPlan.workgroups);\n  releaseUniformBuffer(uniformBuffer);\n\n  return createTensor(C, actualOutputDtype, [M, N], 'matmul_output');\n}\n\n// Debug counter for recordMatmul\nlet _recordMatmulDebugCount = 0;\n\n/**\n * Record matrix multiplication (batched, no submit)\n *\n * @param recorder - Command recorder for batched execution\n * @param A - Activation tensor (Tensor with explicit dtype)\n * @param B - Weight buffer (GPUBuffer or WeightBuffer)\n * @returns Output tensor with computed dtype\n */\nexport async function recordMatmul(\n  recorder: CommandRecorder,\n  A: Tensor,\n  B: GPUBuffer | WeightBuffer,\n  M: number,\n  N: number,\n  K: number,\n  options: MatmulOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    alpha = 1.0,\n    outputBuffer = null,\n    transposeB: transposeBOption = true,  // Default: assume row-major (SafeTensors)\n    aOffset = 0,\n    bOffset = 0,\n    cOffset = 0,\n  } = options;\n\n  // Extract underlying GPUBuffer from WeightBuffer if needed\n  const bBuffer = getBuffer(B);\n  const weightDtype = getWeightDtype(B);\n\n  // Debug: log what options are being passed\n  if (isTraceEnabled('kernels') && _recordMatmulDebugCount < 20) {\n    _recordMatmulDebugCount++;\n    const weightLayout = getLayout(B);\n    trace.kernels(`recordMatmul: M=${M}, N=${N}, K=${K}, transposeBOption=${transposeBOption}, weightLayout=${weightLayout}, weightDtype=${weightDtype}`);\n  }\n\n  const transposeB = resolveTransposeB(B, transposeBOption);\n  validateMatmulDimensions('recordMatmul', M, N, K);\n\n  // Get activation dtype from Tensor, weight dtype from WeightBuffer or options\n  const aDtype = toMatmulDtype(A.dtype);\n  // Prefer WeightBuffer dtype, fall back to options.bDtype\n  const bDtype = toMatmulDtype(weightDtype ?? options.bDtype);\n  const requestedOutputDtype = options.outputDtype || A.dtype;\n\n  validateMatmulOffsets('recordMatmul', aOffset, bOffset, cOffset);\n  const { aBindingSize, bBindingSize } = getMatmulBindingSizes(\n    'recordMatmul',\n    A.buffer,\n    bBuffer,\n    M,\n    N,\n    K,\n    aDtype,\n    bDtype,\n    transposeB,\n    aOffset,\n    bOffset\n  );\n\n  const { variant, useQ4KFused, useGemv } = selectMatmulVariantAndFlags(\n    'record',\n    M,\n    N,\n    K,\n    aDtype,\n    bDtype,\n    transposeB,\n    requestedOutputDtype,\n    options\n  );\n\n  const config = getKernelConfig('matmul', variant);\n  const kernel = new MatmulKernel(device);\n\n  // Fast path: use synchronously cached pipeline if available\n  let pipeline = getCachedPipeline('matmul', variant);\n  if (!pipeline) {\n    pipeline = await createPipeline('matmul', variant);\n  }\n\n  const { output: C, outputSize, cBindingSize, actualOutputDtype } = resolveMatmulOutput(\n    variant,\n    M,\n    N,\n    outputBuffer\n  );\n\n  if (!Number.isFinite(outputSize) || outputSize <= 0) {\n    throw new Error(`[recordMatmul] Invalid output size: ${outputSize} (M=${M}, N=${N})`);\n  }\n\n  const cRequired = cOffset + cBindingSize;\n  if (C.size < cRequired) {\n    throw new Error(`[recordMatmul] Output buffer too small: ${C.size} < ${cRequired} (M=${M}, N=${N})`);\n  }\n\n  const dispatchPlan = calculateMatmulDispatch(variant, useQ4KFused, useGemv, M, N, config);\n  const uniformBuffer = createMatmulUniformBuffer(\n    'matmul_uniforms',\n    M,\n    N,\n    K,\n    alpha,\n    useQ4KFused,\n    transposeB,\n    dispatchPlan.uniformWorkgroupsX,\n    recorder,\n    device\n  );\n\n  // Q4K F16 variants use binding 4 for output (F16), all other variants use binding 3\n  const isQ4KF16 = variant === 'q4_fused_multicol_f16' || variant === 'q4_fused_batched_f16';\n  const entries: GPUBindGroupEntry[] = [\n    { binding: 0, resource: { buffer: uniformBuffer } },\n    { binding: 1, resource: { buffer: A.buffer, offset: aOffset, size: aBindingSize } },\n    { binding: 2, resource: { buffer: bBuffer, offset: bOffset, size: bBindingSize } },\n  ];\n\n  if (isQ4KF16) {\n    entries.push({ binding: 4, resource: { buffer: C, offset: cOffset, size: cBindingSize } });\n  } else {\n    entries.push({ binding: 3, resource: { buffer: C, offset: cOffset, size: cBindingSize } });\n  }\n\n  const bindGroup = device.createBindGroup({\n    label: 'matmul_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  kernel.record(recorder, pipeline, bindGroup, dispatchPlan.workgroups);\n  return createTensor(C, actualOutputDtype, [M, N], 'matmul_output');\n}\n", "/**\n * Kernel Base - Shared dispatch and pipeline helpers for kernel wrappers.\n */\n\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast } from './utils.js';\n\nexport abstract class KernelBase {\n  protected readonly device: GPUDevice;\n\n  constructor(device: GPUDevice) {\n    this.device = device;\n  }\n\n  protected async getPipelineFor(\n    operation: string,\n    variant: string,\n    bindGroupLayout: GPUBindGroupLayout | null = null\n  ): Promise<GPUComputePipeline> {\n    return getPipelineFast(operation, variant, bindGroupLayout);\n  }\n\n  protected dispatchKernel(\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: number | [number, number, number],\n    label: string\n  ): void {\n    dispatch(this.device, pipeline, bindGroup, workgroups, label);\n  }\n\n  protected recordKernel(\n    recorder: CommandRecorder,\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: number | [number, number, number],\n    label: string\n  ): void {\n    recordDispatch(recorder, pipeline, bindGroup, workgroups, label);\n  }\n}\n", "/**\n * Dequantization Kernels\n *\n * Provides dequantization operations for:\n * - Q4_K_M quantization (GGUF format)\n * - MXFP4 quantization (GPT-OSS format)\n * - F16/F32 output support\n * - Subgroup and shared memory variants\n */\n\nimport { getDevice, getKernelCapabilities } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { createTensor, type Tensor, type TensorDtype } from '../tensor.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { GPU_LIMITS, TILE_SIZES, WORKGROUP_SIZES } from './constants.js';\nimport { Q6K_BLOCK_BYTES, Q8_0_BLOCK_BYTES, Q8_0_BLOCK_SIZE } from '../../loader/quantization-constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView, getOrCreateBindGroupLayout } from './utils.js';\nimport { releaseUniformBuffer } from '../uniform-cache.js';\nimport type { OutputBufferOptions, OutputDtypeOptions, OutputOffsetOptions, Vec4Options } from './types.js';\n\n/** Dequantization kernel options */\nexport interface DequantOptions extends OutputBufferOptions, OutputOffsetOptions, OutputDtypeOptions, Vec4Options {\n  groupSize?: number;\n}\n\n/**\n * Select the best dequantization kernel variant\n */\nexport function selectDequantKernel(options: DequantOptions = {}): string {\n  const capabilities = getKernelCapabilities();\n  const { useVec4 = true, outputDtype = 'f32' } = options;\n\n  const wantsF16Out = outputDtype === 'f16' && capabilities.hasF16;\n\n  if (capabilities.hasSubgroups) {\n    if (wantsF16Out) {\n      return useVec4 ? 'subgroup_vec4_f16out' : 'subgroup_f16out';\n    }\n    return useVec4 ? 'subgroup_vec4' : 'subgroup';\n  }\n\n  if (wantsF16Out) {\n    return useVec4 ? 'shared_vec4_f16out' : 'shared_f16out';\n  }\n\n  return useVec4 ? 'shared_vec4' : 'shared';\n}\n\nfunction calculateDequantWorkgroups(variant: string, numBlocks: number): [number, number, number] {\n  const QK_K = TILE_SIZES.Q4K_SUPER_BLOCK_SIZE;\n  let workgroups: number;\n\n  if (variant.includes('vec4')) {\n    workgroups = numBlocks;\n  } else if (variant.includes('shared')) {\n    workgroups = numBlocks;\n  } else {\n    workgroups = Math.ceil((numBlocks * QK_K) / (WORKGROUP_SIZES.DEFAULT / 4));\n  }\n\n  const maxWorkgroups = GPU_LIMITS.MAX_WORKGROUPS;\n  if (workgroups <= maxWorkgroups) {\n    return [workgroups, 1, 1];\n  }\n\n  const wgY = Math.ceil(workgroups / maxWorkgroups);\n  const wgX = Math.min(workgroups, maxWorkgroups);\n  return [wgX, wgY, 1];\n}\n\n/**\n * Create bind group layout for dequant operation\n */\nexport function createDequantBindGroupLayout(): GPUBindGroupLayout {\n  return getOrCreateBindGroupLayout('dequant_bind_group_layout', [\n    {\n      binding: 0,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'uniform' },\n    },\n    {\n      binding: 1,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'read-only-storage' },\n    },\n    {\n      binding: 2,\n      visibility: GPUShaderStage.COMPUTE,\n      buffer: { type: 'storage' },\n    },\n  ]);\n}\n\n/**\n * Run Q4_K_M dequantization\n */\nexport async function dequantize(\n  quantized: GPUBuffer,\n  numBlocks: number,\n  options: DequantOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    outputOffset = 0,\n    outputBuffer = null,\n    outputDtype = 'f32',\n  } = options;\n\n  // Select kernel\n  const variant = selectDequantKernel({ ...options, outputDtype });\n  const pipeline = await getPipelineFast('dequant', variant);\n\n  // Q4_K_M: 256 elements per block\n  const QK_K = TILE_SIZES.Q4K_SUPER_BLOCK_SIZE;\n  const bytesPerElem = outputDtype === 'f16' ? 2 : 4;\n  const outputSize = numBlocks * QK_K * bytesPerElem;\n\n  // Create output buffer if not provided\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'dequant_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'dequant_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numBlocks, true);\n      view.setUint32(4, outputOffset, true);\n      view.setUint32(8, 0, true); // padding\n      view.setUint32(12, 0, true); // padding\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'dequant_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: quantized } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = calculateDequantWorkgroups(variant, numBlocks);\n  dispatch(device, pipeline, bindGroup, workgroups, 'dequant');\n\n  // Release uniform buffer back to cache (or destroy if not cached)\n  releaseUniformBuffer(uniformBuffer);\n\n  const dtype: TensorDtype = outputDtype === 'f16' ? 'f16' : 'f32';\n  return createTensor(output, dtype, [numBlocks * QK_K], 'dequant_output');\n}\n\n/**\n * Dequantize MXFP4 weights (GPT-OSS format)\n */\nexport async function dequantizeMXFP4(\n  blocks: GPUBuffer,\n  scales: GPUBuffer,\n  totalElements: number,\n  numGroups: number,\n  options: DequantOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    outputBuffer = null,\n    groupSize = 32,  // 32 elements per group (16 bytes * 2 nibbles)\n  } = options;\n\n  const pipeline = await getPipelineFast('dequant', 'mxfp4');\n\n  const outputSize = totalElements * 4; // F32 output\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'mxfp4_dequant_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'mxfp4_dequant_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, totalElements, true);\n      view.setUint32(4, numGroups, true);\n      view.setUint32(8, groupSize, true);\n      view.setUint32(12, numGroups * groupSize, true); // row_stride\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'mxfp4_dequant_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: blocks } },\n      { binding: 2, resource: { buffer: scales } },\n      { binding: 3, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil(totalElements / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize: [number, number, number] = [\n    Math.min(workgroups, GPU_LIMITS.MAX_WORKGROUPS),\n    Math.max(1, Math.ceil(workgroups / GPU_LIMITS.MAX_WORKGROUPS)),\n    1,\n  ];\n  dispatch(device, pipeline, bindGroup, dispatchSize, 'mxfp4_dequant');\n\n  releaseUniformBuffer(uniformBuffer);\n\n  return createTensor(output, 'f32', [totalElements], 'mxfp4_dequant_output');\n}\n\n/**\n * Dequantize MXFP4 expert weights (extracts single expert from packed tensor)\n */\nexport async function dequantizeMXFP4Expert(\n  blocks: GPUBuffer,\n  scales: GPUBuffer,\n  expertIdx: number,\n  numExperts: number,\n  outDim: number,\n  numGroups: number,\n  options: DequantOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { outputBuffer = null } = options;\n\n  const pipeline = await getPipelineFast('dequant', 'mxfp4_expert');\n\n  // Output is [out_dim, num_groups * 32] as F32\n  const totalOutput = outDim * numGroups * 32;\n  const outputSize = totalOutput * 4;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'mxfp4_expert_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'mxfp4_expert_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, expertIdx, true);\n      view.setUint32(4, numExperts, true);\n      view.setUint32(8, outDim, true);\n      view.setUint32(12, numGroups, true);\n      view.setUint32(16, totalOutput, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'mxfp4_expert_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: blocks } },\n      { binding: 2, resource: { buffer: scales } },\n      { binding: 3, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil(totalOutput / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize: [number, number, number] = [\n    Math.min(workgroups, GPU_LIMITS.MAX_WORKGROUPS),\n    Math.max(1, Math.ceil(workgroups / GPU_LIMITS.MAX_WORKGROUPS)),\n    1,\n  ];\n  dispatch(device, pipeline, bindGroup, dispatchSize, 'mxfp4_expert');\n\n  releaseUniformBuffer(uniformBuffer);\n\n  return createTensor(output, 'f32', [outDim, numGroups * 32], 'mxfp4_expert_output');\n}\n\n/**\n * Run Q6_K dequantization\n *\n * Q6_K format: 210 bytes per 256 elements\n * - d: 2 bytes (f16 super-block scale)\n * - ql: 128 bytes (low 4 bits packed)\n * - qh: 64 bytes (high 2 bits packed)\n * - scales: 16 bytes (8-bit signed block scales)\n */\nexport async function dequantizeQ6K(\n  quantized: GPUBuffer,\n  numBlocks: number,\n  options: DequantOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    outputOffset = 0,\n    outputBuffer = null,\n    outputDtype = 'f16',  // Q6_K always outputs f16 for now\n  } = options;\n\n  // Q6_K only has f16 output kernel currently\n  const pipeline = await getPipelineFast('dequant', 'q6k_f16out');\n\n  // Q6_K: 256 elements per block\n  const QK_K = TILE_SIZES.Q4K_SUPER_BLOCK_SIZE;\n  const bytesPerElem = outputDtype === 'f16' ? 2 : 4;\n  const outputSize = numBlocks * QK_K * bytesPerElem;\n\n  // Create output buffer if not provided\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'q6k_dequant_output');\n\n  // Calculate workgroups for 2D dispatch\n  const maxWorkgroups = GPU_LIMITS.MAX_WORKGROUPS;\n  const workgroupsX = Math.min(numBlocks, maxWorkgroups);\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'q6k_dequant_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numBlocks, true);\n      view.setUint32(4, outputOffset, true);\n      view.setUint32(8, workgroupsX, true); // workgroups_x for 2D dispatch\n      view.setUint32(12, 0, true); // padding\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'q6k_dequant_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: quantized } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  // One workgroup per block, handle 2D dispatch for large counts\n  const workgroups: [number, number, number] = [\n    workgroupsX,\n    numBlocks > maxWorkgroups ? Math.ceil(numBlocks / maxWorkgroups) : 1,\n    1\n  ];\n\n  dispatch(device, pipeline, bindGroup, workgroups, 'q6k_dequant');\n\n  releaseUniformBuffer(uniformBuffer);\n\n  const dtype: TensorDtype = outputDtype === 'f16' ? 'f16' : 'f32';\n  return createTensor(output, dtype, [numBlocks * QK_K], 'q6k_dequant_output');\n}\n\n/**\n * Run Q8_0 dequantization\n *\n * Q8_0 format: 34 bytes per 32 elements\n * - d: 2 bytes (f16 scale)\n * - qs: 32 bytes (int8 quantized values)\n *\n * Dequant: output[i] = d * qs[i]\n */\nexport async function dequantizeQ8_0(\n  quantized: GPUBuffer,\n  numBlocks: number,\n  options: DequantOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    outputOffset = 0,\n    outputBuffer = null,\n    outputDtype = 'f16',  // Q8_0 outputs f16 for now\n  } = options;\n\n  // Q8_0 only has f16 output kernel currently\n  const pipeline = await getPipelineFast('dequant', 'q8_0_f16out');\n\n  // Q8_0: 32 elements per block\n  const bytesPerElem = outputDtype === 'f16' ? 2 : 4;\n  const outputSize = numBlocks * Q8_0_BLOCK_SIZE * bytesPerElem;\n\n  // Create output buffer if not provided\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'q8_0_dequant_output');\n\n  // Calculate workgroups for 2D dispatch\n  const maxWorkgroups = GPU_LIMITS.MAX_WORKGROUPS;\n  const workgroupsX = Math.min(numBlocks, maxWorkgroups);\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'q8_0_dequant_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numBlocks, true);\n      view.setUint32(4, outputOffset, true);\n      view.setUint32(8, workgroupsX, true); // workgroups_x for 2D dispatch\n      view.setUint32(12, 0, true); // padding\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'q8_0_dequant_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: quantized } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  // One workgroup per block, handle 2D dispatch for large counts\n  const workgroups: [number, number, number] = [\n    workgroupsX,\n    numBlocks > maxWorkgroups ? Math.ceil(numBlocks / maxWorkgroups) : 1,\n    1\n  ];\n\n  dispatch(device, pipeline, bindGroup, workgroups, 'q8_0_dequant');\n\n  releaseUniformBuffer(uniformBuffer);\n\n  const dtype: TensorDtype = outputDtype === 'f16' ? 'f16' : 'f32';\n  return createTensor(output, dtype, [numBlocks * Q8_0_BLOCK_SIZE], 'q8_0_dequant_output');\n}\n\n/**\n * Record Q4_K_M dequantization (batched, no submit)\n */\nexport async function recordDequantize(\n  recorder: CommandRecorder,\n  quantized: GPUBuffer,\n  numBlocks: number,\n  options: DequantOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    outputOffset = 0,\n    outputBuffer = null,\n    outputDtype = 'f32',\n  } = options;\n\n  // Select kernel\n  const variant = selectDequantKernel({ ...options, outputDtype });\n  const pipeline = await getPipelineFast('dequant', variant);\n\n  // Q4_K: 256 elements per block\n  const QK_K = TILE_SIZES.Q4K_SUPER_BLOCK_SIZE;\n  const bytesPerElem = outputDtype === 'f16' ? 2 : 4;\n  const outputSize = numBlocks * QK_K * bytesPerElem;\n\n  // Output buffer\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'dequant_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'dequant_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numBlocks, true);\n      view.setUint32(4, outputOffset, true);\n    },\n    recorder\n  );\n\n  // Bind group\n  const bindGroup = device.createBindGroup({\n    label: 'dequant_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: quantized } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = calculateDequantWorkgroups(variant, numBlocks);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'dequant');\n\n  const dtype: TensorDtype = outputDtype === 'f16' ? 'f16' : 'f32';\n  return createTensor(output, dtype, [numBlocks * QK_K], 'dequant_output');\n}\n", "/**\n * Centralized Quantization Format Constants\n *\n * Single source of truth for quantization block sizes and formats.\n * Import these instead of redefining locally.\n *\n * @module loader/quantization-constants\n */\n\n// Re-export Q4K constants from quantizer (source of truth)\nexport { QK_K, QK4_K_BLOCK_SIZE, K_SCALE_SIZE } from '../converter/quantizer.js';\n\n/** Q4K block size in bytes (alias for clarity) */\nexport const Q4K_BLOCK_BYTES = 144;\n\n/** Q6K block size in bytes (210 bytes per 256 weights) */\nexport const Q6K_BLOCK_BYTES = 210;\n\n/** Q8_0 block size in bytes (34 bytes per 32 weights: 2 byte scale + 32 byte qs) */\nexport const Q8_0_BLOCK_BYTES = 34;\n\n/** Q8_0 block size in elements (32 weights per block) */\nexport const Q8_0_BLOCK_SIZE = 32;\n", "/**\n * Attention Kernels\n *\n * Provides optimized attention operations with support for:\n * - Prefill and decode phases\n * - Causal masking\n * - Grouped-query attention (GQA)\n * - Multiple implementation tiers (tiled, streaming)\n * - F16/F32 KV cache support\n */\n\nimport { getDevice, getDeviceLimits, getKernelCapabilities } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { createTensor, type Tensor, type TensorDtype } from '../tensor.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { KernelBase } from './kernel-base.js';\nimport { DIMENSION_LIMITS, MEMORY_THRESHOLDS, TILE_SIZES } from './constants.js';\nimport { getKernelThresholds } from '../../config/schema/kernel-thresholds.schema.js';\nimport { createUniformBufferWithView, getKernelConfig, hasRequiredFeatures } from './utils.js';\nimport { dispatchIndirect, recordDispatchIndirect } from './dispatch.js';\nimport { releaseUniformBuffer } from '../uniform-cache.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { log, trace } from '../../debug/index.js';\nimport { getKernelPathAttentionVariant, getKernelPathStrict } from '../../config/kernel-path-loader.js';\n\n// Track if we've logged the attention tier selection (avoid spam)\nlet loggedAttentionTier = false;\n\n/**\n * Get max KV length for chunked attention from kernel config.\n * Cached for performance since it's called frequently.\n */\nlet _chunkedMaxKVLen: number | null = null;\nfunction getChunkedMaxKVLen(): number {\n  if (_chunkedMaxKVLen === null) {\n    const config = getKernelConfig('attention', 'decode_chunked_f16kv');\n    _chunkedMaxKVLen = config.variantMetadata?.maxKVLen ?? 2048;\n  }\n  return _chunkedMaxKVLen;\n}\n\nlet kvLenFallbackBuffer: GPUBuffer | null = null;\nfunction getKvLenFallbackBuffer(device: GPUDevice): GPUBuffer {\n  if (!kvLenFallbackBuffer) {\n    kvLenFallbackBuffer = device.createBuffer({\n      label: 'attention_kv_len_fallback',\n      size: 4,\n      usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n    });\n    device.queue.writeBuffer(kvLenFallbackBuffer, 0, new Uint32Array([0]));\n  }\n  return kvLenFallbackBuffer;\n}\n\n/** Attention kernel options */\nexport interface AttentionOptions extends OutputBufferOptions {\n  seqLen?: number;\n  kvLen?: number;\n  numKVHeads?: number;\n  scale?: number;\n  causal?: boolean;\n  startPos?: number;\n  slidingWindow?: number;\n  /** Layer index for kernel path layer overrides */\n  layerIdx?: number;\n  /** Gemma 2 attention softcapping: score = tanh(score / softcap) * softcap. 0 = disabled. */\n  attnSoftcap?: number;\n  /** Optional GPU buffer containing KV length (u32). When provided, kernel reads KV length from buffer. */\n  kvLenBuffer?: GPUBuffer | null;\n  /** Optional indirect dispatch buffer for GPU-driven workgroup counts. */\n  indirectBuffer?: GPUBuffer | null;\n  /** Byte offset into indirect dispatch buffer (default: 0). */\n  indirectOffset?: number;\n}\n\ntype AttentionTier = 'subgroup' | 'tiled_large' | 'tiled_small' | 'streaming';\n\ninterface AttentionPlan {\n  tier: AttentionTier;\n  variant: string;\n  workgroups: number;\n  useF16KV: boolean;\n  isDecode: boolean;\n}\n\nclass AttentionKernel extends KernelBase {\n  async getPipeline(variant: string): Promise<GPUComputePipeline> {\n    return this.getPipelineFor('attention', variant);\n  }\n\n  dispatch(\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: number\n  ): void {\n    this.dispatchKernel(pipeline, bindGroup, workgroups, 'attention');\n  }\n\n  record(\n    recorder: CommandRecorder,\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroups: number\n  ): void {\n    this.recordKernel(recorder, pipeline, bindGroup, workgroups, 'attention');\n  }\n}\n\nfunction selectAttentionTier(\n  headDim: number,\n  seqLen: number,\n  useF16KV: boolean,\n  forcedTier: AttentionTier | null,\n  sharedLimit: number,\n  caps: ReturnType<typeof getKernelCapabilities>,\n  strict: boolean\n): AttentionTier {\n  const isDecode = seqLen === 1;\n  const canLarge =\n    headDim <= DIMENSION_LIMITS.ATTENTION_LARGE_MAX_HEAD_DIM &&\n    sharedLimit >= MEMORY_THRESHOLDS.ATTENTION_LARGE_SHARED;\n  const smallRequired = useF16KV\n    ? MEMORY_THRESHOLDS.ATTENTION_SMALL_SHARED_F16\n    : MEMORY_THRESHOLDS.ATTENTION_SMALL_SHARED_F32;\n  const canSmall =\n    headDim <= DIMENSION_LIMITS.ATTENTION_SMALL_MAX_HEAD_DIM &&\n    sharedLimit >= smallRequired;\n  const canSubgroup =\n    caps.hasSubgroups &&\n    headDim <= DIMENSION_LIMITS.ATTENTION_SUBGROUP_MAX_HEAD_DIM &&\n    sharedLimit >= MEMORY_THRESHOLDS.ATTENTION_SUBGROUP_SHARED &&\n    isDecode;\n\n  const failOrWarn = (message: string): void => {\n    if (strict) {\n      throw new Error(message);\n    }\n    log.warn('Attention', message);\n  };\n\n  let tier = forcedTier;\n\n  if (tier === 'tiled_large' && !canLarge) {\n    failOrWarn(`Requested tiled_large but device doesn't support it (headDim=${headDim}, shared=${sharedLimit}).`);\n    tier = null;\n  }\n  if (tier === 'tiled_small' && !canSmall) {\n    failOrWarn(`Requested tiled_small but device doesn't support it (headDim=${headDim}, shared=${sharedLimit}).`);\n    tier = null;\n  }\n  if (tier === 'subgroup' && !canSubgroup) {\n    failOrWarn(`Requested subgroup attention but device doesn't support it (headDim=${headDim}, shared=${sharedLimit}, subgroups=${caps.hasSubgroups}).`);\n    tier = null;\n  }\n\n  if (!tier) {\n    if (canSubgroup) {\n      tier = 'subgroup';\n      if (!loggedAttentionTier) {\n        trace.attn(0, `Using subgroup decode kernel (headDim=${headDim}, hasSubgroups=true)`);\n        loggedAttentionTier = true;\n      }\n    } else if (canLarge) {\n      tier = 'tiled_large';\n    } else if (canSmall) {\n      tier = 'tiled_small';\n    } else if (isDecode) {\n      tier = 'streaming';\n    } else {\n      log.warn('Attention', `No tiled kernel fits prefill (headDim=${headDim}, shared=${sharedLimit}). Falling back to streaming. Expect slow prefill.`);\n      tier = 'streaming';\n    }\n  }\n\n  return tier as AttentionTier;\n}\n\n// Track if we've logged chunked kernel selection\nlet loggedChunkedKernel = false;\n\nfunction resolveAttentionVariant(\n  tier: AttentionTier,\n  isDecode: boolean,\n  useF16KV: boolean,\n  numHeads: number,\n  headDim: number,\n  kvLen: number\n): string {\n  const base = isDecode ? 'decode' : 'prefill';\n\n  // Check if chunked kernel is viable:\n  // - Decode only (seqLen=1)\n  // - F16 KV cache\n  // - Large headDim (parallelizes across dimensions)\n  // - KV length within shared memory limit (from kernel config)\n  const chunkedMaxKVLen = getChunkedMaxKVLen();\n  const minHeadDimForChunked = getKernelThresholds().attention.minHeadDimForChunked;\n  const canUseChunked = isDecode && useF16KV && headDim >= minHeadDimForChunked && kvLen <= chunkedMaxKVLen;\n  const decodeSubgroupMaxKVLen = chunkedMaxKVLen;\n  const decodeSubgroupMaxHeadDim = getKernelThresholds().attention.tierHeadDimLimits.tier1;\n  const canUseDecodeSubgroup = isDecode && !useF16KV && headDim <= decodeSubgroupMaxHeadDim && kvLen <= decodeSubgroupMaxKVLen;\n\n  if (tier === 'subgroup') {\n    // decode_subgroup only supports F32 KV cache\n    // Fall back to chunked for F16 KV cache (much faster than streaming)\n    if (useF16KV) {\n      if (canUseChunked) {\n        if (!loggedChunkedKernel) {\n          trace.attn(0, `Using chunked decode kernel (headDim=${headDim}, numHeads=${numHeads}, f16kv=true)`);\n          loggedChunkedKernel = true;\n        }\n        return 'decode_chunked_f16kv';\n      }\n      return 'decode_streaming_f16kv';\n    }\n    if (canUseDecodeSubgroup) {\n      return 'decode_subgroup';\n    }\n    return 'decode_streaming';\n  }\n  if (tier === 'tiled_large') {\n    return base + (useF16KV ? '_f16kv' : '');\n  }\n  if (tier === 'tiled_small') {\n    return `${base}_small${useF16KV ? '_f16kv' : ''}`;\n  }\n  // For streaming tier, prefer chunked if viable\n  if (canUseChunked) {\n    if (!loggedChunkedKernel) {\n      trace.attn(0, `Using chunked decode kernel (headDim=${headDim}, numHeads=${numHeads}, f16kv=true)`);\n      loggedChunkedKernel = true;\n    }\n    return 'decode_chunked_f16kv';\n  }\n  return `${base}_streaming${useF16KV ? '_f16kv' : ''}`;\n}\n\nfunction calculateAttentionWorkgroups(tier: AttentionTier, seqLen: number, numHeads: number): number {\n  if (tier === 'subgroup') {\n    return numHeads;\n  }\n  if (tier === 'streaming') {\n    return seqLen * numHeads;\n  }\n  if (tier === 'tiled_large') {\n    return Math.ceil(seqLen / TILE_SIZES.ATTENTION_LARGE_BLOCK_SIZE) * numHeads;\n  }\n  return Math.ceil(seqLen / TILE_SIZES.ATTENTION_SMALL_BLOCK_SIZE) * numHeads;\n}\n\nfunction inferAttentionTierFromVariant(variant: string): AttentionTier {\n  if (variant === 'decode_subgroup') return 'subgroup';\n  if (variant.startsWith('prefill_streaming') || variant.startsWith('decode_streaming') || variant === 'decode_chunked_f16kv') {\n    return 'streaming';\n  }\n  if (variant.startsWith('prefill_small') || variant.startsWith('decode_small')) return 'tiled_small';\n  return 'tiled_large';\n}\n\nfunction validateAttentionVariant(\n  variant: string,\n  isDecode: boolean,\n  useF16KV: boolean,\n  caps: ReturnType<typeof getKernelCapabilities>,\n  strict: boolean\n): string | null {\n  const normalized = variant.trim();\n  const failOrWarn = (message: string): string | null => {\n    if (strict) {\n      throw new Error(message);\n    }\n    log.warn('Attention', message);\n    return null;\n  };\n\n  let config;\n  try {\n    config = getKernelConfig('attention', normalized);\n  } catch {\n    return failOrWarn(`Unknown attention kernel variant \"${variant}\".`);\n  }\n\n  if (!hasRequiredFeatures(config.requires, caps)) {\n    return failOrWarn(`Attention kernel \"${variant}\" requires unsupported GPU features.`);\n  }\n\n  const expectsF16KV = normalized.includes('_f16kv');\n  if (expectsF16KV !== useF16KV) {\n    const kvLabel = useF16KV ? 'f16' : 'f32';\n    return failOrWarn(`Attention kernel \"${variant}\" incompatible with ${kvLabel} KV cache.`);\n  }\n\n  const isDecodeVariant = normalized.startsWith('decode');\n  const isPrefillVariant = normalized.startsWith('prefill');\n  if (isDecode && isPrefillVariant) {\n    return failOrWarn(`Attention kernel \"${variant}\" is prefill-only but decode requested.`);\n  }\n  if (!isDecode && isDecodeVariant) {\n    return failOrWarn(`Attention kernel \"${variant}\" is decode-only but prefill requested.`);\n  }\n\n  return normalized;\n}\n\nfunction resolveAttentionPlan(\n  seqLen: number,\n  kvLen: number,\n  headDim: number,\n  numHeads: number,\n  kvDtype: string,\n  sharedLimit: number,\n  caps: ReturnType<typeof getKernelCapabilities>,\n  layerIdx?: number\n): AttentionPlan {\n  const useF16KV = kvDtype === 'f16';\n  const isDecode = seqLen === 1;\n  const strict = getKernelPathStrict();\n  const pathVariant = getKernelPathAttentionVariant(isDecode ? 'decode' : 'prefill', layerIdx);\n\n  if (pathVariant) {\n    const variantOverride = validateAttentionVariant(pathVariant, isDecode, useF16KV, caps, strict);\n    if (variantOverride) {\n      const tier = inferAttentionTierFromVariant(variantOverride);\n      const workgroups = calculateAttentionWorkgroups(tier, seqLen, numHeads);\n      return { tier, variant: variantOverride, workgroups, useF16KV, isDecode };\n    }\n  }\n\n  const tier = selectAttentionTier(headDim, seqLen, useF16KV, null, sharedLimit, caps, strict);\n  const variant = resolveAttentionVariant(tier, isDecode, useF16KV, numHeads, headDim, kvLen);\n  const workgroups = calculateAttentionWorkgroups(tier, seqLen, numHeads);\n\n  return { tier, variant, workgroups, useF16KV, isDecode };\n}\n\nfunction createAttentionUniformBuffer(\n  device: GPUDevice,\n  recorder: CommandRecorder | null,\n  params: {\n    numHeads: number;\n    numKVHeads: number;\n    headDim: number;\n    kvLen: number;\n    seqLen: number;\n    scale: number;\n    causal: boolean;\n    startPos: number;\n    attnSoftcap: number;\n    slidingWindow: number;\n    kvLenSource: number;\n  }\n): GPUBuffer {\n  return createUniformBufferWithView(\n    'attention_uniforms',\n    48, // 44 bytes used + 4 padding for 16-byte alignment\n    (view) => {\n      view.setUint32(0, params.numHeads, true);\n      view.setUint32(4, params.numKVHeads, true);\n      view.setUint32(8, params.headDim, true);\n      view.setUint32(12, params.kvLen, true);\n      view.setUint32(16, params.seqLen, true);\n      view.setFloat32(20, params.scale, true);\n      view.setUint32(24, params.causal ? 1 : 0, true);\n      view.setUint32(28, params.startPos, true);\n      view.setFloat32(32, params.attnSoftcap, true); // Gemma 2: 50.0, 0 = disabled\n      view.setUint32(36, params.slidingWindow, true); // Sliding window size, 0 = disabled\n      view.setUint32(40, params.kvLenSource, true); // 0 = uniform kvLen, 1 = buffer\n    },\n    recorder,\n    device\n  );\n}\n\n/**\n * Run attention operation\n */\nexport async function runAttention(\n  Q: Tensor,\n  K: Tensor,\n  V: Tensor,\n  mask: GPUBuffer | null,\n  numHeads: number,\n  headDim: number,\n  options: AttentionOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    seqLen = 1,\n    kvLen = seqLen,\n    numKVHeads = numHeads,\n    scale = 1.0 / Math.sqrt(headDim),\n    causal = true,\n    startPos = 0,\n    layerIdx,\n    outputBuffer = null,\n    attnSoftcap = 0,\n    slidingWindow = 0,\n    kvLenBuffer = null,\n    indirectBuffer = null,\n    indirectOffset = 0,\n  } = options;\n\n  const limits = getDeviceLimits();\n  const sharedLimit = limits?.maxComputeWorkgroupStorageSize ?? Infinity;\n  const caps = getKernelCapabilities();\n  const kvDtype: TensorDtype = K.dtype;\n  const plan = resolveAttentionPlan(\n    seqLen,\n    kvLen,\n    headDim,\n    numHeads,\n    kvDtype,\n    sharedLimit,\n    caps,\n    layerIdx\n  );\n  const kernel = new AttentionKernel(device);\n  const pipeline = await kernel.getPipeline(plan.variant);\n\n  // Output is always f32 (attention scores computed in f32)\n  const outputDtype: TensorDtype = 'f32';\n  const outputSize = seqLen * numHeads * headDim * 4;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'attention_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createAttentionUniformBuffer(device, null, {\n    numHeads,\n    numKVHeads,\n    headDim,\n    kvLen,\n    seqLen,\n    scale,\n    causal,\n    startPos,\n    attnSoftcap,\n    slidingWindow,\n    kvLenSource: kvLenBuffer ? 1 : 0,\n  });\n\n  // Create bind group\n  const kvLenBinding = kvLenBuffer || getKvLenFallbackBuffer(device);\n  const bindGroup = device.createBindGroup({\n    label: 'attention_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: Q.buffer } },\n      { binding: 2, resource: { buffer: K.buffer } },\n      { binding: 3, resource: { buffer: V.buffer } },\n      { binding: 4, resource: { buffer: outputBuf } },\n      { binding: 5, resource: { buffer: kvLenBinding } },\n    ],\n  });\n\n  if (!indirectBuffer && limits && plan.workgroups > limits.maxComputeWorkgroupsPerDimension) {\n    throw new Error(\n      `Attention dispatch requires ${plan.workgroups} workgroups but device limit is ` +\n      `${limits.maxComputeWorkgroupsPerDimension}. Reduce prompt length or use streaming attention.`\n    );\n  }\n\n  if (indirectBuffer) {\n    dispatchIndirect(device, pipeline, bindGroup, indirectBuffer, indirectOffset, 'attention');\n  } else {\n    kernel.dispatch(pipeline, bindGroup, plan.workgroups);\n  }\n\n  releaseUniformBuffer(uniformBuffer);\n\n  return createTensor(outputBuf, outputDtype, [seqLen, numHeads, headDim], 'attention_output');\n}\n\n/**\n * Record attention operation (batched, no submit)\n */\nexport async function recordAttention(\n  recorder: CommandRecorder,\n  Q: Tensor,\n  K: Tensor,\n  V: Tensor,\n  mask: GPUBuffer | null,\n  numHeads: number,\n  headDim: number,\n  options: AttentionOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    seqLen = 1,\n    kvLen = seqLen,\n    numKVHeads = numHeads,\n    scale = 1.0 / Math.sqrt(headDim),\n    causal = true,\n    startPos = 0,\n    layerIdx,\n    outputBuffer = null,\n    attnSoftcap = 0,\n    slidingWindow = 0,\n    kvLenBuffer = null,\n    indirectBuffer = null,\n    indirectOffset = 0,\n  } = options;\n\n  const limits = getDeviceLimits();\n  const sharedLimit = limits?.maxComputeWorkgroupStorageSize ?? Infinity;\n  const caps = getKernelCapabilities();\n  const kvDtype: TensorDtype = K.dtype;\n  const plan = resolveAttentionPlan(\n    seqLen,\n    kvLen,\n    headDim,\n    numHeads,\n    kvDtype,\n    sharedLimit,\n    caps,\n    layerIdx\n  );\n\n  trace.attn(0, `recordAttention: isDecode=${plan.isDecode}, tier=${plan.tier}, variant=${plan.variant}, seqLen=${seqLen}, kvLen=${kvLen}, numHeads=${numHeads}, headDim=${headDim}, useF16KV=${plan.useF16KV}`);\n\n  const kernel = new AttentionKernel(device);\n  const pipeline = await kernel.getPipeline(plan.variant);\n\n  // Output is always f32 (attention scores computed in f32)\n  const outputDtype: TensorDtype = 'f32';\n  const outputSize = seqLen * numHeads * headDim * 4;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'attention_output');\n\n  const uniformBuffer = createAttentionUniformBuffer(device, recorder, {\n    numHeads,\n    numKVHeads,\n    headDim,\n    kvLen,\n    seqLen,\n    scale,\n    causal,\n    startPos,\n    attnSoftcap,\n    slidingWindow,\n    kvLenSource: kvLenBuffer ? 1 : 0,\n  });\n\n  const kvLenBinding = kvLenBuffer || getKvLenFallbackBuffer(device);\n  const bindGroup = device.createBindGroup({\n    label: 'attention_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: Q.buffer } },\n      { binding: 2, resource: { buffer: K.buffer } },\n      { binding: 3, resource: { buffer: V.buffer } },\n      { binding: 4, resource: { buffer: outputBuf } },\n      { binding: 5, resource: { buffer: kvLenBinding } },\n    ],\n  });\n\n  if (!indirectBuffer && limits && plan.workgroups > limits.maxComputeWorkgroupsPerDimension) {\n    throw new Error(\n      `Attention dispatch requires ${plan.workgroups} workgroups but device limit is ` +\n      `${limits.maxComputeWorkgroupsPerDimension}. Reduce prompt length or use streaming attention.`\n    );\n  }\n\n  if (indirectBuffer) {\n    recordDispatchIndirect(recorder, pipeline, bindGroup, indirectBuffer, indirectOffset, 'attention');\n  } else {\n    kernel.record(recorder, pipeline, bindGroup, plan.workgroups);\n  }\n\n  return createTensor(outputBuf, outputDtype, [seqLen, numHeads, headDim], 'attention_output');\n}\n", "/**\n * RMSNorm Kernels\n *\n * Provides RMS normalization with optional residual connection.\n */\n\nimport { getDevice, getKernelCapabilities } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { Tensor, createTensor } from '../tensor.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\nimport { getKernelThresholds } from '../../config/schema/index.js';\n\n/** RMSNorm kernel options */\nexport interface RMSNormOptions extends OutputBufferOptions {\n  batchSize?: number;\n  hiddenSize?: number | null;\n  residual?: Tensor | null;\n}\n\n/**\n * Check if F16 can be used based on tensor dtypes.\n * F16 shader requires F16 input, and F16 residual if present.\n */\nfunction canUseF16(input: Tensor, residual: Tensor | null): boolean {\n  if (input.dtype !== 'f16') return false;\n  if (residual && residual.dtype !== 'f16') return false;\n  return true;\n}\n\n/**\n * Select RMSNorm kernel variant based on options, tensor dtypes, and GPU capabilities.\n * Prefers subgroup-accelerated variants when available (3-5x faster reductions).\n */\nexport function selectRMSNormKernel(options: RMSNormOptions = {}, isF16: boolean = false): string {\n  const { residual = null, hiddenSize = null } = options;\n  const { smallThreshold } = getKernelThresholds().rmsnorm;\n\n  // Check if subgroups are available\n  const caps = getKernelCapabilities();\n  const hasSubgroups = caps?.hasSubgroups ?? false;\n\n  // F16 variants don't have subgroup support yet\n  if (isF16) {\n    if (hiddenSize !== null && hiddenSize <= smallThreshold) {\n      return 'small_f16';\n    }\n    return 'default_f16';\n  }\n\n  // Residual variants use the inplace_residual kernel (doesn't have subgroup variant yet)\n  if (residual) {\n    if (hiddenSize !== null && hiddenSize <= smallThreshold) {\n      return 'residual_small';\n    }\n    return 'residual';\n  }\n\n  // Prefer subgroup variants when available\n  if (hasSubgroups) {\n    if (hiddenSize !== null && hiddenSize <= smallThreshold) {\n      return 'small_subgroup';\n    }\n    return 'subgroup';\n  }\n\n  // Fallback to non-subgroup variants\n  if (hiddenSize !== null && hiddenSize <= smallThreshold) {\n    return 'small';\n  }\n  return 'default';\n}\n\n/**\n * Run RMSNorm\n */\nexport async function runRMSNorm(\n  input: Tensor,\n  weight: GPUBuffer,\n  eps: number = 1e-5,\n  options: RMSNormOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { batchSize = 1, hiddenSize, residual = null, outputBuffer = null } = options;\n\n  // Check if F16 can be used based on tensor dtypes\n  const isF16 = canUseF16(input, residual);\n  const variant = selectRMSNormKernel(options, isF16);\n  trace.kernels(`RMSNorm: input.dtype=${input.dtype}, isF16=${isF16}, variant=${variant}`);\n\n  if (residual) {\n    trace.kernels(`RMSNorm: Using residual variant, residual.size=${residual.buffer.size}, inferredHiddenSize=${hiddenSize || (weight.size / 4)}, batchSize=${batchSize}`);\n  }\n\n  const pipeline = await getPipelineFast('rmsnorm', variant);\n\n  // Create output buffer if not provided\n  // Weight buffer is always F32, so hidden size = weight.size / 4\n  const inferredHiddenSize = hiddenSize || (weight.size / 4);\n  const bytesPerElement = isF16 ? 2 : 4;\n  const outputSize = batchSize * inferredHiddenSize * bytesPerElement;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'rmsnorm_output');\n\n  // Create uniform buffer\n  const hasResidualFlag = residual ? 1 : 0;\n  const uniformBuffer = createUniformBufferWithView(\n    'rmsnorm_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredHiddenSize, true);\n      view.setUint32(4, batchSize, true);\n      view.setFloat32(8, eps, true);\n      view.setUint32(12, hasResidualFlag, true); // hasResidual flag\n    },\n    null,\n    device\n  );\n  if (hasResidualFlag) {\n    trace.kernels(`RMSNorm: Uniform hasResidual=${hasResidualFlag}, hiddenSize=${inferredHiddenSize}, batchSize=${batchSize}`);\n  }\n\n  // Shader expects 5 bindings - create placeholder when no residual (uniform flags it as unused)\n  const residualBuffer = residual?.buffer || device.createBuffer({\n    label: 'rmsnorm_residual_placeholder',\n    size: 4,\n    usage: GPUBufferUsage.STORAGE,\n  });\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'rmsnorm_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: weight } },\n      { binding: 3, resource: { buffer: outputBuf } },\n      { binding: 4, resource: { buffer: residualBuffer } },\n    ],\n  });\n\n  dispatch(device, pipeline, bindGroup, batchSize, 'rmsnorm');\n\n  uniformBuffer.destroy();\n  if (!residual) residualBuffer.destroy();\n\n  return createTensor(outputBuf, input.dtype, [batchSize, inferredHiddenSize], 'rmsnorm_output');\n}\n\n/**\n * Record RMSNorm (batched, no submit)\n */\nexport async function recordRMSNorm(\n  recorder: CommandRecorder,\n  input: Tensor,\n  weight: GPUBuffer,\n  eps: number = 1e-5,\n  options: RMSNormOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    batchSize = 1,\n    hiddenSize = null,\n    residual = null,\n    outputBuffer = null,\n  } = options;\n\n  // Infer hidden size from weight buffer (weight is always F32)\n  const inferredHiddenSize = hiddenSize || (weight.size / 4);\n\n  // Check if F16 can be used based on tensor dtypes\n  const isF16 = canUseF16(input, residual);\n  const variant = selectRMSNormKernel(options, isF16);\n  const bytesPerElement = isF16 ? 2 : 4;\n  const outputSize = batchSize * inferredHiddenSize * bytesPerElement;\n\n  const pipeline = await getPipelineFast('rmsnorm', variant);\n\n  // Output buffer\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'rmsnorm_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'rmsnorm_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredHiddenSize, true);\n      view.setUint32(4, batchSize, true);\n      view.setFloat32(8, eps, true);\n      view.setUint32(12, residual ? 1 : 0, true); // hasResidual flag\n    },\n    recorder\n  );\n\n  // Shader expects 5 bindings - create placeholder when no residual (uniform flags it as unused)\n  const residualBuffer = residual?.buffer || device.createBuffer({\n    label: 'rmsnorm_residual_placeholder',\n    size: 4,\n    usage: GPUBufferUsage.STORAGE,\n  });\n\n  // Bind group\n  const bindGroup = device.createBindGroup({\n    label: 'rmsnorm_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: weight } },\n      { binding: 3, resource: { buffer: outputBuf } },\n      { binding: 4, resource: { buffer: residualBuffer } },\n    ],\n  });\n\n  recordDispatch(recorder, pipeline, bindGroup, batchSize, 'rmsnorm');\n\n  // Track dummy buffer for cleanup if we created it\n  if (!residual) {\n    recorder.trackTemporaryBuffer(residualBuffer);\n  }\n\n  return createTensor(outputBuf, input.dtype, [batchSize, inferredHiddenSize], 'rmsnorm_output');\n}\n", "/**\n * Softmax Kernels\n *\n * Provides softmax operations with support for:\n * - Temperature scaling\n * - Top-K fused softmax (for MoE routing)\n */\n\nimport { getDevice, getKernelCapabilities } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { createTensor, type Tensor } from '../tensor.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { createPipeline, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\n\n/** Softmax kernel options */\nexport interface SoftmaxOptions extends OutputBufferOptions {\n  batchSize?: number;\n  size?: number | null;\n  seqLen?: number | null;\n  temperature?: number;\n  normalize?: boolean;\n}\n\n/** Threshold for \"small\" softmax variant (single element per thread) */\nconst SOFTMAX_SMALL_THRESHOLD = 256;\n\n/**\n * Select softmax kernel variant based on size and GPU capabilities.\n * Prefers subgroup-accelerated variants when available.\n */\nfunction selectSoftmaxVariant(innerSize: number): string {\n  const caps = getKernelCapabilities();\n  const hasSubgroups = caps?.hasSubgroups ?? false;\n\n  if (hasSubgroups) {\n    if (innerSize <= SOFTMAX_SMALL_THRESHOLD) {\n      return 'small_subgroup';\n    }\n    return 'subgroup';\n  }\n\n  if (innerSize <= SOFTMAX_SMALL_THRESHOLD) {\n    return 'small';\n  }\n  return 'default';\n}\n\n/**\n * Run softmax operation\n */\nexport async function runSoftmax(\n  input: Tensor,\n  axis: number,\n  options: SoftmaxOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { batchSize = 1, size, temperature = 1.0, outputBuffer = null } = options;\n\n  const bytesPerElement = input.dtype === 'f16' ? 2 : 4;\n  const inferredSize = size || (input.buffer.size / (batchSize * bytesPerElement));\n  const variant = selectSoftmaxVariant(inferredSize);\n  trace.kernels(`Softmax: size=${inferredSize}, variant=${variant}`);\n  const pipeline = await createPipeline('softmax', variant);\n\n  const outputSize = batchSize * inferredSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'softmax_output');\n\n  // Create uniform buffer\n  // WGSL struct: { innerSize: u32, outerSize: u32, temperature: f32, _pad: u32 }\n  const uniformBuffer = createUniformBufferWithView(\n    'softmax_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredSize, true);  // innerSize at offset 0\n      view.setUint32(4, batchSize, true);     // outerSize at offset 4\n      view.setFloat32(8, temperature, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'softmax_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  dispatch(device, pipeline, bindGroup, batchSize, 'softmax');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, input.dtype, [batchSize, inferredSize], 'softmax_output');\n}\n\n/**\n * Run fused softmax + top-K for MoE routing\n */\nexport async function runSoftmaxTopK(\n  logits: GPUBuffer,\n  numTokens: number,\n  numExperts: number,\n  topK: number,\n  options: SoftmaxOptions = {}\n): Promise<{ indices: GPUBuffer; weights: GPUBuffer }> {\n  const device = getDevice();\n  const { normalize = true } = options;\n\n  const pipeline = await createPipeline('topk', 'fused');\n\n  // Output buffers: indices [numTokens, topK] as u32, weights [numTokens, topK] as f32\n  const indicesSize = numTokens * topK * 4; // u32\n  const weightsSize = numTokens * topK * 4; // f32\n\n  const indices = acquireBuffer(indicesSize, undefined, 'softmax_topk_indices');\n  const weights = acquireBuffer(weightsSize, undefined, 'softmax_topk_weights');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'softmax_topk_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, numExperts, true);\n      view.setUint32(8, topK, true);\n      view.setUint32(12, normalize ? 1 : 0, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'softmax_topk_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n    ],\n  });\n\n  dispatch(device, pipeline, bindGroup, numTokens, 'softmax_topk');\n\n  uniformBuffer.destroy();\n\n  return { indices, weights };\n}\n\n/**\n * Record softmax (batched, no submit)\n */\nexport async function recordSoftmax(\n  recorder: CommandRecorder,\n  input: Tensor,\n  axis: number,\n  options: SoftmaxOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    batchSize = 1,\n    seqLen = null,\n    outputBuffer = null,\n  } = options;\n\n  const bytesPerElement = input.dtype === 'f16' ? 2 : 4;\n  const inferredSeqLen = seqLen || (input.buffer.size / (batchSize * bytesPerElement));\n  const pipeline = await createPipeline('softmax', 'default');\n\n  const outputSize = batchSize * inferredSeqLen * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'softmax_output');\n\n  // Uniform buffer\n  // WGSL struct: { innerSize: u32, outerSize: u32, temperature: f32, _pad: u32 }\n  const uniformBuffer = createUniformBufferWithView(\n    'softmax_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredSeqLen, true);  // innerSize at offset 0\n      view.setUint32(4, batchSize, true);       // outerSize at offset 4\n      view.setFloat32(8, 1.0, true);            // temperature (default 1.0)\n    },\n    recorder\n  );\n\n  // Bind group\n  const bindGroup = device.createBindGroup({\n    label: 'softmax_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  recordDispatch(recorder, pipeline, bindGroup, batchSize, 'softmax');\n\n  return createTensor(output, input.dtype, [batchSize, inferredSeqLen], 'softmax_output');\n}\n", "/**\n * RoPE (Rotary Position Embedding) Kernels\n *\n * Provides rotary position embedding with multiple variants:\n * - Standard RoPE\n * - NTK-scaled RoPE\n * - YaRN (Yet another RoPE extensioN)\n */\n\nimport { getDevice } from '../device.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { Tensor, createTensor } from '../tensor.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { getKernelThresholds } from '../../config/schema/index.js';\n\n// Get RoPE defaults from schema\nconst getRopeDefaults = () => getKernelThresholds().rope;\n\n/** RoPE kernel options */\nexport interface RoPEOptions extends OutputBufferOptions {\n  numHeads?: number;\n  headDim?: number;\n  ropeTheta?: number;\n  startPos?: number;\n}\n\n/**\n * Run RoPE operation\n */\nexport async function runRoPE(\n  input: Tensor,\n  freqsCos: GPUBuffer,\n  freqsSin: GPUBuffer,\n  seqLen: number,\n  options: RoPEOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const ropeDefaults = getRopeDefaults();\n  const {\n    numHeads = 1,\n    headDim = 64,\n    ropeTheta = ropeDefaults.defaultTheta,\n  } = options;\n\n  const pipeline = await getPipelineFast('rope', 'default');\n\n  // Note: RoPE shader modifies input in-place (no output buffer)\n\n  // Create uniform buffer (size from schema to match WGSL struct)\n  // struct RoPEUniforms { seqLen, numHeads, headDim, startPos, ropeBase, ropeScale, _pad0, _pad1 }\n  const uniformBuffer = createUniformBufferWithView(\n    'rope_uniforms',\n    ropeDefaults.uniformSize,\n    (view) => {\n      view.setUint32(0, seqLen, true);          // seqLen\n      view.setUint32(4, numHeads, true);        // numHeads\n      view.setUint32(8, headDim, true);         // headDim\n      view.setUint32(12, options.startPos || 0, true);  // startPos\n      view.setFloat32(16, ropeTheta, true);     // ropeBase\n      view.setFloat32(20, 1.0, true);           // ropeScale (default 1.0)\n    },\n    null,\n    device\n  );\n\n  // Create bind group (only 4 bindings - shader modifies input in-place)\n  const bindGroup = device.createBindGroup({\n    label: 'rope_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: freqsCos } },\n      { binding: 3, resource: { buffer: freqsSin } },\n    ],\n  });\n\n  // Dispatch\n  if (headDim % 2 !== 0) {\n    throw new Error(`RoPE headDim must be even, got ${headDim}`);\n  }\n  const halfDim = headDim / 2;\n  const workgroups = Math.ceil((seqLen * numHeads * halfDim) / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'rope');\n\n  uniformBuffer.destroy();\n\n  // Return tensor wrapping input buffer (modified in-place by shader)\n  return createTensor(input.buffer, input.dtype, [...input.shape], 'rope_output');\n}\n\n/**\n * Record RoPE (batched, no submit)\n */\nexport async function recordRoPE(\n  recorder: CommandRecorder,\n  input: Tensor,\n  freqsCos: GPUBuffer,\n  freqsSin: GPUBuffer,\n  seqLen: number,\n  options: RoPEOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const ropeDefaults = getRopeDefaults();\n  const {\n    numHeads = 1,\n    headDim = 64,\n    ropeTheta = ropeDefaults.defaultTheta,\n  } = options;\n\n  const pipeline = await getPipelineFast('rope', 'default');\n\n  // Note: RoPE shader modifies input in-place (no output buffer)\n\n  // Uniform buffer (size from schema to match WGSL struct)\n  // struct RoPEUniforms { seqLen, numHeads, headDim, startPos, ropeBase, ropeScale, _pad0, _pad1 }\n  const uniformBuffer = createUniformBufferWithView(\n    'rope_uniforms',\n    ropeDefaults.uniformSize,\n    (view) => {\n      view.setUint32(0, seqLen, true);          // seqLen\n      view.setUint32(4, numHeads, true);        // numHeads\n      view.setUint32(8, headDim, true);         // headDim\n      view.setUint32(12, options.startPos || 0, true);  // startPos\n      view.setFloat32(16, ropeTheta, true);     // ropeBase from options or schema default\n      view.setFloat32(20, 1.0, true);           // ropeScale (default 1.0)\n    },\n    recorder\n  );\n\n  // Bind group (only 4 bindings - shader modifies input in-place)\n  const bindGroup = device.createBindGroup({\n    label: 'rope_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: freqsCos } },\n      { binding: 3, resource: { buffer: freqsSin } },\n    ],\n  });\n\n  if (headDim % 2 !== 0) {\n    throw new Error(`RoPE headDim must be even, got ${headDim}`);\n  }\n  const halfDim = headDim / 2;\n  const workgroups = Math.ceil((seqLen * numHeads * halfDim) / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'rope');\n\n  // Return tensor wrapping input buffer (modified in-place by shader)\n  return createTensor(input.buffer, input.dtype, [...input.shape], 'rope_output');\n}\n", "/**\n * SiLU (Swish) Activation Kernels\n *\n * Provides SiLU activation with variants:\n * - Standard SiLU: x * sigmoid(x)\n * - SiLU with gating (for GLU layers)\n * - SwiGLU with row-split bias\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { Tensor, createTensor, type TensorDtype, dtypeBytes } from '../tensor.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\n\n// =============================================================================\n// SiLU Variant Lookup\n// =============================================================================\n\n/**\n * SiLU variant lookup table keyed by \"${base}/${f16}\".\n * Replaces string concatenation for F16 variant selection.\n */\nconst SILU_VARIANTS: Record<string, string> = {\n  'default/false': 'default',\n  'default/true': 'default_f16',\n  'vec4/false': 'vec4',\n  'vec4/true': 'vec4_f16',\n  'gate/false': 'gate',\n  'gate/true': 'gate_f16',\n  'gate_rowsplit/false': 'gate_rowsplit',\n  'gate_rowsplit/true': 'gate_rowsplit_f16',\n  'geglu_rowsplit/false': 'geglu_rowsplit',\n  'geglu_rowsplit/true': 'geglu_rowsplit_f16',\n};\n\n/**\n * Select SiLU variant based on base variant and F16 mode.\n */\nfunction selectSiLUVariant(base: string, isF16: boolean): string {\n  const key = `${base}/${isF16}`;\n  return SILU_VARIANTS[key] ?? base;\n}\n\n/**\n * Check if F16 can be used based on tensor dtype.\n */\nfunction canUseF16(input: Tensor): boolean {\n  return input.dtype === 'f16';\n}\n\n/**\n * Create bind group entries for SiLU, optionally adding gate binding.\n */\nfunction createSiLUBindGroupEntries(\n  uniformBuffer: GPUBuffer,\n  input: Tensor,\n  output: GPUBuffer,\n  gate: Tensor | null\n): GPUBindGroupEntry[] {\n  const entries: GPUBindGroupEntry[] = [\n    { binding: 0, resource: { buffer: uniformBuffer } },\n    { binding: 1, resource: { buffer: input.buffer } },\n    { binding: 2, resource: { buffer: output } },\n  ];\n  if (gate) {\n    entries.push({ binding: 3, resource: { buffer: gate.buffer } });\n  }\n  return entries;\n}\n\n/** SiLU kernel options */\nexport interface SiLUOptions extends OutputBufferOptions {\n  size?: number | null;\n  gate?: Tensor | null;\n  useVec4?: boolean;\n  biasOffset?: number;\n}\n\n/**\n * Run SiLU activation\n */\nexport async function runSiLU(\n  input: Tensor,\n  options: SiLUOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { size, gate = null, outputBuffer = null, useVec4 = false } = options;\n\n  const isF16 = canUseF16(input);\n  const bytesPerElement = dtypeBytes(input.dtype);\n\n  // Select variant using lookup table\n  const baseVariant = gate ? 'gate' : (useVec4 ? 'vec4' : 'default');\n  const variant = selectSiLUVariant(baseVariant, isF16);\n  const pipeline = await getPipelineFast('silu', variant);\n\n  const inferredSize = size || (input.buffer.size / bytesPerElement);\n  const outputSize = inferredSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'silu_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'silu_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredSize, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group using helper\n  const entries = createSiLUBindGroupEntries(uniformBuffer, input, output, gate);\n\n  const bindGroup = device.createBindGroup({\n    label: 'silu_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  const workgroups = Math.ceil(inferredSize / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'silu');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, input.dtype, [inferredSize], 'silu_output');\n}\n\n/**\n * Run SwiGLU with row-split bias\n */\nexport async function runSwiGLURowsplitBias(\n  input: Tensor,\n  bias: Tensor,\n  numTokens: number,\n  dim: number,\n  options: SiLUOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { outputBuffer = null, biasOffset = 0 } = options;\n\n  const pipeline = await getPipelineFast('swiglu', 'rowsplit_bias');\n\n  const bytesPerElement = dtypeBytes(input.dtype);\n  const outputSize = numTokens * dim * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'swiglu_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'swiglu_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, dim, true);\n      view.setUint32(8, biasOffset, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'swiglu_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: bias.buffer } },\n      { binding: 3, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil((numTokens * dim) / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'swiglu');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, input.dtype, [numTokens, dim], 'swiglu_output');\n}\n\n/**\n * Row-split SiLU options for fused gate+up FFN\n */\nexport interface SiLURowSplitOptions extends OutputBufferOptions {\n  numTokens: number;\n  dim: number;  // intermediateSize\n  activation?: 'silu' | 'gelu';\n}\n\n/**\n * Run row-split SiLU/GELU for fused gate+up FFN.\n *\n * Input: [numTokens, 2*dim] where each row is [gate[0..dim), up[0..dim)]\n * Output: [numTokens, dim] = activation(gate) * up\n */\nexport async function runSiLURowSplit(\n  input: Tensor,\n  options: SiLURowSplitOptions\n): Promise<Tensor> {\n  const device = getDevice();\n  const { numTokens, dim, activation = 'silu', outputBuffer = null } = options;\n\n  const isF16 = canUseF16(input);\n  const bytesPerElement = dtypeBytes(input.dtype);\n\n  // Select variant (append _f16 for F16 mode)\n  let variant = activation === 'gelu' ? 'geglu_rowsplit' : 'gate_rowsplit';\n  if (isF16) {\n    variant = variant + '_f16';\n  }\n  const pipeline = await getPipelineFast('silu', variant);\n\n  const outputSize = numTokens * dim * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'silu_rowsplit_output');\n\n  // Create uniform buffer\n  // size = output elements, hasBias = dim (repurposed for rowsplit)\n  const uniformBuffer = createUniformBufferWithView(\n    'silu_rowsplit_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens * dim, true);  // size\n      view.setUint32(4, dim, true);               // hasBias = dim\n      view.setUint32(8, 0, true);                 // hasGate (unused)\n    },\n    null,\n    device\n  );\n\n  // Create bind group - rowsplit only needs uniforms, input, and output (no gate binding)\n  const bindGroup = device.createBindGroup({\n    label: 'silu_rowsplit_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil((numTokens * dim) / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'silu_rowsplit');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, input.dtype, [numTokens, dim], 'silu_rowsplit_output');\n}\n\n/**\n * Record row-split SiLU/GELU (batched, no submit)\n */\nexport async function recordSiLURowSplit(\n  recorder: CommandRecorder,\n  input: Tensor,\n  options: SiLURowSplitOptions\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { numTokens, dim, activation = 'silu', outputBuffer = null } = options;\n\n  const isF16 = canUseF16(input);\n  const bytesPerElement = dtypeBytes(input.dtype);\n\n  // Select variant (append _f16 for F16 mode)\n  let variant = activation === 'gelu' ? 'geglu_rowsplit' : 'gate_rowsplit';\n  if (isF16) {\n    variant = variant + '_f16';\n  }\n  const pipeline = await getPipelineFast('silu', variant);\n\n  const outputSize = numTokens * dim * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'silu_rowsplit_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'silu_rowsplit_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens * dim, true);  // size\n      view.setUint32(4, dim, true);               // hasBias = dim\n    },\n    recorder\n  );\n\n  // Rowsplit only needs uniforms, input, and output (no gate binding)\n  const bindGroup = device.createBindGroup({\n    label: 'silu_rowsplit_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil((numTokens * dim) / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'silu_rowsplit');\n\n  return createTensor(output, input.dtype, [numTokens, dim], 'silu_rowsplit_output');\n}\n\n/**\n * Record SiLU (batched, no submit)\n * Supports gated variant when options.gate is provided.\n */\nexport async function recordSiLU(\n  recorder: CommandRecorder,\n  input: Tensor,\n  options: SiLUOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { size, gate = null, outputBuffer = null } = options;\n\n  const isF16 = canUseF16(input);\n  const bytesPerElement = dtypeBytes(input.dtype);\n\n  // Select variant using lookup table\n  const baseVariant = gate ? 'gate' : 'default';\n  const variant = selectSiLUVariant(baseVariant, isF16);\n  const pipeline = await getPipelineFast('silu', variant);\n\n  const inferredSize = size || (input.buffer.size / bytesPerElement);\n  const outputSize = inferredSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'silu_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'silu_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredSize, true);\n    },\n    recorder\n  );\n\n  // Create bind group using helper\n  const entries = createSiLUBindGroupEntries(uniformBuffer, input, output, gate);\n\n  const bindGroup = device.createBindGroup({\n    label: 'silu_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  const workgroups = Math.ceil(inferredSize / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'silu');\n\n  return createTensor(output, input.dtype, [inferredSize], 'silu_output');\n}\n", "/**\n * GeLU Activation Kernels\n *\n * Provides GeLU activation: x * Phi(x) where Phi is the CDF of standard normal distribution.\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { Tensor, createTensor, type TensorDtype, dtypeBytes } from '../tensor.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { createPipeline, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\n\n/**\n * Check if F16 can be used based on tensor dtype.\n */\nfunction canUseF16(input: Tensor): boolean {\n  return input.dtype === 'f16';\n}\n\n/** GeLU kernel options */\nexport interface GeLUOptions extends OutputBufferOptions {\n  size?: number | null;\n  gate?: Tensor | null;\n}\n\n/**\n * Run GeLU activation\n */\nexport async function runGeLU(\n  input: Tensor,\n  options: GeLUOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { size, gate = null, outputBuffer = null } = options;\n\n  const isF16 = canUseF16(input);\n  const bytesPerElement = dtypeBytes(input.dtype);\n\n  // Select gated variant when gate buffer is provided\n  // Use F16 variants when dtype is 'f16' (geglu_rowsplit_f16 in silu_f16.wgsl)\n  let variant: string;\n  if (gate) {\n    variant = isF16 ? 'geglu_rowsplit_f16' : 'geglu';\n  } else {\n    variant = 'gelu';  // No F16 gelu (non-gated) variant - use F32\n  }\n  const pipeline = await createPipeline('silu', variant);\n\n  const inferredSize = size || (input.buffer.size / bytesPerElement);\n  const outputSize = inferredSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'gelu_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'gelu_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredSize, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  // WGSL bindings: 0=uniforms, 1=input, 2=output, 3=gate, 4=bias\n  const gateBuffer = gate ? gate.buffer : input.buffer;\n  const bindGroup = device.createBindGroup({\n    label: 'gelu_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n      { binding: 3, resource: { buffer: gateBuffer } },\n    ],\n  });\n\n  const workgroups = Math.ceil(inferredSize / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'gelu');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, input.dtype, [inferredSize], 'gelu_output');\n}\n\n/**\n * Record GeLU (batched, no submit)\n * Supports gated variant (GeGLU) when options.gate is provided.\n */\nexport async function recordGeLU(\n  recorder: CommandRecorder,\n  input: Tensor,\n  options: GeLUOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { size, gate = null, outputBuffer = null } = options;\n\n  const isF16 = canUseF16(input);\n  const bytesPerElement = dtypeBytes(input.dtype);\n\n  // Select gated variant when gate buffer is provided\n  // Use F16 variants when dtype is 'f16' (geglu_rowsplit_f16 in silu_f16.wgsl)\n  let variant: string;\n  if (gate) {\n    variant = isF16 ? 'geglu_rowsplit_f16' : 'geglu';\n  } else {\n    variant = 'gelu';  // No F16 gelu (non-gated) variant - use F32\n  }\n  const pipeline = await createPipeline('silu', variant);\n\n  const inferredSize = size || (input.buffer.size / bytesPerElement);\n  const outputSize = inferredSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'gelu_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'gelu_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredSize, true);\n    },\n    recorder\n  );\n\n  // Bind group entries - gate variant needs binding 3\n  const entries: GPUBindGroupEntry[] = [\n    { binding: 0, resource: { buffer: uniformBuffer } },\n    { binding: 1, resource: { buffer: input.buffer } },\n    { binding: 2, resource: { buffer: output } },\n  ];\n\n  // Add gate binding for gated variant\n  if (gate) {\n    entries.push({ binding: 3, resource: { buffer: gate.buffer } });\n  }\n\n  const bindGroup = device.createBindGroup({\n    label: 'gelu_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  const workgroups = Math.ceil(inferredSize / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'gelu');\n\n  return createTensor(output, input.dtype, [inferredSize], 'gelu_output');\n}\n", "/**\n * Scale kernel - multiply each element by a scalar factor\n * Used for embedding scaling in Gemma models (sqrt(hidden_size))\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { createTensor, dtypeBytes } from '../tensor.js';\nimport type { Tensor } from '../tensor.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { createPipeline, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\n\n/** Scale kernel options */\nexport interface ScaleOptions extends OutputBufferOptions {\n  /** Number of elements to scale (inferred from buffer size if not provided) */\n  count?: number;\n  /** Whether to scale in-place (output = input) */\n  inplace?: boolean;\n}\n\n/**\n * Run scale operation: output = input * scale\n */\nexport async function runScale(\n  input: Tensor,\n  scale: number,\n  options: ScaleOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { count, outputBuffer = null, inplace = false } = options;\n\n  const bytesPerElement = dtypeBytes(input.dtype);\n  const inferredCount = count ?? Math.floor(input.buffer.size / bytesPerElement);\n  const variant = inplace ? 'inplace' : 'default';\n  const pipeline = await createPipeline('scale', variant);\n\n  const outputSize = inferredCount * bytesPerElement;\n  const outputBuf = inplace ? input.buffer : (outputBuffer || acquireBuffer(outputSize, undefined, 'scale_output'));\n\n  // Create uniform buffer (16 bytes to match WGSL struct with padding)\n  const uniformBuffer = createUniformBufferWithView(\n    'scale_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredCount, true);\n      view.setFloat32(4, scale, true);\n      // _pad0 and _pad1 at offsets 8 and 12 (unused)\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'scale_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: outputBuf } },\n    ],\n  });\n\n  const workgroups = Math.ceil(inferredCount / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'scale');\n\n  uniformBuffer.destroy();\n\n  return createTensor(outputBuf, input.dtype, [...input.shape], 'scale_output');\n}\n\n/**\n * Record scale operation (batched, no submit)\n */\nexport async function recordScale(\n  recorder: CommandRecorder,\n  input: Tensor,\n  scale: number,\n  options: ScaleOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { count, outputBuffer = null, inplace = false } = options;\n\n  const bytesPerElement = dtypeBytes(input.dtype);\n  const inferredCount = count ?? Math.floor(input.buffer.size / bytesPerElement);\n  const variant = inplace ? 'inplace' : 'default';\n  const pipeline = await createPipeline('scale', variant);\n\n  const outputSize = inferredCount * bytesPerElement;\n  const outputBuf = inplace ? input.buffer : (outputBuffer || acquireBuffer(outputSize, undefined, 'scale_output'));\n\n  // Create uniform buffer via recorder (tracked for cleanup, 16 bytes to match WGSL)\n  const uniformBuffer = createUniformBufferWithView(\n    'scale_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, inferredCount, true);\n      view.setFloat32(4, scale, true);\n      // _pad0 and _pad1 at offsets 8 and 12 (unused)\n    },\n    recorder\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'scale_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: outputBuf } },\n    ],\n  });\n\n  const workgroups = Math.ceil(inferredCount / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'scale');\n\n  return createTensor(outputBuf, input.dtype, [...input.shape], 'scale_output');\n}\n", "/**\n * Gather (Embedding Lookup) Kernels\n *\n * Provides token embedding lookups from embedding tables.\n */\n\nimport { getDevice, getKernelCapabilities } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { WORKGROUP_SIZES, VEC4_ELEMENTS_PER_WG } from './constants.js';\nimport { dispatch, dispatchIndirect, recordDispatch, recordDispatchIndirect } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView, getKernelConfig } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\nimport { createTensor, type Tensor, type TensorDtype } from '../tensor.js';\nimport { DTYPE_SIZES } from '../../config/schema/index.js';\n\n// =============================================================================\n// Variant Lookup Table\n// =============================================================================\n\n/**\n * Gather variant lookup table keyed by \"${f16In}/${f16Out}/${vec4}\".\n * Replaces if-else chain for variant selection.\n */\nconst GATHER_VARIANTS: Record<string, string> = {\n  'false/false/false': 'default',\n  'false/false/true': 'vec4',\n  'true/false/false': 'f16',\n  'true/false/true': 'f16_vec4',\n  'false/true/false': 'f16_out',\n  'false/true/true': 'vec4_f16_out',\n  'true/true/false': 'f16_f16_out',\n  'true/true/true': 'f16_vec4_f16_out',\n};\n\n/**\n * Select gather variant based on input/output dtype and vec4 preference.\n */\nfunction selectGatherVariant(useF16Input: boolean, useF16Output: boolean, useVec4: boolean): string {\n  const key = `${useF16Input}/${useF16Output}/${useVec4}`;\n  const variant = GATHER_VARIANTS[key];\n  if (!variant) {\n    throw new Error(`Unknown gather variant combination: ${key}`);\n  }\n  return variant;\n}\n\n/**\n * Get output binding index from kernel config, falling back to 3 for F32 output.\n */\nfunction getOutputBinding(variant: string, useF16Output: boolean): number {\n  if (!useF16Output) {\n    return 3; // F32 output always uses binding 3\n  }\n  const config = getKernelConfig('gather', variant);\n  return config.variantMetadata?.outputBinding ?? 4;\n}\n\n/** Gather kernel options */\nexport interface GatherOptions extends OutputBufferOptions {\n  useVec4?: boolean;\n  embeddingDtype?: 'f16' | 'f32';  // Override auto-detection for input embeddings\n  /**\n   * Output dtype. When 'f16', converts F32 embeddings to F16 output.\n   * Used for F16 activation mode to reduce memory bandwidth.\n   * Default: 'f32'\n   */\n  outputDtype?: 'f16' | 'f32';\n  /**\n   * True if embeddings are stored as [hidden_size, vocab_size] (GGUF layout).\n   * False if embeddings are stored as [vocab_size, hidden_size] (PyTorch layout).\n   * Default: false (RDRR format uses PyTorch layout from SafeTensors).\n   */\n  transpose?: boolean;\n  /** Optional indirect dispatch buffer for GPU-driven workgroup counts. */\n  indirectBuffer?: GPUBuffer | null;\n  /** Byte offset into indirect dispatch buffer (default: 0). */\n  indirectOffset?: number;\n}\n\n/**\n * Run gather/embedding lookup\n * Automatically detects F16 embeddings and uses optimized kernel\n * Returns Tensor with explicit dtype for type-safe pipeline.\n */\nexport async function runGather(\n  indices: GPUBuffer,\n  embeddings: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  vocabSize: number,\n  options: GatherOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    useVec4 = true,\n    outputBuffer = null,\n    embeddingDtype,\n    outputDtype = 'f32',\n    transpose = false,\n    indirectBuffer = null,\n    indirectOffset = 0,\n  } = options;\n\n  // Detect embedding dtype (F16 embeddings enable optimized lm_head)\n  const caps = getKernelCapabilities();\n  const detectedDtype = embeddingDtype || 'f32';\n  const useF16Input = detectedDtype === 'f16' && caps.hasF16;\n  const useF16Output = outputDtype === 'f16' && caps.hasF16;\n  trace.embed(`Gather: numTokens=${numTokens}, hiddenSize=${hiddenSize}, vocabSize=${vocabSize}, transpose=${transpose}, detectedDtype=${detectedDtype}, useF16Input=${useF16Input}, useF16Output=${useF16Output}`);\n\n  // Select kernel variant using lookup table\n  const variant = selectGatherVariant(useF16Input, useF16Output, useVec4);\n  trace.embed(`Gather variant: ${variant}`);\n  const pipeline = await getPipelineFast('gather', variant);\n\n  // Calculate output size using DTYPE_SIZES\n  const outputDtypeKey = useF16Output ? 'f16' : 'f32';\n  const bytesPerElement = DTYPE_SIZES[outputDtypeKey];\n  const outputSize = numTokens * hiddenSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'gather_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'gather_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, vocabSize, true);\n      view.setUint32(12, transpose ? 1 : 0, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group - output binding from kernel config\n  const outputBinding = getOutputBinding(variant, useF16Output);\n  const entries: GPUBindGroupEntry[] = [\n    { binding: 0, resource: { buffer: uniformBuffer } },\n    { binding: 1, resource: { buffer: indices } },\n    { binding: 2, resource: { buffer: embeddings } },\n    { binding: outputBinding, resource: { buffer: output } },\n  ];\n  const bindGroup = device.createBindGroup({\n    label: 'gather_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  // gather.wgsl uses @workgroup_size(256); gather_vec4.wgsl uses @workgroup_size(64)\n  // vec4 variant: 64 threads \u00D7 4 floats = 256 floats per workgroup\n  const workgroups = useVec4\n    ? Math.ceil((numTokens * hiddenSize) / VEC4_ELEMENTS_PER_WG)\n    : Math.ceil((numTokens * hiddenSize) / WORKGROUP_SIZES.DEFAULT);\n  if (indirectBuffer) {\n    dispatchIndirect(device, pipeline, bindGroup, indirectBuffer, indirectOffset, 'gather');\n  } else {\n    dispatch(device, pipeline, bindGroup, workgroups, 'gather');\n  }\n\n  uniformBuffer.destroy();\n\n  const actualDtype: TensorDtype = useF16Output ? 'f16' : 'f32';\n  return createTensor(output, actualDtype, [numTokens, hiddenSize], 'gather_output');\n}\n\n/**\n * Record gather (batched, no submit)\n * Returns Tensor with explicit dtype for type-safe pipeline.\n */\nexport async function recordGather(\n  recorder: CommandRecorder,\n  indices: GPUBuffer,\n  embeddings: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  vocabSize: number,\n  options: GatherOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    useVec4 = true,\n    outputBuffer = null,\n    embeddingDtype,\n    outputDtype = 'f32',\n    transpose = false,\n    indirectBuffer = null,\n    indirectOffset = 0,\n  } = options;\n\n  // Detect embedding dtype (same logic as runGather)\n  const caps = getKernelCapabilities();\n  const detectedDtype = embeddingDtype || 'f32';\n  const useF16Input = detectedDtype === 'f16' && caps.hasF16;\n  const useF16Output = outputDtype === 'f16' && caps.hasF16;\n\n  // Select kernel variant using lookup table\n  const variant = selectGatherVariant(useF16Input, useF16Output, useVec4);\n  trace.embed(`Gather variant: ${variant}`);\n  const pipeline = await getPipelineFast('gather', variant);\n\n  // Calculate output size using DTYPE_SIZES\n  const outputDtypeKey = useF16Output ? 'f16' : 'f32';\n  const bytesPerElement = DTYPE_SIZES[outputDtypeKey];\n  const outputSize = numTokens * hiddenSize * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'gather_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'gather_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, vocabSize, true);\n      view.setUint32(12, transpose ? 1 : 0, true);\n    },\n    recorder\n  );\n\n  // Create bind group - output binding from kernel config\n  const outputBinding = getOutputBinding(variant, useF16Output);\n  const entries: GPUBindGroupEntry[] = [\n    { binding: 0, resource: { buffer: uniformBuffer } },\n    { binding: 1, resource: { buffer: indices } },\n    { binding: 2, resource: { buffer: embeddings } },\n    { binding: outputBinding, resource: { buffer: output } },\n  ];\n  const bindGroup = device.createBindGroup({\n    label: 'gather_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries,\n  });\n\n  // gather.wgsl uses @workgroup_size(256); gather_vec4.wgsl uses @workgroup_size(64)\n  // vec4 variant: 64 threads \u00D7 4 floats = 256 floats per workgroup\n  const workgroups = useVec4\n    ? Math.ceil((numTokens * hiddenSize) / VEC4_ELEMENTS_PER_WG)\n    : Math.ceil((numTokens * hiddenSize) / WORKGROUP_SIZES.DEFAULT);\n  if (indirectBuffer) {\n    recordDispatchIndirect(recorder, pipeline, bindGroup, indirectBuffer, indirectOffset, 'gather');\n  } else {\n    recordDispatch(recorder, pipeline, bindGroup, workgroups, 'gather');\n  }\n\n  const actualDtype: TensorDtype = useF16Output ? 'f16' : 'f32';\n  return createTensor(output, actualDtype, [numTokens, hiddenSize], 'gather_output');\n}\n", "/**\n * Residual Connection Kernels\n *\n * Provides element-wise addition operations for:\n * - Residual connections (add two tensors)\n * - Bias addition\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer, releaseBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { Tensor, createTensor, inferOutputDtype, dtypeBytes } from '../tensor.js';\nimport { WORKGROUP_SIZES, VEC4_ELEMENTS_PER_WG } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { castF16ToF32, castF32ToF16, recordCastF16ToF32, recordCastF32ToF16 } from './cast.js';\n\n/** Residual kernel options */\nexport interface ResidualOptions extends OutputBufferOptions {\n  useVec4?: boolean;\n  dataOffset?: number;\n  biasOffset?: number;\n}\n\nasync function alignResidualInputs(\n  a: Tensor,\n  b: Tensor,\n  recorder?: CommandRecorder\n): Promise<{ a: Tensor; b: Tensor; temps: GPUBuffer[] }> {\n  if (a.dtype === b.dtype) {\n    return { a, b, temps: [] };\n  }\n\n  if (a.dtype === 'f16' && b.dtype === 'f32') {\n    const casted = recorder ? await recordCastF16ToF32(recorder, a) : await castF16ToF32(a);\n    return { a: casted, b, temps: [casted.buffer] };\n  }\n\n  if (a.dtype === 'f32' && b.dtype === 'f16') {\n    const casted = recorder ? await recordCastF16ToF32(recorder, b) : await castF16ToF32(b);\n    return { a, b: casted, temps: [casted.buffer] };\n  }\n\n  return { a, b, temps: [] };\n}\n\nasync function alignBiasTensor(\n  data: Tensor,\n  bias: Tensor,\n  recorder?: CommandRecorder\n): Promise<{ bias: Tensor; temps: GPUBuffer[] }> {\n  if (data.dtype === bias.dtype) {\n    return { bias, temps: [] };\n  }\n\n  if (data.dtype === 'f16' && bias.dtype === 'f32') {\n    const casted = recorder ? await recordCastF32ToF16(recorder, bias) : await castF32ToF16(bias);\n    return { bias: casted, temps: [casted.buffer] };\n  }\n\n  if (data.dtype === 'f32' && bias.dtype === 'f16') {\n    const casted = recorder ? await recordCastF16ToF32(recorder, bias) : await castF16ToF32(bias);\n    return { bias: casted, temps: [casted.buffer] };\n  }\n\n  return { bias, temps: [] };\n}\n\n/**\n * Run residual add (element-wise addition)\n */\nexport async function runResidualAdd(\n  a: Tensor,\n  b: Tensor,\n  size: number,\n  options: ResidualOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { useVec4 = true, outputBuffer = null } = options;\n\n  const { a: aAligned, b: bAligned, temps } = await alignResidualInputs(a, b);\n  const outputDtype = inferOutputDtype(aAligned, bAligned);\n  const bytesPerElement = dtypeBytes(outputDtype);\n\n  const variant = useVec4\n    ? (outputDtype === 'f16' ? 'vec4_f16' : 'vec4')\n    : (outputDtype === 'f16' ? 'default_f16' : 'default');\n  const pipeline = await getPipelineFast('residual', variant);\n\n  const outputSize = size * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'residual_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'residual_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, size, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'residual_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: aAligned.buffer } },\n      { binding: 2, resource: { buffer: bAligned.buffer } },\n      { binding: 3, resource: { buffer: output } },\n    ],\n  });\n\n  // residual.wgsl: main uses @workgroup_size(256), add_vec4 uses @workgroup_size(64)\n  // vec4 variant: 64 threads \u00D7 4 elements = 256 elements per workgroup\n  const workgroups = useVec4\n    ? Math.ceil(size / VEC4_ELEMENTS_PER_WG)\n    : Math.ceil(size / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'residual');\n\n  uniformBuffer.destroy();\n\n  for (const temp of temps) {\n    releaseBuffer(temp);\n  }\n\n  return createTensor(output, outputDtype, [size], 'residual_output');\n}\n\n/**\n * Run bias add\n */\nexport async function runBiasAdd(\n  data: Tensor,\n  bias: Tensor,\n  numTokens: number,\n  dim: number,\n  options: ResidualOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { dataOffset = 0, biasOffset = 0 } = options;\n\n  const { bias: biasAligned, temps } = await alignBiasTensor(data, bias);\n  const variant = data.dtype === 'f16' && biasAligned.dtype === 'f16' ? 'f16' : 'default';\n  const pipeline = await getPipelineFast('bias_add', variant);\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'bias_add_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, dim, true);\n      view.setUint32(8, dataOffset, true);\n      view.setUint32(12, biasOffset, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'bias_add_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: data.buffer } },\n      { binding: 2, resource: { buffer: biasAligned.buffer } },\n    ],\n  });\n\n  const workgroups = Math.ceil((numTokens * dim) / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'bias_add');\n\n  uniformBuffer.destroy();\n\n  for (const temp of temps) {\n    releaseBuffer(temp);\n  }\n\n  // Bias add is in-place, return tensor with same buffer\n  return createTensor(data.buffer, data.dtype, [numTokens, dim], 'bias_add_output');\n}\n\n/**\n * Record residual add (batched, no submit)\n */\nexport async function recordResidualAdd(\n  recorder: CommandRecorder,\n  a: Tensor,\n  b: Tensor,\n  size: number,\n  options: ResidualOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { outputBuffer = null, useVec4 = true } = options;\n\n  const { a: aAligned, b: bAligned, temps } = await alignResidualInputs(a, b, recorder);\n  const outputDtype = inferOutputDtype(aAligned, bAligned);\n  const bytesPerElement = dtypeBytes(outputDtype);\n\n  const variant = useVec4\n    ? (outputDtype === 'f16' ? 'vec4_f16' : 'vec4')\n    : (outputDtype === 'f16' ? 'default_f16' : 'default');\n  const pipeline = await getPipelineFast('residual', variant);\n\n  const outputSize = size * bytesPerElement;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'residual_output');\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'residual_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, size, true);\n    },\n    recorder\n  );\n\n  // Bind group\n  const bindGroup = device.createBindGroup({\n    label: 'residual_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: aAligned.buffer } },\n      { binding: 2, resource: { buffer: bAligned.buffer } },\n      { binding: 3, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = useVec4\n    ? Math.ceil(size / VEC4_ELEMENTS_PER_WG)\n    : Math.ceil(size / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'residual');\n\n  for (const temp of temps) {\n    recorder.trackTemporaryBuffer(temp);\n  }\n\n  return createTensor(output, outputDtype, [size], 'residual_output');\n}\n\n/**\n * Record bias add (batched, no submit)\n */\nexport async function recordBiasAdd(\n  recorder: CommandRecorder,\n  data: Tensor,\n  bias: Tensor,\n  numTokens: number,\n  dim: number,\n  options: ResidualOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { dataOffset = 0, biasOffset = 0 } = options;\n\n  const { bias: biasAligned, temps } = await alignBiasTensor(data, bias, recorder);\n  const variant = data.dtype === 'f16' && biasAligned.dtype === 'f16' ? 'f16' : 'default';\n  const pipeline = await getPipelineFast('bias_add', variant);\n\n  // Uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'bias_add_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, dim, true);\n      view.setUint32(8, dataOffset, true);\n      view.setUint32(12, biasOffset, true);\n    },\n    recorder\n  );\n\n  // Bind group\n  const bindGroup = device.createBindGroup({\n    label: 'bias_add_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: data.buffer } },\n      { binding: 2, resource: { buffer: biasAligned.buffer } },\n    ],\n  });\n\n  const workgroups = Math.ceil((numTokens * dim) / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'bias_add');\n\n  for (const temp of temps) {\n    recorder.trackTemporaryBuffer(temp);\n  }\n\n  // Bias add is in-place, return tensor with same buffer\n  return createTensor(data.buffer, data.dtype, [numTokens, dim], 'bias_add_output');\n}\n", "/**\n * Type Casting Kernels\n *\n * Provides GPU-based type conversions:\n * - F32 to F16\n * - F16 to F32\n * - BF16 to F32\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { createTensor, Tensor } from '../tensor.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { createPipeline, createUniformBufferWithView } from './utils.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { GPU_LIMITS, WORKGROUP_SIZES } from './constants.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\nimport { DTYPE_SIZES } from '../../config/schema/index.js';\n\n// =============================================================================\n// Dispatch Helpers\n// =============================================================================\n\n/**\n * Calculate 2D dispatch for large workgroup counts.\n * WebGPU has a limit of 65535 workgroups per dimension.\n */\nfunction calculate2DDispatch(workgroups: number): [number, number, number] {\n  const maxWorkgroupsPerDim = GPU_LIMITS.MAX_WORKGROUPS;\n  return workgroups <= maxWorkgroupsPerDim\n    ? [workgroups, 1, 1]\n    : [maxWorkgroupsPerDim, Math.ceil(workgroups / maxWorkgroupsPerDim), 1];\n}\n\n/**\n * LCM utility for alignment calculations.\n */\nfunction lcm(a: number, b: number): number {\n  const gcd = (x: number, y: number): number => {\n    let a0 = x;\n    let b0 = y;\n    while (b0 !== 0) {\n      const t = b0;\n      b0 = a0 % b0;\n      a0 = t;\n    }\n    return a0;\n  };\n  return (a / gcd(a, b)) * b;\n}\n\n/** Cast kernel options */\nexport interface CastOptions extends OutputBufferOptions {}\n\n/**\n * Cast F32 buffer to F16 on GPU\n */\nexport async function castF32ToF16(\n  input: Tensor,\n  options: CastOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { outputBuffer = null } = options;\n  const numElements = input.shape.reduce((a, b) => a * b, 1);\n\n  const pipeline = await createPipeline('cast', 'f32_to_f16');\n\n  const outputSize = numElements * DTYPE_SIZES.f16;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'cast_f32_to_f16_output');\n\n  const uniformBuffer = createUniformBufferWithView(\n    'cast_f32_to_f16_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numElements, true);\n    },\n    null,\n    device\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'cast_f32_to_f16_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  // Use 2D dispatch for large tensors (like embeddings with 300M+ elements)\n  const workgroups = Math.ceil(numElements / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize = calculate2DDispatch(workgroups);\n\n  dispatch(device, pipeline, bindGroup, dispatchSize, 'cast_f32_to_f16');\n\n  // Wait for GPU work to complete before returning\n  // Critical for large tensors (embeddings/lm_head) that may take time to convert\n  await device.queue.onSubmittedWorkDone();\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, 'f16', [...input.shape], input.label ? `${input.label}_f16` : 'cast_f32_to_f16_output');\n}\n\n/**\n * Cast F16 buffer to F32 on GPU\n */\nexport async function castF16ToF32(\n  input: Tensor,\n  options: CastOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { outputBuffer = null } = options;\n  const numElements = input.shape.reduce((a, b) => a * b, 1);\n\n  const pipeline = await createPipeline('cast', 'f16_to_f32');\n\n  const outputSize = numElements * DTYPE_SIZES.f32;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'cast_f16_to_f32_output');\n\n  const uniformBuffer = createUniformBufferWithView(\n    'cast_f16_to_f32_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numElements, true);\n    },\n    null,\n    device\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'cast_f16_to_f32_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil(numElements / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize = calculate2DDispatch(workgroups);\n\n  dispatch(device, pipeline, bindGroup, dispatchSize, 'cast_f16_to_f32');\n\n  await device.queue.onSubmittedWorkDone();\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, 'f32', [...input.shape], input.label ? `${input.label}_f32` : 'cast_f16_to_f32_output');\n}\n\n/**\n * Record F32 to F16 cast (batched, no submit)\n */\nexport async function recordCastF32ToF16(\n  recorder: CommandRecorder,\n  input: Tensor,\n  options: CastOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { outputBuffer = null } = options;\n  const numElements = input.shape.reduce((a, b) => a * b, 1);\n\n  const pipeline = await createPipeline('cast', 'f32_to_f16');\n\n  const outputSize = numElements * DTYPE_SIZES.f16;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'cast_f32_to_f16_output');\n\n  const uniformBuffer = createUniformBufferWithView(\n    'cast_f32_to_f16_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numElements, true);\n    },\n    recorder\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'cast_f32_to_f16_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  // Use 2D dispatch for large tensors\n  const workgroups = Math.ceil(numElements / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize = calculate2DDispatch(workgroups);\n\n  recordDispatch(recorder, pipeline, bindGroup, dispatchSize, 'cast_f32_to_f16');\n\n  return createTensor(output, 'f16', [...input.shape], input.label ? `${input.label}_f16` : 'cast_f32_to_f16_output');\n}\n\n/**\n * Record F16 to F32 cast (batched, no submit)\n */\nexport async function recordCastF16ToF32(\n  recorder: CommandRecorder,\n  input: Tensor,\n  options: CastOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { outputBuffer = null } = options;\n  const numElements = input.shape.reduce((a, b) => a * b, 1);\n\n  const pipeline = await createPipeline('cast', 'f16_to_f32');\n\n  const outputSize = numElements * DTYPE_SIZES.f32;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'cast_f16_to_f32_output');\n\n  const uniformBuffer = createUniformBufferWithView(\n    'cast_f16_to_f32_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numElements, true);\n    },\n    recorder\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'cast_f16_to_f32_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const workgroups = Math.ceil(numElements / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize = calculate2DDispatch(workgroups);\n\n  recordDispatch(recorder, pipeline, bindGroup, dispatchSize, 'cast_f16_to_f32');\n\n  return createTensor(output, 'f32', [...input.shape], input.label ? `${input.label}_f32` : 'cast_f16_to_f32_output');\n}\n\n/**\n * Convert BF16 buffer to F32 on GPU\n */\nexport async function runBF16ToF32(\n  input: GPUBuffer,\n  shape: readonly number[],\n  name: string = 'bf16_to_f32_output'\n): Promise<Tensor> {\n  const numElements = shape.reduce((a, b) => a * b, 1);\n  trace.kernels(`BF16ToF32: Entry numElements=${numElements}, name=${name}, inputSize=${input.size}`);\n  const device = getDevice();\n\n  // Check for size limits (handle chunking if needed)\n  const limits = device.limits;\n  const maxBufferSize = limits.maxBufferSize;\n  const maxBindingSize = limits.maxStorageBufferBindingSize;\n  const outputSize = numElements * DTYPE_SIZES.f32;\n  trace.kernels(`BF16ToF32: outputSize=${outputSize}, maxBufferSize=${maxBufferSize}, maxBindingSize=${maxBindingSize}`);\n\n  if (outputSize > maxBufferSize) {\n    throw new Error(\n      `BF16\u2192F32 output (${outputSize} bytes) exceeds device maxBufferSize (${maxBufferSize}). ` +\n      `This often happens for large-vocab models when converting embeddings/LM head. ` +\n      `Enable F16 and use BF16\u2192F16 weights, or run on a device with a higher maxBufferSize.`\n    );\n  }\n\n  if (outputSize > maxBindingSize) {\n    // Need to chunk - output buffer can exist, but must be bound in smaller ranges.\n    return runBF16ToF32Chunked(input, shape, name, maxBindingSize);\n  }\n\n  const pipeline = await createPipeline('bf16_to_f32', 'default');\n  trace.kernels('BF16ToF32: Pipeline created');\n\n  const output = acquireBuffer(outputSize, undefined, name);\n  trace.kernels(`BF16ToF32: Output buffer acquired, size=${output.size}`);\n\n  const uniformBuffer = createUniformBufferWithView(\n    'bf16_to_f32_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numElements, true);\n    },\n    null,\n    device\n  );\n  trace.kernels(`BF16ToF32: Uniform numElements=${numElements}`);\n\n  const bindGroup = device.createBindGroup({\n    label: 'bf16_to_f32_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n  trace.kernels('BF16ToF32: BindGroup created');\n\n  // Each thread processes 2 BF16 values (1 u32), so divide by 2 for thread count\n  // Then divide by 256 for workgroup count\n  const numPairs = Math.ceil(numElements / 2);\n  const workgroups = Math.ceil(numPairs / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize = calculate2DDispatch(workgroups);\n\n  trace.kernels(`BF16ToF32: Dispatching ${dispatchSize[0]}x${dispatchSize[1]} workgroups for ${numPairs} pairs (${numElements} elements)`);\n  dispatch(device, pipeline, bindGroup, dispatchSize, 'bf16_to_f32');\n\n  // Wait for GPU work to complete before returning\n  await device.queue.onSubmittedWorkDone();\n  trace.kernels('BF16ToF32: GPU work completed');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, 'f32', [...shape], name);\n}\n\n/**\n * Convert BF16 buffer to F16 on GPU (no intermediate F32 buffer)\n */\nexport async function runBF16ToF16(\n  input: GPUBuffer,\n  shape: readonly number[],\n  name: string = 'bf16_to_f16_output'\n): Promise<Tensor> {\n  const numElements = shape.reduce((a, b) => a * b, 1);\n  const device = getDevice();\n  const pipeline = await createPipeline('bf16_to_f16', 'default');\n\n  const limits = device.limits;\n  const maxBufferSize = limits.maxBufferSize;\n  const maxBindingSize = limits.maxStorageBufferBindingSize;\n  const outputSize = numElements * DTYPE_SIZES.f16;\n\n  if (outputSize > maxBufferSize) {\n    throw new Error(\n      `BF16\u2192F16 output (${outputSize} bytes) exceeds device maxBufferSize (${maxBufferSize}).`\n    );\n  }\n  if (outputSize > maxBindingSize) {\n    throw new Error(\n      `BF16\u2192F16 output (${outputSize} bytes) exceeds device maxStorageBufferBindingSize (${maxBindingSize}).`\n    );\n  }\n\n  const output = acquireBuffer(outputSize, undefined, name);\n\n  const uniformBuffer = createUniformBufferWithView(\n    'bf16_to_f16_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numElements, true);\n      view.setUint32(4, 0, true);\n      view.setUint32(8, 0, true);\n    },\n    null,\n    device\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'bf16_to_f16_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input } },\n      { binding: 2, resource: { buffer: output } },\n    ],\n  });\n\n  const numPairs = Math.ceil(numElements / 2);\n  const workgroups = Math.ceil(numPairs / WORKGROUP_SIZES.DEFAULT);\n  const dispatchSize = calculate2DDispatch(workgroups);\n\n  dispatch(device, pipeline, bindGroup, dispatchSize, 'bf16_to_f16');\n  await device.queue.onSubmittedWorkDone();\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, 'f16', [...shape], name);\n}\n\n/**\n * Convert BF16 to F32 in chunks (for large buffers)\n */\nasync function runBF16ToF32Chunked(\n  input: GPUBuffer,\n  shape: readonly number[],\n  name: string,\n  maxBindingSize: number\n): Promise<Tensor> {\n  const numElements = shape.reduce((a, b) => a * b, 1);\n  const device = getDevice();\n  const pipeline = await createPipeline('bf16_to_f32', 'default');\n\n  // Calculate chunk size\n  const alignmentBytes = device.limits.minStorageBufferOffsetAlignment;\n\n  const inElemAlign = Math.max(1, Math.floor(alignmentBytes / DTYPE_SIZES.bf16)); // BF16 elements\n  const outElemAlign = Math.max(1, Math.floor(alignmentBytes / DTYPE_SIZES.f32)); // F32 elements\n  const elemAlign = lcm(inElemAlign, outElemAlign);\n\n  let maxElementsPerChunk = Math.floor(maxBindingSize / DTYPE_SIZES.f32); // F32 output bytes\n  maxElementsPerChunk -= maxElementsPerChunk % elemAlign;\n  if (maxElementsPerChunk <= 0) {\n    throw new Error(`BF16\u2192F32 chunk size underflow (maxBindingSize=${maxBindingSize}, alignment=${alignmentBytes})`);\n  }\n  const numChunks = Math.ceil(numElements / maxElementsPerChunk);\n\n  // Create full output buffer\n  const outputSize = numElements * DTYPE_SIZES.f32;\n  const output = acquireBuffer(outputSize, undefined, name);\n\n  trace.kernels(`BF16ToF32: Chunking ${numElements} elements in ${numChunks} chunks`);\n\n  for (let chunkIdx = 0; chunkIdx < numChunks; chunkIdx++) {\n    const chunkStart = chunkIdx * maxElementsPerChunk;\n    const chunkEnd = Math.min((chunkIdx + 1) * maxElementsPerChunk, numElements);\n    const chunkSize = chunkEnd - chunkStart;\n\n    const uniformBuffer = createUniformBufferWithView(\n      `bf16_to_f32_chunk${chunkIdx}_uniforms`,\n      16,\n      (view) => {\n        view.setUint32(0, chunkSize, true);\n        view.setUint32(4, 0, true);\n        view.setUint32(8, 0, true);\n      },\n      null,\n      device\n    );\n\n    const inputOffsetBytes = chunkStart * DTYPE_SIZES.bf16;\n    const outputOffsetBytes = chunkStart * DTYPE_SIZES.f32;\n    const inputPairs = Math.ceil(chunkSize / 2);\n    const inputSizeBytes = inputPairs * DTYPE_SIZES.f32; // Pairs read as u32\n    const outputSizeBytes = chunkSize * DTYPE_SIZES.f32;\n\n    const bindGroup = device.createBindGroup({\n      label: `bf16_to_f32_chunk${chunkIdx}_bind_group`,\n      layout: pipeline.getBindGroupLayout(0),\n      entries: [\n        { binding: 0, resource: { buffer: uniformBuffer } },\n        { binding: 1, resource: { buffer: input, offset: inputOffsetBytes, size: inputSizeBytes } },\n        { binding: 2, resource: { buffer: output, offset: outputOffsetBytes, size: outputSizeBytes } },\n      ],\n    });\n\n    // Each thread processes 2 BF16 values\n    const numPairs = Math.ceil(chunkSize / 2);\n    const workgroups = Math.ceil(numPairs / WORKGROUP_SIZES.DEFAULT);\n    const dispatchSize = calculate2DDispatch(workgroups);\n\n    dispatch(device, pipeline, bindGroup, dispatchSize, `bf16_to_f32_chunk${chunkIdx}`);\n\n    uniformBuffer.destroy();\n  }\n\n  return createTensor(output, 'f32', [...shape], name);\n}\n", "/**\n * Mixture of Experts (MoE) Kernels\n *\n * Provides kernels for MoE routing and token distribution:\n * - Top-K expert selection\n * - MoE token gathering (dispatching tokens to experts)\n * - Scatter-add (collecting expert outputs back to tokens)\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { createTensor, type Tensor } from '../tensor.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { createPipeline, createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\n\n/** MoE kernel options */\nexport interface MoEOptions extends OutputBufferOptions {\n  normalize?: boolean;\n  maxTokensPerExpert?: number;\n}\n\n/** MoE gather result */\nexport interface MoEGatherResult {\n  gathered: Tensor;\n  tokenCounts: GPUBuffer;\n  tokenMap: GPUBuffer;\n  maxTokensPerExpert: number;\n}\n\n/**\n * Run top-K expert selection\n */\nexport async function runTopK(\n  probs: GPUBuffer,\n  numTokens: number,\n  numExperts: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<{ indices: GPUBuffer; weights: GPUBuffer }> {\n  const device = getDevice();\n  const { normalize = true } = options;\n\n  const pipeline = await createPipeline('topk', 'default');\n\n  // Output buffers\n  const indicesSize = numTokens * topK * 4; // u32\n  const weightsSize = numTokens * topK * 4; // f32\n  const indices = acquireBuffer(indicesSize, undefined, 'topk_indices');\n  const weights = acquireBuffer(weightsSize, undefined, 'topk_weights');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'topk_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, numExperts, true);\n      view.setUint32(8, topK, true);\n      view.setUint32(12, normalize ? 1 : 0, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'topk_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: probs } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n    ],\n  });\n\n  dispatch(device, pipeline, bindGroup, numTokens, 'topk');\n\n  uniformBuffer.destroy();\n\n  return { indices, weights };\n}\n\n/**\n * Record top-K expert selection (batched, no submit)\n */\nexport async function recordTopK(\n  recorder: CommandRecorder,\n  probs: GPUBuffer,\n  numTokens: number,\n  numExperts: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<{ indices: GPUBuffer; weights: GPUBuffer }> {\n  const device = recorder.device;\n  const { normalize = true } = options;\n\n  const pipeline = await createPipeline('topk', 'default');\n\n  const indicesSize = numTokens * topK * 4; // u32\n  const weightsSize = numTokens * topK * 4; // f32\n  const indices = acquireBuffer(indicesSize, undefined, 'topk_indices');\n  const weights = acquireBuffer(weightsSize, undefined, 'topk_weights');\n\n  const uniformBuffer = createUniformBufferWithView(\n    'topk_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, numExperts, true);\n      view.setUint32(8, topK, true);\n      view.setUint32(12, normalize ? 1 : 0, true);\n    },\n    recorder\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'topk_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: probs } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n    ],\n  });\n\n  recordDispatch(recorder, pipeline, bindGroup, numTokens, 'topk');\n\n  return { indices, weights };\n}\n\n// Cached explicit bind group layout for MoE gather (all 6 bindings)\n// See docs/postmortems/MOE-EXPLICIT-LAYOUT-POSTMORTEM.md for why this is needed\nlet moeGatherBindGroupLayout: GPUBindGroupLayout | null = null;\n\nfunction getMoEGatherBindGroupLayout(device: GPUDevice): GPUBindGroupLayout {\n  if (moeGatherBindGroupLayout) return moeGatherBindGroupLayout;\n\n  moeGatherBindGroupLayout = device.createBindGroupLayout({\n    label: 'moe_gather_explicit_layout',\n    entries: [\n      { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },\n      { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },\n      { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },\n      { binding: 3, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },\n      { binding: 4, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },\n      { binding: 5, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },\n    ],\n  });\n  return moeGatherBindGroupLayout;\n}\n\n/**\n * Run MoE gather (dispatch tokens to experts)\n * Returns gathered hidden states organized by expert, along with token counts and mapping\n */\nexport async function runMoEGather(\n  hiddenStates: Tensor,\n  expertIndices: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<MoEGatherResult> {\n  const device = getDevice();\n  const { maxTokensPerExpert = numTokens } = options;\n\n  // Use explicit bind group layout (required because count_and_map doesn't use all bindings)\n  const explicitLayout = getMoEGatherBindGroupLayout(device);\n\n  // Two-phase approach: count_and_map builds token assignments, gather copies hidden states\n  const countPipeline = await createPipeline('moe_gather', 'count', explicitLayout);\n  const gatherPipeline = await createPipeline('moe_gather', 'gather', explicitLayout);\n\n  // Output buffers per WGSL shader:\n  // - gathered: [numExperts, maxTokensPerExpert, hiddenSize]\n  // - tokenCounts: [numExperts]\n  // - tokenMap: [numExperts, maxTokensPerExpert, 2] (tokenIdx, kIdx)\n  const bytesPerElement = hiddenStates.dtype === 'f16' ? 2 : 4;\n  const gatheredSize = numExperts * maxTokensPerExpert * hiddenSize * bytesPerElement;\n  const tokenCountsSize = numExperts * 4;\n  const tokenMapSize = numExperts * maxTokensPerExpert * 2 * 4;\n\n  const gatheredBuffer = acquireBuffer(gatheredSize, undefined, 'moe_gathered');\n  const tokenCounts = acquireBuffer(tokenCountsSize, undefined, 'moe_token_counts');\n  const tokenMap = acquireBuffer(tokenMapSize, undefined, 'moe_token_map');\n\n  // Create uniform buffer (32 bytes to match WGSL struct with padding)\n  const uniformBuffer = createUniformBufferWithView(\n    'moe_gather_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, numExperts, true);\n      view.setUint32(12, topK, true);\n      view.setUint32(16, maxTokensPerExpert, true);\n      view.setUint32(20, 0, true); // _pad1\n      view.setUint32(24, 0, true); // _pad2\n      view.setUint32(28, 0, true); // _pad3\n    },\n    null,\n    device\n  );\n\n  // Create bind group with explicit layout (all 6 bindings)\n  const bindGroup = device.createBindGroup({\n    label: 'moe_gather_bind_group',\n    layout: explicitLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: hiddenStates.buffer } },\n      { binding: 2, resource: { buffer: expertIndices } },\n      { binding: 3, resource: { buffer: gatheredBuffer } },\n      { binding: 4, resource: { buffer: tokenCounts } },\n      { binding: 5, resource: { buffer: tokenMap } },\n    ],\n  });\n\n  // Phase 1: Count tokens per expert and build token map\n  const encoder = device.createCommandEncoder({ label: 'moe_gather_encoder' });\n  encoder.clearBuffer(tokenCounts); // Zero-initialize tokenCounts (atomics start at 0)\n\n  const countPass = encoder.beginComputePass({ label: 'moe_gather_count_pass' });\n  countPass.setPipeline(countPipeline);\n  countPass.setBindGroup(0, bindGroup);\n  const countWorkgroups = Math.ceil((numTokens * topK) / WORKGROUP_SIZES.DEFAULT);\n  countPass.dispatchWorkgroups(countWorkgroups);\n  countPass.end();\n\n  // Phase 2: Gather hidden states based on token map\n  const gatherPass = encoder.beginComputePass({ label: 'moe_gather_gather_pass' });\n  gatherPass.setPipeline(gatherPipeline);\n  gatherPass.setBindGroup(0, bindGroup);\n  const gatherWorkgroups = Math.ceil((numExperts * maxTokensPerExpert * hiddenSize) / WORKGROUP_SIZES.DEFAULT);\n  gatherPass.dispatchWorkgroups(gatherWorkgroups);\n  gatherPass.end();\n\n  device.queue.submit([encoder.finish()]);\n\n  uniformBuffer.destroy();\n\n  const gathered = createTensor(\n    gatheredBuffer,\n    hiddenStates.dtype,\n    [numExperts, maxTokensPerExpert, hiddenSize],\n    'moe_gathered'\n  );\n\n  return { gathered, tokenCounts, tokenMap, maxTokensPerExpert };\n}\n\n/**\n * Record MoE gather (batched, no submit)\n */\nexport async function recordMoEGather(\n  recorder: CommandRecorder,\n  hiddenStates: Tensor,\n  expertIndices: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<MoEGatherResult> {\n  const device = recorder.device;\n  const { maxTokensPerExpert = numTokens } = options;\n\n  // Use explicit bind group layout (required because count_and_map doesn't use all bindings)\n  const explicitLayout = getMoEGatherBindGroupLayout(device);\n\n  // Two-phase approach: count_and_map builds token assignments, gather copies hidden states\n  const countPipeline = await createPipeline('moe_gather', 'count', explicitLayout);\n  const gatherPipeline = await createPipeline('moe_gather', 'gather', explicitLayout);\n\n  const bytesPerElement = hiddenStates.dtype === 'f16' ? 2 : 4;\n  const gatheredSize = numExperts * maxTokensPerExpert * hiddenSize * bytesPerElement;\n  const tokenCountsSize = numExperts * 4;\n  const tokenMapSize = numExperts * maxTokensPerExpert * 2 * 4;\n\n  const gatheredBuffer = acquireBuffer(gatheredSize, undefined, 'moe_gathered');\n  const tokenCounts = acquireBuffer(tokenCountsSize, undefined, 'moe_token_counts');\n  const tokenMap = acquireBuffer(tokenMapSize, undefined, 'moe_token_map');\n\n  // Create uniform buffer (32 bytes to match WGSL struct with padding)\n  const uniformBuffer = createUniformBufferWithView(\n    'moe_gather_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, numExperts, true);\n      view.setUint32(12, topK, true);\n      view.setUint32(16, maxTokensPerExpert, true);\n      view.setUint32(20, 0, true); // _pad1\n      view.setUint32(24, 0, true); // _pad2\n      view.setUint32(28, 0, true); // _pad3\n    },\n    recorder\n  );\n\n  // Create bind group with explicit layout (all 6 bindings)\n  const bindGroup = device.createBindGroup({\n    label: 'moe_gather_bind_group',\n    layout: explicitLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: hiddenStates.buffer } },\n      { binding: 2, resource: { buffer: expertIndices } },\n      { binding: 3, resource: { buffer: gatheredBuffer } },\n      { binding: 4, resource: { buffer: tokenCounts } },\n      { binding: 5, resource: { buffer: tokenMap } },\n    ],\n  });\n\n  const encoder = recorder.getEncoder();\n  encoder.clearBuffer(tokenCounts);\n\n  // Phase 1: Count tokens per expert and build token map\n  const countPass = recorder.beginComputePass('moe_gather_count');\n  countPass.setPipeline(countPipeline);\n  countPass.setBindGroup(0, bindGroup);\n  countPass.dispatchWorkgroups(Math.ceil((numTokens * topK) / WORKGROUP_SIZES.DEFAULT));\n  countPass.end();\n\n  // Phase 2: Gather hidden states based on token map\n  const gatherPass = recorder.beginComputePass('moe_gather_gather');\n  gatherPass.setPipeline(gatherPipeline);\n  gatherPass.setBindGroup(0, bindGroup);\n  gatherPass.dispatchWorkgroups(Math.ceil((numExperts * maxTokensPerExpert * hiddenSize) / WORKGROUP_SIZES.DEFAULT));\n  gatherPass.end();\n\n  const gathered = createTensor(\n    gatheredBuffer,\n    hiddenStates.dtype,\n    [numExperts, maxTokensPerExpert, hiddenSize],\n    'moe_gathered'\n  );\n\n  return { gathered, tokenCounts, tokenMap, maxTokensPerExpert };\n}\n\n/**\n * Run scatter-add (collect expert outputs back to tokens)\n */\nexport async function runScatterAdd(\n  expertOutputs: Tensor,\n  indices: GPUBuffer,\n  weights: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { outputBuffer = null } = options;\n\n  const pipeline = await createPipeline('scatter_add', 'default');\n\n  // Output: [numTokens, hiddenSize]\n  const bytesPerElement = expertOutputs.dtype === 'f16' ? 2 : 4;\n  const outputSize = numTokens * hiddenSize * bytesPerElement;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'scatter_add_output');\n\n  // Create uniform buffer\n  // WGSL struct order: numTokens, hiddenSize, topK, numExperts\n  const uniformBuffer = createUniformBufferWithView(\n    'scatter_add_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, topK, true);      // offset 8 = topK (per WGSL struct)\n      view.setUint32(12, numExperts, true); // offset 12 = numExperts\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'scatter_add_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: expertOutputs.buffer } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n      { binding: 4, resource: { buffer: outputBuf } },\n    ],\n  });\n\n  // Dispatch\n  const encoder = device.createCommandEncoder({ label: 'scatter_add_encoder' });\n  encoder.clearBuffer(outputBuf);\n  const pass = encoder.beginComputePass({ label: 'scatter_add_pass' });\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n\n  // WGSL main kernel: each thread handles one output element (numTokens * hiddenSize total)\n  const workgroups = Math.ceil((numTokens * hiddenSize) / WORKGROUP_SIZES.DEFAULT);\n  pass.dispatchWorkgroups(workgroups);\n  pass.end();\n\n  device.queue.submit([encoder.finish()]);\n\n  uniformBuffer.destroy();\n\n  return createTensor(outputBuf, expertOutputs.dtype, [numTokens, hiddenSize], 'scatter_add_output');\n}\n\n/**\n * Record scatter-add (batched, no submit)\n */\nexport async function recordScatterAdd(\n  recorder: CommandRecorder,\n  expertOutputs: Tensor,\n  indices: GPUBuffer,\n  weights: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { outputBuffer = null } = options;\n\n  const pipeline = await createPipeline('scatter_add', 'default');\n  const bytesPerElement = expertOutputs.dtype === 'f16' ? 2 : 4;\n  const outputSize = numTokens * hiddenSize * bytesPerElement;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'scatter_add_output');\n\n  // WGSL struct order: numTokens, hiddenSize, topK, numExperts\n  const uniformBuffer = createUniformBufferWithView(\n    'scatter_add_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, topK, true);      // offset 8 = topK (per WGSL struct)\n      view.setUint32(12, numExperts, true); // offset 12 = numExperts\n    },\n    recorder\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'scatter_add_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: expertOutputs.buffer } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n      { binding: 4, resource: { buffer: outputBuf } },\n    ],\n  });\n\n  recorder.getEncoder().clearBuffer(outputBuf);\n\n  const pass = recorder.beginComputePass('scatter_add');\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n  // WGSL main kernel: each thread handles one output element (numTokens * hiddenSize total)\n  pass.dispatchWorkgroups(Math.ceil((numTokens * hiddenSize) / WORKGROUP_SIZES.DEFAULT));\n  pass.end();\n\n  return createTensor(outputBuf, expertOutputs.dtype, [numTokens, hiddenSize], 'scatter_add_output');\n}\n\n/**\n * Run dynamic scatter-add with token offsets\n */\nexport async function runScatterAddDynamic(\n  expertOutputs: Tensor,\n  indices: GPUBuffer,\n  weights: GPUBuffer,\n  tokenOffsets: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const { outputBuffer = null } = options;\n\n  const pipeline = await createPipeline('scatter_add', 'dynamic');\n\n  // Output: [numTokens, hiddenSize]\n  const bytesPerElement = expertOutputs.dtype === 'f16' ? 2 : 4;\n  const outputSize = numTokens * hiddenSize * bytesPerElement;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'scatter_add_dynamic_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'scatter_add_dynamic_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, topK, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'scatter_add_dynamic_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: expertOutputs.buffer } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n      { binding: 4, resource: { buffer: tokenOffsets } },\n      { binding: 5, resource: { buffer: outputBuf } },\n    ],\n  });\n\n  // Dispatch\n  const encoder = device.createCommandEncoder({ label: 'scatter_add_dynamic_encoder' });\n  encoder.clearBuffer(outputBuf);\n  const pass = encoder.beginComputePass({ label: 'scatter_add_dynamic_pass' });\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n\n  const workgroups = Math.ceil((numTokens * topK * hiddenSize) / WORKGROUP_SIZES.DEFAULT);\n  pass.dispatchWorkgroups(workgroups);\n  pass.end();\n\n  device.queue.submit([encoder.finish()]);\n\n  uniformBuffer.destroy();\n\n  return createTensor(outputBuf, expertOutputs.dtype, [numTokens, hiddenSize], 'scatter_add_dynamic_output');\n}\n\n/**\n * Record dynamic scatter-add (batched, no submit)\n */\nexport async function recordScatterAddDynamic(\n  recorder: CommandRecorder,\n  expertOutputs: Tensor,\n  indices: GPUBuffer,\n  weights: GPUBuffer,\n  tokenOffsets: GPUBuffer,\n  numTokens: number,\n  hiddenSize: number,\n  topK: number,\n  options: MoEOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const { outputBuffer = null } = options;\n\n  const pipeline = await createPipeline('scatter_add', 'dynamic');\n  const bytesPerElement = expertOutputs.dtype === 'f16' ? 2 : 4;\n  const outputSize = numTokens * hiddenSize * bytesPerElement;\n  const outputBuf = outputBuffer || acquireBuffer(outputSize, undefined, 'scatter_add_dynamic_output');\n\n  const uniformBuffer = createUniformBufferWithView(\n    'scatter_add_dynamic_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, hiddenSize, true);\n      view.setUint32(8, topK, true);\n    },\n    recorder\n  );\n\n  const bindGroup = device.createBindGroup({\n    label: 'scatter_add_dynamic_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: expertOutputs.buffer } },\n      { binding: 2, resource: { buffer: indices } },\n      { binding: 3, resource: { buffer: weights } },\n      { binding: 4, resource: { buffer: tokenOffsets } },\n      { binding: 5, resource: { buffer: outputBuf } },\n    ],\n  });\n\n  recorder.getEncoder().clearBuffer(outputBuf);\n\n  const pass = recorder.beginComputePass('scatter_add_dynamic');\n  pass.setPipeline(pipeline);\n  pass.setBindGroup(0, bindGroup);\n  pass.dispatchWorkgroups(Math.ceil((numTokens * topK * hiddenSize) / WORKGROUP_SIZES.DEFAULT));\n  pass.end();\n\n  return createTensor(outputBuf, expertOutputs.dtype, [numTokens, hiddenSize], 'scatter_add_dynamic_output');\n}\n", "/**\n * GPU-Side Sampling Kernel\n *\n * Performs sampling entirely on GPU, reducing readback from ~1MB to 4 bytes.\n * Supports:\n * - Temperature scaling\n * - Top-k selection\n * - Softmax\n * - Multinomial sampling\n * - Greedy argmax (for temperature=0)\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer, releaseBuffer } from '../buffer-pool.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { createPipeline, createUniformBufferWithView, getOrCreateBindGroupLayout } from './utils.js';\nimport { allowReadback } from '../perf-guards.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { getRuntimeConfig } from '../../config/runtime.js';\n\nexport interface SampleOptions {\n  temperature?: number;\n  topK?: number;\n  randomSeed?: number;\n  padTokenId?: number;\n  logitSoftcap?: number;  // Gemma 2: 30.0, 0 = disabled\n}\n\nexport interface SampleResult {\n  tokenId: number;\n  gpuBuffer: GPUBuffer;  // Buffer containing the token ID\n}\n\n/**\n * Get or create explicit bind group layout for sample kernels.\n * Required because different entry points use different binding subsets,\n * so layout: 'auto' fails to include all bindings.\n */\nfunction getSampleBindGroupLayout(device: GPUDevice): GPUBindGroupLayout {\n  return getOrCreateBindGroupLayout(\n    'sample_bind_group_layout',\n    [\n      { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },\n      { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'read-only-storage' } },\n      { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },\n      { binding: 3, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },\n      { binding: 4, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },\n    ],\n    device\n  );\n}\n\n/**\n * Create sample pipeline with explicit bind group layout.\n */\nasync function createSamplePipeline(device: GPUDevice, entryPoint: string): Promise<GPUComputePipeline> {\n  return createPipeline('sample', entryPoint, getSampleBindGroupLayout(device));\n}\n\n/**\n * Run GPU-side argmax (greedy decoding)\n * Returns the token ID with highest logit\n */\nexport async function runArgmax(\n  logits: GPUBuffer,\n  vocabSize: number,\n  options: SampleOptions = {}\n): Promise<number> {\n  if (!allowReadback('sample.runArgmax')) {\n    throw new Error('[Sample] GPU readback disabled for argmax');\n  }\n\n  const device = getDevice();\n  if (!device) throw new Error('GPU device not initialized');\n\n  // Pipelines with explicit layout\n  const argmaxPipeline = await createSamplePipeline(device, 'argmax');\n  const reducePipeline = await createSamplePipeline(device, 'argmax_reduce');\n\n  // Workgroups for first pass\n  const workgroupSize = WORKGROUP_SIZES.DEFAULT;\n  const numWorkgroups = Math.min(workgroupSize, Math.ceil(vocabSize / workgroupSize));\n\n  // Intermediate buffers\n  const tempLogits = acquireBuffer(workgroupSize * 4, undefined, 'argmax_temp_logits');\n  const tempIndices = acquireBuffer(workgroupSize * 4, undefined, 'argmax_temp_indices');\n  const outputBuffer = acquireBuffer(4, undefined, 'argmax_output');\n\n  // Uniforms\n  const padTokenId = options.padTokenId ?? 0xFFFFFFFF;\n  const logitSoftcap = options.logitSoftcap ?? 0;\n  const uniformBuffer = createUniformBufferWithView(\n    'argmax_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, vocabSize, true);     // vocabSize\n      view.setUint32(4, 1, true);             // topK (unused for argmax)\n      view.setFloat32(8, 1.0, true);          // temperature (unused)\n      view.setFloat32(12, 0.0, true);         // randomValue (unused)\n      view.setUint32(16, padTokenId, true);   // padTokenId\n      view.setFloat32(20, logitSoftcap, true); // logitSoftcap (Gemma 2: 30.0)\n    },\n    null,\n    device\n  );\n\n  // Bind groups with explicit layout (auto-layout fails for multi-entry-point shaders)\n  const bindGroupLayout = getSampleBindGroupLayout(device);\n  const argmaxBindGroup = device.createBindGroup({\n    label: 'argmax_bind_group',\n    layout: bindGroupLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },\n      { binding: 2, resource: { buffer: outputBuffer } },\n      { binding: 3, resource: { buffer: tempIndices } },\n      { binding: 4, resource: { buffer: tempLogits } },\n    ],\n  });\n\n  const reduceBindGroup = device.createBindGroup({\n    label: 'argmax_reduce_bind_group',\n    layout: bindGroupLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },  // Shader may not use, but layout requires\n      { binding: 2, resource: { buffer: outputBuffer } },\n      { binding: 3, resource: { buffer: tempIndices } },\n      { binding: 4, resource: { buffer: tempLogits } },\n    ],\n  });\n\n  // Execute\n  const encoder = device.createCommandEncoder({ label: 'argmax_encoder' });\n\n  // Pass 1: Find max per workgroup\n  const pass1 = encoder.beginComputePass({ label: 'argmax_pass1' });\n  pass1.setPipeline(argmaxPipeline);\n  pass1.setBindGroup(0, argmaxBindGroup);\n  pass1.dispatchWorkgroups(numWorkgroups);\n  pass1.end();\n\n  // Pass 2: Reduce workgroup results\n  const pass2 = encoder.beginComputePass({ label: 'argmax_pass2' });\n  pass2.setPipeline(reducePipeline);\n  pass2.setBindGroup(0, reduceBindGroup);\n  pass2.dispatchWorkgroups(1);\n  pass2.end();\n\n  device.queue.submit([encoder.finish()]);\n\n  // Read result\n  const stagingBuffer = device.createBuffer({\n    label: 'argmax_staging',\n    size: 4,\n    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,\n  });\n\n  const copyEncoder = device.createCommandEncoder({ label: 'argmax_copy' });\n  copyEncoder.copyBufferToBuffer(outputBuffer, 0, stagingBuffer, 0, 4);\n  device.queue.submit([copyEncoder.finish()]);\n\n  await stagingBuffer.mapAsync(GPUMapMode.READ);\n  const tokenId = new Uint32Array(stagingBuffer.getMappedRange())[0];\n  stagingBuffer.unmap();\n\n  // Cleanup\n  stagingBuffer.destroy();\n  uniformBuffer.destroy();\n  releaseBuffer(tempLogits);\n  releaseBuffer(tempIndices);\n  releaseBuffer(outputBuffer);\n\n  return tokenId;\n}\n\n/**\n * Run GPU-side top-k sampling\n * Applies temperature, selects top-k, applies softmax, samples\n */\nexport async function runGPUSample(\n  logits: GPUBuffer,\n  vocabSize: number,\n  options: SampleOptions = {}\n): Promise<number> {\n  if (!allowReadback('sample.runGPUSample')) {\n    throw new Error('[Sample] GPU readback disabled for sampling');\n  }\n\n  const samplingDefaults = getRuntimeConfig().inference.sampling;\n  const {\n    temperature = samplingDefaults.temperature,\n    topK = samplingDefaults.topK,\n    randomSeed,\n    padTokenId,\n    logitSoftcap = 0,\n  } = options;\n\n  // For temperature=0 or very low, use greedy argmax\n  const { greedyThreshold } = getRuntimeConfig().inference.sampling;\n  if (temperature < greedyThreshold) {\n    return runArgmax(logits, vocabSize, { padTokenId, logitSoftcap });\n  }\n\n  const device = getDevice();\n  if (!device) throw new Error('GPU device not initialized');\n\n  // Generate random value for sampling\n  const randomValue = randomSeed !== undefined\n    ? seededRandom(randomSeed)\n    : Math.random();\n\n  // Get pipelines with explicit layout\n  const phase1Pipeline = await createSamplePipeline(device, 'find_topk_phase1');\n  const phase2Pipeline = await createSamplePipeline(device, 'find_topk_phase2');\n  const phase3Pipeline = await createSamplePipeline(device, 'softmax_and_sample');\n\n  // Workgroups for phase 1\n  const workgroupSize = WORKGROUP_SIZES.DEFAULT;\n  const numWorkgroups = Math.min(workgroupSize, Math.ceil(vocabSize / workgroupSize));\n\n  // Buffers\n  const topkLogits = acquireBuffer(workgroupSize * 4, undefined, 'topk_logits');\n  const topkIndices = acquireBuffer(workgroupSize * 4, undefined, 'topk_indices');\n  const outputBuffer = acquireBuffer(4, undefined, 'sample_output');\n\n  // Uniforms\n  const uniformBuffer = createUniformBufferWithView(\n    'sample_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, vocabSize, true);\n      view.setUint32(4, topK, true);\n      view.setFloat32(8, temperature, true);\n      view.setFloat32(12, randomValue, true);\n      view.setUint32(16, padTokenId ?? 0xFFFFFFFF, true);\n      view.setFloat32(20, logitSoftcap, true);  // Gemma 2: 30.0\n    },\n    null,\n    device\n  );\n\n  // Bind group with explicit layout (auto-layout fails for multi-entry-point shaders)\n  const bindGroupLayout = getSampleBindGroupLayout(device);\n  const bindGroup = device.createBindGroup({\n    label: 'sample_bind_group',\n    layout: bindGroupLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },\n      { binding: 2, resource: { buffer: outputBuffer } },\n      { binding: 3, resource: { buffer: topkIndices } },\n      { binding: 4, resource: { buffer: topkLogits } },\n    ],\n  });\n\n  // Execute all phases\n  const encoder = device.createCommandEncoder({ label: 'sample_encoder' });\n\n  // Phase 1: Find per-workgroup top values\n  const pass1 = encoder.beginComputePass({ label: 'sample_phase1' });\n  pass1.setPipeline(phase1Pipeline);\n  pass1.setBindGroup(0, bindGroup);\n  pass1.dispatchWorkgroups(numWorkgroups);\n  pass1.end();\n\n  // Phase 2: Merge and select top-k\n  const pass2 = encoder.beginComputePass({ label: 'sample_phase2' });\n  pass2.setPipeline(phase2Pipeline);\n  pass2.setBindGroup(0, bindGroup);\n  pass2.dispatchWorkgroups(1);\n  pass2.end();\n\n  // Phase 3: Softmax and sample\n  const pass3 = encoder.beginComputePass({ label: 'sample_phase3' });\n  pass3.setPipeline(phase3Pipeline);\n  pass3.setBindGroup(0, bindGroup);\n  pass3.dispatchWorkgroups(1);\n  pass3.end();\n\n  device.queue.submit([encoder.finish()]);\n\n  // Read result (just 4 bytes!)\n  const stagingBuffer = device.createBuffer({\n    label: 'sample_staging',\n    size: 4,\n    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,\n  });\n\n  const copyEncoder = device.createCommandEncoder({ label: 'sample_copy' });\n  copyEncoder.copyBufferToBuffer(outputBuffer, 0, stagingBuffer, 0, 4);\n  device.queue.submit([copyEncoder.finish()]);\n\n  await stagingBuffer.mapAsync(GPUMapMode.READ);\n  const tokenId = new Uint32Array(stagingBuffer.getMappedRange())[0];\n  stagingBuffer.unmap();\n\n  // Cleanup\n  stagingBuffer.destroy();\n  uniformBuffer.destroy();\n  releaseBuffer(topkLogits);\n  releaseBuffer(topkIndices);\n  releaseBuffer(outputBuffer);\n\n  return tokenId;\n}\n\n/**\n * Record GPU argmax (batched, no submit)\n * Returns buffer containing token ID\n */\nexport async function recordArgmax(\n  recorder: CommandRecorder,\n  logits: GPUBuffer,\n  vocabSize: number,\n  options: SampleOptions = {}\n): Promise<GPUBuffer> {\n  const device = recorder.device;\n\n  // Pipelines with explicit layout\n  const argmaxPipeline = await createSamplePipeline(device, 'argmax');\n  const reducePipeline = await createSamplePipeline(device, 'argmax_reduce');\n\n  const numWorkgroups = Math.min(WORKGROUP_SIZES.DEFAULT, Math.ceil(vocabSize / WORKGROUP_SIZES.DEFAULT));\n\n  // Buffers\n  const tempLogits = acquireBuffer(WORKGROUP_SIZES.DEFAULT * 4, undefined, 'argmax_temp_logits');\n  const tempIndices = acquireBuffer(WORKGROUP_SIZES.DEFAULT * 4, undefined, 'argmax_temp_indices');\n  const outputBuffer = acquireBuffer(4, undefined, 'argmax_output');\n\n  // Uniforms\n  const padTokenId = options.padTokenId ?? 0xFFFFFFFF;\n  const logitSoftcap = options.logitSoftcap ?? 0;\n  const uniformBuffer = createUniformBufferWithView(\n    'argmax_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, vocabSize, true);\n      view.setUint32(4, 1, true);\n      view.setFloat32(8, 1.0, true);\n      view.setFloat32(12, 0.0, true);\n      view.setUint32(16, padTokenId, true);\n      view.setFloat32(20, logitSoftcap, true);  // Gemma 2: 30.0\n    },\n    recorder\n  );\n\n  // Bind groups with explicit layout\n  const bindGroupLayout = getSampleBindGroupLayout(device);\n  const bindGroup = device.createBindGroup({\n    label: 'argmax_bind_group',\n    layout: bindGroupLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },\n      { binding: 2, resource: { buffer: outputBuffer } },\n      { binding: 3, resource: { buffer: tempIndices } },\n      { binding: 4, resource: { buffer: tempLogits } },\n    ],\n  });\n\n  // Pass 1\n  const pass1 = recorder.beginComputePass('argmax_phase1');\n  pass1.setPipeline(argmaxPipeline);\n  pass1.setBindGroup(0, bindGroup);\n  pass1.dispatchWorkgroups(numWorkgroups);\n  pass1.end();\n\n  // Pass 2 (reuse same bind group since layout is the same)\n  const reduceBindGroup = device.createBindGroup({\n    label: 'argmax_reduce_bind_group',\n    layout: bindGroupLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },\n      { binding: 2, resource: { buffer: outputBuffer } },\n      { binding: 3, resource: { buffer: tempIndices } },\n      { binding: 4, resource: { buffer: tempLogits } },\n    ],\n  });\n\n  const pass2 = recorder.beginComputePass('argmax_phase2');\n  pass2.setPipeline(reducePipeline);\n  pass2.setBindGroup(0, reduceBindGroup);\n  pass2.dispatchWorkgroups(1);\n  pass2.end();\n\n  // Schedule cleanup of temp buffers after submit.\n  recorder.trackTemporaryBuffer(tempLogits);\n  recorder.trackTemporaryBuffer(tempIndices);\n\n  return outputBuffer;\n}\n\n/**\n * Record GPU top-k sampling (batched, no submit)\n * Returns buffer containing token ID\n */\nexport async function recordGPUSample(\n  recorder: CommandRecorder,\n  logits: GPUBuffer,\n  vocabSize: number,\n  options: SampleOptions = {}\n): Promise<GPUBuffer> {\n  const samplingDefaults = getRuntimeConfig().inference.sampling;\n  const {\n    temperature = samplingDefaults.temperature,\n    topK = samplingDefaults.topK,\n    randomSeed,\n    padTokenId,\n    logitSoftcap = 0,\n  } = options;\n\n  // For temperature=0 or very low, use greedy argmax\n  const { greedyThreshold } = getRuntimeConfig().inference.sampling;\n  if (temperature < greedyThreshold) {\n    return recordArgmax(recorder, logits, vocabSize, { padTokenId, logitSoftcap });\n  }\n\n  const device = recorder.device;\n\n  // Generate random value for sampling\n  const randomValue = randomSeed !== undefined\n    ? seededRandom(randomSeed)\n    : Math.random();\n\n  // Get pipelines with explicit layout\n  const phase1Pipeline = await createSamplePipeline(device, 'find_topk_phase1');\n  const phase2Pipeline = await createSamplePipeline(device, 'find_topk_phase2');\n  const phase3Pipeline = await createSamplePipeline(device, 'softmax_and_sample');\n\n  // Workgroups for phase 1\n  const numWorkgroups = Math.min(WORKGROUP_SIZES.DEFAULT, Math.ceil(vocabSize / WORKGROUP_SIZES.DEFAULT));\n\n  // Buffers\n  const topkLogits = acquireBuffer(WORKGROUP_SIZES.DEFAULT * 4, undefined, 'topk_logits');\n  const topkIndices = acquireBuffer(WORKGROUP_SIZES.DEFAULT * 4, undefined, 'topk_indices');\n  const outputBuffer = acquireBuffer(4, undefined, 'sample_output');\n\n  // Uniforms\n  const uniformBuffer = createUniformBufferWithView(\n    'sample_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, vocabSize, true);\n      view.setUint32(4, topK, true);\n      view.setFloat32(8, temperature, true);\n      view.setFloat32(12, randomValue, true);\n      view.setUint32(16, padTokenId ?? 0xFFFFFFFF, true);\n      view.setFloat32(20, logitSoftcap, true);  // Gemma 2: 30.0\n    },\n    recorder\n  );\n\n  // Bind group with explicit layout\n  const bindGroupLayout = getSampleBindGroupLayout(device);\n  const bindGroup = device.createBindGroup({\n    label: 'sample_bind_group',\n    layout: bindGroupLayout,\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: logits } },\n      { binding: 2, resource: { buffer: outputBuffer } },\n      { binding: 3, resource: { buffer: topkIndices } },\n      { binding: 4, resource: { buffer: topkLogits } },\n    ],\n  });\n\n  // Phase 1: Find per-workgroup top values\n  const pass1 = recorder.beginComputePass('sample_phase1');\n  pass1.setPipeline(phase1Pipeline);\n  pass1.setBindGroup(0, bindGroup);\n  pass1.dispatchWorkgroups(numWorkgroups);\n  pass1.end();\n\n  // Phase 2: Merge and select top-k\n  const pass2 = recorder.beginComputePass('sample_phase2');\n  pass2.setPipeline(phase2Pipeline);\n  pass2.setBindGroup(0, bindGroup);\n  pass2.dispatchWorkgroups(1);\n  pass2.end();\n\n  // Phase 3: Softmax and sample\n  const pass3 = recorder.beginComputePass('sample_phase3');\n  pass3.setPipeline(phase3Pipeline);\n  pass3.setBindGroup(0, bindGroup);\n  pass3.dispatchWorkgroups(1);\n  pass3.end();\n\n  // Track temp buffers for cleanup\n  recorder.trackTemporaryBuffer(topkLogits);\n  recorder.trackTemporaryBuffer(topkIndices);\n\n  return outputBuffer;\n}\n\n/**\n * Simple seeded random number generator\n */\nfunction seededRandom(seed: number): number {\n  const x = Math.sin(seed) * 10000;\n  return x - Math.floor(x);\n}\n\n/**\n * Check if GPU sampling is available\n */\nexport function isGPUSamplingAvailable(): boolean {\n  return getDevice() !== null;\n}\n", "/**\n * Fused FFN Kernel (Tier 2 P0)\n *\n * EXPERIMENTAL: Not currently wired into layer.ts.\n * Complete gate+up fusion kernel, kept for future integration.\n *\n * Fuses gate + up weight projections with activation for:\n * - 2x reduction in input reads\n * - Elimination of intermediate buffers\n * - Single kernel launch instead of 3\n *\n * Supports:\n * - SiLU (SwiGLU) and GeLU (GeGLU) activations\n * - F32 and F16 weight formats\n * - Batched execution for prefill\n * - Command recording for batched GPU operations\n */\n\nimport { getDevice, getKernelCapabilities } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { createTensor, Tensor } from '../tensor.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { KernelBase } from './kernel-base.js';\nimport { createUniformBufferWithView } from './utils.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\nimport { getBuffer, getWeightDtype, type WeightBuffer } from '../weight-buffer.js';\nimport { isFusedQ4KDisabled } from './matmul.js';\n\n/** FFN activation type */\nexport type FFNActivation = 'silu' | 'gelu';\n\n/** Fused FFN options */\nexport interface FusedFFNOptions extends OutputBufferOptions {\n  /** Batch size (default: 1) */\n  batchSize?: number;\n  /** Activation function (default: 'silu') */\n  activation?: FFNActivation;\n  /** Scale factor (default: 1.0) */\n  alpha?: number;\n}\n\nclass FusedFFNKernel extends KernelBase {\n  async getPipeline(variant: string): Promise<GPUComputePipeline> {\n    return this.getPipelineFor('fused_ffn', variant);\n  }\n\n  dispatch(\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroupsX: number,\n    workgroupsY: number = 1\n  ): void {\n    this.dispatchKernel(pipeline, bindGroup, [workgroupsX, workgroupsY, 1], 'fused_ffn');\n  }\n\n  record(\n    recorder: CommandRecorder,\n    pipeline: GPUComputePipeline,\n    bindGroup: GPUBindGroup,\n    workgroupsX: number,\n    workgroupsY: number = 1\n  ): void {\n    this.recordKernel(recorder, pipeline, bindGroup, [workgroupsX, workgroupsY, 1], 'fused_ffn');\n  }\n}\n\nfunction selectFFNVariant(\n  batchSize: number,\n  weightDtype: 'f16' | 'f32' | 'q4k',\n  intermediateSize: number\n): string {\n  // Q4K variants - only if fused path is enabled\n  if (weightDtype === 'q4k' && !isFusedQ4KDisabled()) {\n    return batchSize > 1 ? 'q4k_batched' : 'q4k';\n  }\n\n  // For small intermediate sizes, use multi-output variant\n  if (batchSize > 1) {\n    return 'batched';\n  }\n\n  if (weightDtype === 'f16') {\n    return 'f16';\n  }\n\n  if (intermediateSize <= 1024) {\n    return 'multi';\n  }\n\n  // Default F32 variant\n  return 'default';\n}\n\nfunction createFFNUniformBuffer(\n  device: GPUDevice,\n  recorder: CommandRecorder | null,\n  params: {\n    M: number;\n    hiddenSize: number;\n    intermediateSize: number;\n    alpha: number;\n    activation: FFNActivation;\n    isQ4K?: boolean;\n  }\n): GPUBuffer {\n  return createUniformBufferWithView(\n    'fused_ffn_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, params.M, true);\n      view.setUint32(4, params.hiddenSize, true);\n      view.setUint32(8, params.intermediateSize, true);\n      view.setFloat32(12, params.alpha, true);\n      view.setUint32(16, params.activation === 'silu' ? 0 : 1, true);\n      // Q4K needs num_blocks_per_row at offset 20\n      if (params.isQ4K) {\n        view.setUint32(20, Math.floor(params.hiddenSize / 256), true);\n      }\n    },\n    recorder,\n    device\n  );\n}\n\n/**\n * Run fused FFN forward pass\n *\n * Computes: output = activation(input @ W_gate^T) * (input @ W_up^T)\n *\n * @param input Input tensor [batchSize, hiddenSize]\n * @param W_gate Gate weight matrix [intermediateSize, hiddenSize]\n * @param W_up Up weight matrix [intermediateSize, hiddenSize]\n * @param hiddenSize Input dimension\n * @param intermediateSize Output dimension\n * @param options FFN options\n * @returns Output tensor [batchSize, intermediateSize]\n */\nexport async function runFusedFFN(\n  input: Tensor,\n  W_gate: GPUBuffer | WeightBuffer,\n  W_up: GPUBuffer | WeightBuffer,\n  hiddenSize: number,\n  intermediateSize: number,\n  options: FusedFFNOptions = {}\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    batchSize = 1,\n    activation = 'silu',\n    alpha = 1.0,\n    outputBuffer = null,\n  } = options;\n\n  if (input.dtype !== 'f32') {\n    throw new Error('Fused FFN requires f32 activations');\n  }\n\n  const gateDtype = getWeightDtype(W_gate) ?? 'f32';\n  const upDtype = getWeightDtype(W_up) ?? 'f32';\n  if (gateDtype !== upDtype) {\n    throw new Error(`Fused FFN requires matching gate/up dtypes (gate=${gateDtype}, up=${upDtype})`);\n  }\n  if (gateDtype !== 'f16' && gateDtype !== 'f32' && gateDtype !== 'q4k') {\n    throw new Error(`Fused FFN does not support ${gateDtype} weights`);\n  }\n\n  const isQ4K = gateDtype === 'q4k';\n  const variant = selectFFNVariant(batchSize, gateDtype as 'f16' | 'f32' | 'q4k', intermediateSize);\n\n  trace.kernels(`FusedFFN: variant=${variant}, batch=${batchSize}, hidden=${hiddenSize}, intermediate=${intermediateSize}, activation=${activation}, isQ4K=${isQ4K}`);\n\n  const kernel = new FusedFFNKernel(device);\n  const pipeline = await kernel.getPipeline(variant);\n\n  // Create output buffer\n  const outputSize = batchSize * intermediateSize * 4;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'fused_ffn_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createFFNUniformBuffer(device, null, {\n    M: batchSize,\n    hiddenSize,\n    intermediateSize,\n    alpha,\n    activation,\n    isQ4K,\n  });\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'fused_ffn_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: getBuffer(W_gate) } },\n      { binding: 3, resource: { buffer: getBuffer(W_up) } },\n      { binding: 4, resource: { buffer: output } },\n    ],\n  });\n\n  // Calculate workgroups\n  let workgroupsX: number;\n  let workgroupsY: number = 1;\n\n  if (variant === 'multi') {\n    const outputsPerWg = 4;\n    workgroupsX = Math.ceil(intermediateSize / outputsPerWg);\n  } else if (variant === 'q4k' || variant === 'q4k_batched') {\n    // Q4K uses multi-column: 32 columns per workgroup\n    const colsPerWg = 32;\n    workgroupsX = Math.ceil(intermediateSize / colsPerWg);\n    workgroupsY = variant === 'q4k_batched' ? batchSize : 1;\n  } else if (variant === 'batched') {\n    workgroupsX = intermediateSize;\n    workgroupsY = batchSize;\n  } else {\n    workgroupsX = intermediateSize;\n  }\n\n  kernel.dispatch(pipeline, bindGroup, workgroupsX, workgroupsY);\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, 'f32', [batchSize, intermediateSize], 'fused_ffn_output');\n}\n\n/**\n * Record fused FFN forward pass (batched, no submit)\n */\nexport async function recordFusedFFN(\n  recorder: CommandRecorder,\n  input: Tensor,\n  W_gate: GPUBuffer | WeightBuffer,\n  W_up: GPUBuffer | WeightBuffer,\n  hiddenSize: number,\n  intermediateSize: number,\n  options: FusedFFNOptions = {}\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    batchSize = 1,\n    activation = 'silu',\n    alpha = 1.0,\n    outputBuffer = null,\n  } = options;\n\n  if (input.dtype !== 'f32') {\n    throw new Error('Fused FFN requires f32 activations');\n  }\n\n  const gateDtype = getWeightDtype(W_gate) ?? 'f32';\n  const upDtype = getWeightDtype(W_up) ?? 'f32';\n  if (gateDtype !== upDtype) {\n    throw new Error(`Fused FFN requires matching gate/up dtypes (gate=${gateDtype}, up=${upDtype})`);\n  }\n  if (gateDtype !== 'f16' && gateDtype !== 'f32' && gateDtype !== 'q4k') {\n    throw new Error(`Fused FFN does not support ${gateDtype} weights`);\n  }\n\n  const isQ4K = gateDtype === 'q4k';\n  const variant = selectFFNVariant(batchSize, gateDtype as 'f16' | 'f32' | 'q4k', intermediateSize);\n\n  trace.kernels(`FusedFFN record: variant=${variant}, batch=${batchSize}, hidden=${hiddenSize}, intermediate=${intermediateSize}, activation=${activation}, isQ4K=${isQ4K}`);\n\n  const kernel = new FusedFFNKernel(device);\n  const pipeline = await kernel.getPipeline(variant);\n\n  const outputSize = batchSize * intermediateSize * 4;\n  const output = outputBuffer || acquireBuffer(outputSize, undefined, 'fused_ffn_output');\n\n  const uniformBuffer = createFFNUniformBuffer(device, recorder, {\n    M: batchSize,\n    hiddenSize,\n    intermediateSize,\n    alpha,\n    activation,\n    isQ4K,\n  });\n\n  const bindGroup = device.createBindGroup({\n    label: 'fused_ffn_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: getBuffer(W_gate) } },\n      { binding: 3, resource: { buffer: getBuffer(W_up) } },\n      { binding: 4, resource: { buffer: output } },\n    ],\n  });\n\n  let workgroupsX: number;\n  let workgroupsY: number = 1;\n\n  if (variant === 'multi') {\n    const outputsPerWg = 4;\n    workgroupsX = Math.ceil(intermediateSize / outputsPerWg);\n  } else if (variant === 'q4k' || variant === 'q4k_batched') {\n    // Q4K uses multi-column: 32 columns per workgroup\n    const colsPerWg = 32;\n    workgroupsX = Math.ceil(intermediateSize / colsPerWg);\n    workgroupsY = variant === 'q4k_batched' ? batchSize : 1;\n  } else if (variant === 'batched') {\n    workgroupsX = intermediateSize;\n    workgroupsY = batchSize;\n  } else {\n    workgroupsX = intermediateSize;\n  }\n\n  kernel.record(recorder, pipeline, bindGroup, workgroupsX, workgroupsY);\n\n  return createTensor(output, 'f32', [batchSize, intermediateSize], 'fused_ffn_output');\n}\n\n/**\n * Calculate memory savings from using fused FFN\n */\nexport function calculateFusedFFNSavings(\n  batchSize: number,\n  hiddenSize: number,\n  intermediateSize: number\n): {\n  separateBytes: number;\n  fusedBytes: number;\n  savingsBytes: number;\n  savingsPct: number;\n} {\n  // Separate kernel approach:\n  // - Read input 2x (once for gate, once for up)\n  // - Write gate output, up output, final output\n  const inputBytes = batchSize * hiddenSize * 4;\n  const intermediateBytes = batchSize * intermediateSize * 4;\n  const separateBytes = 2 * inputBytes + 3 * intermediateBytes;\n\n  // Fused approach:\n  // - Read input 1x\n  // - Write final output 1x\n  const fusedBytes = inputBytes + intermediateBytes;\n\n  const savingsBytes = separateBytes - fusedBytes;\n  const savingsPct = (savingsBytes / separateBytes) * 100;\n\n  return {\n    separateBytes,\n    fusedBytes,\n    savingsBytes,\n    savingsPct,\n  };\n}\n", "/**\n * Fused GEMV + Residual Kernel\n *\n * For decode (M=1), combines output projection matmul with residual add in a single kernel:\n * C[N] = A[K] * B^T[K,N] + residual[N]\n *\n * Benefits:\n * - Single GPU dispatch instead of 2\n * - No intermediate buffer for matmul output\n * - Better cache locality\n *\n * Expected speedup: eliminates 1 dispatch barrier per layer (16 barriers for 16-layer model)\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport { createTensor, dtypeBytes } from '../tensor.js';\nimport type { Tensor, TensorDtype } from '../tensor.js';\nimport { type WeightBuffer, getBuffer } from '../weight-buffer.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport type { OutputBufferOptions } from './types.js';\nimport { trace } from '../../debug/index.js';\n\n/** Fused MatmulResidual kernel options */\nexport interface MatmulResidualFusedOptions extends OutputBufferOptions {\n  /** Output dimension N (hiddenSize) */\n  N: number;\n  /** Input dimension K (numHeads * headDim) */\n  K: number;\n  /** Scaling factor (default: 1.0) */\n  alpha?: number;\n}\n\n/**\n * Check if fused GEMV+residual should be used.\n *\n * Only use for decode (M=1) where GEMV kernel is applicable.\n */\nexport function shouldUseFusedMatmulResidual(M: number): boolean {\n  return M === 1;\n}\n\n/**\n * Run fused GEMV + Residual\n *\n * Combines output projection matmul (M=1) with residual add in a single kernel.\n * Use this for the attention output path during decode.\n *\n * @param input - Input activation tensor [1, K] (attention output before o_proj)\n * @param weight - Output projection weight buffer (GPUBuffer or WeightBuffer)\n * @param residual - Residual tensor [1, N] (original input to add)\n * @param options - Kernel options including N, K dimensions\n * @returns Output tensor [1, N] with projected + residual result\n */\nexport async function runMatmulResidualFused(\n  input: Tensor,\n  weight: GPUBuffer | WeightBuffer,\n  residual: Tensor,\n  options: MatmulResidualFusedOptions\n): Promise<Tensor> {\n  const device = getDevice();\n  const {\n    N,\n    K,\n    alpha = 1.0,\n    outputBuffer = null,\n  } = options;\n\n  const weightBuffer = getBuffer(weight);\n  const outputDtype: TensorDtype = input.dtype;\n\n  trace.kernels(`MatmulResidualFused: N=${N}, K=${K}, alpha=${alpha}, dtype=${outputDtype}`);\n\n  const pipeline = await getPipelineFast('fused_matmul_residual', 'default');\n\n  const output = outputBuffer || acquireBuffer(N * dtypeBytes(outputDtype), undefined, 'matmul_residual_output');\n\n  // Create uniform buffer (same layout as matmul_gemv)\n  const uniformBuffer = createUniformBufferWithView(\n    'matmul_residual_uniforms',\n    32,  // 8 u32s\n    (view) => {\n      view.setUint32(0, 1, true);         // M = 1 (decode)\n      view.setUint32(4, N, true);         // N (output dimension)\n      view.setUint32(8, K, true);         // K (input dimension)\n      view.setFloat32(12, alpha, true);   // alpha\n      view.setUint32(16, 1, true);        // transpose_b = 1\n      view.setUint32(20, 0, true);        // _pad0\n      view.setUint32(24, 0, true);        // _pad1\n      view.setUint32(28, 0, true);        // _pad2\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'matmul_residual_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: weightBuffer } },\n      { binding: 3, resource: { buffer: output } },\n      { binding: 4, resource: { buffer: residual.buffer } },\n    ],\n  });\n\n  // One workgroup per output element\n  const workgroups = N;\n  dispatch(device, pipeline, bindGroup, workgroups, 'matmul_residual_fused');\n\n  uniformBuffer.destroy();\n\n  return createTensor(output, outputDtype, [1, N], 'matmul_residual_output');\n}\n\n/**\n * Record fused GEMV + Residual (batched, no submit)\n */\nexport async function recordMatmulResidualFused(\n  recorder: CommandRecorder,\n  input: Tensor,\n  weight: GPUBuffer | WeightBuffer,\n  residual: Tensor,\n  options: MatmulResidualFusedOptions\n): Promise<Tensor> {\n  const device = recorder.device;\n  const {\n    N,\n    K,\n    alpha = 1.0,\n    outputBuffer = null,\n  } = options;\n\n  const weightBuffer = getBuffer(weight);\n  const outputDtype: TensorDtype = input.dtype;\n\n  const pipeline = await getPipelineFast('fused_matmul_residual', 'default');\n\n  const output = outputBuffer || acquireBuffer(N * dtypeBytes(outputDtype), undefined, 'matmul_residual_output');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'matmul_residual_uniforms',\n    32,\n    (view) => {\n      view.setUint32(0, 1, true);         // M = 1\n      view.setUint32(4, N, true);         // N\n      view.setUint32(8, K, true);         // K\n      view.setFloat32(12, alpha, true);   // alpha\n      view.setUint32(16, 1, true);        // transpose_b = 1\n      view.setUint32(20, 0, true);        // _pad0\n      view.setUint32(24, 0, true);        // _pad1\n      view.setUint32(28, 0, true);        // _pad2\n    },\n    recorder\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'matmul_residual_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: input.buffer } },\n      { binding: 2, resource: { buffer: weightBuffer } },\n      { binding: 3, resource: { buffer: output } },\n      { binding: 4, resource: { buffer: residual.buffer } },\n    ],\n  });\n\n  // One workgroup per output element\n  const workgroups = N;\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'matmul_residual_fused');\n\n  return createTensor(output, outputDtype, [1, N], 'matmul_residual_output');\n}\n", "/**\n * CommandRecorder - Batched GPU Command Recording\n *\n * Enables recording multiple GPU operations into a single command buffer,\n * avoiding per-kernel submit overhead. Manages temporary buffers automatically.\n *\n * Usage:\n *   const recorder = new CommandRecorder(device);\n *   recordMatmul(recorder, A, B, M, N, K);\n *   recordRMSNorm(recorder, input, weight, eps);\n *   // ... more operations\n *   await recorder.submit();  // Single GPU submission + cleanup\n *\n * Performance impact:\n *   Without batching: 260+ submits per forward pass (~50-100ms overhead)\n *   With batching: 1 submit per forward pass (~0.5ms overhead)\n *\n * Profiling mode:\n *   const recorder = new CommandRecorder(device, 'decode', { profile: true });\n *   // ... record operations ...\n *   recorder.submit();\n *   const timings = await recorder.resolveProfileTimings();\n *   log.info('CommandRecorder', 'Kernel timings', timings);\n */\n\nimport { getDevice, hasFeature, FEATURES } from './device.js';\nimport { allowReadback, trackAllocation } from './perf-guards.js';\nimport { getUniformCache } from './uniform-cache.js';\nimport { log } from '../debug/index.js';\n\n/** Statistics about recorded operations */\nexport interface RecorderStats {\n  opCount: number;\n  tempBufferCount: number;\n  submitted: boolean;\n}\n\n/** Options for CommandRecorder */\nexport interface RecorderOptions {\n  /** Enable GPU timestamp profiling (requires 'timestamp-query' feature) */\n  profile?: boolean;\n}\n\n/** Profiling timing entry */\ninterface ProfileEntry {\n  label: string;\n  startQueryIndex: number;\n  endQueryIndex: number;\n}\n\n/** Profiling result - maps kernel label to time in milliseconds */\nexport type ProfileTimings = Record<string, number>;\n\n/**\n * CommandRecorder wraps a GPUCommandEncoder and manages temporary resources.\n */\nexport class CommandRecorder {\n  readonly device: GPUDevice;\n  readonly label: string;\n  private encoder: GPUCommandEncoder;\n\n  /** Temporary buffers to destroy after submit */\n  private tempBuffers: GPUBuffer[];\n  private cleanupPromise: Promise<void> | null = null;\n\n  /** Track if already submitted */\n  private submitted: boolean;\n\n  /** Operation count for debugging */\n  private opCount: number;\n\n  // Profiling state\n  private profilingEnabled: boolean;\n  private querySet: GPUQuerySet | null = null;\n  private queryBuffer: GPUBuffer | null = null;\n  private readbackBuffer: GPUBuffer | null = null;\n  private profileEntries: ProfileEntry[] = [];\n  private nextQueryIndex = 0;\n  private static readonly MAX_QUERIES = 512; // 256 kernel pairs\n\n  /**\n   * @param device - GPU device (auto-detected if not provided)\n   * @param label - Label for debugging\n   * @param options - Recorder options (profiling, etc.)\n   */\n  constructor(device: GPUDevice | null = null, label: string = 'command_recorder', options: RecorderOptions = {}) {\n    this.device = device || getDevice();\n    if (!this.device) {\n      throw new Error('[CommandRecorder] No GPU device available');\n    }\n\n    this.label = label;\n    this.encoder = this.device.createCommandEncoder({ label });\n\n    // Temporary buffers to destroy after submit\n    this.tempBuffers = [];\n    this.cleanupPromise = null;\n\n    // Track if already submitted\n    this.submitted = false;\n\n    // Operation count for debugging\n    this.opCount = 0;\n\n    // Initialize profiling if requested and available\n    this.profilingEnabled = options.profile === true && hasFeature(FEATURES.TIMESTAMP_QUERY);\n    if (this.profilingEnabled) {\n      this._initProfiling();\n    }\n  }\n\n  /**\n   * Initialize GPU timestamp query resources for profiling.\n   * @private\n   */\n  private _initProfiling(): void {\n    try {\n      this.querySet = this.device.createQuerySet({\n        type: 'timestamp',\n        count: CommandRecorder.MAX_QUERIES,\n      });\n\n      // Buffer to hold query results (8 bytes per timestamp = BigUint64)\n      this.queryBuffer = this.device.createBuffer({\n        label: `${this.label}_query_buffer`,\n        size: CommandRecorder.MAX_QUERIES * 8,\n        usage: GPUBufferUsage.QUERY_RESOLVE | GPUBufferUsage.COPY_SRC,\n      });\n\n      // Readback buffer\n      this.readbackBuffer = this.device.createBuffer({\n        label: `${this.label}_readback_buffer`,\n        size: CommandRecorder.MAX_QUERIES * 8,\n        usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,\n      });\n    } catch (e) {\n      log.warn('CommandRecorder', `Failed to initialize profiling: ${e}`);\n      this.profilingEnabled = false;\n    }\n  }\n\n  /**\n   * Check if profiling is enabled and available.\n   */\n  isProfilingEnabled(): boolean {\n    return this.profilingEnabled;\n  }\n\n  /**\n   * Create a temporary buffer that will be destroyed after submit.\n   * Use for uniform buffers and other per-operation temporaries.\n   *\n   * @param size - Buffer size in bytes\n   * @param usage - Buffer usage flags\n   * @param label - Buffer label for debugging\n   * @returns GPUBuffer\n   */\n  createTempBuffer(size: number, usage: GPUBufferUsageFlags, label: string = 'temp_buffer'): GPUBuffer {\n    if (this.submitted) {\n      throw new Error('[CommandRecorder] Cannot create buffers after submit');\n    }\n\n    const buffer = this.device.createBuffer({\n      label: `${this.label}_${label}_${this.tempBuffers.length}`,\n      size,\n      usage,\n    });\n    trackAllocation(size, label);\n\n    this.tempBuffers.push(buffer);\n    return buffer;\n  }\n\n  /**\n   * Create an indirect dispatch buffer initialized with workgroup counts.\n   * Buffer usage includes STORAGE so GPU kernels can update counts.\n   */\n  createIndirectDispatchBuffer(\n    workgroups: [number, number, number] | Uint32Array = [0, 0, 0],\n    label: string = 'indirect_dispatch'\n  ): GPUBuffer {\n    const data = workgroups instanceof Uint32Array\n      ? workgroups\n      : new Uint32Array(workgroups);\n    const size = Math.max(12, data.byteLength);\n    const buffer = this.createTempBuffer(\n      size,\n      GPUBufferUsage.INDIRECT | GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,\n      label\n    );\n    const source = data.buffer as ArrayBuffer;\n    this.device.queue.writeBuffer(buffer, 0, source, data.byteOffset, data.byteLength);\n    return buffer;\n  }\n\n  /**\n   * Update an indirect dispatch buffer with new workgroup counts.\n   */\n  writeIndirectDispatchBuffer(\n    buffer: GPUBuffer,\n    workgroups: [number, number, number] | Uint32Array,\n    offset: number = 0\n  ): void {\n    if (this.submitted) {\n      throw new Error('[CommandRecorder] Cannot write buffers after submit');\n    }\n    const data = workgroups instanceof Uint32Array\n      ? workgroups\n      : new Uint32Array(workgroups);\n    const source = data.buffer as ArrayBuffer;\n    this.device.queue.writeBuffer(buffer, offset, source, data.byteOffset, data.byteLength);\n  }\n\n  /**\n   * Create a uniform buffer, write data, and track for cleanup.\n   * Uses content-addressed caching for identical uniform data.\n   *\n   * @param data - Data to write\n   * @param label - Buffer label\n   * @returns GPUBuffer\n   */\n  createUniformBuffer(data: ArrayBuffer | ArrayBufferView, label: string = 'uniforms'): GPUBuffer {\n    // Convert ArrayBufferView to ArrayBuffer for caching\n    const arrayBuffer = data instanceof ArrayBuffer\n      ? data\n      : data.buffer.slice(data.byteOffset, data.byteOffset + data.byteLength);\n\n    // Use content-addressed cache for uniform buffers\n    // Cache handles creation, writeBuffer, and lifecycle - no cleanup needed\n    return getUniformCache().getOrCreate(arrayBuffer, label);\n  }\n\n  /**\n   * Begin a compute pass on the encoder.\n   * When profiling is enabled, injects timestampWrites to measure GPU execution time.\n   *\n   * @param label - Pass label for debugging (used as key in profile results)\n   * @returns GPUComputePassEncoder\n   */\n  beginComputePass(label: string = 'compute_pass'): GPUComputePassEncoder {\n    if (this.submitted) {\n      throw new Error('[CommandRecorder] Cannot begin pass after submit');\n    }\n    this.opCount++;\n\n    const passLabel = `${this.label}_${label}_${this.opCount}`;\n\n    // If profiling enabled, add timestamp writes\n    if (this.profilingEnabled && this.querySet && this.nextQueryIndex + 2 <= CommandRecorder.MAX_QUERIES) {\n      const startIndex = this.nextQueryIndex;\n      const endIndex = startIndex + 1;\n      this.nextQueryIndex += 2;\n\n      // Track this entry for later resolution\n      this.profileEntries.push({\n        label,\n        startQueryIndex: startIndex,\n        endQueryIndex: endIndex,\n      });\n\n      return this.encoder.beginComputePass({\n        label: passLabel,\n        timestampWrites: {\n          querySet: this.querySet,\n          beginningOfPassWriteIndex: startIndex,\n          endOfPassWriteIndex: endIndex,\n        },\n      });\n    }\n\n    // Non-profiling path\n    return this.encoder.beginComputePass({\n      label: passLabel,\n    });\n  }\n\n  /**\n   * Get the raw encoder for advanced use cases.\n   * @returns GPUCommandEncoder\n   */\n  getEncoder(): GPUCommandEncoder {\n    if (this.submitted) {\n      throw new Error('[CommandRecorder] Cannot access encoder after submit');\n    }\n    return this.encoder;\n  }\n\n  /**\n   * Track an externally created buffer for cleanup after submit.\n   * Use for buffers created outside the recorder that need cleanup.\n   *\n   * @param buffer - Buffer to track for destruction\n   */\n  trackTemporaryBuffer(buffer: GPUBuffer): void {\n    if (this.submitted) {\n      throw new Error('[CommandRecorder] Cannot track buffers after submit');\n    }\n    this.tempBuffers.push(buffer);\n  }\n\n  /**\n   * Submit all recorded commands and clean up temporary buffers.\n   * After calling this, the recorder cannot be reused.\n   */\n  submit(): void {\n    if (this.submitted) {\n      throw new Error('[CommandRecorder] Already submitted');\n    }\n\n    // Submit commands\n    this.device.queue.submit([this.encoder.finish()]);\n    this.submitted = true;\n\n    const buffersToDestroy = this.tempBuffers;\n    this.tempBuffers = [];\n\n    this.cleanupPromise = this.device.queue.onSubmittedWorkDone().then(() => {\n      for (const buffer of buffersToDestroy) {\n        buffer.destroy();\n      }\n      // Safe to destroy evicted uniform buffers now that GPU work is complete\n      getUniformCache().flushPendingDestruction();\n    }).catch((err) => {\n      log.warn('CommandRecorder', `Deferred cleanup failed: ${(err as Error).message}`);\n    });\n  }\n\n  /**\n   * Submit and wait for GPU to complete (useful for debugging/profiling).\n   * Also flushes the uniform cache's pending destruction queue to clean up\n   * any evicted buffers that were referenced by this command buffer.\n   * @returns Promise that resolves when GPU work is done\n   */\n  async submitAndWait(): Promise<void> {\n    this.submit();\n    if (this.cleanupPromise) {\n      await this.cleanupPromise;\n    } else {\n      await this.device.queue.onSubmittedWorkDone();\n      // Safe to destroy evicted uniform buffers now that GPU work is complete\n      getUniformCache().flushPendingDestruction();\n    }\n  }\n\n  /**\n   * Get statistics about recorded operations.\n   * @returns Statistics object\n   */\n  getStats(): RecorderStats {\n    return {\n      opCount: this.opCount,\n      tempBufferCount: this.tempBuffers.length,\n      submitted: this.submitted,\n    };\n  }\n\n  /**\n   * Abort recording without submitting (cleanup only).\n   * Use if an error occurs during recording.\n   */\n  abort(): void {\n    if (this.submitted) return;\n\n    // Destroy temp buffers without submitting\n    for (const buffer of this.tempBuffers) {\n      buffer.destroy();\n    }\n    this.tempBuffers = [];\n    this._destroyProfilingResources();\n    this.submitted = true; // Prevent further use\n  }\n\n  /**\n   * Resolve profiling timestamps and return per-kernel timings.\n   * Must be called after submit() and GPU work is done.\n   *\n   * Returns a map of kernel label to execution time in milliseconds.\n   * Labels with multiple invocations are aggregated (e.g., 'matmul' across all layers).\n   *\n   * @returns Promise resolving to timing map, or null if profiling not enabled\n   */\n  async resolveProfileTimings(): Promise<ProfileTimings | null> {\n    if (!this.profilingEnabled || !this.querySet || !this.queryBuffer || !this.readbackBuffer) {\n      return null;\n    }\n\n    if (!this.submitted) {\n      throw new Error('[CommandRecorder] Must submit before resolving timings');\n    }\n\n    if (this.profileEntries.length === 0) {\n      return {};\n    }\n\n    // Wait for GPU work to complete\n    await this.device.queue.onSubmittedWorkDone();\n\n    // Resolve queries to buffer\n    const maxIndex = Math.max(...this.profileEntries.map(e => e.endQueryIndex)) + 1;\n    const resolveEncoder = this.device.createCommandEncoder({ label: 'profile_resolve' });\n    resolveEncoder.resolveQuerySet(this.querySet, 0, maxIndex, this.queryBuffer, 0);\n    resolveEncoder.copyBufferToBuffer(this.queryBuffer, 0, this.readbackBuffer, 0, maxIndex * 8);\n    this.device.queue.submit([resolveEncoder.finish()]);\n\n    if (!allowReadback('CommandRecorder.resolveProfileTimings')) {\n      return null;\n    }\n\n    // Read back timestamps\n    await this.readbackBuffer.mapAsync(GPUMapMode.READ);\n    const timestamps = new BigUint64Array(this.readbackBuffer.getMappedRange());\n\n    // Aggregate timings by label\n    const timings: ProfileTimings = {};\n\n    for (const entry of this.profileEntries) {\n      const startNs = timestamps[entry.startQueryIndex];\n      const endNs = timestamps[entry.endQueryIndex];\n      const durationMs = Number(endNs - startNs) / 1_000_000;\n\n      // Skip invalid timings\n      if (durationMs < 0 || durationMs > 60000) {\n        continue;\n      }\n\n      // Aggregate by label\n      if (timings[entry.label] !== undefined) {\n        timings[entry.label] += durationMs;\n      } else {\n        timings[entry.label] = durationMs;\n      }\n    }\n\n    this.readbackBuffer.unmap();\n\n    // Clean up profiling resources after use\n    this._destroyProfilingResources();\n\n    return timings;\n  }\n\n  /**\n   * Get a formatted profiling report.\n   * Must be called after resolveProfileTimings().\n   *\n   * @param timings - Timings from resolveProfileTimings()\n   * @returns Formatted string report\n   */\n  static formatProfileReport(timings: ProfileTimings): string {\n    const entries = Object.entries(timings).sort((a, b) => b[1] - a[1]);\n    const total = entries.reduce((sum, [, t]) => sum + t, 0);\n\n    let report = 'GPU Profile Report\\n';\n    report += '\u2500'.repeat(50) + '\\n';\n    report += 'Kernel'.padEnd(25) + 'Time (ms)'.padStart(12) + '%'.padStart(8) + '\\n';\n    report += '\u2500'.repeat(50) + '\\n';\n\n    for (const [label, time] of entries) {\n      const pct = (time / total * 100).toFixed(1);\n      report += label.padEnd(25) + time.toFixed(2).padStart(12) + pct.padStart(8) + '\\n';\n    }\n\n    report += '\u2500'.repeat(50) + '\\n';\n    report += 'TOTAL'.padEnd(25) + total.toFixed(2).padStart(12) + '100.0'.padStart(8) + '\\n';\n\n    return report;\n  }\n\n  /**\n   * Clean up profiling resources.\n   * @private\n   */\n  private _destroyProfilingResources(): void {\n    if (this.querySet) {\n      this.querySet.destroy();\n      this.querySet = null;\n    }\n    if (this.queryBuffer) {\n      this.queryBuffer.destroy();\n      this.queryBuffer = null;\n    }\n    if (this.readbackBuffer) {\n      this.readbackBuffer.destroy();\n      this.readbackBuffer = null;\n    }\n    this.profileEntries = [];\n  }\n}\n\n/**\n * Create a new CommandRecorder.\n * @param label - Label for debugging\n * @param options - Recorder options\n * @returns CommandRecorder instance\n */\nexport function createCommandRecorder(label: string = 'command_recorder', options?: RecorderOptions): CommandRecorder {\n  return new CommandRecorder(null, label, options);\n}\n\n/**\n * Create a profiling-enabled CommandRecorder.\n * Falls back to non-profiling if timestamp-query not available.\n *\n * @param label - Label for debugging\n * @returns CommandRecorder with profiling enabled\n */\nexport function createProfilingRecorder(label: string = 'profiled_recorder'): CommandRecorder {\n  return new CommandRecorder(null, label, { profile: true });\n}\n\nexport default CommandRecorder;\n", "/**\n * Kernel Benchmark Harness (Tier 2 P0)\n *\n * Infrastructure to measure kernel performance with comprehensive metrics:\n * - Throughput (GB/s)\n * - Latency (ms)\n * - FLOPS (computational efficiency)\n * - Before/after comparisons\n *\n * Outputs JSON results for tracking performance over time.\n */\n\nimport { getDevice, getDeviceLimits, getKernelCapabilities } from './device.js';\nimport { acquireBuffer, releaseBuffer } from './buffer-pool.js';\nimport { createTensor } from './tensor.js';\nimport { runMatmul } from './kernels/matmul.js';\nimport { runRMSNorm } from './kernels/rmsnorm.js';\nimport { runAttention } from './kernels/attention.js';\nimport { runSiLU } from './kernels/silu.js';\nimport { PERFORMANCE } from './kernels/constants.js';\nimport { log, trace } from '../debug/index.js';\n\n/** Benchmark result for a single kernel */\nexport interface KernelBenchmarkResult {\n  kernel: string;\n  variant: string;\n  config: Record<string, number>;\n  latency: {\n    median_ms: number;\n    min_ms: number;\n    max_ms: number;\n    p95_ms: number;\n    p99_ms: number;\n    stddev_ms: number;\n  };\n  throughput: {\n    gb_per_sec: number;\n    elements_per_sec: number;\n  };\n  flops: {\n    gflops: number;\n    theoretical_gflops: number;\n    efficiency_pct: number;\n  };\n  memory: {\n    read_bytes: number;\n    write_bytes: number;\n    total_bytes: number;\n  };\n  iterations: number;\n  warmup_iterations: number;\n  timestamp: string;\n}\n\n/** Comparison result between two benchmark runs */\nexport interface BenchmarkComparison {\n  baseline: KernelBenchmarkResult;\n  optimized: KernelBenchmarkResult;\n  speedup: number;\n  latency_reduction_pct: number;\n  throughput_increase_pct: number;\n}\n\n/** Full benchmark report */\nexport interface BenchmarkReport {\n  device_info: {\n    vendor: string;\n    architecture: string;\n    max_workgroup_size: number;\n    max_shared_memory: number;\n    has_f16: boolean;\n    has_subgroups: boolean;\n  };\n  model_config: {\n    name: string;\n    hidden_size: number;\n    intermediate_size: number;\n    num_heads: number;\n    num_kv_heads: number;\n    head_dim: number;\n    num_layers: number;\n    vocab_size: number;\n  };\n  results: KernelBenchmarkResult[];\n  comparisons: BenchmarkComparison[];\n  summary: {\n    total_decode_latency_ms: number;\n    estimated_tok_per_sec: number;\n    bottleneck_kernel: string;\n    bottleneck_percentage: number;\n  };\n  generated_at: string;\n}\n\n/** Benchmark configuration */\nexport interface BenchmarkConfig {\n  warmupIterations?: number;\n  timedIterations?: number;\n  modelConfig?: {\n    hiddenSize?: number;\n    intermediateSize?: number;\n    numHeads?: number;\n    numKVHeads?: number;\n    headDim?: number;\n    vocabSize?: number;\n    numLayers?: number;\n  };\n}\n\nconst DEFAULT_CONFIG: Required<BenchmarkConfig> = {\n  warmupIterations: PERFORMANCE.WARMUP_RUNS,\n  timedIterations: PERFORMANCE.TIMED_RUNS,\n  modelConfig: {\n    hiddenSize: 1152,       // Gemma 3 1B\n    intermediateSize: 6912, // Gemma 3 1B\n    numHeads: 4,            // Gemma 3 1B\n    numKVHeads: 1,          // Gemma 3 1B (GQA)\n    headDim: 256,           // Gemma 3 1B\n    vocabSize: 262144,      // Gemma 3 1B\n    numLayers: 26,          // Gemma 3 1B\n  },\n};\n\n/**\n * Calculate statistics from timing array\n */\nfunction calculateStats(times: number[]): {\n  median: number;\n  min: number;\n  max: number;\n  p95: number;\n  p99: number;\n  stddev: number;\n  mean: number;\n} {\n  const sorted = [...times].sort((a, b) => a - b);\n  const n = sorted.length;\n\n  const mean = times.reduce((a, b) => a + b, 0) / n;\n  const variance = times.reduce((sum, t) => sum + (t - mean) ** 2, 0) / n;\n  const stddev = Math.sqrt(variance);\n\n  return {\n    median: sorted[Math.floor(n / 2)],\n    min: sorted[0],\n    max: sorted[n - 1],\n    p95: sorted[Math.floor(n * 0.95)],\n    p99: sorted[Math.floor(n * 0.99)],\n    stddev,\n    mean,\n  };\n}\n\n/**\n * Estimate FLOPS for different kernel types\n */\nfunction estimateFLOPS(\n  kernel: string,\n  config: Record<string, number>,\n  latencyMs: number\n): { gflops: number; theoretical: number } {\n  let flops = 0;\n\n  switch (kernel) {\n    case 'matmul':\n      // GEMM: 2 * M * N * K FLOPs\n      flops = 2 * (config.M || 1) * (config.N || 1) * (config.K || 1);\n      break;\n    case 'attention':\n      // QK^T: 2 * seqLen * kvLen * headDim * numHeads\n      // softmax: ~5 * seqLen * kvLen * numHeads\n      // V: 2 * seqLen * kvLen * headDim * numHeads\n      const qk = 2 * (config.seqLen || 1) * (config.kvLen || 1) * (config.headDim || 128) * (config.numHeads || 1);\n      const sm = 5 * (config.seqLen || 1) * (config.kvLen || 1) * (config.numHeads || 1);\n      const v = 2 * (config.seqLen || 1) * (config.kvLen || 1) * (config.headDim || 128) * (config.numHeads || 1);\n      flops = qk + sm + v;\n      break;\n    case 'rmsnorm':\n      // 2 * size (for variance) + 2 * size (for normalize)\n      flops = 4 * (config.size || 1);\n      break;\n    case 'silu':\n      // 2 ops per element (sigmoid, multiply)\n      flops = 2 * (config.size || 1);\n      break;\n    default:\n      flops = config.size || config.elements || 1;\n  }\n\n  const gflops = flops / (latencyMs * 1e6);\n  // Theoretical peak: ~10 TFLOPS for M1 Pro, ~20 TFLOPS for M1 Max\n  const theoretical = 10000; // Conservative estimate\n\n  return { gflops, theoretical };\n}\n\n/**\n * Create random test buffer\n */\nfunction createTestBuffer(size: number, label: string): GPUBuffer {\n  const buffer = acquireBuffer(size, undefined, label);\n  const device = getDevice();\n\n  // Initialize with random data\n  const data = new Float32Array(size / 4);\n  for (let i = 0; i < data.length; i++) {\n    data[i] = (Math.random() - 0.5) * 2;\n  }\n  device.queue.writeBuffer(buffer, 0, data);\n\n  return buffer;\n}\n\n/**\n * Benchmark a single kernel execution\n */\nasync function benchmarkKernel(\n  name: string,\n  variant: string,\n  config: Record<string, number>,\n  runFn: () => Promise<void>,\n  warmupIterations: number,\n  timedIterations: number\n): Promise<KernelBenchmarkResult> {\n  const device = getDevice();\n\n  // Warmup\n  for (let i = 0; i < warmupIterations; i++) {\n    await runFn();\n    await device.queue.onSubmittedWorkDone();\n  }\n\n  // Timed runs\n  const times: number[] = [];\n  for (let i = 0; i < timedIterations; i++) {\n    const start = performance.now();\n    await runFn();\n    await device.queue.onSubmittedWorkDone();\n    times.push(performance.now() - start);\n  }\n\n  const stats = calculateStats(times);\n  const flopsInfo = estimateFLOPS(name, config, stats.median);\n\n  // Calculate memory bandwidth\n  const readBytes = config.readBytes || config.size * 4 || 0;\n  const writeBytes = config.writeBytes || config.size * 4 || 0;\n  const totalBytes = readBytes + writeBytes;\n  const gbPerSec = totalBytes / (stats.median * 1e6);\n\n  return {\n    kernel: name,\n    variant,\n    config,\n    latency: {\n      median_ms: stats.median,\n      min_ms: stats.min,\n      max_ms: stats.max,\n      p95_ms: stats.p95,\n      p99_ms: stats.p99,\n      stddev_ms: stats.stddev,\n    },\n    throughput: {\n      gb_per_sec: gbPerSec,\n      elements_per_sec: (config.size || config.elements || 1) / (stats.median / 1000),\n    },\n    flops: {\n      gflops: flopsInfo.gflops,\n      theoretical_gflops: flopsInfo.theoretical,\n      efficiency_pct: (flopsInfo.gflops / flopsInfo.theoretical) * 100,\n    },\n    memory: {\n      read_bytes: readBytes,\n      write_bytes: writeBytes,\n      total_bytes: totalBytes,\n    },\n    iterations: timedIterations,\n    warmup_iterations: warmupIterations,\n    timestamp: new Date().toISOString(),\n  };\n}\n\n/**\n * Benchmark matmul kernel\n */\nexport async function benchmarkMatmul(\n  M: number,\n  N: number,\n  K: number,\n  options: BenchmarkConfig = {}\n): Promise<KernelBenchmarkResult> {\n  const config = { ...DEFAULT_CONFIG, ...options };\n  const device = getDevice();\n\n  const A = createTestBuffer(M * K * 4, 'bench_A');\n  const B = createTestBuffer(K * N * 4, 'bench_B');\n  const tensorA = createTensor(A, 'f32', [M, K], 'bench_A');\n\n  const result = await benchmarkKernel(\n    'matmul',\n    'f32',\n    {\n      M, N, K,\n      readBytes: (M * K + K * N) * 4,\n      writeBytes: M * N * 4,\n    },\n    async () => {\n      const C = await runMatmul(tensorA, B, M, N, K);\n      releaseBuffer(C.buffer);\n    },\n    config.warmupIterations,\n    config.timedIterations\n  );\n\n  releaseBuffer(A);\n  releaseBuffer(B);\n\n  return result;\n}\n\n/**\n * Benchmark attention decode kernel\n */\nexport async function benchmarkAttentionDecode(\n  numHeads: number,\n  headDim: number,\n  kvLen: number,\n  options: BenchmarkConfig = {}\n): Promise<KernelBenchmarkResult> {\n  const config = { ...DEFAULT_CONFIG, ...options };\n\n  const QBuf = createTestBuffer(numHeads * headDim * 4, 'bench_Q');\n  const KBuf = createTestBuffer(kvLen * numHeads * headDim * 4, 'bench_K');\n  const VBuf = createTestBuffer(kvLen * numHeads * headDim * 4, 'bench_V');\n  const Q = createTensor(QBuf, 'f32', [1, numHeads * headDim], 'bench_Q');\n  const K = createTensor(KBuf, 'f32', [kvLen, numHeads * headDim], 'bench_K');\n  const V = createTensor(VBuf, 'f32', [kvLen, numHeads * headDim], 'bench_V');\n\n  const result = await benchmarkKernel(\n    'attention',\n    'decode',\n    {\n      seqLen: 1,\n      kvLen,\n      numHeads,\n      headDim,\n      readBytes: (numHeads * headDim + 2 * kvLen * numHeads * headDim) * 4,\n      writeBytes: numHeads * headDim * 4,\n    },\n    async () => {\n      const out = await runAttention(Q, K, V, null, numHeads, headDim, {\n        seqLen: 1,\n        kvLen,\n        numKVHeads: numHeads,\n      });\n      releaseBuffer(out.buffer);\n    },\n    config.warmupIterations,\n    config.timedIterations\n  );\n\n  releaseBuffer(QBuf);\n  releaseBuffer(KBuf);\n  releaseBuffer(VBuf);\n\n  return result;\n}\n\n/**\n * Benchmark RMSNorm kernel\n */\nexport async function benchmarkRMSNorm(\n  batchSize: number,\n  hiddenSize: number,\n  options: BenchmarkConfig = {}\n): Promise<KernelBenchmarkResult> {\n  const config = { ...DEFAULT_CONFIG, ...options };\n\n  const size = batchSize * hiddenSize;\n  const input = createTestBuffer(size * 4, 'bench_input');\n  const weight = createTestBuffer(hiddenSize * 4, 'bench_weight');\n  const inputTensor = createTensor(input, 'f32', [batchSize, hiddenSize], 'bench_input');\n\n  const result = await benchmarkKernel(\n    'rmsnorm',\n    'default',\n    {\n      batchSize,\n      hiddenSize,\n      size,\n      readBytes: (size + hiddenSize) * 4,\n      writeBytes: size * 4,\n    },\n    async () => {\n      const out = await runRMSNorm(inputTensor, weight, 1e-6, { batchSize, hiddenSize });\n      releaseBuffer(out.buffer);\n    },\n    config.warmupIterations,\n    config.timedIterations\n  );\n\n  releaseBuffer(input);\n  releaseBuffer(weight);\n\n  return result;\n}\n\n/**\n * Benchmark SiLU kernel\n */\nexport async function benchmarkSiLU(\n  size: number,\n  options: BenchmarkConfig = {}\n): Promise<KernelBenchmarkResult> {\n  const config = { ...DEFAULT_CONFIG, ...options };\n\n  const input = createTestBuffer(size * 4, 'bench_input');\n  const inputTensor = createTensor(input, 'f32', [size], 'bench_input');\n\n  const result = await benchmarkKernel(\n    'silu',\n    'default',\n    {\n      size,\n      readBytes: size * 4,\n      writeBytes: size * 4,\n    },\n    async () => {\n      const out = await runSiLU(inputTensor, { size });\n      releaseBuffer(out.buffer);\n    },\n    config.warmupIterations,\n    config.timedIterations\n  );\n\n  releaseBuffer(input);\n\n  return result;\n}\n\n/**\n * Benchmark fused Matmul+RMSNorm kernel\n *\n * Compares separate matmul + rmsnorm vs fused kernel for decode (M=1)\n */\nexport async function benchmarkMatmulRMSNormFused(\n  N: number,  // hiddenSize (output)\n  K: number,  // intermediateSize (input)\n  options: BenchmarkConfig = {}\n): Promise<{\n  separate: KernelBenchmarkResult;\n  fused: KernelBenchmarkResult;\n  comparison: BenchmarkComparison;\n}> {\n  const config = { ...DEFAULT_CONFIG, ...options };\n\n  // Import fused kernel\n  const { runMatmulRMSNormFused, shouldUseFusedMatmulRMSNorm } = await import('./kernels/fused_matmul_rmsnorm.js');\n\n  if (!shouldUseFusedMatmulRMSNorm(1, N)) {\n    throw new Error(`Fused kernel not supported for N=${N} with current thresholds.`);\n  }\n\n  const input = createTestBuffer(K * 4, 'bench_input');\n  const weight = createTestBuffer(K * N * 4, 'bench_weight');\n  const normWeight = createTestBuffer(N * 4, 'bench_norm_weight');\n  const residual = createTestBuffer(N * 4, 'bench_residual');\n  const inputTensor = createTensor(input, 'f32', [1, K], 'bench_input');\n  const residualTensor = createTensor(residual, 'f32', [1, N], 'bench_residual');\n\n  // Benchmark separate: matmul + rmsnorm\n  const separateResult = await benchmarkKernel(\n    'matmul+rmsnorm',\n    'separate',\n    {\n      M: 1, N, K,\n      readBytes: (K + K * N + N + N) * 4,  // input + weight + norm_weight + residual\n      writeBytes: N * 4,\n    },\n    async () => {\n      const matmulOut = await runMatmul(inputTensor, weight, 1, N, K);\n      const normOut = await runRMSNorm(matmulOut, normWeight, 1e-6, {\n        batchSize: 1,\n        hiddenSize: N,\n        residual: residualTensor,\n      });\n      releaseBuffer(matmulOut.buffer);\n      releaseBuffer(normOut.buffer);\n    },\n    config.warmupIterations,\n    config.timedIterations\n  );\n\n  // Benchmark fused: matmul+rmsnorm in one kernel\n  const fusedResult = await benchmarkKernel(\n    'matmul+rmsnorm',\n    'fused',\n    {\n      M: 1, N, K,\n      readBytes: (K + K * N + N + N) * 4,\n      writeBytes: N * 4,\n    },\n    async () => {\n      const out = await runMatmulRMSNormFused(inputTensor, weight, normWeight, {\n        N, K,\n        eps: 1e-6,\n        residual: residual,  // fused kernel still takes GPUBuffer for residual\n      });\n      releaseBuffer(out.buffer);\n    },\n    config.warmupIterations,\n    config.timedIterations\n  );\n\n  releaseBuffer(input);\n  releaseBuffer(weight);\n  releaseBuffer(normWeight);\n  releaseBuffer(residual);\n\n  // Calculate comparison\n  const speedup = separateResult.latency.median_ms / fusedResult.latency.median_ms;\n  const comparison: BenchmarkComparison = {\n    baseline: separateResult,\n    optimized: fusedResult,\n    speedup,\n    latency_reduction_pct: (1 - fusedResult.latency.median_ms / separateResult.latency.median_ms) * 100,\n    throughput_increase_pct: (speedup - 1) * 100,\n  };\n\n  trace.perf(`Benchmark: Matmul+RMSNorm (N=${N}, K=${K}): Separate: ${separateResult.latency.median_ms.toFixed(3)}ms, Fused: ${fusedResult.latency.median_ms.toFixed(3)}ms, Speedup: ${speedup.toFixed(2)}x`);\n\n  return { separate: separateResult, fused: fusedResult, comparison };\n}\n\n/**\n * Run comprehensive decode benchmark (one token generation)\n */\nexport async function benchmarkDecodePass(\n  options: BenchmarkConfig = {}\n): Promise<BenchmarkReport> {\n  const config = { ...DEFAULT_CONFIG.modelConfig, ...options.modelConfig };\n  const device = getDevice();\n  const limits = getDeviceLimits();\n  const caps = getKernelCapabilities();\n\n  const results: KernelBenchmarkResult[] = [];\n\n  trace.perf(`Benchmark: Starting decode pass benchmark... Model config: hidden=${config.hiddenSize}, intermediate=${config.intermediateSize}, heads=${config.numHeads}`);\n\n  // 1. RMSNorm (input normalization)\n  trace.perf('Benchmark: Running RMSNorm...');\n  results.push(await benchmarkRMSNorm(1, config.hiddenSize, options));\n\n  // 2. QKV projection matmul\n  trace.perf('Benchmark: Running QKV projection...');\n  const qkvDim = (config.numHeads + 2 * config.numKVHeads) * config.headDim;\n  results.push(await benchmarkMatmul(1, qkvDim, config.hiddenSize, options));\n\n  // 3. Attention (decode)\n  trace.perf('Benchmark: Running Attention decode...');\n  const kvLen = 512; // Simulate 512 token context\n  results.push(await benchmarkAttentionDecode(config.numHeads, config.headDim, kvLen, options));\n\n  // 4. Output projection matmul\n  trace.perf('Benchmark: Running output projection...');\n  results.push(await benchmarkMatmul(1, config.hiddenSize, config.numHeads * config.headDim, options));\n\n  // 5. FFN gate+up projection\n  trace.perf('Benchmark: Running FFN gate+up...');\n  results.push(await benchmarkMatmul(1, config.intermediateSize * 2, config.hiddenSize, options));\n\n  // 6. SiLU activation\n  trace.perf('Benchmark: Running SiLU...');\n  results.push(await benchmarkSiLU(config.intermediateSize, options));\n\n  // 7. FFN down projection\n  trace.perf('Benchmark: Running FFN down...');\n  results.push(await benchmarkMatmul(1, config.hiddenSize, config.intermediateSize, options));\n\n  // 8. Final RMSNorm\n  trace.perf('Benchmark: Running final RMSNorm...');\n  results.push(await benchmarkRMSNorm(1, config.hiddenSize, options));\n\n  // 9. LM head projection\n  trace.perf('Benchmark: Running LM head...');\n  results.push(await benchmarkMatmul(1, config.vocabSize, config.hiddenSize, options));\n\n  // Calculate summary\n  const perLayerLatency = results.slice(0, 8).reduce((sum, r) => sum + r.latency.median_ms, 0);\n  const lmHeadLatency = results[8].latency.median_ms;\n  const totalDecodeLatency = perLayerLatency * config.numLayers + lmHeadLatency;\n  const tokPerSec = 1000 / totalDecodeLatency;\n\n  // Find bottleneck\n  const sortedByLatency = [...results].sort((a, b) => b.latency.median_ms - a.latency.median_ms);\n  const bottleneck = sortedByLatency[0];\n  const bottleneckPct = (bottleneck.latency.median_ms / totalDecodeLatency) * 100;\n\n  const report: BenchmarkReport = {\n    device_info: {\n      vendor: 'WebGPU',\n      architecture: 'Unknown',\n      max_workgroup_size: limits?.maxComputeInvocationsPerWorkgroup || 256,\n      max_shared_memory: limits?.maxComputeWorkgroupStorageSize || 16384,\n      has_f16: caps.hasF16,\n      has_subgroups: caps.hasSubgroups,\n    },\n    model_config: {\n      name: 'Gemma 3 1B',\n      hidden_size: config.hiddenSize,\n      intermediate_size: config.intermediateSize,\n      num_heads: config.numHeads,\n      num_kv_heads: config.numKVHeads,\n      head_dim: config.headDim,\n      num_layers: config.numLayers,\n      vocab_size: config.vocabSize,\n    },\n    results,\n    comparisons: [],\n    summary: {\n      total_decode_latency_ms: totalDecodeLatency,\n      estimated_tok_per_sec: tokPerSec,\n      bottleneck_kernel: `${bottleneck.kernel}/${bottleneck.variant}`,\n      bottleneck_percentage: bottleneckPct,\n    },\n    generated_at: new Date().toISOString(),\n  };\n\n  trace.perf(`Benchmark Summary: Total decode latency: ${totalDecodeLatency.toFixed(2)}ms, Estimated tokens/sec: ${tokPerSec.toFixed(1)}, Bottleneck: ${bottleneck.kernel} (${bottleneckPct.toFixed(1)}%)`);\n\n  return report;\n}\n\n/**\n * Compare two benchmark results\n */\nexport function compareBenchmarks(\n  baseline: KernelBenchmarkResult,\n  optimized: KernelBenchmarkResult\n): BenchmarkComparison {\n  const speedup = baseline.latency.median_ms / optimized.latency.median_ms;\n  const latencyReduction = ((baseline.latency.median_ms - optimized.latency.median_ms) / baseline.latency.median_ms) * 100;\n  const throughputIncrease = ((optimized.throughput.gb_per_sec - baseline.throughput.gb_per_sec) / baseline.throughput.gb_per_sec) * 100;\n\n  return {\n    baseline,\n    optimized,\n    speedup,\n    latency_reduction_pct: latencyReduction,\n    throughput_increase_pct: throughputIncrease,\n  };\n}\n\n/**\n * Export benchmark report as JSON\n */\nexport function exportBenchmarkJSON(report: BenchmarkReport): string {\n  return JSON.stringify(report, null, 2);\n}\n\n/**\n * Print benchmark report to console\n */\nexport function printBenchmarkReport(report: BenchmarkReport): void {\n  log.info('Benchmark', '='.repeat(60));\n  log.info('Benchmark', 'KERNEL BENCHMARK REPORT');\n  log.info('Benchmark', '='.repeat(60));\n\n  log.info('Benchmark', 'Device Info:');\n  log.info('Benchmark', `  Max Workgroup Size: ${report.device_info.max_workgroup_size}`);\n  log.info('Benchmark', `  Max Shared Memory: ${(report.device_info.max_shared_memory / 1024).toFixed(1)}KB`);\n  log.info('Benchmark', `  F16 Support: ${report.device_info.has_f16}`);\n  log.info('Benchmark', `  Subgroup Support: ${report.device_info.has_subgroups}`);\n\n  log.info('Benchmark', 'Model Config:');\n  log.info('Benchmark', `  Name: ${report.model_config.name}`);\n  log.info('Benchmark', `  Hidden Size: ${report.model_config.hidden_size}`);\n  log.info('Benchmark', `  Intermediate Size: ${report.model_config.intermediate_size}`);\n  log.info('Benchmark', `  Heads: ${report.model_config.num_heads} (KV: ${report.model_config.num_kv_heads})`);\n\n  log.info('Benchmark', 'Kernel Results:');\n  log.info('Benchmark', '-'.repeat(60));\n  log.info('Benchmark', 'Kernel           | Latency (ms) | GB/s    | GFLOPS');\n  log.info('Benchmark', '-'.repeat(60));\n\n  for (const r of report.results) {\n    log.info('Benchmark',\n      `${(r.kernel + '/' + r.variant).padEnd(16)} | ` +\n      `${r.latency.median_ms.toFixed(3).padStart(12)} | ` +\n      `${r.throughput.gb_per_sec.toFixed(2).padStart(7)} | ` +\n      `${r.flops.gflops.toFixed(1).padStart(7)}`\n    );\n  }\n\n  log.info('Benchmark', '-'.repeat(60));\n  log.info('Benchmark', 'Summary:');\n  log.info('Benchmark', `  Total Decode Latency: ${report.summary.total_decode_latency_ms.toFixed(2)}ms`);\n  log.info('Benchmark', `  Estimated Tokens/sec: ${report.summary.estimated_tok_per_sec.toFixed(1)}`);\n  log.info('Benchmark', `  Bottleneck: ${report.summary.bottleneck_kernel} (${report.summary.bottleneck_percentage.toFixed(1)}%)`);\n\n  if (report.comparisons.length > 0) {\n    log.info('Benchmark', 'Comparisons:');\n    for (const c of report.comparisons) {\n      log.info('Benchmark', `  ${c.baseline.kernel}: ${c.speedup.toFixed(2)}x speedup`);\n    }\n  }\n\n  log.info('Benchmark', '='.repeat(60));\n}\n", "/**\n * Split QKV Kernel\n *\n * Splits fused QKV projection output into separate Q, K, V buffers.\n * Used for 3\u21921 matmul optimization in attention.\n */\n\nimport { getDevice } from '../device.js';\nimport { acquireBuffer } from '../buffer-pool.js';\nimport type { CommandRecorder } from '../command-recorder.js';\nimport { createTensor, type Tensor, type TensorDtype, dtypeBytes } from '../tensor.js';\nimport { WORKGROUP_SIZES } from './constants.js';\nimport { dispatch, recordDispatch } from './dispatch.js';\nimport { getPipelineFast, createUniformBufferWithView } from './utils.js';\n\n/** Split QKV options */\nexport interface SplitQKVOptions {\n  numTokens: number;\n  qSize: number;  // numHeads * headDim\n  kSize: number;  // numKVHeads * headDim\n  vSize: number;  // numKVHeads * headDim\n  /** Pre-allocated Q output tensor */\n  qTensor?: Tensor | null;\n  /** Pre-allocated K output tensor */\n  kTensor?: Tensor | null;\n  /** Pre-allocated V output tensor */\n  vTensor?: Tensor | null;\n}\n\n/** Split QKV result */\nexport interface SplitQKVResult {\n  Q: Tensor;\n  K: Tensor;\n  V: Tensor;\n}\n\n/**\n * Split fused QKV output into separate Q, K, V tensors.\n *\n * @param qkvTensor - Fused QKV output [numTokens, qSize + kSize + vSize]\n * @param options - Split configuration\n * @returns Separate Q, K, V tensors\n */\nexport async function runSplitQKV(\n  qkvTensor: Tensor,\n  options: SplitQKVOptions\n): Promise<SplitQKVResult> {\n  const device = getDevice();\n  const { numTokens, qSize, kSize, vSize, qTensor = null, kTensor = null, vTensor = null } = options;\n\n  const pipeline = await getPipelineFast('split_qkv', 'default');\n\n  const outputDtype: TensorDtype = qkvTensor.dtype;\n  const bytesPerElement = dtypeBytes(outputDtype);\n\n  // Allocate output buffers if not provided\n  const qBuffer = qTensor?.buffer || acquireBuffer(numTokens * qSize * bytesPerElement, undefined, 'Q');\n  const kBuffer = kTensor?.buffer || acquireBuffer(numTokens * kSize * bytesPerElement, undefined, 'K');\n  const vBuffer = vTensor?.buffer || acquireBuffer(numTokens * vSize * bytesPerElement, undefined, 'V');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'split_qkv_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, qSize, true);\n      view.setUint32(8, kSize, true);\n      view.setUint32(12, vSize, true);\n    },\n    null,\n    device\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'split_qkv_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: qkvTensor.buffer } },\n      { binding: 2, resource: { buffer: qBuffer } },\n      { binding: 3, resource: { buffer: kBuffer } },\n      { binding: 4, resource: { buffer: vBuffer } },\n    ],\n  });\n\n  // Dispatch - total elements across all outputs\n  const totalElements = numTokens * (qSize + kSize + vSize);\n  const workgroups = Math.ceil(totalElements / WORKGROUP_SIZES.DEFAULT);\n  dispatch(device, pipeline, bindGroup, workgroups, 'split_qkv');\n\n  uniformBuffer.destroy();\n\n  const Q = qTensor || createTensor(qBuffer, outputDtype, [numTokens, qSize], 'Q');\n  const K = kTensor || createTensor(kBuffer, outputDtype, [numTokens, kSize], 'K');\n  const V = vTensor || createTensor(vBuffer, outputDtype, [numTokens, vSize], 'V');\n\n  return { Q, K, V };\n}\n\n/**\n * Record split QKV (batched, no submit).\n */\nexport async function recordSplitQKV(\n  recorder: CommandRecorder,\n  qkvTensor: Tensor,\n  options: SplitQKVOptions\n): Promise<SplitQKVResult> {\n  const device = recorder.device;\n  const { numTokens, qSize, kSize, vSize, qTensor = null, kTensor = null, vTensor = null } = options;\n\n  const pipeline = await getPipelineFast('split_qkv', 'default');\n\n  const outputDtype: TensorDtype = qkvTensor.dtype;\n  const bytesPerElement = dtypeBytes(outputDtype);\n\n  // Allocate output buffers if not provided\n  const qBuffer = qTensor?.buffer || acquireBuffer(numTokens * qSize * bytesPerElement, undefined, 'Q');\n  const kBuffer = kTensor?.buffer || acquireBuffer(numTokens * kSize * bytesPerElement, undefined, 'K');\n  const vBuffer = vTensor?.buffer || acquireBuffer(numTokens * vSize * bytesPerElement, undefined, 'V');\n\n  // Create uniform buffer\n  const uniformBuffer = createUniformBufferWithView(\n    'split_qkv_uniforms',\n    16,\n    (view) => {\n      view.setUint32(0, numTokens, true);\n      view.setUint32(4, qSize, true);\n      view.setUint32(8, kSize, true);\n      view.setUint32(12, vSize, true);\n    },\n    recorder\n  );\n\n  // Create bind group\n  const bindGroup = device.createBindGroup({\n    label: 'split_qkv_bind_group',\n    layout: pipeline.getBindGroupLayout(0),\n    entries: [\n      { binding: 0, resource: { buffer: uniformBuffer } },\n      { binding: 1, resource: { buffer: qkvTensor.buffer } },\n      { binding: 2, resource: { buffer: qBuffer } },\n      { binding: 3, resource: { buffer: kBuffer } },\n      { binding: 4, resource: { buffer: vBuffer } },\n    ],\n  });\n\n  // Dispatch\n  const totalElements = numTokens * (qSize + kSize + vSize);\n  const workgroups = Math.ceil(totalElements / WORKGROUP_SIZES.DEFAULT);\n  recordDispatch(recorder, pipeline, bindGroup, workgroups, 'split_qkv');\n\n  const Q = qTensor || createTensor(qBuffer, outputDtype, [numTokens, qSize], 'Q');\n  const K = kTensor || createTensor(kBuffer, outputDtype, [numTokens, kSize], 'K');\n  const V = vTensor || createTensor(vBuffer, outputDtype, [numTokens, vSize], 'V');\n\n  return { Q, K, V };\n}\n", "/**\n * Performance Profiler (Tier 2 P0)\n *\n * Real-time profiling utilities to identify performance bottlenecks\n * in the inference pipeline.\n *\n * Usage:\n * 1. Enable profiling: window.DOPPLER_PROFILE = true\n * 2. Run inference\n * 3. View results: log.info('Profile', 'Report', getProfileReport())\n */\n\nimport { getDevice } from './device.js';\nimport { log } from '../debug/index.js';\n\n/** Profile entry for a single operation */\nexport interface ProfileEntry {\n  name: string;\n  category: 'kernel' | 'memory' | 'sync' | 'other';\n  startTime: number;\n  endTime: number;\n  duration: number;\n  metadata?: Record<string, unknown>;\n}\n\n/** Profile report summary */\nexport interface ProfileReport {\n  entries: ProfileEntry[];\n  summary: {\n    totalTime: number;\n    kernelTime: number;\n    memoryTime: number;\n    syncTime: number;\n    otherTime: number;\n    kernelCount: number;\n    memoryOps: number;\n    syncOps: number;\n  };\n  breakdown: {\n    name: string;\n    totalTime: number;\n    count: number;\n    avgTime: number;\n    pctOfTotal: number;\n  }[];\n  bottlenecks: {\n    name: string;\n    impact: number;\n    suggestion: string;\n  }[];\n}\n\n/** Global profiler state */\nlet profilingEnabled = false;\nlet profileEntries: ProfileEntry[] = [];\nlet profileStartTime = 0;\n\n/**\n * Check if profiling is enabled\n */\nexport function isProfilingEnabled(): boolean {\n  if (typeof window !== 'undefined') {\n    return Boolean((window as unknown as { DOPPLER_PROFILE?: boolean }).DOPPLER_PROFILE);\n  }\n  return profilingEnabled;\n}\n\n/**\n * Enable/disable profiling\n */\nexport function setProfilingEnabled(enabled: boolean): void {\n  profilingEnabled = enabled;\n  if (typeof window !== 'undefined') {\n    (window as unknown as { DOPPLER_PROFILE?: boolean }).DOPPLER_PROFILE = enabled;\n  }\n}\n\n/**\n * Clear all profile entries\n */\nexport function clearProfile(): void {\n  profileEntries = [];\n  profileStartTime = 0;\n}\n\n/**\n * Start a new profiling session\n */\nexport function startProfileSession(): void {\n  clearProfile();\n  profileStartTime = performance.now();\n}\n\n/**\n * Record a profile entry\n */\nexport function recordProfileEntry(\n  name: string,\n  category: ProfileEntry['category'],\n  startTime: number,\n  endTime: number,\n  metadata?: Record<string, unknown>\n): void {\n  if (!isProfilingEnabled()) return;\n\n  profileEntries.push({\n    name,\n    category,\n    startTime,\n    endTime,\n    duration: endTime - startTime,\n    metadata,\n  });\n}\n\n/**\n * Profile an async operation\n */\nexport async function profileAsync<T>(\n  name: string,\n  category: ProfileEntry['category'],\n  fn: () => Promise<T>,\n  metadata?: Record<string, unknown>\n): Promise<T> {\n  if (!isProfilingEnabled()) {\n    return fn();\n  }\n\n  const startTime = performance.now();\n  try {\n    const result = await fn();\n    const endTime = performance.now();\n    recordProfileEntry(name, category, startTime, endTime, metadata);\n    return result;\n  } catch (error) {\n    const endTime = performance.now();\n    recordProfileEntry(name, category, startTime, endTime, { ...metadata, error: true });\n    throw error;\n  }\n}\n\n/**\n * Profile a sync operation\n */\nexport function profileSync<T>(\n  name: string,\n  category: ProfileEntry['category'],\n  fn: () => T,\n  metadata?: Record<string, unknown>\n): T {\n  if (!isProfilingEnabled()) {\n    return fn();\n  }\n\n  const startTime = performance.now();\n  try {\n    const result = fn();\n    const endTime = performance.now();\n    recordProfileEntry(name, category, startTime, endTime, metadata);\n    return result;\n  } catch (error) {\n    const endTime = performance.now();\n    recordProfileEntry(name, category, startTime, endTime, { ...metadata, error: true });\n    throw error;\n  }\n}\n\n/**\n * Profile a GPU kernel dispatch with queue sync\n */\nexport async function profileKernel(\n  name: string,\n  dispatchFn: () => void,\n  metadata?: Record<string, unknown>\n): Promise<void> {\n  if (!isProfilingEnabled()) {\n    dispatchFn();\n    return;\n  }\n\n  const device = getDevice();\n  const startTime = performance.now();\n\n  dispatchFn();\n\n  // Wait for GPU to finish\n  await device.queue.onSubmittedWorkDone();\n\n  const endTime = performance.now();\n  recordProfileEntry(name, 'kernel', startTime, endTime, metadata);\n}\n\n/**\n * Generate profile report\n */\nexport function getProfileReport(): ProfileReport {\n  const entries = [...profileEntries];\n  const totalTime = entries.reduce((sum, e) => sum + e.duration, 0);\n\n  // Calculate category totals\n  const kernelEntries = entries.filter(e => e.category === 'kernel');\n  const memoryEntries = entries.filter(e => e.category === 'memory');\n  const syncEntries = entries.filter(e => e.category === 'sync');\n  const otherEntries = entries.filter(e => e.category === 'other');\n\n  const kernelTime = kernelEntries.reduce((sum, e) => sum + e.duration, 0);\n  const memoryTime = memoryEntries.reduce((sum, e) => sum + e.duration, 0);\n  const syncTime = syncEntries.reduce((sum, e) => sum + e.duration, 0);\n  const otherTime = otherEntries.reduce((sum, e) => sum + e.duration, 0);\n\n  // Generate breakdown by operation name\n  const byName = new Map<string, { totalTime: number; count: number }>();\n  for (const entry of entries) {\n    const existing = byName.get(entry.name) || { totalTime: 0, count: 0 };\n    existing.totalTime += entry.duration;\n    existing.count += 1;\n    byName.set(entry.name, existing);\n  }\n\n  const breakdown = Array.from(byName.entries())\n    .map(([name, stats]) => ({\n      name,\n      totalTime: stats.totalTime,\n      count: stats.count,\n      avgTime: stats.totalTime / stats.count,\n      pctOfTotal: (stats.totalTime / totalTime) * 100,\n    }))\n    .sort((a, b) => b.totalTime - a.totalTime);\n\n  // Identify bottlenecks\n  const bottlenecks: ProfileReport['bottlenecks'] = [];\n\n  // Check for excessive sync operations\n  if (syncEntries.length > entries.length * 0.1) {\n    bottlenecks.push({\n      name: 'Excessive GPU Syncs',\n      impact: syncTime / totalTime,\n      suggestion: 'Use CommandRecorder to batch operations and reduce syncs',\n    });\n  }\n\n  // Check for memory-bound operations\n  if (memoryTime > kernelTime) {\n    bottlenecks.push({\n      name: 'Memory Bandwidth Bound',\n      impact: memoryTime / totalTime,\n      suggestion: 'Consider kernel fusion to reduce memory traffic',\n    });\n  }\n\n  // Check for small kernels (overhead-bound)\n  const smallKernels = kernelEntries.filter(e => e.duration < 0.1);\n  if (smallKernels.length > kernelEntries.length * 0.5) {\n    const smallKernelTime = smallKernels.reduce((sum, e) => sum + e.duration, 0);\n    bottlenecks.push({\n      name: 'Kernel Launch Overhead',\n      impact: smallKernelTime / totalTime,\n      suggestion: 'Batch small kernels or increase work per kernel',\n    });\n  }\n\n  // Check for dominant operations\n  for (const item of breakdown.slice(0, 3)) {\n    if (item.pctOfTotal > 30) {\n      bottlenecks.push({\n        name: `${item.name} dominates (${item.pctOfTotal.toFixed(1)}%)`,\n        impact: item.pctOfTotal / 100,\n        suggestion: `Optimize ${item.name} or check if it's using optimal variant`,\n      });\n    }\n  }\n\n  return {\n    entries,\n    summary: {\n      totalTime,\n      kernelTime,\n      memoryTime,\n      syncTime,\n      otherTime,\n      kernelCount: kernelEntries.length,\n      memoryOps: memoryEntries.length,\n      syncOps: syncEntries.length,\n    },\n    breakdown,\n    bottlenecks,\n  };\n}\n\n/**\n * Print profile report via debug log\n */\nexport function printProfileReport(report?: ProfileReport): void {\n  const r = report || getProfileReport();\n\n  log.info('Profile', '='.repeat(60));\n  log.info('Profile', 'PERFORMANCE PROFILE REPORT');\n  log.info('Profile', '='.repeat(60));\n\n  log.info('Profile', 'Summary:');\n  log.info('Profile', `  Total Time: ${r.summary.totalTime.toFixed(2)}ms`);\n  log.info('Profile', `  Kernel Time: ${r.summary.kernelTime.toFixed(2)}ms (${((r.summary.kernelTime / r.summary.totalTime) * 100).toFixed(1)}%)`);\n  log.info('Profile', `  Memory Time: ${r.summary.memoryTime.toFixed(2)}ms (${((r.summary.memoryTime / r.summary.totalTime) * 100).toFixed(1)}%)`);\n  log.info('Profile', `  Sync Time: ${r.summary.syncTime.toFixed(2)}ms (${((r.summary.syncTime / r.summary.totalTime) * 100).toFixed(1)}%)`);\n  log.info('Profile', `  Kernel Count: ${r.summary.kernelCount}`);\n\n  log.info('Profile', 'Top Operations:');\n  log.info('Profile', '-'.repeat(60));\n  log.info('Profile', 'Operation                    | Time (ms) | Count | % Total');\n  log.info('Profile', '-'.repeat(60));\n\n  for (const item of r.breakdown.slice(0, 10)) {\n    log.info('Profile',\n      `${item.name.padEnd(28)} | ${item.totalTime.toFixed(2).padStart(9)} | ` +\n      `${item.count.toString().padStart(5)} | ${item.pctOfTotal.toFixed(1).padStart(7)}%`\n    );\n  }\n\n  if (r.bottlenecks.length > 0) {\n    log.info('Profile', 'Bottlenecks:');\n    log.info('Profile', '-'.repeat(60));\n    for (const b of r.bottlenecks) {\n      log.info('Profile', `  [${(b.impact * 100).toFixed(0)}%] ${b.name}`);\n      log.info('Profile', `       Fix: ${b.suggestion}`);\n    }\n  }\n\n  log.info('Profile', '='.repeat(60));\n}\n\n/**\n * Export profile data as JSON\n */\nexport function exportProfileJSON(report?: ProfileReport): string {\n  return JSON.stringify(report || getProfileReport(), null, 2);\n}\n\n/**\n * Analyze decode performance and suggest optimizations\n */\nexport function analyzeDecodePerformance(\n  tokensGenerated: number,\n  totalTimeMs: number,\n  targetTokPerSec: number = 40\n): {\n  currentTokPerSec: number;\n  targetTokPerSec: number;\n  gap: number;\n  suggestions: string[];\n} {\n  const currentTokPerSec = (tokensGenerated / totalTimeMs) * 1000;\n  const gap = targetTokPerSec / currentTokPerSec;\n\n  const suggestions: string[] = [];\n\n  if (gap > 5) {\n    suggestions.push('Critical: Enable CommandRecorder for batched execution');\n    suggestions.push('Critical: Verify GEMV kernels are being used for M=1 matmuls');\n    suggestions.push('Critical: Check if subgroups are available and enabled');\n  }\n\n  if (gap > 3) {\n    suggestions.push('Use fused FFN kernel to reduce memory bandwidth');\n    suggestions.push('Enable optimized decode attention kernel');\n    suggestions.push('Profile individual kernels to find dominant operation');\n  }\n\n  if (gap > 1.5) {\n    suggestions.push('Consider F16 KV cache to reduce memory traffic');\n    suggestions.push('Tune workgroup sizes for your GPU');\n    suggestions.push('Check for unnecessary GPU syncs');\n  }\n\n  return {\n    currentTokPerSec,\n    targetTokPerSec,\n    gap,\n    suggestions,\n  };\n}\n", "/**\n * Reference Implementation Exports\n */\n\n// Matrix operations\nexport { matmulRef, batchMatmulRef, matvecRef } from './matmul.js';\n\n// Activation functions\nexport { softmaxRef, logSoftmaxRef, softmaxInplaceRef } from './softmax.js';\nexport { siluRef, siluGatedRef, siluFusedRef, siluInplaceRef } from './silu.js';\n\n// Normalization\nexport { rmsNormRef, rmsNormNoWeightRef } from './rmsnorm.js';\n\n// Position embeddings\nexport { ropeRef, ropeInterleavedRef, computeRopeFreqs, type RopeFrequencies } from './rope.js';\n\n// Attention\nexport { attentionRef, createCausalMask, flashAttentionRef, mqaRef } from './attention.js';\n\n// MoE operations\nexport { topkRef, softmaxTopkRef, type TopKResult } from './topk.js';\nexport { scatterAddRef, scatterAddAccumulateRef } from './scatter-add.js';\nexport {\n  moeGatherRef,\n  moeComputeAssignmentsRef,\n  type MoeGatherResult,\n  type MoeAssignmentResult,\n} from './moe-gather.js';\n\n// Memory operations\nexport { gatherRef, batchGatherRef, gatherWithPosRef } from './gather.js';\nexport { residualAddRef, residualAddInplaceRef, scaledResidualAddRef } from './residual.js';\n\n// Quantization\nexport {\n  float32ToFloat16,\n  dequantInt8Ref,\n  dequantInt4Ref,\n  dequantQ4_0Ref,\n  quantizeQ4_KRef,\n  quantizeQ4_KBlockRef,\n  dequantQ4_KRef,\n  dequantizeQ4_KBlockRef,\n} from './dequant.js';\n\n// Sampling\nexport {\n  argmaxRef,\n  topkArgmaxRef,\n  softmaxWithTemp,\n  sampleTopKRef,\n  seededRandom,\n} from './sample.js';\n", "/**\n * Reference Matrix Multiplication\n */\n\n/**\n * Reference matrix multiplication\n * C = alpha * A @ B\n *\n * @param A Matrix A [M x K] row-major\n * @param B Matrix B [K x N] row-major\n * @param M Rows of A\n * @param N Cols of B\n * @param K Shared dimension\n * @param alpha Scaling factor\n * @returns Result C [M x N]\n */\nexport function matmulRef(\n  A: Float32Array,\n  B: Float32Array,\n  M: number,\n  N: number,\n  K: number,\n  alpha: number = 1.0\n): Float32Array {\n  const C = new Float32Array(M * N);\n\n  for (let m = 0; m < M; m++) {\n    for (let n = 0; n < N; n++) {\n      let sum = 0;\n      for (let k = 0; k < K; k++) {\n        sum += A[m * K + k] * B[k * N + n];\n      }\n      C[m * N + n] = sum * alpha;\n    }\n  }\n\n  return C;\n}\n\n/**\n * Batched matrix multiplication\n * @param A [batch, M, K]\n * @param B [batch, K, N]\n * @param batch Batch size\n * @param M Rows of each A\n * @param N Cols of each B\n * @param K Shared dimension\n * @returns [batch, M, N]\n */\nexport function batchMatmulRef(\n  A: Float32Array,\n  B: Float32Array,\n  batch: number,\n  M: number,\n  N: number,\n  K: number\n): Float32Array {\n  const C = new Float32Array(batch * M * N);\n  const strideA = M * K;\n  const strideB = K * N;\n  const strideC = M * N;\n\n  for (let b = 0; b < batch; b++) {\n    for (let m = 0; m < M; m++) {\n      for (let n = 0; n < N; n++) {\n        let sum = 0;\n        for (let k = 0; k < K; k++) {\n          sum += A[b * strideA + m * K + k] * B[b * strideB + k * N + n];\n        }\n        C[b * strideC + m * N + n] = sum;\n      }\n    }\n  }\n\n  return C;\n}\n\n/**\n * Matrix-vector multiplication\n * y = A @ x\n * @param A [M, K]\n * @param x [K]\n * @param M Number of rows\n * @param K Number of columns\n * @returns [M]\n */\nexport function matvecRef(A: Float32Array, x: Float32Array, M: number, K: number): Float32Array {\n  const y = new Float32Array(M);\n\n  for (let m = 0; m < M; m++) {\n    let sum = 0;\n    for (let k = 0; k < K; k++) {\n      sum += A[m * K + k] * x[k];\n    }\n    y[m] = sum;\n  }\n\n  return y;\n}\n\nexport default matmulRef;\n", "/**\n * Reference Softmax Implementation\n */\n\n/**\n * Reference online softmax (numerically stable)\n *\n * @param input Input logits [outerSize x innerSize]\n * @param innerSize Size of softmax dimension\n * @param outerSize Batch/outer dimension\n * @param temperature Temperature scaling\n * @returns Softmax probabilities\n */\nexport function softmaxRef(\n  input: Float32Array,\n  innerSize: number,\n  outerSize: number,\n  temperature: number = 1.0\n): Float32Array {\n  const output = new Float32Array(input.length);\n\n  for (let row = 0; row < outerSize; row++) {\n    const offset = row * innerSize;\n\n    // Find max for numerical stability\n    let maxVal = -Infinity;\n    for (let i = 0; i < innerSize; i++) {\n      maxVal = Math.max(maxVal, input[offset + i] / temperature);\n    }\n\n    // Compute exp and sum\n    let sum = 0;\n    for (let i = 0; i < innerSize; i++) {\n      const expVal = Math.exp(input[offset + i] / temperature - maxVal);\n      output[offset + i] = expVal;\n      sum += expVal;\n    }\n\n    // Normalize\n    for (let i = 0; i < innerSize; i++) {\n      output[offset + i] /= sum;\n    }\n  }\n\n  return output;\n}\n\n/**\n * Log softmax (useful for cross-entropy loss)\n * @param input Input logits\n * @param innerSize Size of softmax dimension\n * @param outerSize Batch/outer dimension\n * @param temperature Temperature scaling\n * @returns Log softmax values\n */\nexport function logSoftmaxRef(\n  input: Float32Array,\n  innerSize: number,\n  outerSize: number,\n  temperature: number = 1.0\n): Float32Array {\n  const output = new Float32Array(input.length);\n\n  for (let row = 0; row < outerSize; row++) {\n    const offset = row * innerSize;\n\n    // Find max\n    let maxVal = -Infinity;\n    for (let i = 0; i < innerSize; i++) {\n      maxVal = Math.max(maxVal, input[offset + i] / temperature);\n    }\n\n    // Compute log(sum(exp))\n    let logSum = 0;\n    for (let i = 0; i < innerSize; i++) {\n      logSum += Math.exp(input[offset + i] / temperature - maxVal);\n    }\n    logSum = Math.log(logSum);\n\n    // log_softmax = x - max - log(sum(exp(x - max)))\n    for (let i = 0; i < innerSize; i++) {\n      output[offset + i] = input[offset + i] / temperature - maxVal - logSum;\n    }\n  }\n\n  return output;\n}\n\n/**\n * Softmax in-place (modifies input array)\n */\nexport function softmaxInplaceRef(\n  input: Float32Array,\n  innerSize: number,\n  outerSize: number,\n  temperature: number = 1.0\n): Float32Array {\n  for (let row = 0; row < outerSize; row++) {\n    const offset = row * innerSize;\n\n    let maxVal = -Infinity;\n    for (let i = 0; i < innerSize; i++) {\n      maxVal = Math.max(maxVal, input[offset + i] / temperature);\n    }\n\n    let sum = 0;\n    for (let i = 0; i < innerSize; i++) {\n      input[offset + i] = Math.exp(input[offset + i] / temperature - maxVal);\n      sum += input[offset + i];\n    }\n\n    for (let i = 0; i < innerSize; i++) {\n      input[offset + i] /= sum;\n    }\n  }\n\n  return input;\n}\n\nexport default softmaxRef;\n", "/**\n * Reference SiLU (Swish) Activation Implementation\n */\n\n/**\n * SiLU activation: x * sigmoid(x)\n * @param x Input value\n * @returns Activated value\n */\nfunction silu(x: number): number {\n  return x / (1 + Math.exp(-x));\n}\n\n/**\n * Reference SiLU activation\n * y = x * sigmoid(x)\n *\n * @param input Input array\n * @returns Activated output\n */\nexport function siluRef(input: Float32Array): Float32Array {\n  const output = new Float32Array(input.length);\n\n  for (let i = 0; i < input.length; i++) {\n    output[i] = silu(input[i]);\n  }\n\n  return output;\n}\n\n/**\n * SiLU with gating (used in LLaMA FFN)\n * y = silu(gate) * up\n *\n * @param gate Gate input [size]\n * @param up Up projection [size]\n * @returns Gated output\n */\nexport function siluGatedRef(gate: Float32Array, up: Float32Array): Float32Array {\n  const output = new Float32Array(gate.length);\n\n  for (let i = 0; i < gate.length; i++) {\n    output[i] = silu(gate[i]) * up[i];\n  }\n\n  return output;\n}\n\n/**\n * Fused SiLU + multiply (for packed gate/up weights)\n * Input is [size * 2] with gate in first half, up in second half\n */\nexport function siluFusedRef(input: Float32Array): Float32Array {\n  const halfSize = input.length / 2;\n  const output = new Float32Array(halfSize);\n\n  for (let i = 0; i < halfSize; i++) {\n    const gateVal = input[i];\n    const upVal = input[halfSize + i];\n    output[i] = silu(gateVal) * upVal;\n  }\n\n  return output;\n}\n\n/**\n * In-place SiLU\n */\nexport function siluInplaceRef(input: Float32Array): Float32Array {\n  for (let i = 0; i < input.length; i++) {\n    input[i] = silu(input[i]);\n  }\n  return input;\n}\n\nexport default siluRef;\n", "/**\n * Reference RMSNorm Implementation\n */\n\n/**\n * Reference RMSNorm\n * y = x * rsqrt(mean(x^2) + eps) * weight\n *\n * @param input Input [batchSize x hiddenSize]\n * @param weight Scale weights [hiddenSize]\n * @param batchSize Number of sequences\n * @param hiddenSize Hidden dimension\n * @param eps Epsilon for numerical stability\n * @returns Normalized output\n */\nexport function rmsNormRef(\n  input: Float32Array,\n  weight: Float32Array,\n  batchSize: number,\n  hiddenSize: number,\n  eps: number = 1e-6\n): Float32Array {\n  const output = new Float32Array(input.length);\n\n  for (let b = 0; b < batchSize; b++) {\n    const offset = b * hiddenSize;\n\n    // Compute mean of squares\n    let sumSq = 0;\n    for (let i = 0; i < hiddenSize; i++) {\n      const val = input[offset + i];\n      sumSq += val * val;\n    }\n    const meanSq = sumSq / hiddenSize;\n\n    // Compute rsqrt\n    const scale = 1.0 / Math.sqrt(meanSq + eps);\n\n    // Apply normalization and weight\n    for (let i = 0; i < hiddenSize; i++) {\n      output[offset + i] = input[offset + i] * scale * weight[i];\n    }\n  }\n\n  return output;\n}\n\n/**\n * RMSNorm without learned weights (just normalization)\n */\nexport function rmsNormNoWeightRef(\n  input: Float32Array,\n  batchSize: number,\n  hiddenSize: number,\n  eps: number = 1e-6\n): Float32Array {\n  const output = new Float32Array(input.length);\n\n  for (let b = 0; b < batchSize; b++) {\n    const offset = b * hiddenSize;\n\n    let sumSq = 0;\n    for (let i = 0; i < hiddenSize; i++) {\n      const val = input[offset + i];\n      sumSq += val * val;\n    }\n    const scale = 1.0 / Math.sqrt(sumSq / hiddenSize + eps);\n\n    for (let i = 0; i < hiddenSize; i++) {\n      output[offset + i] = input[offset + i] * scale;\n    }\n  }\n\n  return output;\n}\n\nexport default rmsNormRef;\n", "/**\n * Reference RoPE (Rotary Position Embedding) Implementation\n */\n\nexport interface RopeFrequencies {\n  cos: Float32Array;\n  sin: Float32Array;\n}\n\n/**\n * Precompute RoPE frequencies\n * @param dim Head dimension\n * @param maxSeqLen Maximum sequence length\n * @param base Base for frequency computation (default 10000)\n * @returns Precomputed cos/sin [maxSeqLen, dim/2]\n */\nexport function computeRopeFreqs(dim: number, maxSeqLen: number, base: number = 10000): RopeFrequencies {\n  const halfDim = dim / 2;\n  const cos = new Float32Array(maxSeqLen * halfDim);\n  const sin = new Float32Array(maxSeqLen * halfDim);\n\n  for (let pos = 0; pos < maxSeqLen; pos++) {\n    for (let i = 0; i < halfDim; i++) {\n      const freq = 1.0 / Math.pow(base, (2 * i) / dim);\n      const angle = pos * freq;\n      cos[pos * halfDim + i] = Math.cos(angle);\n      sin[pos * halfDim + i] = Math.sin(angle);\n    }\n  }\n\n  return { cos, sin };\n}\n\n/**\n * Reference RoPE application\n * Applies rotary position embeddings to Q and K\n *\n * @param x Input [seqLen, numHeads, headDim]\n * @param cos Cos frequencies [seqLen, headDim/2]\n * @param sin Sin frequencies [seqLen, headDim/2]\n * @param seqLen Sequence length\n * @param numHeads Number of heads\n * @param headDim Head dimension\n * @param startPos Starting position (for KV cache)\n * @returns Output with RoPE applied\n */\nexport function ropeRef(\n  x: Float32Array,\n  cos: Float32Array,\n  sin: Float32Array,\n  seqLen: number,\n  numHeads: number,\n  headDim: number,\n  startPos: number = 0\n): Float32Array {\n  const output = new Float32Array(x.length);\n  const halfDim = headDim / 2;\n\n  for (let s = 0; s < seqLen; s++) {\n    const pos = s + startPos;\n\n    for (let h = 0; h < numHeads; h++) {\n      const offset = s * numHeads * headDim + h * headDim;\n\n      for (let i = 0; i < halfDim; i++) {\n        const x0 = x[offset + i];\n        const x1 = x[offset + i + halfDim];\n\n        const cosVal = cos[pos * halfDim + i];\n        const sinVal = sin[pos * halfDim + i];\n\n        // Apply rotation\n        output[offset + i] = x0 * cosVal - x1 * sinVal;\n        output[offset + i + halfDim] = x0 * sinVal + x1 * cosVal;\n      }\n    }\n  }\n\n  return output;\n}\n\n/**\n * Alternative RoPE layout (interleaved pairs)\n * Some models use [x0, x1, x2, x3, ...] -> rotate pairs (x0,x1), (x2,x3), ...\n */\nexport function ropeInterleavedRef(\n  x: Float32Array,\n  cos: Float32Array,\n  sin: Float32Array,\n  seqLen: number,\n  numHeads: number,\n  headDim: number,\n  startPos: number = 0\n): Float32Array {\n  const output = new Float32Array(x.length);\n  const halfDim = headDim / 2;\n\n  for (let s = 0; s < seqLen; s++) {\n    const pos = s + startPos;\n\n    for (let h = 0; h < numHeads; h++) {\n      const offset = s * numHeads * headDim + h * headDim;\n\n      for (let i = 0; i < halfDim; i++) {\n        const x0 = x[offset + 2 * i];\n        const x1 = x[offset + 2 * i + 1];\n\n        const cosVal = cos[pos * halfDim + i];\n        const sinVal = sin[pos * halfDim + i];\n\n        output[offset + 2 * i] = x0 * cosVal - x1 * sinVal;\n        output[offset + 2 * i + 1] = x0 * sinVal + x1 * cosVal;\n      }\n    }\n  }\n\n  return output;\n}\n\nexport default ropeRef;\n", "/**\n * Reference Attention Implementation\n */\n\n/**\n * Reference scaled dot-product attention\n * Attention(Q, K, V) = softmax(Q @ K^T / sqrt(d_k)) @ V\n *\n * @param Q Queries [seqLen, numHeads, headDim]\n * @param K Keys [kvLen, numKVHeads, headDim]\n * @param V Values [kvLen, numKVHeads, headDim]\n * @param seqLen Query sequence length\n * @param kvLen Key/Value sequence length\n * @param numHeads Number of query heads\n * @param numKVHeads Number of KV heads (for GQA)\n * @param headDim Dimension per head\n * @param mask Optional attention mask [seqLen, kvLen]\n * @returns Output [seqLen, numHeads, headDim]\n */\nexport function attentionRef(\n  Q: Float32Array,\n  K: Float32Array,\n  V: Float32Array,\n  seqLen: number,\n  kvLen: number,\n  numHeads: number,\n  numKVHeads: number,\n  headDim: number,\n  mask: Float32Array | null = null\n): Float32Array {\n  const output = new Float32Array(seqLen * numHeads * headDim);\n  const scale = 1.0 / Math.sqrt(headDim);\n\n  // Number of query heads per KV head (for GQA)\n  const headsPerKV = numHeads / numKVHeads;\n\n  for (let h = 0; h < numHeads; h++) {\n    const kvHead = Math.floor(h / headsPerKV);\n\n    for (let q = 0; q < seqLen; q++) {\n      // Compute attention scores for this query position\n      const scores = new Float32Array(kvLen);\n\n      // Q @ K^T\n      for (let k = 0; k < kvLen; k++) {\n        let score = 0;\n        for (let d = 0; d < headDim; d++) {\n          const qIdx = q * numHeads * headDim + h * headDim + d;\n          const kIdx = k * numKVHeads * headDim + kvHead * headDim + d;\n          score += Q[qIdx] * K[kIdx];\n        }\n        scores[k] = score * scale;\n\n        // Apply mask if provided\n        if (mask) {\n          scores[k] += mask[q * kvLen + k];\n        }\n      }\n\n      // Softmax\n      let maxScore = -Infinity;\n      for (let k = 0; k < kvLen; k++) {\n        maxScore = Math.max(maxScore, scores[k]);\n      }\n\n      let sumExp = 0;\n      for (let k = 0; k < kvLen; k++) {\n        scores[k] = Math.exp(scores[k] - maxScore);\n        sumExp += scores[k];\n      }\n\n      for (let k = 0; k < kvLen; k++) {\n        scores[k] /= sumExp;\n      }\n\n      // Attention @ V\n      for (let d = 0; d < headDim; d++) {\n        let val = 0;\n        for (let k = 0; k < kvLen; k++) {\n          const vIdx = k * numKVHeads * headDim + kvHead * headDim + d;\n          val += scores[k] * V[vIdx];\n        }\n        output[q * numHeads * headDim + h * headDim + d] = val;\n      }\n    }\n  }\n\n  return output;\n}\n\n/**\n * Create causal attention mask\n * Returns mask where mask[i,j] = 0 if j <= i, else -inf\n */\nexport function createCausalMask(seqLen: number, kvLen: number | null = null): Float32Array {\n  if (kvLen === null) kvLen = seqLen;\n\n  const mask = new Float32Array(seqLen * kvLen);\n\n  for (let i = 0; i < seqLen; i++) {\n    for (let j = 0; j < kvLen; j++) {\n      // For causal: can attend to positions <= current\n      // Offset by (kvLen - seqLen) for KV cache scenarios\n      const offset = kvLen - seqLen;\n      mask[i * kvLen + j] = j <= i + offset ? 0 : -Infinity;\n    }\n  }\n\n  return mask;\n}\n\n/**\n * Flash attention style - fused attention with chunked computation\n * (Reference only - actual flash attention is GPU-specific)\n */\nexport function flashAttentionRef(\n  Q: Float32Array,\n  K: Float32Array,\n  V: Float32Array,\n  seqLen: number,\n  kvLen: number,\n  numHeads: number,\n  numKVHeads: number,\n  headDim: number,\n  blockSize: number = 64\n): Float32Array {\n  // This is just a reference that produces the same result\n  // Real flash attention saves memory by not materializing full attention matrix\n  return attentionRef(Q, K, V, seqLen, kvLen, numHeads, numKVHeads, headDim, createCausalMask(seqLen, kvLen));\n}\n\n/**\n * Multi-query attention (all heads share same K,V)\n */\nexport function mqaRef(\n  Q: Float32Array,\n  K: Float32Array,\n  V: Float32Array,\n  seqLen: number,\n  kvLen: number,\n  numHeads: number,\n  headDim: number,\n  mask: Float32Array | null = null\n): Float32Array {\n  return attentionRef(Q, K, V, seqLen, kvLen, numHeads, 1, headDim, mask);\n}\n\nexport default attentionRef;\n", "/**\n * Reference Top-K Selection for MoE Routing\n */\n\nexport interface TopKResult {\n  indices: Uint32Array;\n  weights: Float32Array;\n}\n\n/**\n * Reference top-k selection\n * @param probs Softmax probabilities [numTokens x numExperts]\n * @param numTokens Number of tokens\n * @param numExperts Number of experts\n * @param topK Top-k value\n * @param normalize Renormalize selected weights\n * @returns Selected indices and weights\n */\nexport function topkRef(\n  probs: Float32Array,\n  numTokens: number,\n  numExperts: number,\n  topK: number,\n  normalize: boolean = true\n): TopKResult {\n  const indices = new Uint32Array(numTokens * topK);\n  const weights = new Float32Array(numTokens * topK);\n\n  for (let token = 0; token < numTokens; token++) {\n    const offset = token * numExperts;\n\n    // Extract probabilities with indices\n    const pairs: Array<{ prob: number; idx: number }> = [];\n    for (let i = 0; i < numExperts; i++) {\n      pairs.push({ prob: probs[offset + i], idx: i });\n    }\n\n    // Sort descending by probability\n    pairs.sort((a, b) => b.prob - a.prob);\n\n    // Take top-k\n    let weightSum = 0;\n    for (let k = 0; k < topK; k++) {\n      indices[token * topK + k] = pairs[k].idx;\n      weights[token * topK + k] = pairs[k].prob;\n      weightSum += pairs[k].prob;\n    }\n\n    // Renormalize if requested\n    if (normalize && weightSum > 0) {\n      for (let k = 0; k < topK; k++) {\n        weights[token * topK + k] /= weightSum;\n      }\n    }\n  }\n\n  return { indices, weights };\n}\n\n/**\n * Combined softmax + top-k (reference for fused kernel)\n * @param logits Router logits [numTokens x numExperts]\n * @param numTokens Number of tokens\n * @param numExperts Number of experts\n * @param topK Top-k value\n * @param normalize Renormalize selected weights\n * @returns Selected indices and weights\n */\nexport function softmaxTopkRef(\n  logits: Float32Array,\n  numTokens: number,\n  numExperts: number,\n  topK: number,\n  normalize: boolean = true\n): TopKResult {\n  const indices = new Uint32Array(numTokens * topK);\n  const weights = new Float32Array(numTokens * topK);\n\n  for (let token = 0; token < numTokens; token++) {\n    const offset = token * numExperts;\n\n    // Find max for numerical stability\n    let maxVal = -Infinity;\n    for (let i = 0; i < numExperts; i++) {\n      maxVal = Math.max(maxVal, logits[offset + i]);\n    }\n\n    // Compute exp and sum\n    const expVals = new Float32Array(numExperts);\n    let expSum = 0;\n    for (let i = 0; i < numExperts; i++) {\n      expVals[i] = Math.exp(logits[offset + i] - maxVal);\n      expSum += expVals[i];\n    }\n\n    // Normalize to get probabilities\n    const pairs: Array<{ prob: number; idx: number }> = [];\n    for (let i = 0; i < numExperts; i++) {\n      pairs.push({ prob: expVals[i] / expSum, idx: i });\n    }\n\n    // Sort descending\n    pairs.sort((a, b) => b.prob - a.prob);\n\n    // Take top-k and optionally renormalize\n    let weightSum = 0;\n    for (let k = 0; k < topK; k++) {\n      indices[token * topK + k] = pairs[k].idx;\n      weights[token * topK + k] = pairs[k].prob;\n      weightSum += pairs[k].prob;\n    }\n\n    if (normalize && weightSum > 0) {\n      for (let k = 0; k < topK; k++) {\n        weights[token * topK + k] /= weightSum;\n      }\n    }\n  }\n\n  return { indices, weights };\n}\n\nexport default topkRef;\n", "/**\n * Reference Scatter-Add for MoE Output Combination\n */\n\n/**\n * Reference scatter-add for MoE output combination\n * Combines expert outputs weighted by routing probabilities\n *\n * @param expertOutputs Expert outputs [numExperts, numTokens, hiddenSize]\n * @param indices Selected expert indices [numTokens, topK]\n * @param weights Routing weights [numTokens, topK]\n * @param numTokens Number of tokens\n * @param hiddenSize Hidden dimension\n * @param numExperts Number of experts\n * @param topK Top-k experts per token\n * @returns Combined output [numTokens, hiddenSize]\n */\nexport function scatterAddRef(\n  expertOutputs: Float32Array,\n  indices: Uint32Array,\n  weights: Float32Array,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number\n): Float32Array {\n  const output = new Float32Array(numTokens * hiddenSize);\n\n  for (let token = 0; token < numTokens; token++) {\n    for (let dim = 0; dim < hiddenSize; dim++) {\n      let sum = 0;\n\n      for (let k = 0; k < topK; k++) {\n        const expertIdx = indices[token * topK + k];\n        const weight = weights[token * topK + k];\n\n        // Expert output layout: [numExperts, numTokens, hiddenSize]\n        const expertOffset = expertIdx * numTokens * hiddenSize + token * hiddenSize + dim;\n        sum += weight * expertOutputs[expertOffset];\n      }\n\n      output[token * hiddenSize + dim] = sum;\n    }\n  }\n\n  return output;\n}\n\n/**\n * In-place accumulation variant (adds to existing output)\n */\nexport function scatterAddAccumulateRef(\n  expertOutputs: Float32Array,\n  indices: Uint32Array,\n  weights: Float32Array,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number,\n  existingOutput: Float32Array\n): Float32Array {\n  const output = new Float32Array(existingOutput);\n\n  for (let token = 0; token < numTokens; token++) {\n    for (let dim = 0; dim < hiddenSize; dim++) {\n      let sum = 0;\n\n      for (let k = 0; k < topK; k++) {\n        const expertIdx = indices[token * topK + k];\n        const weight = weights[token * topK + k];\n        const expertOffset = expertIdx * numTokens * hiddenSize + token * hiddenSize + dim;\n        sum += weight * expertOutputs[expertOffset];\n      }\n\n      output[token * hiddenSize + dim] += sum;\n    }\n  }\n\n  return output;\n}\n\nexport default scatterAddRef;\n", "/**\n * Reference MoE Gather (Token-to-Expert Assignment) Implementation\n */\n\nexport interface MoeGatherResult {\n  gatheredTokens: Float32Array;\n  tokenCounts: Uint32Array;\n  tokenIndices: Uint32Array;\n  maxTokensPerExpert: number;\n}\n\n/**\n * Reference MoE gather - reorder tokens by expert assignment\n * Creates a permutation where tokens assigned to the same expert are grouped\n *\n * @param tokens Input tokens [numTokens x hiddenSize]\n * @param expertIndices Expert assignments [numTokens x topK]\n * @param numTokens Number of tokens\n * @param hiddenSize Hidden dimension\n * @param numExperts Number of experts\n * @param topK Top-k experts per token\n * @returns Gathered tokens and metadata\n */\nexport function moeGatherRef(\n  tokens: Float32Array,\n  expertIndices: Uint32Array,\n  numTokens: number,\n  hiddenSize: number,\n  numExperts: number,\n  topK: number\n): MoeGatherResult {\n  // Count tokens per expert\n  const tokenCounts = new Uint32Array(numExperts);\n\n  for (let t = 0; t < numTokens; t++) {\n    for (let k = 0; k < topK; k++) {\n      const expertIdx = expertIndices[t * topK + k];\n      tokenCounts[expertIdx]++;\n    }\n  }\n\n  // Find max tokens per expert for allocation\n  let maxTokensPerExpert = 0;\n  for (let e = 0; e < numExperts; e++) {\n    maxTokensPerExpert = Math.max(maxTokensPerExpert, tokenCounts[e]);\n  }\n\n  // Allocate output buffers\n  const gatheredTokens = new Float32Array(numExperts * maxTokensPerExpert * hiddenSize);\n  const tokenIndices = new Uint32Array(numExperts * maxTokensPerExpert);\n\n  // Fill with invalid index\n  tokenIndices.fill(0xFFFFFFFF);\n\n  // Reset counts for second pass\n  const currentCounts = new Uint32Array(numExperts);\n\n  // Gather tokens by expert\n  for (let t = 0; t < numTokens; t++) {\n    for (let k = 0; k < topK; k++) {\n      const expertIdx = expertIndices[t * topK + k];\n      const slotIdx = currentCounts[expertIdx];\n\n      // Copy token to expert's slot\n      const srcOffset = t * hiddenSize;\n      const dstOffset = expertIdx * maxTokensPerExpert * hiddenSize + slotIdx * hiddenSize;\n\n      for (let d = 0; d < hiddenSize; d++) {\n        gatheredTokens[dstOffset + d] = tokens[srcOffset + d];\n      }\n\n      // Record original token index\n      tokenIndices[expertIdx * maxTokensPerExpert + slotIdx] = t;\n\n      currentCounts[expertIdx]++;\n    }\n  }\n\n  return {\n    gatheredTokens,\n    tokenCounts,\n    tokenIndices,\n    maxTokensPerExpert,\n  };\n}\n\nexport interface MoeAssignmentResult {\n  tokenCounts: Uint32Array;\n  expertOffsets: Uint32Array;\n  totalAssignments: number;\n}\n\n/**\n * Simple variant - just compute counts and offsets (no actual gather)\n * Useful for determining buffer sizes before kernel launch\n */\nexport function moeComputeAssignmentsRef(\n  expertIndices: Uint32Array,\n  numTokens: number,\n  numExperts: number,\n  topK: number\n): MoeAssignmentResult {\n  const tokenCounts = new Uint32Array(numExperts);\n  const expertOffsets = new Uint32Array(numExperts);\n\n  // Count tokens per expert\n  for (let t = 0; t < numTokens; t++) {\n    for (let k = 0; k < topK; k++) {\n      const expertIdx = expertIndices[t * topK + k];\n      tokenCounts[expertIdx]++;\n    }\n  }\n\n  // Compute prefix sum for offsets\n  let offset = 0;\n  for (let e = 0; e < numExperts; e++) {\n    expertOffsets[e] = offset;\n    offset += tokenCounts[e];\n  }\n\n  return { tokenCounts, expertOffsets, totalAssignments: offset };\n}\n\nexport default moeGatherRef;\n", "/**\n * Reference Gather (Embedding Lookup) Implementation\n */\n\n/**\n * Reference gather/embedding lookup\n * output[i] = embeddings[indices[i]]\n *\n * @param embeddings Embedding table [vocabSize x embedDim]\n * @param indices Token indices [seqLen]\n * @param vocabSize Vocabulary size\n * @param embedDim Embedding dimension\n * @returns Gathered embeddings [seqLen x embedDim]\n */\nexport function gatherRef(\n  embeddings: Float32Array,\n  indices: Uint32Array,\n  vocabSize: number,\n  embedDim: number\n): Float32Array {\n  const seqLen = indices.length;\n  const output = new Float32Array(seqLen * embedDim);\n\n  for (let i = 0; i < seqLen; i++) {\n    const idx = indices[i];\n    const srcOffset = idx * embedDim;\n    const dstOffset = i * embedDim;\n\n    for (let d = 0; d < embedDim; d++) {\n      output[dstOffset + d] = embeddings[srcOffset + d];\n    }\n  }\n\n  return output;\n}\n\n/**\n * Batched gather\n * @param embeddings [vocabSize x embedDim]\n * @param indices [batchSize x seqLen]\n * @param batchSize Batch size\n * @param seqLen Sequence length\n * @param embedDim Embedding dimension\n * @returns [batchSize x seqLen x embedDim]\n */\nexport function batchGatherRef(\n  embeddings: Float32Array,\n  indices: Uint32Array,\n  batchSize: number,\n  seqLen: number,\n  embedDim: number\n): Float32Array {\n  const output = new Float32Array(batchSize * seqLen * embedDim);\n\n  for (let b = 0; b < batchSize; b++) {\n    for (let s = 0; s < seqLen; s++) {\n      const idx = indices[b * seqLen + s];\n      const srcOffset = idx * embedDim;\n      const dstOffset = (b * seqLen + s) * embedDim;\n\n      for (let d = 0; d < embedDim; d++) {\n        output[dstOffset + d] = embeddings[srcOffset + d];\n      }\n    }\n  }\n\n  return output;\n}\n\n/**\n * Gather with position embeddings added\n */\nexport function gatherWithPosRef(\n  embeddings: Float32Array,\n  posEmbeddings: Float32Array,\n  indices: Uint32Array,\n  vocabSize: number,\n  embedDim: number,\n  startPos: number = 0\n): Float32Array {\n  const seqLen = indices.length;\n  const output = new Float32Array(seqLen * embedDim);\n\n  for (let i = 0; i < seqLen; i++) {\n    const tokenIdx = indices[i];\n    const posIdx = i + startPos;\n\n    const tokenOffset = tokenIdx * embedDim;\n    const posOffset = posIdx * embedDim;\n    const dstOffset = i * embedDim;\n\n    for (let d = 0; d < embedDim; d++) {\n      output[dstOffset + d] = embeddings[tokenOffset + d] + posEmbeddings[posOffset + d];\n    }\n  }\n\n  return output;\n}\n\nexport default gatherRef;\n", "/**\n * Reference Residual Add Implementation\n */\n\n/**\n * Reference residual add\n * output = x + residual\n *\n * @param x Input\n * @param residual Residual connection\n * @returns Sum\n */\nexport function residualAddRef(x: Float32Array, residual: Float32Array): Float32Array {\n  const output = new Float32Array(x.length);\n\n  for (let i = 0; i < x.length; i++) {\n    output[i] = x[i] + residual[i];\n  }\n\n  return output;\n}\n\n/**\n * In-place residual add (modifies x)\n */\nexport function residualAddInplaceRef(x: Float32Array, residual: Float32Array): Float32Array {\n  for (let i = 0; i < x.length; i++) {\n    x[i] += residual[i];\n  }\n  return x;\n}\n\n/**\n * Scaled residual add\n * output = x + scale * residual\n */\nexport function scaledResidualAddRef(x: Float32Array, residual: Float32Array, scale: number): Float32Array {\n  const output = new Float32Array(x.length);\n\n  for (let i = 0; i < x.length; i++) {\n    output[i] = x[i] + scale * residual[i];\n  }\n\n  return output;\n}\n\n/**\n * Residual add with dropout mask\n * output = x + residual * mask * (1 / (1 - dropProb))\n */\nexport function residualAddDropoutRef(\n  x: Float32Array,\n  residual: Float32Array,\n  mask: Float32Array,\n  dropProb: number\n): Float32Array {\n  const output = new Float32Array(x.length);\n  const scale = 1.0 / (1.0 - dropProb);\n\n  for (let i = 0; i < x.length; i++) {\n    output[i] = x[i] + residual[i] * mask[i] * scale;\n  }\n\n  return output;\n}\n\nexport default residualAddRef;\n", "/**\n * Reference Dequantization Implementation\n */\n\n// ============================================================================\n// Helpers (fp16)\n// ============================================================================\n\n/**\n * Convert fp16 bits to fp32\n */\nfunction float16ToFloat32(bits: number): number {\n  const sign = (bits >> 15) & 1;\n  const exp = (bits >> 10) & 0x1F;\n  const frac = bits & 0x3FF;\n\n  if (exp === 0) {\n    if (frac === 0) return sign ? -0 : 0;\n    // Denormalized\n    return (sign ? -1 : 1) * Math.pow(2, -14) * (frac / 1024);\n  }\n\n  if (exp === 31) {\n    return frac ? NaN : (sign ? -Infinity : Infinity);\n  }\n\n  return (sign ? -1 : 1) * Math.pow(2, exp - 15) * (1 + frac / 1024);\n}\n\nexport function float32ToFloat16(value: number): number {\n  const floatView = new Float32Array(1);\n  const int32View = new Int32Array(floatView.buffer);\n  floatView[0] = value;\n  const f = int32View[0];\n\n  const sign = (f >> 31) & 0x1;\n  let exp = (f >> 23) & 0xff;\n  let frac = f & 0x7fffff;\n\n  if (exp === 0xff) {\n    return (sign << 15) | 0x7c00 | (frac ? 0x200 : 0);\n  }\n\n  if (exp === 0) {\n    return sign << 15;\n  }\n\n  exp = exp - 127 + 15;\n\n  if (exp >= 31) {\n    return (sign << 15) | 0x7c00;\n  }\n\n  if (exp <= 0) {\n    if (exp < -10) {\n      return sign << 15;\n    }\n    frac = (frac | 0x800000) >> (1 - exp);\n    return (sign << 15) | (frac >> 13);\n  }\n\n  return (sign << 15) | (exp << 10) | (frac >> 13);\n}\n\n/**\n * Reference INT8 dequantization\n * float = (int8 - zero_point) * scale\n *\n * @param quantized Quantized values\n * @param scales Per-channel or per-tensor scales\n * @param zeroPoints Zero points (optional, default 0)\n * @param numChannels Number of output channels\n * @param channelSize Elements per channel\n * @returns Dequantized values\n */\nexport function dequantInt8Ref(\n  quantized: Int8Array,\n  scales: Float32Array,\n  zeroPoints: Int8Array | null = null,\n  numChannels: number = 1,\n  channelSize: number = 0\n): Float32Array {\n  const output = new Float32Array(quantized.length);\n\n  if (channelSize === 0) {\n    channelSize = quantized.length / numChannels;\n  }\n\n  for (let c = 0; c < numChannels; c++) {\n    const scale = scales[c];\n    const zp = zeroPoints ? zeroPoints[c] : 0;\n\n    for (let i = 0; i < channelSize; i++) {\n      const idx = c * channelSize + i;\n      output[idx] = (quantized[idx] - zp) * scale;\n    }\n  }\n\n  return output;\n}\n\n/**\n * Reference INT4 dequantization (packed 2 values per byte)\n * @param quantized Packed INT4 values (2 per byte)\n * @param scales Scales\n * @param numElements Total number of output elements\n * @param groupSize Group size for quantization\n * @returns Dequantized values\n */\nexport function dequantInt4Ref(\n  quantized: Uint8Array,\n  scales: Float32Array,\n  numElements: number,\n  groupSize: number = 32\n): Float32Array {\n  const output = new Float32Array(numElements);\n  const numGroups = Math.ceil(numElements / groupSize);\n\n  for (let i = 0; i < numElements; i++) {\n    const byteIdx = Math.floor(i / 2);\n    const groupIdx = Math.floor(i / groupSize);\n    const scale = scales[groupIdx];\n\n    let val: number;\n    if (i % 2 === 0) {\n      // Low nibble\n      val = quantized[byteIdx] & 0x0F;\n    } else {\n      // High nibble\n      val = (quantized[byteIdx] >> 4) & 0x0F;\n    }\n\n    // Convert from unsigned [0,15] to signed [-8,7]\n    if (val >= 8) {\n      val = val - 16;\n    }\n\n    output[i] = val * scale;\n  }\n\n  return output;\n}\n\n/**\n * Reference block-wise quantization (Q4_0 style)\n * Each block has: scale (fp16) + 32 int4 values (16 bytes)\n */\nexport function dequantQ4_0Ref(quantized: Uint8Array, numBlocks: number): Float32Array {\n  const blockSize = 32;\n  const output = new Float32Array(numBlocks * blockSize);\n  const dataView = new DataView(quantized.buffer);\n\n  for (let block = 0; block < numBlocks; block++) {\n    // Q4_0 block: 2 bytes scale (fp16) + 16 bytes data (32 int4)\n    const blockOffset = block * 18;\n\n    // Read scale as fp16 (simplified - just use the bytes directly for now)\n    const scaleBytes = dataView.getUint16(blockOffset, true);\n    const scale = float16ToFloat32(scaleBytes);\n\n    // Unpack 32 int4 values from 16 bytes\n    for (let i = 0; i < 16; i++) {\n      const byte = quantized[blockOffset + 2 + i];\n\n      const low = (byte & 0x0F) - 8;\n      const high = ((byte >> 4) & 0x0F) - 8;\n\n      output[block * blockSize + i * 2] = low * scale;\n      output[block * blockSize + i * 2 + 1] = high * scale;\n    }\n  }\n\n  return output;\n}\n\n// ============================================================================\n// Q4_K (llama.cpp block_q4_K) reference\n// ============================================================================\n\nconst Q4K_K = 256;\nconst Q4K_BLOCK_SIZE = 144;\n\nfunction findMinMax(data: Float32Array, offset: number, length: number): { min: number; max: number } {\n  let min = Infinity;\n  let max = -Infinity;\n  for (let i = 0; i < length; i++) {\n    const val = data[offset + i];\n    if (val < min) min = val;\n    if (val > max) max = val;\n  }\n  return { min, max };\n}\n\n/**\n * Quantize a single Q4_K block (256 values) into llama.cpp Q4_K byte layout.\n * This matches the dequant_* kernels in `doppler/gpu/kernels/dequant_*.wgsl`.\n */\nexport function quantizeQ4_KBlockRef(data: Float32Array, offset: number): Uint8Array {\n  const block = new Uint8Array(Q4K_BLOCK_SIZE);\n  const view = new DataView(block.buffer);\n\n  const scales = new Float32Array(8);\n  const minOffsets = new Float32Array(8);\n  const qs = new Uint8Array(256);\n\n  for (let sb = 0; sb < 8; sb++) {\n    const sbOffset = offset + sb * 32;\n    const { min, max } = findMinMax(data, sbOffset, 32);\n\n    minOffsets[sb] = -min;\n    const range = max - min;\n    scales[sb] = range > 0 ? range / 15 : 0;\n\n    const invScale = scales[sb] > 0 ? 1 / scales[sb] : 0;\n    for (let i = 0; i < 32; i++) {\n      const val = data[sbOffset + i];\n      let q = Math.round((val - min) * invScale);\n      q = Math.max(0, Math.min(15, q));\n      qs[sb * 32 + i] = q;\n    }\n  }\n\n  let maxScale = 0;\n  let maxMinOffset = 0;\n  for (let i = 0; i < 8; i++) {\n    if (scales[i] > maxScale) maxScale = scales[i];\n    if (minOffsets[i] > maxMinOffset) maxMinOffset = minOffsets[i];\n    if (minOffsets[i] < 0) minOffsets[i] = 0;\n  }\n\n  const d = maxScale / 63;\n  const dmin = maxMinOffset / 63;\n\n  view.setUint16(0, float32ToFloat16(d), true);\n  view.setUint16(2, float32ToFloat16(dmin), true);\n\n  const invD = d > 0 ? 1 / d : 0;\n  const invDmin = dmin > 0 ? 1 / dmin : 0;\n\n  const scaleBits = new Uint8Array(8);\n  const minBits = new Uint8Array(8);\n  for (let i = 0; i < 8; i++) {\n    scaleBits[i] = Math.min(63, Math.round(scales[i] * invD));\n    minBits[i] = Math.min(63, Math.round(Math.max(0, minOffsets[i]) * invDmin));\n  }\n\n  // bytes 0-3: low 6 bits of scales[0..3], high 2 bits from scales[4..7]\n  for (let i = 0; i < 4; i++) {\n    const scaleLo = scaleBits[i] & 0x3f;\n    const scaleHi2 = (scaleBits[i + 4] >> 4) & 0x03;\n    block[4 + i] = scaleLo | (scaleHi2 << 6);\n  }\n\n  // bytes 4-7: low 6 bits of mins[0..3], high 2 bits from mins[4..7]\n  for (let i = 0; i < 4; i++) {\n    const minLo = minBits[i] & 0x3f;\n    const minHi2 = (minBits[i + 4] >> 4) & 0x03;\n    block[4 + 4 + i] = minLo | (minHi2 << 6);\n  }\n\n  // bytes 8-11: low 4 bits scales[4..7] and mins[4..7]\n  for (let i = 0; i < 4; i++) {\n    const scaleLo4 = scaleBits[i + 4] & 0x0f;\n    const minLo4 = minBits[i + 4] & 0x0f;\n    block[4 + 8 + i] = scaleLo4 | (minLo4 << 4);\n  }\n\n  // qs: 4 chunks of 64 elements, packed into 32 bytes each (lo nibbles then hi nibbles)\n  for (let chunk = 0; chunk < 4; chunk++) {\n    const chunkBase = chunk * 64;\n    const byteBase = 16 + chunk * 32;\n    for (let i = 0; i < 32; i++) {\n      const lo = qs[chunkBase + i] & 0x0f;\n      const hi = qs[chunkBase + 32 + i] & 0x0f;\n      block[byteBase + i] = lo | (hi << 4);\n    }\n  }\n\n  return block;\n}\n\nexport function quantizeQ4_KRef(values: Float32Array, numBlocks: number): Uint8Array {\n  const out = new Uint8Array(numBlocks * Q4K_BLOCK_SIZE);\n  for (let b = 0; b < numBlocks; b++) {\n    const block = quantizeQ4_KBlockRef(values, b * Q4K_K);\n    out.set(block, b * Q4K_BLOCK_SIZE);\n  }\n  return out;\n}\n\nexport function dequantizeQ4_KBlockRef(block: Uint8Array): Float32Array {\n  const view = new DataView(block.buffer, block.byteOffset);\n  const out = new Float32Array(Q4K_K);\n\n  const d = float16ToFloat32(view.getUint16(0, true));\n  const dmin = float16ToFloat32(view.getUint16(2, true));\n\n  const scaleBits = new Uint8Array(8);\n  const minBits = new Uint8Array(8);\n\n  for (let i = 0; i < 4; i++) {\n    scaleBits[i] = block[4 + i] & 0x3f;\n    scaleBits[i + 4] = ((block[4 + i] >> 6) & 0x03) << 4;\n  }\n  for (let i = 0; i < 4; i++) {\n    minBits[i] = block[4 + 4 + i] & 0x3f;\n    minBits[i + 4] = ((block[4 + 4 + i] >> 6) & 0x03) << 4;\n  }\n  for (let i = 0; i < 4; i++) {\n    scaleBits[i + 4] |= block[4 + 8 + i] & 0x0f;\n    minBits[i + 4] |= (block[4 + 8 + i] >> 4) & 0x0f;\n  }\n\n  const scales = new Float32Array(8);\n  const mins = new Float32Array(8);\n  for (let i = 0; i < 8; i++) {\n    scales[i] = d * scaleBits[i];\n    mins[i] = dmin * minBits[i];\n  }\n\n  for (let chunk = 0; chunk < 4; chunk++) {\n    const chunkBase = chunk * 64;\n    const byteBase = 16 + chunk * 32;\n    for (let i = 0; i < 32; i++) {\n      const byte = block[byteBase + i];\n      const lo = byte & 0x0f;\n      const hi = (byte >> 4) & 0x0f;\n\n      const sb0 = Math.floor((chunkBase + i) / 32);\n      const sb1 = Math.floor((chunkBase + 32 + i) / 32);\n\n      out[chunkBase + i] = scales[sb0] * lo - mins[sb0];\n      out[chunkBase + 32 + i] = scales[sb1] * hi - mins[sb1];\n    }\n  }\n\n  return out;\n}\n\nexport function dequantQ4_KRef(quantized: Uint8Array, numBlocks: number): Float32Array {\n  const out = new Float32Array(numBlocks * Q4K_K);\n  for (let b = 0; b < numBlocks; b++) {\n    const start = b * Q4K_BLOCK_SIZE;\n    const block = quantized.subarray(start, start + Q4K_BLOCK_SIZE);\n    out.set(dequantizeQ4_KBlockRef(block), b * Q4K_K);\n  }\n  return out;\n}\n\nexport default dequantInt8Ref;\n", "/**\n * Reference Implementation for Sampling Operations\n *\n * These implement CPU-side sampling for validating GPU sample kernels.\n */\n\n/**\n * Argmax - find index of maximum value (greedy decoding)\n */\nexport function argmaxRef(logits: Float32Array): number {\n  let maxIdx = 0;\n  let maxVal = logits[0];\n\n  for (let i = 1; i < logits.length; i++) {\n    if (logits[i] > maxVal) {\n      maxVal = logits[i];\n      maxIdx = i;\n    }\n  }\n\n  return maxIdx;\n}\n\n/**\n * Top-k argmax - find indices of k largest values\n */\nexport function topkArgmaxRef(logits: Float32Array, k: number): { indices: number[]; values: number[] } {\n  // Create index array and sort by value\n  const indexed = Array.from(logits).map((val, idx) => ({ val, idx }));\n  indexed.sort((a, b) => b.val - a.val);\n\n  const topK = indexed.slice(0, k);\n  return {\n    indices: topK.map(x => x.idx),\n    values: topK.map(x => x.val),\n  };\n}\n\n/**\n * Softmax with temperature\n */\nexport function softmaxWithTemp(logits: Float32Array, temperature: number): Float32Array {\n  const scaled = new Float32Array(logits.length);\n\n  // Apply temperature\n  for (let i = 0; i < logits.length; i++) {\n    scaled[i] = logits[i] / temperature;\n  }\n\n  // Find max for numerical stability\n  let max = scaled[0];\n  for (let i = 1; i < scaled.length; i++) {\n    if (scaled[i] > max) max = scaled[i];\n  }\n\n  // Compute exp and sum\n  let sum = 0;\n  for (let i = 0; i < scaled.length; i++) {\n    scaled[i] = Math.exp(scaled[i] - max);\n    sum += scaled[i];\n  }\n\n  // Normalize\n  for (let i = 0; i < scaled.length; i++) {\n    scaled[i] /= sum;\n  }\n\n  return scaled;\n}\n\n/**\n * Top-k sampling with temperature\n * Returns sampled token ID given:\n * - logits: raw logits\n * - temperature: scaling factor\n * - topK: number of candidates\n * - randomValue: pre-generated random [0,1) for reproducibility\n */\nexport function sampleTopKRef(\n  logits: Float32Array,\n  temperature: number,\n  topK: number,\n  randomValue: number\n): number {\n  // For very low temperature, use greedy\n  if (temperature < 0.01) {\n    return argmaxRef(logits);\n  }\n\n  // Get top-k candidates\n  const { indices, values } = topkArgmaxRef(logits, topK);\n\n  // Apply temperature and softmax to top-k values\n  const scaledValues = values.map(v => v / temperature);\n\n  // Softmax on scaled values\n  const max = Math.max(...scaledValues);\n  const expValues = scaledValues.map(v => Math.exp(v - max));\n  const sum = expValues.reduce((a, b) => a + b, 0);\n  const probs = expValues.map(v => v / sum);\n\n  // Sample from multinomial distribution\n  let cumProb = 0;\n  for (let i = 0; i < probs.length; i++) {\n    cumProb += probs[i];\n    if (cumProb >= randomValue) {\n      return indices[i];\n    }\n  }\n\n  // Fallback to last item\n  return indices[indices.length - 1];\n}\n\n/**\n * Simple seeded random number generator (matches GPU implementation)\n */\nexport function seededRandom(seed: number): number {\n  const x = Math.sin(seed) * 10000;\n  return x - Math.floor(x);\n}\n", "/**\n * Floating-Point Tolerance and Comparison Utilities\n */\n\nexport interface ToleranceConfig {\n  rtol: number;\n  atol: number;\n}\n\nexport interface TopKToleranceConfig {\n  indices: { exact: boolean };\n  weights: ToleranceConfig;\n}\n\nexport interface KernelTolerances {\n  matmul_f32: ToleranceConfig;\n  matmul_f16: ToleranceConfig;\n  attention: ToleranceConfig;\n  softmax: ToleranceConfig;\n  rmsnorm: ToleranceConfig;\n  rope: ToleranceConfig;\n  silu: ToleranceConfig;\n  topk: TopKToleranceConfig;\n  scatter_add: ToleranceConfig;\n  moe_gather: ToleranceConfig;\n  gather: { exact: boolean };\n  residual: ToleranceConfig;\n  dequant: ToleranceConfig;\n}\n\n/**\n * Per-kernel tolerance settings based on numerical characteristics\n */\nexport const KERNEL_TOLERANCES: KernelTolerances = {\n  matmul_f32: { rtol: 1e-5, atol: 1e-6 },\n  matmul_f16: { rtol: 1e-2, atol: 1e-3 }, // FP16 has ~3 decimal digits\n\n  attention: { rtol: 1e-4, atol: 1e-5 }, // Softmax accumulation\n\n  softmax: { rtol: 1e-5, atol: 1e-7 }, // Must sum to 1\n\n  rmsnorm: { rtol: 1e-5, atol: 1e-6 },\n\n  rope: { rtol: 1e-5, atol: 1e-6 }, // Sin/cos operations\n\n  silu: { rtol: 1e-5, atol: 1e-6 },\n\n  topk: {\n    indices: { exact: true }, // Indices must match exactly\n    weights: { rtol: 1e-5, atol: 1e-7 },\n  },\n\n  scatter_add: { rtol: 1e-5, atol: 1e-6 },\n\n  moe_gather: { rtol: 1e-5, atol: 1e-6 },\n\n  gather: { exact: true }, // Embedding lookup is exact\n\n  residual: { rtol: 1e-6, atol: 1e-8 }, // Simple addition\n\n  dequant: { rtol: 1e-4, atol: 1e-5 }, // Quantization introduces error\n};\n\nexport interface Mismatch {\n  index: number;\n  expected: number;\n  actual: number;\n  error: number;\n  threshold: number;\n}\n\nexport interface ComparisonResult {\n  passed: boolean;\n  error?: string;\n  maxError: number;\n  avgError: number;\n  mismatchCount: number;\n  mismatchRatio?: number;\n  firstMismatches?: Mismatch[];\n}\n\n/**\n * Compare floating-point arrays with configurable tolerance\n * @param expected Expected values\n * @param actual Actual values\n * @param options Tolerance configuration\n * @returns Comparison results\n */\nexport function compareArrays(\n  expected: Float32Array,\n  actual: Float32Array,\n  options: Partial<ToleranceConfig> = {}\n): ComparisonResult {\n  const { rtol = 1e-5, atol = 1e-8 } = options;\n\n  if (expected.length !== actual.length) {\n    return {\n      passed: false,\n      error: `Length mismatch: expected ${expected.length}, got ${actual.length}`,\n      maxError: Infinity,\n      avgError: Infinity,\n      mismatchCount: expected.length,\n    };\n  }\n\n  let maxError = 0;\n  let sumError = 0;\n  let mismatchCount = 0;\n  const mismatches: Mismatch[] = [];\n\n  for (let i = 0; i < expected.length; i++) {\n    const e = expected[i];\n    const a = actual[i];\n    const error = Math.abs(e - a);\n    const threshold = atol + rtol * Math.abs(e);\n\n    maxError = Math.max(maxError, error);\n    sumError += error;\n\n    if (error > threshold) {\n      mismatchCount++;\n      if (mismatches.length < 10) {\n        mismatches.push({ index: i, expected: e, actual: a, error, threshold });\n      }\n    }\n  }\n\n  return {\n    passed: mismatchCount === 0,\n    maxError,\n    avgError: sumError / expected.length,\n    mismatchCount,\n    mismatchRatio: mismatchCount / expected.length,\n    firstMismatches: mismatches,\n  };\n}\n\nexport interface IntMismatch {\n  index: number;\n  expected: number;\n  actual: number;\n}\n\nexport interface IntComparisonResult {\n  passed: boolean;\n  error?: string;\n  mismatchCount: number;\n  firstMismatches?: IntMismatch[];\n}\n\n/**\n * Compare integer arrays (exact match)\n * @param expected Expected values\n * @param actual Actual values\n * @returns Comparison results\n */\nexport function compareIntArrays(\n  expected: Uint32Array | Int32Array,\n  actual: Uint32Array | Int32Array\n): IntComparisonResult {\n  if (expected.length !== actual.length) {\n    return {\n      passed: false,\n      error: `Length mismatch: expected ${expected.length}, got ${actual.length}`,\n      mismatchCount: expected.length,\n    };\n  }\n\n  let mismatchCount = 0;\n  const mismatches: IntMismatch[] = [];\n\n  for (let i = 0; i < expected.length; i++) {\n    if (expected[i] !== actual[i]) {\n      mismatchCount++;\n      if (mismatches.length < 10) {\n        mismatches.push({ index: i, expected: expected[i], actual: actual[i] });\n      }\n    }\n  }\n\n  return {\n    passed: mismatchCount === 0,\n    mismatchCount,\n    firstMismatches: mismatches,\n  };\n}\n\nexport type DataType = 'float32' | 'int32' | 'uint32';\n\nexport interface GenerateOptions {\n  min?: number;\n  max?: number;\n  dtype?: DataType;\n}\n\n/**\n * Generate deterministic test data using LCG PRNG\n * @param size Number of elements\n * @param seed Random seed\n * @param options Generation options\n * @returns Generated array\n */\nexport function generateTestData(\n  size: number,\n  seed: number = 42,\n  options: GenerateOptions = {}\n): Float32Array | Int32Array | Uint32Array {\n  const { min = -1, max = 1, dtype = 'float32' } = options;\n\n  let data: Float32Array | Int32Array | Uint32Array;\n  switch (dtype) {\n    case 'uint32':\n      data = new Uint32Array(size);\n      break;\n    case 'int32':\n      data = new Int32Array(size);\n      break;\n    default:\n      data = new Float32Array(size);\n  }\n\n  // Simple LCG PRNG for reproducibility\n  let state = seed;\n  const range = max - min;\n\n  for (let i = 0; i < size; i++) {\n    state = (state * 1103515245 + 12345) & 0x7fffffff;\n    const normalized = state / 0x7fffffff; // [0, 1]\n\n    if (dtype === 'float32') {\n      data[i] = min + normalized * range;\n    } else {\n      data[i] = Math.floor(min + normalized * range);\n    }\n  }\n\n  return data;\n}\n\nexport interface SumVerificationResult {\n  passed: boolean;\n  expectedSum: number;\n  actualSum: number;\n  error: number;\n}\n\n/**\n * Verify array sums to expected value (e.g., softmax sums to 1)\n * @param arr Input array\n * @param expectedSum Expected sum\n * @param tolerance Error tolerance\n * @returns Verification result\n */\nexport function verifySumTo(\n  arr: Float32Array,\n  expectedSum: number,\n  tolerance: number = 1e-5\n): SumVerificationResult {\n  const actualSum = arr.reduce((a, b) => a + b, 0);\n  const error = Math.abs(actualSum - expectedSum);\n\n  return {\n    passed: error < tolerance,\n    expectedSum,\n    actualSum,\n    error,\n  };\n}\n\nexport interface RangeVerificationResult {\n  passed: boolean;\n  outOfRangeCount: number;\n  actualMin: number;\n  actualMax: number;\n}\n\n/**\n * Verify all elements are in range\n * @param arr Input array\n * @param min Minimum value\n * @param max Maximum value\n * @returns Verification result\n */\nexport function verifyRange(arr: Float32Array, min: number, max: number): RangeVerificationResult {\n  let outOfRange = 0;\n  let minVal = Infinity;\n  let maxVal = -Infinity;\n\n  for (let i = 0; i < arr.length; i++) {\n    if (arr[i] < min || arr[i] > max) outOfRange++;\n    minVal = Math.min(minVal, arr[i]);\n    maxVal = Math.max(maxVal, arr[i]);\n  }\n\n  return {\n    passed: outOfRange === 0,\n    outOfRangeCount: outOfRange,\n    actualMin: minVal,\n    actualMax: maxVal,\n  };\n}\n"],
  "mappings": ";;;;;;;;;;;AAAA,IAsBa;AAtBb;AAAA;AAsBO,IAAM,aAAa,KAAK,OAAO;AAAA;AAAA;;;ACtBtC,IAuKa;AAvKb;AAAA;AAuKO,IAAM,gBAAgB;AAAA;AAAA;;;ACvK7B;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;;;ACAA,IAkCa,4BA8BA,kCAuBA,0BAsBA,6BAsBA;AAnIb;AAAA;AAkCO,IAAM,6BAAqD;AAAA,MAChE,aAAa;AAAA,MACb,gBAAgB;AAAA,MAChB,eAAe;AAAA,IACjB;AA0BO,IAAM,mCAAiE;AAAA,MAC5E,qBAAqB;AAAA,MACrB,qBAAqB,MAAM,OAAO;AAAA;AAAA,MAClC,qBAAqB;AAAA,MACrB,eAAe;AAAA;AAAA,IACjB;AAkBO,IAAM,2BAAiD;AAAA,MAC5D,aAAa;AAAA,IACf;AAoBO,IAAM,8BAAuD;AAAA,MAClE,kBAAkB,IAAI,OAAO,OAAO;AAAA;AAAA,MACpC,qBAAqB;AAAA;AAAA,IACvB;AAmBO,IAAM,yBAA8C;AAAA,MACzD,YAAY;AAAA,MACZ,kBAAkB;AAAA,MAClB,UAAU;AAAA,MACV,aAAa;AAAA,IACf;AAAA;AAAA;;;ACxIA;AAAA;AAAA;AAAA;;;ACAA,IAgCa,sBA4BA,gCAqBA,kCAoBA;AArGb;AAAA;AAgCO,IAAM,uBAA0C;AAAA,MACrD,wBAAwB,MAAM,OAAO;AAAA;AAAA,MACrC,6BAA6B,MAAM,OAAO;AAAA;AAAA,MAC1C,mBAAmB;AAAA;AAAA,IACrB;AAwBO,IAAM,iCAA6D;AAAA,MACxE,oBAAoB;AAAA;AAAA,MACpB,mBAAmB,IAAI,OAAO,OAAO;AAAA;AAAA,MACrC,sBAAsB,MAAM,OAAO;AAAA;AAAA,IACrC;AAiBO,IAAM,mCAAiE;AAAA,MAC5E,sBAAsB;AAAA;AAAA,IACxB;AAkBO,IAAM,8BAAuD;AAAA,MAClE,OAAO;AAAA,MACP,gBAAgB;AAAA,MAChB,WAAW;AAAA,IACb;AAAA;AAAA;;;ACzGA,IAkDa,2BA4BA,0BA4BA,6BA2BA,2BA4BA,4BA4CA;AA7Mb;AAAA;AAkDO,IAAM,4BAAoD;AAAA,MAC/D,WAAW;AAAA;AAAA,MACX,WAAW;AAAA,MACX,eAAe;AAAA,IACjB;AAwBO,IAAM,2BAAkD;AAAA,MAC7D,iBAAiB;AAAA;AAAA,MACjB,0BAA0B;AAAA;AAAA,MAC1B,2BAA2B;AAAA;AAAA,IAC7B;AAwBO,IAAM,8BAAuD;AAAA,MAClE,SAAS;AAAA,MACT,aAAa;AAAA,MACb,WAAW;AAAA,MACX,iBAAiB;AAAA,IACnB;AAsBO,IAAM,4BAAoD;AAAA,MAC/D,aAAa;AAAA,MACb,MAAM;AAAA,MACN,MAAM;AAAA,MACN,mBAAmB;AAAA,MACnB,iBAAiB;AAAA,MACjB,yBAAyB;AAAA,IAC3B;AAqBO,IAAM,6BAAsD;AAAA,MACjE,aAAa;AAAA,MACb,aAAa;AAAA,IACf;AAyCO,IAAM,oCAAmE;AAAA,MAC9E,UAAU;AAAA,MACV,UAAU;AAAA,MACV,SAAS;AAAA,MACT,WAAW;AAAA,MACX,cAAc;AAAA,MACd,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,YAAY;AAAA,IACd;AAAA;AAAA;;;ACtNA,IA4Ca;AA5Cb;AAAA;AA4CO,IAAM,8BAAwD;AAAA,MACnE,qBAAqB;AAAA,MACrB,YAAY;AAAA,MACZ,qBAAqB;AAAA,MACrB,iBAAiB;AAAA,MACjB,mBAAmB,IAAI,OAAO;AAAA;AAAA,MAC9B,aAAa;AAAA,MACb,0BAA0B;AAAA,IAC5B;AAAA;AAAA;;;ACpDA,IAwCa,4BAuBA,0BAmBA;AAlFb;AAAA;AAwCO,IAAM,6BAAqD;AAAA,MAChE,YAAY;AAAA,MACZ,MAAM;AAAA,MACN,kBAAkB;AAAA,MAClB,aAAa;AAAA,IACf;AAkBO,IAAM,2BAAiD;AAAA,MAC5D,wBAAwB;AAAA,IAC1B;AAiBO,IAAM,6BAAqD;AAAA,MAChE,SAAS;AAAA,MACT,OAAO;AAAA,IACT;AAAA;AAAA;;;ACrFA,IAkEa;AAlEb;AAAA;AAkEO,IAAM,yBAA8C;AAAA,MACzD,WAAW;AAAA,MACX,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,YAAY;AAAA,IACd;AAAA;AAAA;;;ACxEA,IA6Ba;AA7Bb;AAAA;AA6BO,IAAM,2BAAiD;AAAA,MAC5D,wBAAwB;AAAA,MACxB,sBAAsB;AAAA;AAAA,IACxB;AAAA;AAAA;;;AChCA,IAgCa;AAhCb;AAAA;AAgCO,IAAM,uBAA0C;AAAA,MACrD,gBAAgB;AAAA,MAChB,yBAAyB;AAAA,MACzB,wBAAwB;AAAA,IAC1B;AAAA;AAAA;;;ACpCA,IA4Ba,2BAsBA,4BAyBA,0BAyCA,sBAiDA,+BAmFA;AAxPb;AAAA;AA4BO,IAAM,4BAAmD;AAAA,MAC9D,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAkBO,IAAM,6BAAqD;AAAA,MAChE,sBAAsB;AAAA,IACxB;AAuBO,IAAM,2BAAiD;AAAA,MAC5D,iBAAiB;AAAA,IACnB;AAuCO,IAAM,uBAA0C;AAAA,MACrD,SAAS;AAAA,MACT,YAAY,CAAC,KAAK;AAAA,MAClB,QAAQ;AAAA,MACR,gBAAgB;AAAA,MAChB,MAAM;AAAA,IACR;AA2CO,IAAM,gCAA2D;AAAA,MACtE,SAAS;AAAA,MACT,YAAY,CAAC;AAAA,MACb,QAAQ;AAAA,MACR,gBAAgB;AAAA,MAChB,iBAAiB;AAAA,MACjB,aAAa;AAAA,MACb,oBAAoB;AAAA,IACtB;AA2EO,IAAM,uBAA0C;AAAA,MACrD,WAAW;AAAA,MACX,YAAY;AAAA,MACZ,UAAU;AAAA,MACV,OAAO;AAAA,MACP,UAAU;AAAA,MACV,QAAQ,CAAC;AAAA,IACX;AAAA;AAAA;;;AC/PA,IA6Ca;AA7Cb;AAAA;AA6CO,IAAM,yBAA8C;AAAA,MACzD,SAAS;AAAA,MACT,WAAW;AAAA,MACX,oBAAoB;AAAA,MACpB,gBAAgB,CAAC;AAAA,MACjB,aAAa;AAAA,IACf;AAAA;AAAA;;;ACnDA,IA+Ba,mCAwBA,mCAoBA,sCAoBA;AA/Fb;AAAA;AA+BO,IAAM,oCAAkE;AAAA,MAC7E,oBAAoB;AAAA;AAAA,MACpB,2BAA2B,KAAK,OAAO;AAAA;AAAA,MACvC,sBAAsB,KAAK,OAAO;AAAA;AAAA,IACpC;AAoBO,IAAM,oCAAkE;AAAA,MAC7E,qBAAqB;AAAA,MACrB,uBAAuB;AAAA,IACzB;AAiBO,IAAM,uCAAwE;AAAA,MACnF,gBAAgB;AAAA;AAAA,IAClB;AAkBO,IAAM,6BAAqD;AAAA,MAChE,QAAQ;AAAA,MACR,QAAQ;AAAA,MACR,WAAW;AAAA,IACb;AAAA;AAAA;;;ACnGA,IAcM,IACA,IAqBO,6BAwBA,gCAqBA,8BAsBA,mCAuBA;AA9Hb;AAAA;AAcA,IAAM,KAAK,OAAO;AAClB,IAAM,KAAK,OAAO;AAqBX,IAAM,8BAAuD;AAAA,MAClE,eAAe,CAAC,KAAK,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,EAAE;AAAA,MACvD,sBAAsB,IAAI;AAAA,IAC5B;AAqBO,IAAM,iCAA6D;AAAA,MACxE,kBAAkB,CAAC,IAAI,IAAI,MAAM,IAAI,MAAM,IAAI,MAAM,EAAE;AAAA,MACvD,sBAAsB,MAAM;AAAA,IAC9B;AAkBO,IAAM,+BAAyD;AAAA,MACpE,yBAAyB,IAAI;AAAA,IAC/B;AAoBO,IAAM,oCAAmE;AAAA,MAC9E,0BAA0B,IAAI;AAAA,MAC9B,sBAAsB,CAAC,MAAM,IAAI,MAAM,IAAI,MAAM,EAAE;AAAA,IACrD;AAoBO,IAAM,+BAAyD;AAAA,MACpE,aAAa;AAAA,MACb,gBAAgB;AAAA,MAChB,cAAc;AAAA,MACd,mBAAmB;AAAA,IACrB;AAAA;AAAA;;;ACnIA,IA4Ba;AA5Bb;AAAA;AA4BO,IAAM,wBAA4C;AAAA,MACvD,kBAAkB,MAAM,OAAO;AAAA;AAAA,MAC/B,oBAAoB;AAAA,IACtB;AAAA;AAAA;;;AC/BA;AAAA;AAAA;AAAA;;;AC6OO,SAAS,sBAAoD;AAClE,SAAO;AACT;AA/OA,IAyBa,2BAoBA,4BA0BA,uBA+CA,8BAsCA,iCAoBA,yBAWA,aA4BA,2BAiBT;AAxOJ;AAAA;AAyBO,IAAM,4BAAoD;AAAA,MAC/D,mBAAmB;AAAA,IACrB;AAkBO,IAAM,6BAAsD;AAAA,MACjE,gBAAgB;AAAA,IAClB;AAwBO,IAAM,wBAA4C;AAAA,MACvD,cAAc;AAAA,MACd,aAAa;AAAA,IACf;AA4CO,IAAM,+BAA0D;AAAA,MACrE,iBAAiB;AAAA,MACjB,sBAAsB;AAAA,MACtB,mBAAmB;AAAA,QACjB,OAAO;AAAA,QACP,OAAO;AAAA,QACP,OAAO;AAAA,MACT;AAAA,MACA,qBAAqB;AAAA,QACnB,OAAO;AAAA;AAAA,QACP,OAAO;AAAA;AAAA,QACP,OAAO;AAAA;AAAA,MACT;AAAA,IACF;AAyBO,IAAM,kCAA+D;AAAA,MAC1E,YAAY;AAAA,MACZ,WAAW;AAAA,IACb;AAiBO,IAAM,0BAAgD;AAAA,MAC3D,qBAAqB;AAAA,IACvB;AASO,IAAM,cAAsC;AAAA,MACjD,KAAK;AAAA,MACL,KAAK;AAAA,MACL,MAAM;AAAA,MACN,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AAAA,MACL,IAAI;AAAA,MACJ,IAAI;AAAA,IACN;AAkBO,IAAM,4BAA0D;AAAA,MACrE,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,MAAM;AAAA,MACN,WAAW;AAAA,MACX,aAAa;AAAA,MACb,MAAM;AAAA,IACR;AAUA,IAAI,oBAAkD,EAAE,GAAG,0BAA0B;AAAA;AAAA;;;AChD9E,SAAS,oBACd,WACqB;AACrB,MAAI,CAAC,WAAW;AACd,WAAO,EAAE,GAAG,uBAAuB;AAAA,EACrC;AAEA,SAAO;AAAA,IACL,OAAO,UAAU,SAAS,uBAAuB;AAAA,IACjD,SAAS,UAAU,UACf,mBAAmB,wBAAwB,UAAU,OAAO,IAC5D,EAAE,GAAG,uBAAuB;AAAA,IAChC,UAAU,UAAU;AAAA,EACtB;AACF;AAeA,SAAS,mBACP,MACA,WACqB;AACrB,SAAO;AAAA,IACL,cAAc,EAAE,GAAG,KAAK,cAAc,GAAG,UAAU,aAAa;AAAA,IAChE,SAAS,UAAU,UACf;AAAA,MACE,OAAO,EAAE,GAAG,KAAK,QAAQ,OAAO,GAAG,UAAU,QAAQ,MAAM;AAAA,MAC3D,gBAAgB,EAAE,GAAG,KAAK,QAAQ,gBAAgB,GAAG,UAAU,QAAQ,eAAe;AAAA,MACtF,WAAW,EAAE,GAAG,KAAK,QAAQ,WAAW,GAAG,UAAU,QAAQ,UAAU;AAAA,IACzE,IACA,EAAE,GAAG,KAAK,QAAQ;AAAA,IACtB,SAAS,UAAU,UACf;AAAA,MACE,YAAY,EAAE,GAAG,KAAK,QAAQ,YAAY,GAAG,UAAU,QAAQ,WAAW;AAAA,MAC1E,kBAAkB,EAAE,GAAG,KAAK,QAAQ,kBAAkB,GAAG,UAAU,QAAQ,iBAAiB;AAAA,MAC5F,UAAU,EAAE,GAAG,KAAK,QAAQ,UAAU,GAAG,UAAU,QAAQ,SAAS;AAAA,MACpE,aAAa,EAAE,GAAG,KAAK,QAAQ,aAAa,GAAG,UAAU,QAAQ,YAAY;AAAA,IAC/E,IACA,EAAE,GAAG,KAAK,QAAQ;AAAA,IACtB,WAAW,UAAU,YACjB;AAAA,MACE,UAAU,EAAE,GAAG,KAAK,UAAU,UAAU,GAAG,UAAU,UAAU,SAAS;AAAA,MACxE,UAAU,EAAE,GAAG,KAAK,UAAU,UAAU,GAAG,UAAU,UAAU,SAAS;AAAA,MACxE,SAAS,EAAE,GAAG,KAAK,UAAU,SAAS,GAAG,UAAU,UAAU,QAAQ;AAAA,MACrE,WAAW,EAAE,GAAG,KAAK,UAAU,WAAW,GAAG,UAAU,UAAU,UAAU;AAAA,MAC3E,cAAc,EAAE,GAAG,KAAK,UAAU,cAAc,GAAG,UAAU,UAAU,aAAa;AAAA,MACpF,QAAQ,UAAU,UAAU,UAAU,KAAK,UAAU;AAAA,MACrD,UAAU,UAAU,UAAU,YAAY,KAAK,UAAU;AAAA,MACzD,YAAY,UAAU,UAAU,cAAc,KAAK,UAAU;AAAA,MAC7D,cAAc,UAAU,UAAU,eAC9B,EAAE,GAAG,KAAK,UAAU,cAAc,GAAG,UAAU,UAAU,aAAa,IACtE,KAAK,UAAU;AAAA;AAAA,MAEnB,gBAAgB,UAAU,UAAU,kBAAkB,KAAK,UAAU;AAAA,IACvE,IACA,EAAE,GAAG,KAAK,UAAU;AAAA,IACxB,SAAS,EAAE,GAAG,KAAK,SAAS,GAAG,UAAU,QAAQ;AAAA,IACjD,KAAK,UAAU,MACX;AAAA,MACE,SAAS,EAAE,GAAG,KAAK,IAAI,SAAS,GAAG,UAAU,IAAI,QAAQ;AAAA,MACzD,OAAO,EAAE,GAAG,KAAK,IAAI,OAAO,GAAG,UAAU,IAAI,MAAM;AAAA,IACrD,IACA,EAAE,GAAG,KAAK,IAAI;AAAA,IAClB,YAAY,UAAU,aAClB;AAAA,MACE,QAAQ,EAAE,GAAG,KAAK,WAAW,QAAQ,GAAG,UAAU,WAAW,OAAO;AAAA,MACpE,QAAQ,EAAE,GAAG,KAAK,WAAW,QAAQ,GAAG,UAAU,WAAW,OAAO;AAAA,MACpE,WAAW,EAAE,GAAG,KAAK,WAAW,WAAW,GAAG,UAAU,WAAW,UAAU;AAAA,IAC/E,IACA,EAAE,GAAG,KAAK,WAAW;AAAA,IACzB,UAAU,EAAE,GAAG,KAAK,UAAU,GAAG,UAAU,SAAS;AAAA,IACpD,OAAO,EAAE,GAAG,KAAK,OAAO,GAAG,UAAU,MAAM;AAAA,IAC3C,QAAQ,UAAU,SACd;AAAA,MACE,aAAa,EAAE,GAAG,KAAK,OAAO,aAAa,GAAG,UAAU,OAAO,YAAY;AAAA,MAC3E,gBAAgB,EAAE,GAAG,KAAK,OAAO,gBAAgB,GAAG,UAAU,OAAO,eAAe;AAAA,MACpF,cAAc,EAAE,GAAG,KAAK,OAAO,cAAc,GAAG,UAAU,OAAO,aAAa;AAAA,MAC9E,mBAAmB,EAAE,GAAG,KAAK,OAAO,mBAAmB,GAAG,UAAU,OAAO,kBAAkB;AAAA,IAC/F,IACA,EAAE,GAAG,KAAK,OAAO;AAAA,IACrB,OAAO,UAAU,QACb;AAAA,MACE,WAAW,EAAE,GAAG,KAAK,MAAM,WAAW,GAAG,UAAU,MAAM,UAAU;AAAA,MACnE,YAAY,EAAE,GAAG,KAAK,MAAM,YAAY,GAAG,UAAU,MAAM,WAAW;AAAA,MACtE,UAAU,EAAE,GAAG,KAAK,MAAM,UAAU,GAAG,UAAU,MAAM,SAAS;AAAA,MAChE,OAAO,EAAE,GAAG,KAAK,MAAM,OAAO,GAAG,UAAU,MAAM,MAAM;AAAA,MACvD,UAAU,EAAE,GAAG,KAAK,MAAM,UAAU,GAAG,UAAU,MAAM,SAAS;AAAA,MAChE,QAAQ,UAAU,MAAM,UAAU,KAAK,MAAM;AAAA,IAC/C,IACA,EAAE,GAAG,KAAK,MAAM;AAAA,IACpB,SAAS,UAAU,UACf;AAAA,MACE,GAAG,KAAK;AAAA,MACR,GAAG,UAAU;AAAA,MACb,gBAAgB,UAAU,QAAQ,kBAAkB,KAAK,QAAQ;AAAA,IACnE,IACA,EAAE,GAAG,KAAK,QAAQ;AAAA,IACtB,QAAQ,EAAE,GAAG,KAAK,QAAQ,GAAG,UAAU,OAAO;AAAA,EAChD;AACF;AAtSA,IAkGa,wBA0DA;AA5Jb;AAAA;AAgCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAsDO,IAAM,yBAA8C;AAAA,MACzD,cAAc;AAAA,MACd,SAAS;AAAA,MACT,SAAS;AAAA,MACT,WAAW;AAAA,MACX,SAAS;AAAA,MACT,KAAK;AAAA,MACL,YAAY;AAAA,MACZ,UAAU;AAAA,MACV,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,OAAO;AAAA,MACP,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AA4CO,IAAM,yBAA8C;AAAA,MACzD,OAAO;AAAA,MACP,SAAS;AAAA,MACT,UAAU;AAAA,IACZ;AAAA;AAAA;;;AChKA;AAAA;AAiBA;AAiDA;AAeA;AA2BA;AAiCA;AAmBA;AAqCA;AAiBA;AAsBA;AAWA;AAgBA;AAaA;AAWA;AAWA;AA6BA;AAYA;AAiBA;AAmBA;AAWA;AAaA;AA6BA;AAAA;AAAA;;;AC1ZO,SAAS,mBAAwC;AACtD,SAAO;AACT;AApBA,IAaI;AAbJ;AAAA;AAUA;AACA;AAEA,IAAI,gBAAqC,oBAAoB,EAAE;AAAA;AAAA;;;AC2FxD,SAAS,WAAW,SAA4B;AACrD,UAAQ,IAAI,GAAG,QAAQ,IAAI,IAAI,KAAK,UAAU,OAAO,CAAC,EAAE;AAC1D;AAKO,SAAS,aAAa,MAAqC;AAChE,UAAQ,IAAI,GAAG,QAAQ,MAAM,IAAI,KAAK,UAAU,IAAI,CAAC,EAAE;AACzD;AAKO,SAAS,YAAY,OAAe,SAAyC;AAClF,UAAQ,IAAI,GAAG,QAAQ,KAAK,IAAI,KAAK,UAAU,EAAE,OAAO,GAAG,QAAQ,CAAC,CAAC,EAAE;AACzE;AAKO,SAAS,eAAe,SAAiB,SAAwB;AACtE,UAAQ,IAAI,GAAG,QAAQ,QAAQ,IAAI,KAAK,UAAU,EAAE,SAAS,QAAQ,CAAC,CAAC,EAAE;AAC3E;AA6JO,SAAS,YAAY,OAAqB;AAC/C,QAAM,WAA0C;AAAA,IAC9C,OAAOA,YAAW;AAAA,IAClB,SAASA,YAAW;AAAA,IACpB,MAAMA,YAAW;AAAA,IACjB,MAAMA,YAAW;AAAA,IACjB,OAAOA,YAAW;AAAA,IAClB,QAAQA,YAAW;AAAA,EACrB;AACA,oBAAkB,SAAS,MAAM,YAAY,CAAC,KAAKA,YAAW;AAC9D,UAAQ,IAAI,+BAA+B,MAAM,YAAY,CAAC,EAAE;AAClE;AAKO,SAAS,cAAsB;AACpC,aAAW,CAAC,MAAM,KAAK,KAAK,OAAO,QAAQA,WAAU,GAAG;AACtD,QAAI,UAAU;AAAiB,aAAO,KAAK,YAAY;AAAA,EACzD;AACA,SAAO;AACT;AAaO,SAAS,SACd,YACA,SACM;AAEN,MAAI,eAAe,OAAO;AACxB,2BAAuB,MAAM;AAC7B,YAAQ,IAAI,0BAA0B;AACtC;AAAA,EACF;AAGA,QAAM,WAAW,OAAO,eAAe,WACnC,WAAW,MAAM,GAAG,EAAE,IAAI,OAAK,EAAE,KAAK,CAAC,IACvC;AAGJ,yBAAuB,MAAM;AAG7B,QAAM,SAAS,SAAS,SAAS,KAAK;AACtC,MAAI,QAAQ;AACV,eAAW,OAAO,kBAAkB;AAClC,6BAAuB,IAAI,GAAG;AAAA,IAChC;AAAA,EACF;AAGA,aAAW,OAAO,UAAU;AAC1B,QAAI,QAAQ;AAAO;AAEnB,QAAI,IAAI,WAAW,GAAG,GAAG;AACvB,YAAM,UAAU,IAAI,MAAM,CAAC;AAC3B,6BAAuB,OAAO,OAAO;AAAA,IACvC,WAAW,iBAAiB,SAAS,GAAoB,GAAG;AAC1D,6BAAuB,IAAI,GAAoB;AAAA,IACjD;AAAA,EACF;AAGA,MAAI,SAAS,QAAQ;AACnB,uBAAmB,QAAQ;AAAA,EAC7B;AACA,MAAI,SAAS,mBAAmB,QAAW;AACzC,0BAAsB,QAAQ;AAAA,EAChC;AACA,MAAI,SAAS,mBAAmB,QAAW;AACzC,0BAAsB,QAAQ;AAAA,EAChC;AAEA,QAAM,UAAU,CAAC,GAAG,sBAAsB,EAAE,KAAK,GAAG,KAAK;AACzD,UAAQ,IAAI,+BAA+B,OAAO,EAAE;AACtD;AA4CO,SAAS,WAA4B;AAC1C,SAAO,CAAC,GAAG,sBAAsB;AACnC;AAKO,SAAS,eAAe,UAAyB,UAA4B;AAClF,MAAI,CAAC,uBAAuB,IAAI,QAAQ;AAAG,WAAO;AAGlD,MAAI,aAAa,UAAa,iBAAiB,SAAS,GAAG;AACzD,QAAI,CAAC,iBAAiB,SAAS,QAAQ;AAAG,aAAO;AAAA,EACnD;AAGA,MAAI,sBAAsB,KAAK,kBAAkB,qBAAqB;AACpE,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAuCO,SAAS,iBAAiB,SAAwB;AACvD,kBAAgB;AAChB,MAAI,SAAS;AACX,UAAM,OAAO,MAAM;AAAA,IAAC;AACpB,YAAQ,MAAM;AACd,YAAQ,QAAQ;AAChB,YAAQ,OAAO;AACf,uBAAmB,qDAAqD;AAAA,EAC1E,OAAO;AACL,YAAQ,MAAM;AACd,YAAQ,QAAQ;AAChB,YAAQ,OAAO;AACf,YAAQ,IAAI,sDAAsD;AAAA,EACpE;AACF;AAKO,SAAS,kBAA2B;AACzC,SAAO;AACT;AAkDO,SAAS,oBAA0B;AACxC,MAAI,OAAO,WAAW;AAAa;AAEnC,QAAM,SAAS,IAAI,gBAAgB,OAAO,SAAS,MAAM;AAGzD,QAAM,WAAW,OAAO,IAAI,KAAK;AACjC,MAAI,UAAU;AACZ,gBAAY,QAAQ;AAAA,EACtB;AAGA,QAAM,aAAa,OAAO,IAAI,OAAO;AACrC,MAAI,YAAY;AACd,UAAM,SAAS,OAAO,IAAI,QAAQ,GAAG,MAAM,GAAG,EAAE,IAAI,MAAM,EAAE,OAAO,OAAK,CAAC,MAAM,CAAC,CAAC;AACjF,UAAM,UAAU,OAAO,IAAI,OAAO,MAAM;AACxC,aAAS,YAAY,EAAE,QAAQ,gBAAgB,QAAQ,CAAC;AAAA,EAC1D;AAGA,QAAM,aAAa,OAAO,IAAI,OAAO;AACrC,MAAI,eAAe,OAAO,CAAC,YAAY;AACrC,aAAS,KAAK;AACd,gBAAY,SAAS;AAAA,EACvB;AACF;AASA,SAAS,UAAU,QAAgB,OAA+B;AAChE,MAAI,QAAQ;AAAiB,WAAO;AAEpC,QAAM,cAAc,OAAO,YAAY;AAEvC,MAAI,eAAe,OAAO,KAAK,CAAC,eAAe,IAAI,WAAW,GAAG;AAC/D,WAAO;AAAA,EACT;AAEA,MAAI,gBAAgB,IAAI,WAAW,GAAG;AACpC,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAKA,SAAS,cAAc,QAAgB,SAAyB;AAC9D,QAAM,YAAY,YAAY,IAAI,EAAE,QAAQ,CAAC;AAC7C,SAAO,IAAI,SAAS,OAAO,MAAM,KAAK,OAAO;AAC/C;AAKA,SAAS,mBAAmB,UAAyB,SAAiB,UAA2B;AAC/F,QAAM,YAAY,YAAY,IAAI,EAAE,QAAQ,CAAC;AAC7C,QAAM,WAAW,aAAa,SAAY,IAAI,QAAQ,MAAM;AAC5D,SAAO,IAAI,SAAS,aAAa,QAAQ,KAAK,QAAQ,GAAG,OAAO;AAClE;AAKA,SAAS,SAAS,OAAe,QAAgB,SAAiB,MAAsB;AACtF,aAAW,KAAK;AAAA,IACd,MAAM,KAAK,IAAI;AAAA,IACf,UAAU,YAAY,IAAI;AAAA,IAC1B;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC;AAED,QAAM,aAAa,iBAAiB,EAAE,MAAM,WAAW;AACvD,MAAI,WAAW,SAAS,YAAY;AAClC,eAAW,MAAM;AAAA,EACnB;AACF;AAKA,SAAS,SAAS,GAAmB;AACnC,QAAM,OAAQ,KAAK,KAAM;AACzB,QAAM,MAAO,KAAK,KAAM;AACxB,QAAM,OAAO,IAAI;AAEjB,MAAI,QAAQ,GAAG;AACb,YAAQ,OAAO,KAAK,KAAK,KAAK,IAAI,GAAG,GAAG,KAAK,OAAO;AAAA,EACtD,WAAW,QAAQ,IAAI;AACrB,WAAO,SAAS,IAAK,OAAO,YAAY,WAAY;AAAA,EACtD;AAEA,UAAQ,OAAO,KAAK,KAAK,KAAK,IAAI,GAAG,MAAM,EAAE,KAAK,IAAI,OAAO;AAC/D;AAyfO,SAAS,cAAc,SAA2B,CAAC,GAAe;AACvE,MAAI,UAAU,CAAC,GAAG,UAAU;AAE5B,MAAI,OAAO,OAAO;AAChB,cAAU,QAAQ,OAAO,CAAC,MAAM,EAAE,UAAU,OAAO,MAAO,YAAY,CAAC;AAAA,EACzE;AAEA,MAAI,OAAO,QAAQ;AACjB,UAAM,IAAI,OAAO,OAAO,YAAY;AACpC,cAAU,QAAQ,OAAO,CAAC,MAAM,EAAE,OAAO,YAAY,EAAE,SAAS,CAAC,CAAC;AAAA,EACpE;AAEA,MAAI,OAAO,MAAM;AACf,cAAU,QAAQ,MAAM,CAAC,OAAO,IAAI;AAAA,EACtC;AAEA,SAAO;AACT;AAYO,SAAS,gBAAgB,QAAQ,IAAU;AAChD,QAAM,SAAS,WAAW,MAAM,CAAC,KAAK;AACtC,UAAQ,IAAI,qBAAqB;AACjC,aAAW,SAAS,QAAQ;AAC1B,UAAM,OAAO,MAAM,SAAS,QAAQ,CAAC;AACrC,YAAQ,IAAI,IAAI,IAAI,OAAO,MAAM,KAAK,KAAK,MAAM,MAAM,KAAK,MAAM,OAAO,EAAE;AAAA,EAC7E;AACA,UAAQ,IAAI,qBAAqB;AACnC;AAKO,SAAS,mBAAkC;AAChD,SAAO;AAAA,IACL,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,IAClC,UAAU,OAAO,KAAKA,WAAU,EAAE;AAAA,MAChC,CAAC,MAAMA,YAAW,CAAa,MAAM;AAAA,IACvC;AAAA,IACA,iBAAiB,CAAC,GAAG,sBAAsB;AAAA,IAC3C,gBAAgB,CAAC,GAAG,cAAc;AAAA,IAClC,iBAAiB,CAAC,GAAG,eAAe;AAAA,IACpC,YAAY,WAAW,MAAM,GAAG,EAAE,IAAI,CAAC,OAAO;AAAA,MAC5C,MAAM,EAAE,SAAS,QAAQ,CAAC;AAAA,MAC1B,OAAO,EAAE;AAAA,MACT,QAAQ,EAAE;AAAA,MACV,SAAS,EAAE;AAAA,IACb,EAAE;AAAA,IACF,YAAY,WAAW,OAAO,CAAC,MAAM,EAAE,UAAU,OAAO,EAAE;AAAA,IAC1D,WAAW,WAAW,OAAO,CAAC,MAAM,EAAE,UAAU,MAAM,EAAE;AAAA,EAC1D;AACF;AA3rCA,IA4Ea,SA4DAA,aAYA,kBAkHT,iBACA,gBACA,iBACA,YAGA,WAGA,wBACA,kBACA,iBACA,qBACA,qBA+LA,eACE,oBACA,sBACA,qBA0LO,KA4FA,OAqJA,QAkNA,MAgJP;AAluCN;AAAA;AA2DA;AAiBO,IAAM,UAAU;AAAA;AAAA,MAErB,MAAM;AAAA;AAAA,MAEN,QAAQ;AAAA;AAAA,MAER,OAAO;AAAA;AAAA,MAEP,UAAU;AAAA,IACZ;AAmDO,IAAMA,cAAa;AAAA,MACxB,OAAO;AAAA,MACP,SAAS;AAAA,MACT,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,IACV;AAKO,IAAM,mBAAmB;AAAA,MAC9B;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,MACA;AAAA;AAAA,IACF;AAuGA,IAAI,kBAAiCA,YAAW;AAChD,IAAI,iBAAiB,oBAAI,IAAY;AACrC,IAAI,kBAAkB,oBAAI,IAAY;AACtC,IAAI,aAAyB,CAAC;AAG9B,IAAI,YAA8B;AAGlC,IAAI,yBAAyB,oBAAI,IAAmB;AACpD,IAAI,mBAA6B,CAAC;AAClC,IAAI,kBAAkB;AACtB,IAAI,sBAAsB;AAC1B,IAAI,sBAAsB;AA+L1B,IAAI,gBAAgB;AACpB,IAAM,qBAAqB,QAAQ;AACnC,IAAM,uBAAuB,QAAQ;AACrC,IAAM,sBAAsB,QAAQ;AA0L7B,IAAM,MAAM;AAAA;AAAA;AAAA;AAAA,MAIjB,MAAM,QAAgB,SAAiB,MAAsB;AAC3D,YAAI,CAAC,UAAU,QAAQA,YAAW,KAAK;AAAG;AAC1C,cAAM,YAAY,cAAc,QAAQ,OAAO;AAC/C,iBAAS,SAAS,QAAQ,SAAS,IAAI;AACvC,YAAI,SAAS,QAAW;AACtB,kBAAQ,MAAM,WAAW,IAAI;AAAA,QAC/B,OAAO;AACL,kBAAQ,MAAM,SAAS;AAAA,QACzB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,QAAQ,QAAgB,SAAiB,MAAsB;AAC7D,YAAI,CAAC,UAAU,QAAQA,YAAW,OAAO;AAAG;AAC5C,cAAM,YAAY,cAAc,QAAQ,OAAO;AAC/C,iBAAS,WAAW,QAAQ,SAAS,IAAI;AACzC,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,KAAK,QAAgB,SAAiB,MAAsB;AAC1D,YAAI,CAAC,UAAU,QAAQA,YAAW,IAAI;AAAG;AACzC,cAAM,YAAY,cAAc,QAAQ,OAAO;AAC/C,iBAAS,QAAQ,QAAQ,SAAS,IAAI;AACtC,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,KAAK,QAAgB,SAAiB,MAAsB;AAC1D,YAAI,CAAC,UAAU,QAAQA,YAAW,IAAI;AAAG;AACzC,cAAM,YAAY,cAAc,QAAQ,OAAO;AAC/C,iBAAS,QAAQ,QAAQ,SAAS,IAAI;AACtC,YAAI,SAAS,QAAW;AACtB,kBAAQ,KAAK,WAAW,IAAI;AAAA,QAC9B,OAAO;AACL,kBAAQ,KAAK,SAAS;AAAA,QACxB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,MAAM,QAAgB,SAAiB,MAAsB;AAC3D,YAAI,CAAC,UAAU,QAAQA,YAAW,KAAK;AAAG;AAC1C,cAAM,YAAY,cAAc,QAAQ,OAAO;AAC/C,iBAAS,SAAS,QAAQ,SAAS,IAAI;AACvC,YAAI,SAAS,QAAW;AACtB,kBAAQ,MAAM,WAAW,IAAI;AAAA,QAC/B,OAAO;AACL,kBAAQ,MAAM,SAAS;AAAA,QACzB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,OAAO,QAAgB,SAAiB,MAAsB;AAC5D,cAAM,YAAY,cAAc,QAAQ,OAAO;AAC/C,iBAAS,UAAU,QAAQ,SAAS,IAAI;AACxC,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA,IACF;AASO,IAAM,QAAQ;AAAA;AAAA;AAAA;AAAA,MAInB,OAAO,SAAiB,MAAsB;AAC5C,YAAI,CAAC,eAAe,QAAQ;AAAG;AAC/B,cAAM,YAAY,mBAAmB,UAAU,OAAO;AACtD,iBAAS,gBAAgB,UAAU,SAAS,IAAI;AAChD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,QAAQ,SAAiB,MAAsB;AAC7C,YAAI,CAAC,eAAe,SAAS;AAAG;AAChC,cAAM,YAAY,mBAAmB,WAAW,OAAO;AACvD,iBAAS,iBAAiB,WAAW,SAAS,IAAI;AAClD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,OAAO,SAAiB,MAAsB;AAC5C,YAAI,CAAC,eAAe,QAAQ;AAAG;AAC/B,cAAM,YAAY,mBAAmB,UAAU,OAAO;AACtD,iBAAS,gBAAgB,UAAU,SAAS,IAAI;AAChD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,MAAM,SAAiB,MAAsB;AAC3C,YAAI,CAAC,eAAe,OAAO;AAAG;AAC9B,cAAM,YAAY,mBAAmB,SAAS,OAAO;AACrD,iBAAS,eAAe,SAAS,SAAS,IAAI;AAC9C,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,KAAK,UAAkB,SAAiB,MAAsB;AAC5D,YAAI,CAAC,eAAe,QAAQ,QAAQ;AAAG;AACvC,cAAM,YAAY,mBAAmB,QAAQ,SAAS,QAAQ;AAC9D,iBAAS,cAAc,SAAS,QAAQ,IAAI,SAAS,IAAI;AACzD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,IAAI,UAAkB,SAAiB,MAAsB;AAC3D,YAAI,CAAC,eAAe,OAAO,QAAQ;AAAG;AACtC,cAAM,YAAY,mBAAmB,OAAO,SAAS,QAAQ;AAC7D,iBAAS,aAAa,QAAQ,QAAQ,IAAI,SAAS,IAAI;AACvD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,GAAG,UAAkB,SAAiB,MAAsB;AAC1D,YAAI,CAAC,eAAe,MAAM,QAAQ;AAAG;AACrC,cAAM,YAAY,mBAAmB,MAAM,SAAS,QAAQ;AAC5D,iBAAS,YAAY,OAAO,QAAQ,IAAI,SAAS,IAAI;AACrD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,OAAO,SAAiB,MAAsB;AAC5C,YAAI,CAAC,eAAe,QAAQ;AAAG;AAC/B,cAAM,YAAY,mBAAmB,UAAU,OAAO;AACtD,iBAAS,gBAAgB,UAAU,SAAS,IAAI;AAChD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,QAAQ,SAAiB,MAAsB;AAC7C,YAAI,CAAC,eAAe,SAAS;AAAG;AAChC,cAAM,YAAY,mBAAmB,WAAW,OAAO;AACvD,iBAAS,iBAAiB,WAAW,SAAS,IAAI;AAClD,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,KAAK,SAAiB,MAAsB;AAC1C,YAAI,CAAC,eAAe,MAAM;AAAG;AAC7B,cAAM,YAAY,mBAAmB,QAAQ,OAAO;AACpD,iBAAS,cAAc,QAAQ,SAAS,IAAI;AAC5C,YAAI,SAAS,QAAW;AACtB,kBAAQ,IAAI,WAAW,IAAI;AAAA,QAC7B,OAAO;AACL,kBAAQ,IAAI,SAAS;AAAA,QACvB;AAAA,MACF;AAAA,IACF;AASO,IAAM,SAAS;AAAA;AAAA;AAAA;AAAA,MAIpB,MAAM,QACJ,QACA,OACA,UAAgC,CAAC,GACJ;AAC7B,cAAM,EAAE,QAAQ,CAAC,GAAG,WAAW,GAAG,WAAW,KAAK,IAAI;AAEtD,YAAI;AACJ,YAAI,QAAQ;AAGZ,YAAI,UAAU,OAAQ,OAAqB,aAAa,YAAY;AAClE,gBAAM,YAAY;AAClB,gBAAM,UAAU,SAAS,WAAW,IAAI;AACxC,iBAAO,IAAI,aAAa,UAAU,eAAe,EAAE,MAAM,CAAC,CAAC;AAC3D,oBAAU,MAAM;AAAA,QAClB,WAAW,UAAW,OAAqB,SAAS,UAAa,WAAW;AAC1E,kBAAQ;AACR,gBAAM,YAAY;AAClB,gBAAM,WAAW,KAAK,IAAI,UAAU,MAAM,IAAI;AAC9C,gBAAM,UAAU,UAAU,aAAa;AAAA,YACrC,OAAO,iBAAiB,KAAK;AAAA,YAC7B,MAAM;AAAA,YACN,OAAO,eAAe,WAAW,eAAe;AAAA,UAClD,CAAC;AAED,gBAAM,UAAU,UAAU,qBAAqB;AAC/C,kBAAQ,mBAAmB,WAAW,GAAG,SAAS,GAAG,QAAQ;AAC7D,oBAAU,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAEzC,gBAAM,QAAQ,SAAS,WAAW,IAAI;AACtC,iBAAO,IAAI,aAAa,QAAQ,eAAe,EAAE,MAAM,CAAC,CAAC;AACzD,kBAAQ,MAAM;AACd,kBAAQ,QAAQ;AAAA,QAClB,WAAW,kBAAkB,gBAAgB,kBAAkB,cAAc;AAC3E,iBAAO,kBAAkB,eAAe,SAAS,IAAI,aAAa,MAAM;AAAA,QAC1E,WAAW,kBAAkB,aAAa;AACxC,iBAAO,IAAI,aAAa,OAAO,MAAM;AACrC,mBAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,iBAAK,CAAC,IAAI,SAAS,OAAO,CAAC,CAAC;AAAA,UAC9B;AAAA,QACF,OAAO;AACL,cAAI,KAAK,SAAS,0BAA0B,KAAK,iBAAiB;AAClE,iBAAO;AAAA,QACT;AAGA,YAAI,MAAM,UACR,MAAM,WACN,MAAM,GACN,QAAQ;AACV,YAAI,WAAW,GACb,WAAW,GACX,YAAY;AAEd,iBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,gBAAM,IAAI,KAAK,CAAC;AAChB,cAAI,OAAO,MAAM,CAAC,GAAG;AACnB;AACA;AAAA,UACF;AACA,cAAI,CAAC,OAAO,SAAS,CAAC,GAAG;AACvB;AACA;AAAA,UACF;AACA,cAAI,MAAM;AAAG;AACb,gBAAM,KAAK,IAAI,KAAK,CAAC;AACrB,gBAAM,KAAK,IAAI,KAAK,CAAC;AACrB,iBAAO;AACP,mBAAS,IAAI;AAAA,QACf;AAEA,cAAM,aAAa,KAAK,SAAS,WAAW;AAC5C,cAAM,OAAO,aAAa,IAAI,MAAM,aAAa;AACjD,cAAM,WAAW,aAAa,IAAI,QAAQ,aAAa,OAAO,OAAO;AACrE,cAAM,MAAM,KAAK,KAAK,KAAK,IAAI,GAAG,QAAQ,CAAC;AAE3C,cAAM,QAAqB;AAAA,UACzB;AAAA,UACA;AAAA,UACA,MAAM,KAAK;AAAA,UACX;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,cAAe,YAAY,KAAK,SAAU,KAAK,QAAQ,CAAC;AAAA,UACxD,OAAO,MAAM,KAAK,KAAK,MAAM,GAAG,QAAQ,CAAC,EAAE,IAAI,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;AAAA,UAClE,MAAM,MAAM,KAAK,KAAK,MAAM,CAAC,QAAQ,CAAC,EAAE,IAAI,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;AAAA,QACjE;AAEA,cAAM,WAAW,MAAM,SAAS,IAAI,IAAI,MAAM,KAAK,GAAG,CAAC,MAAM,IAAI,KAAK,MAAM;AAC5E,YAAI;AAAA,UACF;AAAA,UACA,GAAG,KAAK,IAAI,QAAQ,SAAS,IAAI,QAAQ,CAAC,CAAC,SAAS,IAAI,QAAQ,CAAC,CAAC,UAAU,KAAK,QAAQ,CAAC,CAAC,SAAS,IAAI,QAAQ,CAAC,CAAC;AAAA,QACpH;AAEA,YAAI,aAAa,WAAW,KAAK,WAAW,IAAI;AAC9C,cAAI,KAAK,UAAU,GAAG,KAAK,QAAQ,QAAQ,YAAY,QAAQ,cAAc;AAAA,QAC/E;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,QACE,GACA,GACA,OACA,YAAY,MACS;AACrB,YAAI,EAAE,WAAW,EAAE,QAAQ;AACzB,cAAI,MAAM,UAAU,GAAG,KAAK,mBAAmB,EAAE,MAAM,OAAO,EAAE,MAAM,EAAE;AACxE,iBAAO,EAAE,OAAO,OAAO,OAAO,OAAO,iBAAiB,SAAS,GAAG,YAAY,GAAG,SAAS,GAAG,eAAe,GAAG,iBAAiB,IAAI;AAAA,QACtI;AAEA,YAAI,UAAU,GACZ,aAAa;AACf,YAAI,UAAU;AACd,YAAI,gBAAgB;AAEpB,iBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,gBAAM,OAAO,KAAK,IAAI,EAAE,CAAC,IAAI,EAAE,CAAC,CAAC;AACjC,qBAAW;AACX,cAAI,OAAO,SAAS;AAClB,sBAAU;AACV,yBAAa;AAAA,UACf;AACA,cAAI,OAAO,WAAW;AACpB;AAAA,UACF;AAAA,QACF;AAEA,cAAM,UAAU,UAAU,EAAE;AAC5B,cAAM,QAAQ,kBAAkB;AAEhC,cAAM,SAA8B;AAAA,UAClC;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA,kBAAmB,gBAAgB,EAAE,SAAU,KAAK,QAAQ,CAAC;AAAA,QAC/D;AAEA,YAAI,OAAO;AACT,cAAI,MAAM,UAAU,GAAG,KAAK,oBAAoB,QAAQ,cAAc,CAAC,CAAC,GAAG;AAAA,QAC7E,OAAO;AACL,cAAI;AAAA,YACF;AAAA,YACA,GAAG,KAAK,cAAc,aAAa,IAAI,EAAE,MAAM,KAAK,OAAO,eAAe,cAAc,QAAQ,QAAQ,CAAC,CAAC,WAAW,UAAU;AAAA,UACjI;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,YAAY,MAAoB,OAAmC;AACjE,cAAM,SAAmB,CAAC;AAE1B,cAAM,UAAU,KAAK,MAAM,CAAC,MAAM,MAAM,CAAC;AACzC,YAAI,SAAS;AACX,iBAAO,KAAK,WAAW;AAAA,QACzB;AAEA,cAAM,SAAS,KAAK,KAAK,CAAC,MAAM,OAAO,MAAM,CAAC,CAAC;AAC/C,cAAM,SAAS,KAAK,KAAK,CAAC,MAAM,CAAC,OAAO,SAAS,CAAC,KAAK,CAAC,OAAO,MAAM,CAAC,CAAC;AACvE,YAAI;AAAQ,iBAAO,KAAK,SAAS;AACjC,YAAI;AAAQ,iBAAO,KAAK,SAAS;AAEjC,cAAM,SAAS,KAAK,IAAI,GAAG,MAAM,KAAK,IAAI,EAAE,IAAI,KAAK,GAAG,EAAE,OAAO,OAAO,QAAQ,CAAC;AACjF,YAAI,SAAS;AAAK,iBAAO,KAAK,uBAAuB,OAAO,cAAc,CAAC,CAAC,GAAG;AAE/E,cAAM,YAAY,KAAK,OAAO,CAAC,MAAM,KAAK,IAAI,CAAC,IAAI,KAAK,KAAK,IAAI,CAAC,IAAI,KAAK,EAAE;AAC7E,YAAI,YAAY,KAAK,SAAS,KAAK;AACjC,iBAAO,KAAK,wBAAwB,SAAS,eAAe;AAAA,QAC9D;AAEA,cAAM,UAAU,OAAO,WAAW;AAElC,YAAI,SAAS;AACX,cAAI,MAAM,UAAU,GAAG,KAAK,WAAW;AAAA,QACzC,OAAO;AACL,cAAI,KAAK,UAAU,GAAG,KAAK,oBAAoB,OAAO,KAAK,IAAI,CAAC,EAAE;AAAA,QACpE;AAEA,eAAO,EAAE,OAAO,SAAS,OAAO;AAAA,MAClC;AAAA,IACF;AASO,IAAM,OAAO;AAAA,MAClB,OAAO,oBAAI,IAAoB;AAAA;AAAA;AAAA;AAAA,MAK/B,KAAK,OAAqB;AACxB,aAAK,MAAM,IAAI,OAAO,YAAY,IAAI,CAAC;AAAA,MACzC;AAAA;AAAA;AAAA;AAAA,MAKA,QAAQ,OAAe,SAAS,QAAgB;AAC9C,cAAM,QAAQ,KAAK,MAAM,IAAI,KAAK;AAClC,YAAI,UAAU,QAAW;AACvB,cAAI,KAAK,QAAQ,sBAAsB,KAAK,GAAG;AAC/C,iBAAO;AAAA,QACT;AAEA,cAAM,WAAW,YAAY,IAAI,IAAI;AACrC,aAAK,MAAM,OAAO,KAAK;AACvB,YAAI,MAAM,QAAQ,GAAG,KAAK,KAAK,SAAS,QAAQ,CAAC,CAAC,IAAI;AACtD,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,MAAM,KAAQ,OAAe,IAAkE;AAC7F,cAAM,QAAQ,YAAY,IAAI;AAC9B,cAAM,SAAS,MAAM,GAAG;AACxB,cAAM,aAAa,YAAY,IAAI,IAAI;AACvC,YAAI,MAAM,QAAQ,GAAG,KAAK,KAAK,WAAW,QAAQ,CAAC,CAAC,IAAI;AACxD,eAAO,EAAE,QAAQ,WAAW;AAAA,MAC9B;AAAA,IACF;AA4GA,IAAM,cAA+B;AAAA;AAAA,MAEnC;AAAA,MACA;AAAA,MACA;AAAA;AAAA,MAEA;AAAA,MACA;AAAA,MACA;AAAA;AAAA,MAEA;AAAA,MACA,SAAS,OAAO,QAAQ,KAAK,MAAM;AAAA;AAAA,MAEnC;AAAA;AAAA,MAEA;AAAA,MACA;AAAA;AAAA,MAEA;AAAA,MACA;AAAA,MACA;AAAA;AAAA,MAEA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAGA,QAAI,OAAO,WAAW,aAAa;AACjC,MAAC,OAAe,UAAU;AAAA,QACxB,GAAK,OAAe,WAAW,CAAC;AAAA,QAChC,GAAG;AAAA,MACL;AAGA,UAAI,SAAS,eAAe,WAAW;AACrC,iBAAS,iBAAiB,oBAAoB,iBAAiB;AAAA,MACjE,OAAO;AACL,0BAAkB;AAAA,MACpB;AAAA,IACF;AAAA;AAAA;;;ACxqCO,SAAS,cAAoB;AAClC,MAAI,OAAO,kBAAkB;AAC3B,aAAS;AACT,QAAI,OAAO,iBAAiB;AAC1B,YAAM,KAAK,sBAAsB,SAAS,OAAO,EAAE;AAAA,IACrD;AAAA,EACF;AACF;AAKO,SAAS,gBAAgB,MAAc,OAAsB;AAClE,MAAI,OAAO,kBAAkB;AAC3B,aAAS;AACT,QAAI,OAAO,iBAAiB;AAC1B,YAAM,QAAQ,0BAA0B,SAAS,WAAW,KAAK,IAAI,WAAW,SAAS,WAAW,GAAG;AAAA,IACzG;AAAA,EACF;AACF;AAMO,SAAS,cAAc,QAA0B;AACtD,MAAI,CAAC,OAAO,kBAAkB;AAC5B,UAAM,UAAU,oCAAoC,UAAU,gBAAgB;AAC9E,QAAI,OAAO,YAAY;AACrB,YAAM,IAAI,MAAM,OAAO;AAAA,IACzB;AACA,QAAI,OAAO,iBAAiB;AAC1B,UAAI,KAAK,aAAa,OAAO;AAAA,IAC/B;AACA,WAAO;AAAA,EACT;AAEA,MAAI,OAAO,kBAAkB;AAC3B,aAAS;AACT,QAAI,OAAO,iBAAiB;AAC1B,YAAM,KAAK,wBAAwB,SAAS,SAAS,KAAK,UAAU,SAAS,EAAE;AAAA,IACjF;AAAA,EACF;AAEA,SAAO;AACT;AAjJA,IAkCM,gBAWF,QAYA;AAzDJ;AAAA;AAOA;AA2BA,IAAM,iBAA6B;AAAA,MACjC,kBAAkB;AAAA;AAAA,MAClB,kBAAkB;AAAA,MAClB,kBAAkB;AAAA,MAClB,iBAAiB;AAAA,MACjB,YAAY;AAAA,IACd;AAKA,IAAI,SAAqB,EAAE,GAAG,eAAe;AAY7C,IAAI,WAAyB;AAAA,MAC3B,SAAS;AAAA,MACT,aAAa;AAAA,MACb,WAAW;AAAA,MACX,WAAW;AAAA,IACb;AAAA;AAAA;;;ACqDO,SAAS,aAAa,YAAoB,QAAuB;AACtE,MAAI,CAAC;AAAe;AAGpB;AACA,cAAY,KAAK,UAAU;AAC3B,mBAAiB;AACjB,gBAAc,KAAK,IAAI,aAAa,UAAU;AAC9C,gBAAc,KAAK,IAAI,aAAa,UAAU;AAG9C,MAAI,QAAQ;AACV,kBAAc,IAAI,SAAS,cAAc,IAAI,MAAM,KAAK,KAAK,CAAC;AAAA,EAChE;AAGA,QAAM,KAAK,WAAW,YAAY;AAClC,KAAG;AACH,KAAG,MAAM,KAAK,UAAU;AACxB,KAAG,WAAW;AACd,KAAG,QAAQ,KAAK,IAAI,GAAG,OAAO,UAAU;AACxC,KAAG,QAAQ,KAAK,IAAI,GAAG,OAAO,UAAU;AAGxC,MAAI,QAAQ;AACV,OAAG,QAAQ,IAAI,SAAS,GAAG,QAAQ,IAAI,MAAM,KAAK,KAAK,CAAC;AAAA,EAC1D;AACF;AAyGA,SAAS,yBAAiC;AACxC,QAAM,QAAQ,IAAI,MAAM,EAAE;AAC1B,MAAI,CAAC;AAAO,WAAO;AAEnB,QAAM,QAAQ,MAAM,MAAM,IAAI;AAE9B,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAM,OAAO,MAAM,CAAC;AAGpB,UAAM,QAAQ,KAAK,MAAM,uBAAuB;AAChD,QAAI,OAAO;AACT,aAAO,GAAG,MAAM,CAAC,CAAC,IAAI,MAAM,CAAC,CAAC;AAAA,IAChC;AAAA,EACF;AACA,SAAO;AACT;AAOO,SAAS,qBAAqB,OAA2B;AAC9D,QAAM,iBAAiB,MAAM,OAAO,KAAK,KAAK;AAE9C,EAAC,MAAc,SAAS,SAAS,gBAAuD;AACtF,UAAM,QAAQ,gBAAgB,YAAY,IAAI,IAAI;AAClD,UAAM,SAAS,eAAe,cAAc;AAC5C,gBAAY;AAEZ,QAAI,CAAC,eAAe;AAClB,aAAO;AAAA,IACT;AAEA,UAAM,WAAW,YAAY,IAAI,IAAI;AACrC,iBAAa,UAAU,uBAAuB,CAAC;AAC/C,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAhSA,IAsBW,eA+BP,aACA,aACA,eACA,aACA,aACA,eAGA,cACE;AA9DN;AAAA;AAkBA;AACA;AAGO,IAAI,gBAAgB;AA+B3B,IAAI,cAAc;AAClB,IAAI,cAAwB,CAAC;AAC7B,IAAI,gBAAgB;AACpB,IAAI,cAAc;AAClB,IAAI,cAAc;AAClB,IAAI,gBAAgB,oBAAI,IAAoB;AAG5C,IAAI,eAA4B;AAChC,IAAM,aAAmJ;AAAA,MACvJ,SAAS,EAAE,OAAO,GAAG,OAAO,CAAC,GAAG,SAAS,GAAG,OAAO,GAAG,OAAO,UAAU,SAAS,oBAAI,IAAI,EAAE;AAAA,MAC1F,QAAQ,EAAE,OAAO,GAAG,OAAO,CAAC,GAAG,SAAS,GAAG,OAAO,GAAG,OAAO,UAAU,SAAS,oBAAI,IAAI,EAAE;AAAA,MACzF,OAAO,EAAE,OAAO,GAAG,OAAO,CAAC,GAAG,SAAS,GAAG,OAAO,GAAG,OAAO,UAAU,SAAS,oBAAI,IAAI,EAAE;AAAA,IAC1F;AAAA;AAAA;;;AClEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAuCO,SAAS,oBAAoB,SAAS;AAC3C,qBAAmB;AACnB,gBAAc,MAAM;AACpB,oBAAkB;AACpB;AAOA,eAAe,mBAAmB,YAAY;AAC5C,MAAI,cAAc,IAAI,UAAU,GAAG;AACjC,WAAO,cAAc,IAAI,UAAU,KAAK;AAAA,EAC1C;AAEA,QAAM,UAAU,oBAAoB,IAAI,IAAI,MAAM,YAAY,GAAG,EAAE;AACnE,QAAM,MAAM,GAAG,OAAO,GAAG,UAAU;AAEnC,MAAI;AACF,UAAM,WAAW,MAAM,MAAM,GAAG;AAChC,QAAI,CAAC,SAAS,IAAI;AAChB,aAAO;AAAA,IACT;AACA,UAAMC,UAAS,MAAM,SAAS,KAAK;AACnC,kBAAc,IAAI,YAAYA,OAAM;AACpC,WAAOA;AAAA,EACT,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAOA,eAAsB,eAAe,aAAa;AAChD,QAAM,SAAS,YAAY,QAAQ,YAAY,KAAK;AACpD,QAAM,eAAe,YAAY,cAAc,YAAY,KAAK;AAChE,QAAMC,UAAS,YAAY,QAAQ,YAAY,KAAK;AACpD,QAAM,cAAc,YAAY,aAAa,YAAY,KAAK;AAG9D,aAAW,cAAc,gBAAgB;AACvC,UAAMD,UAAS,MAAM,mBAAmB,UAAU;AAClD,QAAI,CAACA;AAAQ;AAEb,UAAM,YAAYA,QAAO;AACzB,QAAI,UAAU;AAEd,QAAI,UAAU,UAAU,CAAC,OAAO,SAAS,UAAU,OAAO,YAAY,CAAC,GAAG;AACxE,gBAAU;AAAA,IACZ;AACA,QAAI,UAAU,gBAAgB,CAAC,aAAa,SAAS,UAAU,aAAa,YAAY,CAAC,GAAG;AAC1F,gBAAU;AAAA,IACZ;AACA,QAAI,UAAU,UAAU,CAACC,QAAO,SAAS,UAAU,OAAO,YAAY,CAAC,GAAG;AACxE,gBAAU;AAAA,IACZ;AACA,QAAI,UAAU,eAAe,CAAC,YAAY,SAAS,UAAU,YAAY,YAAY,CAAC,GAAG;AACvF,gBAAU;AAAA,IACZ;AAEA,QAAI,WAAW,CAACD,QAAO,WAAW;AAChC,wBAAkBA;AAClB,aAAOA;AAAA,IACT;AAAA,EACF;AAGA,QAAM,gBAAgB,MAAM,mBAAmB,SAAS;AACxD,MAAI,eAAe;AACjB,sBAAkB;AAClB,WAAO;AAAA,EACT;AAGA,QAAM,WAAW;AAAA,IACf,IAAI;AAAA,IACJ,MAAM;AAAA,IACN,WAAW,CAAC;AAAA,IACZ,WAAW;AAAA,EACb;AACA,oBAAkB;AAClB,SAAO;AACT;AAOA,eAAsB,mBAAmB,SAAS;AAChD,QAAM,cAAc,QAAQ;AAC5B,QAAM,WAAW,MAAM,eAAe,WAAW;AAGjD,QAAM,WAAW,QAAQ;AACzB,wBAAsB;AAAA,IACpB,QAAQ,SAAS,IAAI,YAAY;AAAA,IACjC,cAAc,SAAS,IAAI,WAAW;AAAA,IACtC,cAAc,SAAS,IAAI,WAAW,IAAI,KAAK;AAAA;AAAA,IAC/C,kBAAkB,QAAQ,OAAO;AAAA,IACjC,iBAAiB,QAAQ,OAAO;AAAA,IAChC,6BAA6B,QAAQ,OAAO;AAAA,IAC5C,eAAe,QAAQ,OAAO;AAAA,EAChC;AAEA,SAAO;AAAA,IACL;AAAA,IACA,cAAc;AAAA,EAChB;AACF;AAMO,SAAS,cAAc;AAC5B,MAAI,CAAC,iBAAiB;AACpB,UAAM,IAAI,MAAM,4DAA4D;AAAA,EAC9E;AACA,SAAO;AACT;AAMO,SAAS,kBAAkB;AAChC,MAAI,CAAC,qBAAqB;AACxB,UAAM,IAAI,MAAM,4DAA4D;AAAA,EAC9E;AACA,SAAO;AACT;AAOO,SAAS,kBAAkB,WAAW;AAC3C,QAAM,WAAW,YAAY;AAC7B,SAAO,SAAS,kBAAkB,SAAS;AAC7C;AAOO,SAAS,oBAAoB,WAAW;AAC7C,SAAO,kBAAkB,SAAS,GAAG;AACvC;AAQO,SAAS,mBAAmB,WAAW,SAAS;AACrD,QAAM,WAAW,kBAAkB,SAAS;AAC5C,SAAO,UAAU,OAAO,SAAS,OAAO,KAAK;AAC/C;AAQO,SAAS,qBAAqB,WAAW,SAAS;AACvD,QAAM,WAAW,kBAAkB,SAAS;AAC5C,SAAO,UAAU,qBAAqB,OAAO;AAC/C;AAQO,SAAS,iBAAiB,WAAW,SAAS;AACnD,QAAM,WAAW,kBAAkB,SAAS;AAC5C,SAAO,UAAU,gBAAgB,OAAO;AAC1C;AAMO,SAAS,iBAAiB;AAC/B,SAAO,YAAY,EAAE;AACvB;AAMO,SAAS,uBAAuB;AACrC,SAAO,eAAe,GAAG,uBAAuB;AAClD;AAMO,SAAS,qBAAqB;AACnC,SAAO,eAAe,GAAG,mBAAmB;AAC9C;AAKO,SAAS,qBAAqB;AACnC,gBAAc,MAAM;AACpB,oBAAkB;AAClB,wBAAsB;AACxB;AAMO,SAAS,4BAA4B;AAC1C,SAAO;AAAA,IACL,UAAU,YAAY;AAAA,IACtB,cAAc,gBAAgB;AAAA,EAChC;AACF;AA9QA,IAUI,iBAGA,qBAGE,eAGF,kBAME;AAzBN;AAAA;AAUA,IAAI,kBAAkB;AAGtB,IAAI,sBAAsB;AAG1B,IAAM,gBAAgB,oBAAI,IAAI;AAG9B,IAAI,mBAAmB;AAMvB,IAAM,iBAAiB;AAAA,MACrB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA;AAAA,IACF;AAAA;AAAA;;;ACjCA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBAAAE;AAAA,EAAA,2BAAAC;AAAA,EAAA;AAAA;AAoBO,SAAS,eAAe,KAAK;AAClC,gBAAc;AACd,mBAAiB;AACnB;AAMA,eAAsB,cAAc;AAClC,MAAI,gBAAgB;AAClB,WAAO;AAAA,EACT;AAEA,QAAM,MAAM,eAAe,IAAI,IAAI,mBAAmB,YAAY,GAAG,EAAE;AACvE,QAAM,WAAW,MAAM,MAAM,GAAG;AAChC,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,IAAI,MAAM,uCAAuC,GAAG,KAAK,SAAS,MAAM,EAAE;AAAA,EAClF;AAEA,mBAAiB,MAAM,SAAS,KAAK;AACrC,SAAO;AACT;AAOO,SAAS,kBAAkB;AAChC,MAAI,CAAC,gBAAgB;AACnB,UAAM,IAAI,MAAM,6DAA6D;AAAA,EAC/E;AACA,SAAO;AACT;AAKO,SAAS,qBAAqB;AACnC,mBAAiB;AACnB;AAOO,SAAS,aAAa,WAAW;AACtC,QAAM,WAAW,gBAAgB;AACjC,SAAO,SAAS,WAAW,SAAS;AACtC;AAQO,SAAS,WAAW,WAAW,SAAS;AAC7C,QAAM,KAAK,aAAa,SAAS;AACjC,SAAO,IAAI,SAAS,OAAO;AAC7B;AAOO,SAAS,gBAAgB,WAAW;AACzC,QAAM,KAAK,aAAa,SAAS;AACjC,SAAO,KAAK,OAAO,KAAK,GAAG,QAAQ,IAAI,CAAC;AAC1C;AASO,SAAS,mBAAmB,WAAW,SAAS,cAAc;AACnE,QAAM,gBAAgB,WAAW,WAAW,OAAO;AACnD,MAAI,CAAC;AAAe,WAAO;AAE3B,QAAM,WAAW,cAAc,YAAY,CAAC;AAC5C,aAAW,OAAO,UAAU;AAC1B,QAAI,QAAQ,gBAAgB,CAAC,aAAa;AAAQ,aAAO;AACzD,QAAI,QAAQ,eAAe,CAAC,aAAa;AAAc,aAAO;AAC9D,QAAI,QAAQ,oBAAoB,CAAC,aAAa,gBAAgB,CAAC,aAAa;AAAS,aAAO;AAAA,EAC9F;AACA,SAAO;AACT;AAQO,SAAS,qBAAqB,WAAW,cAAc;AAC5D,SAAO,gBAAgB,SAAS,EAAE,OAAO,OAAK,mBAAmB,WAAW,GAAG,YAAY,CAAC;AAC9F;AASO,SAASD,eAAc,MAAM,UAAU;AAC5C,MAAI,CAAC,YAAY,SAAS,WAAW,GAAG;AACtC,WAAO,CAAC,GAAG,IAAI;AAAA,EACjB;AAEA,QAAM,SAAS,CAAC,GAAG,IAAI;AACvB,aAAW,WAAW,UAAU;AAC9B,UAAM,cAAc,OAAO,UAAU,OAAK,EAAE,UAAU,QAAQ,KAAK;AACnE,QAAI,eAAe,GAAG;AACpB,aAAO,WAAW,IAAI;AAAA,IACxB,OAAO;AACL,aAAO,KAAK,OAAO;AAAA,IACrB;AAAA,EACF;AAEA,SAAO,OAAO,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAChD;AASO,SAASC,qBAAoB,WAAW,SAAS;AACtD,QAAM,WAAW,aAAa,SAAS;AACvC,QAAM,gBAAgB,WAAW,WAAW,OAAO;AAEnD,MAAI,CAAC,YAAY,CAAC,eAAe;AAC/B,WAAO;AAAA,EACT;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,MAAM,cAAc;AAAA,IACpB,YAAY,cAAc;AAAA,IAC1B,WAAW,cAAc;AAAA,IACzB,UAAU,cAAc,YAAY,CAAC;AAAA,IACrC,UAAUD,eAAc,SAAS,cAAc,cAAc,gBAAgB;AAAA,IAC7E,UAAU,cAAc,oBAAoB,SAAS;AAAA,IACrD,eAAe,cAAc,iBAAiB,CAAC;AAAA,IAC/C,cAAc,cAAc,gBAAgB;AAAA,EAC9C;AACF;AAhLA,IAUI,gBAGA;AAbJ;AAAA;AAUA,IAAI,iBAAiB;AAGrB,IAAI,cAAc;AAAA;AAAA;;;ACoFX,SAAS,oBAA6B;AAC3C,SAAO,OAAO,cAAc,eAAe,SAAS;AACtD;AAOA,eAAe,eAAe,UAAiC,CAAC,GAA+B;AAC7F,MAAI,CAAC,kBAAkB,GAAG;AACxB,WAAO;AAAA,EACT;AAGA,QAAM,iBAA6C;AAAA,IACjD,EAAE,iBAAiB,oBAAoB,GAAG,QAAQ;AAAA,IAClD,EAAE,iBAAiB,aAAa,GAAG,QAAQ;AAAA,IAC3C,EAAE,GAAG,QAAQ;AAAA;AAAA,EACf;AAEA,aAAW,QAAQ,gBAAgB;AACjC,QAAI;AACF,YAAM,UAAU,MAAM,UAAU,IAAI,eAAe,IAAI;AACvD,UAAI,SAAS;AACX,eAAO;AAAA,MACT;AAAA,IACF,SAAS,GAAG;AAAA,IAEZ;AAAA,EACF;AAEA,SAAO;AACT;AAOA,SAAS,eAAe,SAAkC;AACxD,QAAM,YAAY,oBAAI,IAAY;AAElC,aAAW,WAAW,QAAQ,UAAU;AACtC,cAAU,IAAI,OAAO;AAAA,EACvB;AAEA,SAAO;AACT;AAOA,SAAS,qBAAqB,WAA0C;AACtE,QAAM,YAA8B,CAAC;AAGrC,MAAI,UAAU,IAAI,SAAS,UAAU,GAAG;AACtC,cAAU,KAAK,SAAS,UAA4B;AAAA,EACtD;AAGA,MAAI,UAAU,IAAI,SAAS,SAAS,GAAG;AACrC,cAAU,KAAK,SAAS,SAA2B;AAAA,EACrD;AAGA,MAAI,UAAU,IAAI,SAAS,aAAa,GAAG;AACzC,cAAU,KAAK,SAAS,aAA+B;AAAA,EACzD;AAGA,MAAI,UAAU,IAAI,SAAS,eAAe,GAAG;AAC3C,cAAU,KAAK,SAAS,eAAiC;AAAA,EAC3D;AAEA,SAAO;AACT;AAOA,SAAS,YAAY,SAAgD;AACnE,QAAM,gBAAgB,QAAQ;AAE9B,SAAO;AAAA;AAAA,IAEL,6BAA6B,cAAc;AAAA;AAAA,IAE3C,eAAe,cAAc;AAAA;AAAA,IAE7B,0BAA0B,cAAc;AAAA,IACxC,0BAA0B,cAAc;AAAA,IACxC,0BAA0B,cAAc;AAAA,IACxC,mCAAmC,cAAc;AAAA,IACjD,gCAAgC,cAAc;AAAA;AAAA,IAE9C,iCAAiC,cAAc;AAAA,IAC/C,6BAA6B,cAAc;AAAA,EAC7C;AACF;AAQA,eAAe,8BAA8B,SAAoC;AAC/E,MAAI,qBAAqB;AACvB;AAAA,EACF;AAEA,wBAAsB;AAEtB,MAAI;AAEF,UAAM,CAAC,gBAAgB,cAAc,IAAI,MAAM,QAAQ,IAAI;AAAA,MACzD;AAAA,MACA;AAAA,IACF,CAAC;AAGD,6BAAyB,MAAM,eAAe,mBAAmB,OAAO;AAGxE,UAAM,eAAe,YAAY;AAEjC,QAAI,MAAM,OAAO,eAAe,uBAAuB,SAAS,OAAO,OAAO,uBAAuB,SAAS,KAAK,GAAG;AACtH,QAAI,MAAM,OAAO,uBAAuB,uBAAuB,aAAa,SAAS,iBAAiB,uBAAuB,aAAa,YAAY;AAAA,EACxJ,SAAS,GAAG;AAEV,QAAI,KAAK,OAAO,gDAAiD,EAAY,OAAO;AACpF,6BAAyB;AAAA,EAC3B;AACF;AAOA,eAAsB,aAAiC;AAErD,MAAIE,YAAW;AACb,WAAOA;AAAA,EACT;AAEA,MAAI,CAAC,kBAAkB,GAAG;AACxB,UAAM,IAAI,MAAM,yCAAyC;AAAA,EAC3D;AAEA,QAAM,UAAU,MAAM,eAAe;AACrC,MAAI,CAAC,SAAS;AACZ,UAAM,IAAI,MAAM,8BAA8B;AAAA,EAChD;AAIA,QAAM,8BAA8B,OAAO;AAG3C,QAAM,oBAAoB,eAAe,OAAO;AAChD,QAAM,oBAAoB,qBAAqB,iBAAiB;AAChE,QAAM,SAAS,YAAY,OAAO;AAGlC,QAAM,cAAc,QAAQ,QAAQ,EAAE,QAAQ,WAAW,cAAc,WAAW,QAAQ,WAAW,aAAa,GAAG;AAErH,MAAI;AACF,IAAAA,aAAY,MAAM,QAAQ,cAAc;AAAA,MACtC,kBAAkB;AAAA,MAClB,gBAAgB;AAAA,IAClB,CAAC;AAAA,EACH,SAAS,GAAG;AAEV,QAAI,KAAK,OAAO,oEAAqE,EAAY,OAAO;AACxG,IAAAA,aAAY,MAAM,QAAQ,cAAc;AAAA,EAC1C;AAEA,MAAI,CAACA,YAAW;AACd,UAAM,IAAI,MAAM,gCAAgC;AAAA,EAClD;AAGA,EAAAA,WAAU,KAAK,KAAK,CAAC,SAAS;AAC5B,QAAI,MAAM,OAAO,kBAAkB,KAAK,UAAU,eAAe,KAAK,MAAM;AAC5E,IAAAA,aAAY;AACZ,yBAAqB;AACrB,6BAAyB;AACzB,0BAAsB;AAAA,EACxB,CAAC;AAGD,uBAAqBA,WAAU,KAAK;AAGpC,uBAAqB;AAAA,IACnB,cAAcA,WAAU,SAAS,IAAI,SAAS,SAAS;AAAA,IACvD,iBAAiBA,WAAU,SAAS,IAAI,SAAS,aAAa;AAAA,IAC9D,QAAQA,WAAU,SAAS,IAAI,SAAS,UAAU;AAAA,IAClD,mBAAmBA,WAAU,SAAS,IAAI,SAAS,eAAe;AAAA,IAClE,eAAeA,WAAU,OAAO;AAAA,IAChC,kBAAkBA,WAAU,OAAO;AAAA,IACnC,yBAAyBA,WAAU,OAAO;AAAA,IAC1C,aAAa;AAAA,MACX,QAAQ,YAAY,UAAU;AAAA,MAC9B,cAAc,YAAY,gBAAgB;AAAA,MAC1C,QAAQ,YAAY,UAAU;AAAA,MAC9B,aAAa,YAAY,eAAe;AAAA,IAC1C;AAAA,EACF;AAEA,QAAM,WAAW;AAAA,IACf,mBAAmB,UAAU;AAAA,IAC7B,mBAAmB,gBAAgB;AAAA,EACrC,EAAE,OAAO,OAAO,EAAE,KAAK,GAAG,KAAK;AAC/B,UAAQ,IAAI,YAAY,YAAY,UAAU,aAAa,OAAO,YAAY,gBAAgB,YAAY,UAAU,MAAM,OAAO,WAAW,QAAQ,mBAAmB,iBAAiB,OAAO,OAAO,OAAO,QAAQ,CAAC,IAAI,IAAI;AAE9N,SAAOA;AACT;AAOO,SAAS,wBAA4C;AAC1D,MAAI,CAAC,oBAAoB;AACvB,UAAM,IAAI,MAAM,kDAAkD;AAAA,EACpE;AACA,SAAO,EAAE,GAAG,mBAAmB;AACjC;AAMO,SAAS,YAA8B;AAC5C,SAAOA;AACT;AAoCO,SAAS,WAAW,SAA0B;AACnD,MAAI,CAACA,YAAW;AACd,WAAO;AAAA,EACT;AACA,SAAOA,WAAU,SAAS,IAAI,OAAyB;AACzD;AAMO,SAAS,kBAAuC;AACrD,MAAI,CAACA,YAAW;AACd,WAAO;AAAA,EACT;AACA,SAAO;AAAA,IACL,6BAA6BA,WAAU,OAAO;AAAA,IAC9C,eAAeA,WAAU,OAAO;AAAA,IAChC,0BAA0BA,WAAU,OAAO;AAAA,IAC3C,0BAA0BA,WAAU,OAAO;AAAA,IAC3C,0BAA0BA,WAAU,OAAO;AAAA,IAC3C,mCAAmCA,WAAU,OAAO;AAAA,IACpD,gCAAgCA,WAAU,OAAO;AAAA,IACjD,iCAAiCA,WAAU,OAAO;AAAA,IAClD,6BAA6BA,WAAU,OAAO;AAAA,IAC9C,kCAAkCA,WAAU,OAAO;AAAA,EACrD;AACF;AApZA,IAyEIA,YACA,oBAGA,wBAGA,qBAKE;AArFN;AAAA;AAWA;AACA;AA6DA,IAAIA,aAA8B;AAClC,IAAI,qBAAgD;AAGpD,IAAI,yBAAwD;AAG5D,IAAI,sBAAsB;AAK1B,IAAM,WAAW;AAAA,MACf,YAAY;AAAA,MACZ,WAAW;AAAA,MACX,eAAe;AAAA,MACf,iBAAiB;AAAA,IACnB;AAAA;AAAA;;;AClEO,SAAS,aACd,QACA,OACA,OACA,OACQ;AACR,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,OAAO,OAAO,OAAO,CAAC,GAAG,KAAK,CAAC;AAAA,IAC/B;AAAA,EACF;AACF;AA6CO,SAAS,WAAW,OAA4B;AACrD,SAAO,UAAU,QAAQ,IAAI;AAC/B;AAoBO,SAAS,iBAAiB,GAAW,GAAwB;AAClE,SAAQ,EAAE,UAAU,SAAS,EAAE,UAAU,QAAS,QAAQ;AAC5D;AAzGA;AAAA;AAAA;AAAA;;;ACAA,IA4Ea;AA5Eb;AAAA;AAeA;AACA;AAEA;AA0DO,IAAM,cAAN,MAAkB;AAAA,MACf;AAAA,MACA;AAAA;AAAA,MAGA,WAA+B;AAAA,MAC/B,cAAgC;AAAA,MAChC,iBAAmC;AAAA,MACnC,gBAAgB;AAAA;AAAA;AAAA,MAGhB,eAAgE,oBAAI,IAAI;AAAA,MACxE,iBAAiB;AAAA,MACjB,kBAAoC,CAAC;AAAA;AAAA,MAGrC,UAAmC,oBAAI,IAAI;AAAA;AAAA,MAG3C,aAAkC,oBAAI,IAAI;AAAA;AAAA;AAAA;AAAA,MAKlD,YAAYC,UAA2B,MAAM;AAC3C,aAAK,SAASA,WAAU,UAAU;AAClC,aAAK,oBAAoB,KAAK,QAAQ,UAAU,IAAI,SAAS,eAAe,KAAK;AAGjF,YAAI,KAAK,qBAAqB,KAAK,QAAQ;AACzC,eAAK,oBAAoB;AAAA,QAC3B;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,sBAA4B;AAClC,YAAI,CAAC,KAAK;AAAQ;AAElB,YAAI;AACF,eAAK,WAAW,KAAK,OAAO,eAAe;AAAA,YACzC,MAAM;AAAA,YACN,OAAO,KAAK,gBAAgB;AAAA;AAAA,UAC9B,CAAC;AAGD,eAAK,cAAc,KAAK,OAAO,aAAa;AAAA,YAC1C,MAAM,KAAK,gBAAgB,IAAI;AAAA,YAC/B,OAAO,eAAe,gBAAgB,eAAe;AAAA,UACvD,CAAC;AAGD,eAAK,iBAAiB,KAAK,OAAO,aAAa;AAAA,YAC7C,MAAM,KAAK,gBAAgB,IAAI;AAAA,YAC/B,OAAO,eAAe,WAAW,eAAe;AAAA,UAClD,CAAC;AAAA,QACH,SAAS,GAAG;AACV,cAAI,KAAK,eAAe,+CAA+C,CAAC,EAAE;AAC1E,eAAK,oBAAoB;AAAA,QAC3B;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,OAAqB;AACzB,YAAI,KAAK,aAAa,IAAI,KAAK,GAAG;AAChC,cAAI,KAAK,eAAe,UAAU,KAAK,kBAAkB;AACzD;AAAA,QACF;AAEA,cAAM,YAAY,YAAY,IAAI;AAGlC,aAAK,aAAa,IAAI,OAAO;AAAA,UAC3B,cAAc;AAAA,QAChB,CAAC;AAAA,MACH;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,IAAI,OAAqB;AACvB,cAAM,SAAS,KAAK,aAAa,IAAI,KAAK;AAC1C,YAAI,CAAC,QAAQ;AACX,cAAI,KAAK,eAAe,oCAAoC,KAAK,GAAG;AACpE;AAAA,QACF;AAEA,cAAM,UAAU,YAAY,IAAI;AAChC,aAAK,aAAa,OAAO,KAAK;AAE9B,YAAI,KAAK,qBAAqB,qBAAqB,QAAQ;AAEzD,eAAK,gBAAgB,KAAK;AAAA,YACxB;AAAA,YACA,YAAY,OAAO;AAAA,YACnB,UAAU,OAAO,kBAAkB;AAAA,YACnC,cAAc,OAAO;AAAA,YACrB,YAAY;AAAA,UACd,CAAC;AAAA,QACH,OAAO;AAEL,eAAK,cAAc,OAAO,UAAU,OAAO,YAAY;AAAA,QACzD;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,eAAe,MAA6B,OAAe,QAAQ,OAAa;AAC9E,YAAI,CAAC,KAAK,qBAAqB,CAAC,KAAK;AAAU;AAE/C,YAAI;AACJ,YAAI,CAAC,OAAO;AAEV,uBAAa,KAAK;AAClB,eAAK,kBAAkB;AACvB,eAAK,aAAa,IAAI,OAAO;AAAA,YAC3B,iBAAiB;AAAA,YACjB,cAAc,YAAY,IAAI;AAAA,UAChC,CAAC;AAAA,QACH,OAAO;AAEL,gBAAM,SAAS,KAAK,aAAa,IAAI,KAAK;AAC1C,cAAI,CAAC,UAAU,EAAE,qBAAqB;AAAS;AAC/C,uBAAa,OAAO,kBAAkB;AACtC,eAAK,aAAa,OAAO,KAAK;AAC9B,eAAK,gBAAgB,KAAK;AAAA,YACxB;AAAA,YACA,YAAY,OAAO;AAAA,YACnB,UAAU;AAAA,YACV,cAAc,OAAO;AAAA,YACrB,YAAY,YAAY,IAAI;AAAA,UAC9B,CAAC;AAAA,QACH;AAIA,QAAC,KAAa,eAAe,KAAK,UAAU,UAAU;AAAA,MACxD;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,UAAyB;AAC7B,YAAI,CAAC,KAAK,qBAAqB,KAAK,gBAAgB,WAAW,GAAG;AAChE;AAAA,QACF;AAEA,YAAI,CAAC,KAAK,UAAU,CAAC,KAAK,YAAY,CAAC,KAAK,eAAe,CAAC,KAAK,gBAAgB;AAC/E,cAAI,KAAK,eAAe,wCAAwC;AAChE;AAAA,QACF;AAEA,cAAM,UAAU,KAAK,OAAO,qBAAqB;AAGjD,cAAM,WAAW,KAAK,IAAI,GAAG,KAAK,gBAAgB,IAAI,OAAK,EAAE,QAAQ,CAAC,IAAI;AAC1E,gBAAQ,gBAAgB,KAAK,UAAU,GAAG,UAAU,KAAK,aAAa,CAAC;AAGvE,gBAAQ;AAAA,UACN,KAAK;AAAA,UACL;AAAA,UACA,KAAK;AAAA,UACL;AAAA,UACA,WAAW;AAAA,QACb;AAEA,aAAK,OAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAE3C,YAAI,CAAC,cAAc,qBAAqB,GAAG;AACzC;AAAA,QACF;AAGA,cAAM,KAAK,eAAe,SAAS,WAAW,IAAI;AAClD,cAAM,aAAa,IAAI,eAAe,KAAK,eAAe,eAAe,CAAC;AAG1E,mBAAW,WAAW,KAAK,iBAAiB;AAC1C,gBAAM,UAAU,WAAW,QAAQ,UAAU;AAC7C,gBAAM,QAAQ,WAAW,QAAQ,QAAQ;AAGzC,gBAAM,aAAa,OAAO,QAAQ,OAAO,IAAI;AAG7C,cAAI,aAAa,KAAK,aAAa,KAAO;AAExC,iBAAK,cAAc,QAAQ,OAAO,QAAQ,aAAa,QAAQ,YAAY;AAAA,UAC7E,OAAO;AACL,iBAAK,cAAc,QAAQ,OAAO,UAAU;AAAA,UAC9C;AAAA,QACF;AAEA,aAAK,eAAe,MAAM;AAC1B,aAAK,kBAAkB,CAAC;AACxB,aAAK,iBAAiB;AAAA,MACxB;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,cAAc,OAAe,QAAsB;AACzD,YAAI,CAAC,KAAK,QAAQ,IAAI,KAAK,GAAG;AAC5B,eAAK,QAAQ,IAAI,OAAO;AAAA,YACtB,OAAO,CAAC;AAAA,YACR,KAAK;AAAA,YACL,KAAK;AAAA,YACL,KAAK;AAAA,YACL,OAAO;AAAA,UACT,CAAC;AAAA,QACH;AAEA,cAAM,SAAS,KAAK,QAAQ,IAAI,KAAK;AACrC,eAAO,MAAM,KAAK,MAAM;AACxB,eAAO,MAAM,KAAK,IAAI,OAAO,KAAK,MAAM;AACxC,eAAO,MAAM,KAAK,IAAI,OAAO,KAAK,MAAM;AACxC,eAAO,OAAO;AACd,eAAO;AAGP,YAAI,OAAO,MAAM,SAAS,KAAK;AAC7B,gBAAM,UAAU,OAAO,MAAM,MAAM;AACnC,iBAAO,OAAO;AACd,iBAAO;AAEP,cAAI,OAAO,MAAM,SAAS,OAAO,GAAG;AAClC,mBAAO,MAAM,KAAK,IAAI,GAAG,OAAO,KAAK;AACrC,mBAAO,MAAM,KAAK,IAAI,GAAG,OAAO,KAAK;AAAA,UACvC;AAAA,QACF;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,aAA4C;AAC1C,cAAM,SAAwC,CAAC;AAE/C,mBAAW,CAAC,OAAO,IAAI,KAAK,KAAK,SAAS;AACxC,iBAAO,KAAK,IAAI;AAAA,YACd,KAAK,KAAK,MAAM,KAAK;AAAA,YACrB,KAAK,KAAK;AAAA,YACV,KAAK,KAAK;AAAA,YACV,OAAO,KAAK;AAAA,YACZ,OAAO,KAAK;AAAA,UACd;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,UAAU,OAAqC;AAC7C,cAAM,OAAO,KAAK,QAAQ,IAAI,KAAK;AACnC,YAAI,CAAC;AAAM,iBAAO;AAElB,eAAO;AAAA,UACL,KAAK,KAAK,MAAM,KAAK;AAAA,UACrB,KAAK,KAAK;AAAA,UACV,KAAK,KAAK;AAAA,UACV,OAAO,KAAK;AAAA,UACZ,OAAO,KAAK;AAAA,QACd;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,QAAc;AACZ,aAAK,QAAQ,MAAM;AACnB,aAAK,aAAa,MAAM;AACxB,aAAK,kBAAkB,CAAC;AACxB,aAAK,iBAAiB;AAAA,MACxB;AAAA;AAAA;AAAA;AAAA,MAKA,YAAoB;AAClB,cAAM,UAAU,KAAK,WAAW;AAChC,cAAM,SAAS,OAAO,KAAK,OAAO,EAAE,KAAK;AAEzC,YAAI,OAAO,WAAW,GAAG;AACvB,iBAAO;AAAA,QACT;AAEA,YAAI,SAAS;AACb,kBAAU,SAAI,OAAO,EAAE,IAAI;AAC3B,kBAAU,QAAQ,OAAO,EAAE,IAAI,WAAW,SAAS,EAAE,IAAI,MAAM,SAAS,EAAE,IAAI,MAAM,SAAS,EAAE,IAAI;AACnG,kBAAU,SAAI,OAAO,EAAE,IAAI;AAE3B,mBAAW,SAAS,QAAQ;AAC1B,gBAAM,IAAI,QAAQ,KAAK;AACvB,oBAAU,MAAM,OAAO,EAAE;AACzB,oBAAU,EAAE,IAAI,QAAQ,CAAC,EAAE,SAAS,EAAE;AACtC,oBAAU,EAAE,IAAI,QAAQ,CAAC,EAAE,SAAS,EAAE;AACtC,oBAAU,EAAE,IAAI,QAAQ,CAAC,EAAE,SAAS,EAAE;AACtC,oBAAU;AAAA,QACZ;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,uBAAgC;AAC9B,eAAO,KAAK;AAAA,MACd;AAAA;AAAA;AAAA;AAAA,MAKA,UAAgB;AACd,YAAI,KAAK,UAAU;AACjB,eAAK,SAAS,QAAQ;AACtB,eAAK,WAAW;AAAA,QAClB;AACA,YAAI,KAAK,aAAa;AACpB,eAAK,YAAY,QAAQ;AACzB,eAAK,cAAc;AAAA,QACrB;AACA,YAAI,KAAK,gBAAgB;AACvB,eAAK,eAAe,QAAQ;AAC5B,eAAK,iBAAiB;AAAA,QACxB;AACA,aAAK,QAAQ,MAAM;AACnB,aAAK,aAAa,MAAM;AAAA,MAC1B;AAAA,IACF;AAAA;AAAA;;;ACzZA,SAAS,iBAAiB;AACxB,SAAO,iBAAiB,EAAE;AAC5B;AAssCA,eAAsB,iBAAuC;AAC3D,MAAI,CAAC,aAAa;AAChB,kBAAc,IAAI,YAAY;AAC9B,UAAM,YAAY,KAAK;AAAA,EACzB;AACA,SAAO;AACT;AA5tCA,IAqHa,aA2lCT;AAhtCJ;AAAA;AASA;AACA;AACA;AACA;AAyGO,IAAM,cAAN,MAAkB;AAAA,MACf;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MAER,cAAc;AACZ,aAAK,SAAS;AACd,aAAK,WAAW;AAChB,aAAK,SAAS;AACd,aAAK,eAAe;AACpB,aAAK,QAAQ,oBAAI,IAAI;AAAA,MACvB;AAAA;AAAA;AAAA;AAAA,MAKA,MAAM,OAAsB;AAC1B,aAAK,SAAS,UAAU;AACxB,YAAI,CAAC,KAAK,QAAQ;AAChB,gBAAM,IAAI,MAAM,4BAA4B;AAAA,QAC9C;AAEA,aAAK,WAAW,IAAI,YAAY,KAAK,MAAM;AAC3C,aAAK,SAAS,gBAAgB;AAC9B,aAAK,eAAe,sBAAsB;AAG1C,aAAK,WAAW;AAAA,MAClB;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,sBAA8B;AACpC,cAAM,OAAmB,KAAK,cAAc,eAAe,EAAE,QAAQ,IAAI,cAAc,IAAI,QAAQ,GAAG;AACtG,eAAO,GAAG,KAAK,MAAM,IAAI,KAAK,YAAY,IAAI,KAAK,MAAM,GAAG,QAAQ,iBAAiB,GAAG;AAAA,MAC1F;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,aAAmB;AACzB,YAAI,OAAO,iBAAiB;AAAa;AAEzC,cAAM,YAAY,KAAK,oBAAoB;AAC3C,cAAM,WAAW,eAAe,EAAE,iBAAiB;AAEnD,YAAI;AACF,gBAAM,SAAS,aAAa,QAAQ,QAAQ;AAC5C,cAAI,QAAQ;AACV,kBAAM,OAAO,KAAK,MAAM,MAAM;AAC9B,iBAAK,QAAQ,IAAI,IAAI,OAAO,QAAQ,IAAI,CAAC;AAAA,UAC3C;AAAA,QACF,SAAS,GAAG;AACV,cAAI,KAAK,eAAe,yBAAyB,CAAC,EAAE;AAAA,QACtD;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,aAAmB;AACzB,YAAI,OAAO,iBAAiB;AAAa;AAEzC,cAAM,YAAY,KAAK,oBAAoB;AAC3C,cAAM,WAAW,eAAe,EAAE,iBAAiB;AAEnD,YAAI;AACF,gBAAM,OAAO,OAAO,YAAY,KAAK,KAAK;AAC1C,uBAAa,QAAQ,UAAU,KAAK,UAAU,IAAI,CAAC;AAAA,QACrD,SAAS,GAAG;AACV,cAAI,KAAK,eAAe,yBAAyB,CAAC,EAAE;AAAA,QACtD;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,+BAAgD;AACtD,cAAM,OAAO,KAAK,QAAQ,4BAA4B;AACtD,cAAM,OAAO,KAAK,QAAQ,4BAA4B;AACtD,cAAM,iBAAiB,KAAK,QAAQ,qCAAqC;AAEzE,cAAM,aAA8B,CAAC;AAGrC,mBAAW,KAAK,CAAC,IAAI,KAAK,KAAK,GAAG,GAAG;AACnC,cAAI,KAAK,QAAQ,KAAK,gBAAgB;AACpC,uBAAW,KAAK,CAAC,GAAG,GAAG,CAAC,CAAC;AAAA,UAC3B;AAAA,QACF;AAGA,mBAAW,KAAK,CAAC,GAAG,IAAI,EAAE,GAAG;AAC3B,qBAAW,KAAK,CAAC,GAAG,IAAI,EAAE,GAAG;AAC3B,gBAAI,KAAK,QAAQ,KAAK,QAAQ,IAAI,KAAK,gBAAgB;AACrD,yBAAW,KAAK,CAAC,GAAG,GAAG,CAAC,CAAC;AAAA,YAC3B;AAAA,UACF;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,MAAM,WACJ,YACA,YACA,UAAsB,CAAC,GACF;AACrB,cAAM;AAAA,UACJ,SAAS,eAAe,EAAE;AAAA,UAC1B,aAAa,eAAe,EAAE;AAAA,UAC9B,cAAc;AAAA,QAChB,IAAI;AAGJ,cAAM,WAAqB,GAAG,UAAU,IAAI,KAAK,UAAU,UAAU,CAAC;AACtE,YAAI,CAAC,eAAe,KAAK,MAAM,IAAI,QAAQ,GAAG;AAC5C,iBAAO,KAAK,MAAM,IAAI,QAAQ;AAAA,QAChC;AAGA,cAAM,aAAa,KAAK,6BAA6B;AAGrD,YAAI;AAEJ,gBAAQ,YAAY;AAAA,UAClB,KAAK;AACH,yBAAa,MAAM,KAAK,YAAY,YAAY,YAAY,QAAQ,UAAU;AAC9E;AAAA,UACF,KAAK;AACH,yBAAa,MAAM,KAAK,eAAe,YAAY,YAAY,QAAQ,UAAU;AACjF;AAAA,UACF,KAAK;AACH,yBAAa,MAAM,KAAK,aAAa,YAAY,YAAY,QAAQ,UAAU;AAC/E;AAAA,UACF,KAAK;AACH,yBAAa,MAAM,KAAK,aAAa,YAAY,YAAY,QAAQ,UAAU;AAC/E;AAAA,UACF,KAAK;AACH,yBAAa,MAAM,KAAK,aAAa,YAAY,YAAY,QAAQ,UAAU;AAC/E;AAAA,UACF;AACE,yBAAa,MAAM,KAAK,aAAa,YAAY,YAAY,YAAY,QAAQ,UAAU;AAAA,QAC/F;AAGA,aAAK,MAAM,IAAI,UAAU,UAAU;AACnC,aAAK,WAAW;AAEhB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,YACZ,YACA,YACA,QACA,YACqB;AACrB,cAAM,EAAE,IAAI,MAAM,IAAI,MAAM,IAAI,KAAK,IAAI;AAGzC,cAAM,mBAAmB,WAAW,OAAO,OAAK,EAAE,CAAC,IAAI,CAAC;AAExD,YAAI,OAAmB;AAAA,UACrB,sBAAsB,CAAC,IAAI,IAAI,CAAC;AAAA,UAChC,iBAAiB;AAAA,UACjB,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY,KAAK,cAAc;AAAA,QACjC;AAEA,YAAI,CAAC,KAAK,QAAQ;AAChB,iBAAO;AAAA,QACT;AAGA,cAAM,UAAU,KAAK,OAAO,aAAa;AAAA,UACvC,MAAM,IAAI,IAAI;AAAA,UACd,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,UAAU,KAAK,OAAO,aAAa;AAAA,UACvC,MAAM,IAAI,IAAI;AAAA,UACd,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,UAAU,KAAK,OAAO,aAAa;AAAA,UACvC,MAAM,IAAI,IAAI;AAAA,UACd,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AAGD,cAAM,QAAQ,IAAI,aAAa,IAAI,CAAC;AACpC,cAAM,QAAQ,IAAI,aAAa,IAAI,CAAC;AACpC,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ;AAAK,gBAAM,CAAC,IAAI,KAAK,OAAO;AAC9D,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ;AAAK,gBAAM,CAAC,IAAI,KAAK,OAAO;AAC9D,aAAK,OAAO,MAAM,YAAY,SAAS,GAAG,KAAK;AAC/C,aAAK,OAAO,MAAM,YAAY,SAAS,GAAG,KAAK;AAE/C,mBAAW,CAAC,KAAK,GAAG,KAAK,kBAAkB;AACzC,cAAI;AAEF,kBAAM,SAAS,KAAK,oBAAoB,KAAK,GAAG;AAChD,kBAAM,WAAW,MAAM,KAAK,uBAAuB,QAAQ,MAAM;AAGjE,kBAAM,gBAAgB,KAAK,OAAO,aAAa;AAAA,cAC7C,MAAM;AAAA,cACN,OAAO,eAAe,UAAU,eAAe;AAAA,YACjD,CAAC;AACD,kBAAM,cAAc,IAAI,YAAY,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC;AAChD,iBAAK,OAAO,MAAM,YAAY,eAAe,GAAG,WAAW;AAE3D,kBAAM,YAAY,KAAK,OAAO,gBAAgB;AAAA,cAC5C,QAAQ,SAAS,mBAAmB,CAAC;AAAA,cACrC,SAAS;AAAA,gBACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,gBAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,gBAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,gBAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,cAC9C;AAAA,YACF,CAAC;AAGD,qBAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,oBAAM,UAAU,KAAK,OAAO,qBAAqB;AACjD,oBAAM,OAAO,QAAQ,iBAAiB;AACtC,mBAAK,YAAY,QAAQ;AACzB,mBAAK,aAAa,GAAG,SAAS;AAC9B,mBAAK,mBAAmB,KAAK,KAAK,IAAI,GAAG,GAAG,KAAK,KAAK,IAAI,GAAG,CAAC;AAC9D,mBAAK,IAAI;AACT,mBAAK,OAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAAA,YAC7C;AACA,kBAAM,KAAK,OAAO,MAAM,oBAAoB;AAG5C,kBAAM,QAAkB,CAAC;AACzB,qBAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,oBAAM,QAAQ,YAAY,IAAI;AAC9B,oBAAM,UAAU,KAAK,OAAO,qBAAqB;AACjD,oBAAM,OAAO,QAAQ,iBAAiB;AACtC,mBAAK,YAAY,QAAQ;AACzB,mBAAK,aAAa,GAAG,SAAS;AAC9B,mBAAK,mBAAmB,KAAK,KAAK,IAAI,GAAG,GAAG,KAAK,KAAK,IAAI,GAAG,CAAC;AAC9D,mBAAK,IAAI;AACT,mBAAK,OAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAC3C,oBAAM,KAAK,OAAO,MAAM,oBAAoB;AAC5C,oBAAM,KAAK,YAAY,IAAI,IAAI,KAAK;AAAA,YACtC;AAEA,kBAAM,UAAU,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,IAAI,MAAM;AACzD,kBAAM,QAAQ,IAAI,IAAI,IAAI;AAC1B,kBAAM,SAAU,QAAQ,UAAW;AAEnC,gBAAI,UAAU,KAAK,QAAQ;AACzB,qBAAO;AAAA,gBACL,sBAAsB,CAAC,KAAK,KAAK,CAAC;AAAA,gBAClC,iBAAiB;AAAA,gBACjB,YAAY;AAAA,gBACZ,QAAQ;AAAA,gBACR,YAAY,KAAK,cAAc;AAAA,cACjC;AAAA,YACF;AAEA,0BAAc,QAAQ;AAAA,UACxB,SAAS,GAAG;AAEV;AAAA,UACF;AAAA,QACF;AAGA,gBAAQ,QAAQ;AAChB,gBAAQ,QAAQ;AAChB,gBAAQ,QAAQ;AAEhB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,oBAAoB,KAAa,KAAqB;AAC5D,eAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BASgB,GAAG,KAAK,GAAG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAYpC;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,eACZ,YACA,YACA,QACA,YACqB;AAErB,cAAM,EAAE,SAAS,MAAM,WAAW,IAAI,UAAU,IAAI,IAAI;AAExD,YAAI,OAAmB;AAAA,UACrB,sBAAsB,CAAC,IAAI,GAAG,CAAC;AAAA,UAC/B,iBAAiB;AAAA,UACjB,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY,KAAK,cAAc;AAAA,QACjC;AAEA,YAAI,CAAC,KAAK,QAAQ;AAChB,iBAAO;AAAA,QACT;AAEA,cAAM,sBAAsB,WAAW,OAAO,OAAK,EAAE,CAAC,MAAM,CAAC;AAC7D,YAAI,oBAAoB,WAAW,GAAG;AACpC,iBAAO;AAAA,QACT;AAEA,cAAM,cAAc;AACpB,cAAM,gBAAgB,KAAK,IAAI,GAAG,SAAS,QAAQ;AACnD,YAAI,cAAc;AAClB,YAAI,aAAa;AACjB,YAAI,gBAAgB,aAAa;AAEjC,YAAI,gBAAgB,aAAa;AAC/B,wBAAc,KAAK,IAAI,GAAG,KAAK,MAAM,eAAe,WAAW,QAAQ,CAAC;AACxE,uBAAa,KAAK,IAAI,GAAG,cAAc,QAAQ;AAC/C,0BAAgB,aAAa;AAAA,QAC/B;AAEA,cAAM,UAAU,KAAK,OAAO,aAAa;AAAA,UACvC,MAAM,gBAAgB;AAAA,UACtB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,UAAU,KAAK,OAAO,aAAa;AAAA,UACvC,MAAM,gBAAgB;AAAA,UACtB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,YAAY,KAAK,OAAO,aAAa;AAAA,UACzC,MAAM,aAAa;AAAA,UACnB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AAED,cAAM,QAAQ,IAAI,aAAa,aAAa;AAC5C,cAAM,QAAQ,IAAI,aAAa,aAAa;AAC5C,iBAAS,IAAI,GAAG,IAAI,eAAe,KAAK;AACtC,gBAAM,CAAC,IAAI,KAAK,OAAO;AACvB,gBAAM,CAAC,IAAI,KAAK,OAAO;AAAA,QACzB;AACA,aAAK,OAAO,MAAM,YAAY,SAAS,GAAG,KAAK;AAC/C,aAAK,OAAO,MAAM,YAAY,SAAS,GAAG,KAAK;AAE/C,mBAAW,CAAC,GAAG,KAAK,qBAAqB;AACvC,cAAI;AACF,kBAAM,SAAS,KAAK,uBAAuB,GAAG;AAC9C,kBAAM,WAAW,MAAM,KAAK,uBAAuB,QAAQ,MAAM;AAEjE,kBAAM,gBAAgB,KAAK,OAAO,aAAa;AAAA,cAC7C,MAAM;AAAA,cACN,OAAO,eAAe,UAAU,eAAe;AAAA,YACjD,CAAC;AACD,kBAAM,cAAc,IAAI,YAAY,CAAC,SAAS,UAAU,aAAa,CAAC,CAAC;AACvE,iBAAK,OAAO,MAAM,YAAY,eAAe,GAAG,WAAW;AAE3D,kBAAM,YAAY,KAAK,OAAO,gBAAgB;AAAA,cAC5C,QAAQ,SAAS,mBAAmB,CAAC;AAAA,cACrC,SAAS;AAAA,gBACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,gBAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,gBAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,gBAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,cAChD;AAAA,YACF,CAAC;AAED,kBAAM,UAAU,MAAM,KAAK;AAAA,cACzB;AAAA,cACA;AAAA,cACA,CAAC,YAAY,GAAG,CAAC;AAAA,cACjB;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,QAAQ,IAAI,aAAa;AAC/B,kBAAM,SAAS,UAAU,IAAK,QAAQ,UAAW,MAAM;AAEvD,gBAAI,UAAU,KAAK,QAAQ;AACzB,qBAAO;AAAA,gBACL,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,gBAChC,iBAAiB;AAAA,gBACjB,YAAY;AAAA,gBACZ,QAAQ;AAAA,gBACR,YAAY,KAAK,cAAc;AAAA,cACjC;AAAA,YACF;AAEA,0BAAc,QAAQ;AAAA,UACxB,SAAS,GAAG;AACV;AAAA,UACF;AAAA,QACF;AAEA,gBAAQ,QAAQ;AAChB,gBAAQ,QAAQ;AAChB,kBAAU,QAAQ;AAElB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,aACZ,YACA,YACA,QACA,YACqB;AACrB,cAAM,EAAE,YAAY,MAAO,YAAY,EAAE,IAAI;AAE7C,YAAI,OAAmB;AAAA,UACrB,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,UAChC,iBAAiB;AAAA,UACjB,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY,KAAK,cAAc;AAAA,QACjC;AAEA,YAAI,CAAC,KAAK,QAAQ;AAChB,iBAAO;AAAA,QACT;AAEA,cAAM,oBAAoB,WAAW,OAAO,OAAK,EAAE,CAAC,MAAM,CAAC;AAC3D,YAAI,kBAAkB,WAAW,GAAG;AAClC,iBAAO;AAAA,QACT;AAEA,cAAM,gBAAgB,KAAK,IAAI,GAAG,YAAY,SAAS;AAEvD,cAAM,WAAW,KAAK,OAAO,aAAa;AAAA,UACxC,MAAM,gBAAgB;AAAA,UACtB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,YAAY,KAAK,OAAO,aAAa;AAAA,UACzC,MAAM,gBAAgB;AAAA,UACtB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AAED,cAAM,SAAS,IAAI,aAAa,aAAa;AAC7C,iBAAS,IAAI,GAAG,IAAI,eAAe,KAAK;AACtC,iBAAO,CAAC,IAAI,KAAK,OAAO;AAAA,QAC1B;AACA,aAAK,OAAO,MAAM,YAAY,UAAU,GAAG,MAAM;AAEjD,mBAAW,CAAC,GAAG,KAAK,mBAAmB;AACrC,cAAI;AACF,kBAAM,SAAS,KAAK,qBAAqB,GAAG;AAC5C,kBAAM,WAAW,MAAM,KAAK,uBAAuB,QAAQ,MAAM;AAEjE,kBAAM,gBAAgB,KAAK,OAAO,aAAa;AAAA,cAC7C,MAAM;AAAA,cACN,OAAO,eAAe,UAAU,eAAe;AAAA,YACjD,CAAC;AACD,kBAAM,cAAc,IAAI,YAAY,CAAC,WAAW,WAAW,GAAG,CAAC,CAAC;AAChE,iBAAK,OAAO,MAAM,YAAY,eAAe,GAAG,WAAW;AAE3D,kBAAM,YAAY,KAAK,OAAO,gBAAgB;AAAA,cAC5C,QAAQ,SAAS,mBAAmB,CAAC;AAAA,cACrC,SAAS;AAAA,gBACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,gBAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,gBAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,cAChD;AAAA,YACF,CAAC;AAED,kBAAM,UAAU,MAAM,KAAK;AAAA,cACzB;AAAA,cACA;AAAA,cACA,CAAC,WAAW,GAAG,CAAC;AAAA,cAChB;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,MAAM,IAAI;AAChB,kBAAM,OAAO,UAAU,IAAK,MAAM,UAAW,MAAM;AAEnD,gBAAI,UAAU,KAAK,QAAQ;AACzB,qBAAO;AAAA,gBACL,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,gBAChC,iBAAiB;AAAA,gBACjB,YAAY;AAAA,gBACZ,QAAQ;AAAA,gBACR,YAAY,KAAK,cAAc;AAAA,cACjC;AAAA,YACF;AAEA,0BAAc,QAAQ;AAAA,UACxB,SAAS,GAAG;AACV;AAAA,UACF;AAAA,QACF;AAEA,iBAAS,QAAQ;AACjB,kBAAU,QAAQ;AAElB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,aACZ,YACA,YACA,QACA,YACqB;AACrB,cAAM,EAAE,aAAa,MAAM,YAAY,EAAE,IAAI;AAE7C,YAAI,OAAmB;AAAA,UACrB,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,UAChC,iBAAiB;AAAA,UACjB,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY,KAAK,cAAc;AAAA,QACjC;AAEA,YAAI,CAAC,KAAK,QAAQ;AAChB,iBAAO;AAAA,QACT;AAEA,cAAM,gBAAgB,WAAW,OAAO,OAAK,EAAE,CAAC,MAAM,CAAC;AACvD,YAAI,cAAc,WAAW,GAAG;AAC9B,iBAAO;AAAA,QACT;AAEA,cAAM,gBAAgB,KAAK,IAAI,GAAG,aAAa,SAAS;AAExD,cAAM,WAAW,KAAK,OAAO,aAAa;AAAA,UACxC,MAAM,gBAAgB;AAAA,UACtB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,eAAe,KAAK,OAAO,aAAa;AAAA,UAC5C,MAAM,aAAa;AAAA,UACnB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,YAAY,KAAK,OAAO,aAAa;AAAA,UACzC,MAAM,gBAAgB;AAAA,UACtB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AAED,cAAM,SAAS,IAAI,aAAa,aAAa;AAC7C,cAAM,aAAa,IAAI,aAAa,UAAU;AAC9C,iBAAS,IAAI,GAAG,IAAI,eAAe,KAAK;AACtC,iBAAO,CAAC,IAAI,KAAK,OAAO;AAAA,QAC1B;AACA,iBAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,qBAAW,CAAC,IAAI,KAAK,OAAO;AAAA,QAC9B;AACA,aAAK,OAAO,MAAM,YAAY,UAAU,GAAG,MAAM;AACjD,aAAK,OAAO,MAAM,YAAY,cAAc,GAAG,UAAU;AAEzD,mBAAW,CAAC,GAAG,KAAK,eAAe;AACjC,cAAI;AACF,kBAAM,SAAS,KAAK,qBAAqB,GAAG;AAC5C,kBAAM,WAAW,MAAM,KAAK,uBAAuB,QAAQ,MAAM;AAEjE,kBAAM,gBAAgB,KAAK,OAAO,aAAa;AAAA,cAC7C,MAAM;AAAA,cACN,OAAO,eAAe,UAAU,eAAe;AAAA,YACjD,CAAC;AACD,kBAAM,cAAc,IAAI,YAAY,EAAE;AACtC,kBAAM,cAAc,IAAI,SAAS,WAAW;AAC5C,wBAAY,UAAU,GAAG,YAAY,IAAI;AACzC,wBAAY,UAAU,GAAG,WAAW,IAAI;AACxC,wBAAY,WAAW,GAAG,MAAM,IAAI;AACpC,wBAAY,UAAU,IAAI,GAAG,IAAI;AACjC,iBAAK,OAAO,MAAM,YAAY,eAAe,GAAG,WAAW;AAE3D,kBAAM,YAAY,KAAK,OAAO,gBAAgB;AAAA,cAC5C,QAAQ,SAAS,mBAAmB,CAAC;AAAA,cACrC,SAAS;AAAA,gBACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,gBAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,gBAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,gBACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,cAChD;AAAA,YACF,CAAC;AAED,kBAAM,UAAU,MAAM,KAAK;AAAA,cACzB;AAAA,cACA;AAAA,cACA,CAAC,WAAW,GAAG,CAAC;AAAA,cAChB;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,MAAM,IAAI;AAChB,kBAAM,OAAO,UAAU,IAAK,MAAM,UAAW,MAAM;AAEnD,gBAAI,UAAU,KAAK,QAAQ;AACzB,qBAAO;AAAA,gBACL,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,gBAChC,iBAAiB;AAAA,gBACjB,YAAY;AAAA,gBACZ,QAAQ;AAAA,gBACR,YAAY,KAAK,cAAc;AAAA,cACjC;AAAA,YACF;AAEA,0BAAc,QAAQ;AAAA,UACxB,SAAS,GAAG;AACV;AAAA,UACF;AAAA,QACF;AAEA,iBAAS,QAAQ;AACjB,qBAAa,QAAQ;AACrB,kBAAU,QAAQ;AAElB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,aACZ,YACA,YACA,QACA,YACqB;AACrB,cAAM,EAAE,YAAY,IAAK,IAAI;AAE7B,YAAI,OAAmB;AAAA,UACrB,sBAAsB,CAAC,IAAI,GAAG,CAAC;AAAA,UAC/B,iBAAiB;AAAA,UACjB,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY,KAAK,cAAc;AAAA,QACjC;AAEA,YAAI,CAAC,KAAK,QAAQ;AAChB,iBAAO;AAAA,QACT;AAEA,cAAM,oBAAoB,WAAW,OAAO,OAAK,EAAE,CAAC,MAAM,CAAC;AAC3D,YAAI,kBAAkB,WAAW,GAAG;AAClC,iBAAO;AAAA,QACT;AAEA,cAAM,cAAc,KAAK,IAAI,GAAG,YAAY,GAAG;AAE/C,cAAM,WAAW,KAAK,OAAO,aAAa;AAAA,UACxC,MAAM,cAAc;AAAA,UACpB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,cAAM,YAAY,KAAK,OAAO,aAAa;AAAA,UACzC,MAAM,cAAc;AAAA,UACpB,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AAED,cAAM,SAAS,IAAI,YAAY,WAAW;AAC1C,iBAAS,IAAI,GAAG,IAAI,aAAa,KAAK;AACpC,iBAAO,CAAC,IAAI,IAAI;AAAA,QAClB;AACA,aAAK,OAAO,MAAM,YAAY,UAAU,GAAG,MAAM;AAEjD,mBAAW,CAAC,GAAG,KAAK,mBAAmB;AACrC,cAAI;AACF,kBAAM,SAAS,KAAK,qBAAqB,GAAG;AAC5C,kBAAM,WAAW,MAAM,KAAK,uBAAuB,QAAQ,MAAM;AAEjE,kBAAM,gBAAgB,KAAK,OAAO,aAAa;AAAA,cAC7C,MAAM;AAAA,cACN,OAAO,eAAe,UAAU,eAAe;AAAA,YACjD,CAAC;AACD,kBAAM,cAAc,IAAI,YAAY,EAAE;AACtC,kBAAM,cAAc,IAAI,SAAS,WAAW;AAC5C,wBAAY,UAAU,GAAG,aAAa,IAAI;AAC1C,wBAAY,WAAW,GAAG,MAAM,IAAI;AACpC,wBAAY,UAAU,GAAG,GAAG,IAAI;AAChC,wBAAY,UAAU,IAAI,GAAG,IAAI;AACjC,iBAAK,OAAO,MAAM,YAAY,eAAe,GAAG,WAAW;AAE3D,kBAAM,YAAY,KAAK,OAAO,gBAAgB;AAAA,cAC5C,QAAQ,SAAS,mBAAmB,CAAC;AAAA,cACrC,SAAS;AAAA,gBACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,gBAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,gBAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,cAChD;AAAA,YACF,CAAC;AAED,kBAAM,aAAa,KAAK,KAAK,cAAc,GAAG;AAC9C,kBAAM,UAAU,MAAM,KAAK;AAAA,cACzB;AAAA,cACA;AAAA,cACA,CAAC,YAAY,GAAG,CAAC;AAAA,cACjB;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,MAAM;AACZ,kBAAM,OAAO,UAAU,IAAK,MAAM,UAAW,MAAM;AAEnD,gBAAI,UAAU,KAAK,QAAQ;AACzB,qBAAO;AAAA,gBACL,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,gBAChC,iBAAiB;AAAA,gBACjB,YAAY;AAAA,gBACZ,QAAQ;AAAA,gBACR,YAAY,KAAK,cAAc;AAAA,cACjC;AAAA,YACF;AAEA,0BAAc,QAAQ;AAAA,UACxB,SAAS,GAAG;AACV;AAAA,UACF;AAAA,QACF;AAEA,iBAAS,QAAQ;AACjB,kBAAU,QAAQ;AAElB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,aACZ,YACA,YACA,YACA,QACA,YACqB;AAErB,eAAO;AAAA,UACL,sBAAsB,CAAC,KAAK,GAAG,CAAC;AAAA,UAChC,iBAAiB;AAAA,UACjB,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY,KAAK,cAAc;AAAA,QACjC;AAAA,MACF;AAAA,MAEA,MAAc,mBACZ,UACA,WACA,YACA,QACA,YACiB;AACjB,YAAI,CAAC,KAAK,QAAQ;AAChB,iBAAO;AAAA,QACT;AAEA,cAAM,CAAC,KAAK,KAAK,GAAG,IAAI;AACxB,YAAI,QAAQ,KAAK,QAAQ,KAAK,QAAQ,GAAG;AACvC,iBAAO;AAAA,QACT;AAEA,iBAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,gBAAM,UAAU,KAAK,OAAO,qBAAqB;AACjD,gBAAM,OAAO,QAAQ,iBAAiB;AACtC,eAAK,YAAY,QAAQ;AACzB,eAAK,aAAa,GAAG,SAAS;AAC9B,eAAK,mBAAmB,KAAK,KAAK,GAAG;AACrC,eAAK,IAAI;AACT,eAAK,OAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAAA,QAC7C;AACA,cAAM,KAAK,OAAO,MAAM,oBAAoB;AAE5C,cAAM,QAAkB,CAAC;AACzB,iBAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,gBAAM,QAAQ,YAAY,IAAI;AAC9B,gBAAM,UAAU,KAAK,OAAO,qBAAqB;AACjD,gBAAM,OAAO,QAAQ,iBAAiB;AACtC,eAAK,YAAY,QAAQ;AACzB,eAAK,aAAa,GAAG,SAAS;AAC9B,eAAK,mBAAmB,KAAK,KAAK,GAAG;AACrC,eAAK,IAAI;AACT,eAAK,OAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAC3C,gBAAM,KAAK,OAAO,MAAM,oBAAoB;AAC5C,gBAAM,KAAK,YAAY,IAAI,IAAI,KAAK;AAAA,QACtC;AAEA,eAAO,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,IAAI,MAAM;AAAA,MAClD;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAc,uBACZ,cACA,YAC6B;AAC7B,YAAI,CAAC,KAAK,QAAQ;AAChB,gBAAM,IAAI,MAAM,wBAAwB;AAAA,QAC1C;AACA,cAAM,SAAS,KAAK,OAAO,mBAAmB,EAAE,MAAM,aAAa,CAAC;AACpE,eAAO,MAAM,KAAK,OAAO,2BAA2B;AAAA,UAClD,QAAQ;AAAA,UACR,SAAS,EAAE,QAAQ,WAAW;AAAA,QAChC,CAAC;AAAA,MACH;AAAA,MAEQ,uBAAuB,QAAwB;AACrD,eAAO;AAAA,uBACY,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAgBF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAsC/B;AAAA,MAEQ,qBAAqB,QAAwB;AACnD,eAAO;AAAA,uBACY,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MA+D/B;AAAA,MAEQ,qBAAqB,QAAwB;AACnD,eAAO;AAAA,uBACY,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAgBF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MA0C/B;AAAA,MAEQ,qBAAqB,QAAwB;AACnD,eAAO;AAAA,uBACY,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAaF,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAM/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,gBAAgB,YAAoB,YAA2C;AAC7E,cAAM,WAAqB,GAAG,UAAU,IAAI,KAAK,UAAU,UAAU,CAAC;AACtE,eAAO,KAAK,MAAM,IAAI,QAAQ,KAAK;AAAA,MACrC;AAAA;AAAA;AAAA;AAAA,MAKA,aAAmB;AACjB,aAAK,MAAM,MAAM;AACjB,YAAI,OAAO,iBAAiB,aAAa;AACvC,gBAAM,YAAY,KAAK,oBAAoB;AAC3C,uBAAa,WAAW,eAAe,EAAE,iBAAiB,SAAS;AAAA,QACrE;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,sBAAkD;AAChD,eAAO,OAAO,YAAY,KAAK,KAAK;AAAA,MACtC;AAAA;AAAA;AAAA;AAAA,MAKA,UAAgB;AACd,YAAI,KAAK,UAAU;AACjB,eAAK,SAAS,QAAQ;AAAA,QACxB;AAAA,MACF;AAAA,IACF;AAGA,IAAI,cAAkC;AAAA;AAAA;;;ACprCtC,SAAS,gBAAgB,MAA+C;AACtE,QAAM,OAAO,IAAI,WAAW,IAAI;AAChC,MAAI,OAAO;AAEX,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,YAAQ,KAAK,CAAC;AACd,WAAO,KAAK,KAAK,MAAM,QAAQ;AAAA,EACjC;AAGA,UAAQ,SAAS,GAAG,SAAS,EAAE,EAAE,SAAS,GAAG,GAAG;AAClD;AAkOO,SAAS,qBAAqB,QAAyB;AAC5D,QAAM,QAAQ,gBAAgB;AAC9B,MAAI,MAAM,SAAS,MAAM,GAAG;AAC1B,UAAM,QAAQ,MAAM;AAAA,EACtB,OAAO;AACL,WAAO,QAAQ;AAAA,EACjB;AACF;AAQO,SAAS,kBAAsC;AACpD,MAAI,CAAC,oBAAoB;AACvB,yBAAqB,IAAI,mBAAmB;AAAA,EAC9C;AACA,SAAO;AACT;AA7RA,IAoDa,oBA+NT;AAnRJ;AAAA;AAQA;AACA;AA2CO,IAAM,qBAAN,MAAyB;AAAA,MACtB,QAAwC,oBAAI,IAAI;AAAA,MAChD,QAA2B;AAAA,QACjC,MAAM;AAAA,QACN,QAAQ;AAAA,QACR,WAAW;AAAA,QACX,aAAa;AAAA,MACf;AAAA;AAAA,MAGQ,qBAAkC,CAAC;AAAA,MAE1B;AAAA,MACA;AAAA,MAEjB,YACE,aAAqB,iBAAiB,EAAE,SAAS,wBACjD,WAAmB,iBAAiB,EAAE,SAAS,sBAC/C;AACA,aAAK,aAAa;AAClB,aAAK,WAAW;AAAA,MAClB;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,YAAY,MAAuC,OAA0B;AAC3E,cAAM,OAAO,gBAAgB,IAAI;AACjC,cAAM,WAAW,KAAK,MAAM,IAAI,IAAI;AAEpC,YAAI,UAAU;AACZ,mBAAS,WAAW,YAAY,IAAI;AACpC,mBAAS;AACT,eAAK,MAAM;AACX,iBAAO,SAAS;AAAA,QAClB;AAGA,aAAK,MAAM;AAEX,cAAMC,UAAS,UAAU;AACzB,YAAI,CAACA,SAAQ;AACX,gBAAM,IAAI,MAAM,4BAA4B;AAAA,QAC9C;AAEA,cAAM,SAASA,QAAO,aAAa;AAAA,UACjC,OAAO,GAAG,KAAK;AAAA,UACf,MAAM,KAAK;AAAA,UACX,OAAO,eAAe,UAAU,eAAe;AAAA,QACjD,CAAC;AACD,QAAAA,QAAO,MAAM,YAAY,QAAQ,GAAG,IAAI;AAGxC,YAAI,KAAK,MAAM,QAAQ,KAAK,YAAY;AACtC,eAAK,SAAS;AAAA,QAChB;AAEA,aAAK,MAAM,IAAI,MAAM;AAAA,UACnB;AAAA,UACA,UAAU,YAAY,IAAI;AAAA,UAC1B,UAAU;AAAA,QACZ,CAAC;AACD,aAAK,MAAM,cAAc,KAAK,MAAM;AAEpC,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,QAAQ,QAAyB;AAE/B,mBAAW,CAAC,MAAM,KAAK,KAAK,KAAK,OAAO;AACtC,cAAI,MAAM,WAAW,QAAQ;AAC3B,kBAAM,WAAW,KAAK,IAAI,GAAG,MAAM,WAAW,CAAC;AAC/C;AAAA,UACF;AAAA,QACF;AAAA,MAGF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOQ,WAAiB;AACvB,YAAI,aAA4B;AAChC,YAAI,aAAa;AAEjB,mBAAW,CAAC,MAAM,KAAK,KAAK,KAAK,OAAO;AAEtC,cAAI,MAAM,aAAa,KAAK,MAAM,WAAW,YAAY;AACvD,yBAAa,MAAM;AACnB,yBAAa;AAAA,UACf;AAAA,QACF;AAGA,YAAI,eAAe,MAAM;AACvB,qBAAW,CAAC,MAAM,KAAK,KAAK,KAAK,OAAO;AACtC,gBAAI,MAAM,WAAW,YAAY;AAC/B,2BAAa,MAAM;AACnB,2BAAa;AAAA,YACf;AAAA,UACF;AAAA,QACF;AAEA,YAAI,YAAY;AACd,gBAAM,QAAQ,KAAK,MAAM,IAAI,UAAU;AACvC,cAAI,OAAO;AAET,iBAAK,mBAAmB,KAAK,MAAM,MAAM;AACzC,iBAAK,MAAM,OAAO,UAAU;AAC5B,iBAAK,MAAM;AACX,iBAAK,MAAM,cAAc,KAAK,MAAM;AAAA,UACtC;AAAA,QACF;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,aAAqB;AACnB,cAAM,MAAM,YAAY,IAAI;AAC5B,YAAI,UAAU;AAEd,mBAAW,CAAC,MAAM,KAAK,KAAK,KAAK,OAAO;AACtC,cAAI,MAAM,aAAa,KAAK,MAAM,MAAM,WAAW,KAAK,UAAU;AAEhE,iBAAK,mBAAmB,KAAK,MAAM,MAAM;AACzC,iBAAK,MAAM,OAAO,IAAI;AACtB;AAAA,UACF;AAAA,QACF;AAEA,aAAK,MAAM,aAAa;AACxB,aAAK,MAAM,cAAc,KAAK,MAAM;AACpC,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,QAAc;AAEZ,aAAK,wBAAwB;AAG7B,mBAAW,SAAS,KAAK,MAAM,OAAO,GAAG;AACvC,gBAAM,OAAO,QAAQ;AAAA,QACvB;AACA,aAAK,MAAM,MAAM;AACjB,aAAK,MAAM,cAAc;AAAA,MAC3B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAUA,0BAAkC;AAChC,cAAM,QAAQ,KAAK,mBAAmB;AACtC,mBAAW,UAAU,KAAK,oBAAoB;AAC5C,iBAAO,QAAQ;AAAA,QACjB;AACA,aAAK,qBAAqB,CAAC;AAC3B,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,6BAAqC;AACnC,eAAO,KAAK,mBAAmB;AAAA,MACjC;AAAA;AAAA;AAAA;AAAA,MAKA,SAAS,QAA4B;AACnC,mBAAW,SAAS,KAAK,MAAM,OAAO,GAAG;AACvC,cAAI,MAAM,WAAW,QAAQ;AAC3B,mBAAO;AAAA,UACT;AAAA,QACF;AACA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,WAAgF;AAC9E,cAAM,QAAQ,KAAK,MAAM,OAAO,KAAK,MAAM;AAC3C,cAAM,UAAU,QAAQ,KAAM,KAAK,MAAM,OAAO,QAAS,KAAK,QAAQ,CAAC,IAAI,MAAM;AACjF,eAAO,EAAE,GAAG,KAAK,OAAO,SAAS,oBAAoB,KAAK,mBAAmB,OAAO;AAAA,MACtF;AAAA,IACF;AAiBA,IAAI,qBAAgD;AAAA;AAAA;;;ACpPpD,SAAS,oBAA4B;AAEnC,MAAI,OAAO,aAAa,aAAa;AACnC,UAAM,OAAO,SAAS;AACtB,QAAI,KAAK,WAAW,IAAI,KAAK,KAAK,WAAW,WAAW,KAAK,SAAS,KAAK,SAAS,OAAO,GAAG;AAC5F,aAAO;AAAA,IACT;AAAA,EACF;AACA,SAAO;AACT;AA03BO,SAAS,wBAAwB,QAAgB,UAAkB,SAAuB;AAC/F,QAAM,SAAS,gBAAgB;AAC/B,MAAI,CAAC;AAAQ;AAGb,QAAM,uBAAuB,SAAS;AACtC,MAAI,uBAAuB,OAAO,kCAAkC;AAClE,UAAM,IAAI;AAAA,MACR,8CAA8C,oBAAoB,iBAC7D,OAAO,gCAAgC,4CACpB,MAAM,kBAAkB,QAAQ;AAAA,IAC1D;AAAA,EACF;AAGA,QAAM,cAAc,SAAS,WAAW,UAAU;AAClD,MAAI,cAAc,OAAO,6BAA6B;AACpD,UAAM,IAAI;AAAA,MACR,kBAAkB,cAAc,KAAK,QAAQ,CAAC,CAAC,4BAC3C,OAAO,8BAA8B,KAAK,QAAQ,CAAC,CAAC;AAAA,IAE1D;AAAA,EACF;AAGA,QAAM,WAAW;AACjB,QAAM,oBAAoB,WAAW,UAAU,IAAI;AACnD,MAAI,oBAAoB,OAAO,gCAAgC;AAC7D,QAAI,KAAK,kBAAkB,wCAAwC,iBAAiB,yBAAyB,OAAO,8BAA8B,uBAAuB;AAAA,EAC3K;AACF;AAKA,eAAsB,iBAAiB,UAAmC;AACxE,MAAI,kBAAkB,IAAI,QAAQ,GAAG;AACnC,WAAO,kBAAkB,IAAI,QAAQ;AAAA,EACvC;AAEA,QAAM,MAAM,GAAG,gBAAgB,IAAI,QAAQ;AAC3C,MAAI;AACF,UAAM,WAAW,MAAM,MAAM,KAAK,EAAE,OAAO,WAAW,CAAC;AACvD,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,IAAI,MAAM,yBAAyB,QAAQ,KAAK,SAAS,MAAM,EAAE;AAAA,IACzE;AACA,UAAM,SAAS,MAAM,SAAS,KAAK;AACnC,sBAAkB,IAAI,UAAU,MAAM;AACtC,WAAO;AAAA,EACT,SAAS,OAAO;AACd,QAAI,MAAM,kBAAkB,yBAAyB,QAAQ,KAAK,KAAK,EAAE;AACzE,UAAM;AAAA,EACR;AACF;AAWO,SAAS,oBAAoB,UAAoB,cAA4C;AAClG,aAAW,WAAW,UAAU;AAC9B,QAAI,YAAY,gBAAgB,CAAC,aAAa;AAAQ,aAAO;AAC7D,QAAI,YAAY,eAAe,CAAC,aAAa;AAAc,aAAO;AAClE,QAAI,YAAY,mBAAmB,CAAC,aAAa;AAAc,aAAO;AAAA,EACxE;AACA,SAAO;AACT;AAKO,SAAS,gBAAgB,WAAmB,SAA+B;AAChF,QAAMC,UAAS,eAAe,SAAS,IAAI,OAAO;AAClD,MAAI,CAACA,SAAQ;AACX,UAAM,IAAI,MAAM,mBAAmB,SAAS,IAAI,OAAO,EAAE;AAAA,EAC3D;AACA,SAAOA;AACT;AAKA,eAAsB,cAAcC,SAAmB,QAAgB,OAAyC;AAC9G,QAAM,SAASA,QAAO,mBAAmB;AAAA,IACvC;AAAA,IACA,MAAM;AAAA,EACR,CAAC;AAGD,QAAM,kBAAkB,MAAM,OAAO,mBAAmB;AACxD,MAAI,gBAAgB,SAAS,SAAS,GAAG;AACvC,eAAW,OAAO,gBAAgB,UAAU;AAC1C,UAAI,IAAI,SAAS,SAAS;AACxB,YAAI,MAAM,iBAAiB,GAAG,KAAK,KAAK,IAAI,OAAO,UAAU,IAAI,OAAO,IAAI,IAAI,OAAO,GAAG;AAAA,MAC5F,WAAW,IAAI,SAAS,WAAW;AACjC,YAAI,KAAK,iBAAiB,GAAG,KAAK,KAAK,IAAI,OAAO,UAAU,IAAI,OAAO,IAAI,IAAI,OAAO,GAAG;AAAA,MAC3F,OAAO;AACL,YAAI,MAAM,iBAAiB,GAAG,KAAK,KAAK,IAAI,OAAO,UAAU,IAAI,OAAO,IAAI,IAAI,OAAO,GAAG;AAAA,MAC5F;AAAA,IACF;AACA,QAAI,gBAAgB,SAAS,KAAK,OAAK,EAAE,SAAS,OAAO,GAAG;AAC1D,YAAM,IAAI,MAAM,iCAAiC,KAAK,EAAE;AAAA,IAC1D;AAAA,EACF;AAEA,SAAO;AACT;AAKA,eAAe,gBACbA,SACA,YACA,OAC0B;AAC1B,QAAM,WAAW;AACjB,QAAM,SAAS,kBAAkB,IAAI,QAAQ;AAC7C,MAAI,QAAQ;AACV,WAAO;AAAA,EACT;AAEA,QAAM,kBAAkB,YAAY;AAClC,UAAM,eAAe,MAAM,iBAAiB,UAAU;AACtD,WAAO,cAAcA,SAAQ,cAAc,KAAK;AAAA,EAClD,GAAG;AAEH,oBAAkB,IAAI,UAAU,cAAc;AAE9C,MAAI;AACF,WAAO,MAAM;AAAA,EACf,SAAS,KAAK;AACZ,sBAAkB,OAAO,QAAQ;AACjC,UAAM;AAAA,EACR;AACF;AAKO,SAAS,2BACd,OACA,SACA,iBAAmC,MACf;AACpB,QAAM,SAAS,qBAAqB,IAAI,KAAK;AAC7C,MAAI,QAAQ;AACV,WAAO;AAAA,EACT;AAEA,QAAMA,UAAS,kBAAkB,UAAU;AAC3C,MAAI,CAACA,SAAQ;AACX,UAAM,IAAI,MAAM,wBAAwB;AAAA,EAC1C;AAEA,QAAM,SAASA,QAAO,sBAAsB,EAAE,OAAO,QAAQ,CAAC;AAC9D,uBAAqB,IAAI,OAAO,MAAM;AACtC,SAAO;AACT;AAKO,SAAS,0BACd,OACA,kBACA,iBAAmC,MAChB;AACnB,QAAM,SAAS,oBAAoB,IAAI,KAAK;AAC5C,MAAI,QAAQ;AACV,WAAO;AAAA,EACT;AAEA,QAAMA,UAAS,kBAAkB,UAAU;AAC3C,MAAI,CAACA,SAAQ;AACX,UAAM,IAAI,MAAM,wBAAwB;AAAA,EAC1C;AAEA,QAAM,SAASA,QAAO,qBAAqB;AAAA,IACzC;AAAA,IACA;AAAA,EACF,CAAC;AAED,sBAAoB,IAAI,OAAO,MAAM;AACrC,SAAO;AACT;AAMO,SAAS,kBACd,WACA,SAC2B;AAC3B,QAAM,WAAW,GAAG,SAAS,IAAI,OAAO;AACxC,SAAO,cAAc,IAAI,QAAQ,KAAK;AACxC;AAOA,eAAsB,gBACpB,WACA,SACA,kBAA6C,MAChB;AAC7B,QAAM,SAAS,kBAAkB,WAAW,OAAO;AACnD,MAAI,QAAQ;AACV,WAAO;AAAA,EACT;AACA,SAAO,eAAe,WAAW,SAAS,eAAe;AAC3D;AAKA,eAAsB,eACpB,WACA,SACA,kBAA6C,MAChB;AAC7B,QAAM,WAAW,GAAG,SAAS,IAAI,OAAO;AAGxC,MAAI,cAAc,IAAI,QAAQ,GAAG;AAC/B,WAAO,cAAc,IAAI,QAAQ;AAAA,EACnC;AAEA,QAAMA,UAAS,UAAU;AACzB,MAAI,CAACA,SAAQ;AACX,UAAM,IAAI,MAAM,wBAAwB;AAAA,EAC1C;AAEA,QAAMD,UAAS,gBAAgB,WAAW,OAAO;AACjD,QAAM,eAAe,sBAAsB;AAG3C,MAAI,CAAC,oBAAoBA,QAAO,UAAU,YAAY,GAAG;AACvD,UAAM,IAAI;AAAA,MACR,UAAU,SAAS,IAAI,OAAO,uBAAuBA,QAAO,SAAS,KAAK,IAAI,CAAC;AAAA,IACjF;AAAA,EACF;AAEA,QAAM;AAAA,IACJ,iBAAiB,SAAS,IAAI,OAAO,SAASA,QAAO,UAAU,UAAUA,QAAO,UAAU,eAC1EA,QAAO,cAAc,KAAK,GAAG,CAAC,cACzCA,QAAO,SAAS,SAAS,IAAIA,QAAO,SAAS,KAAK,GAAG,IAAI,MAAM;AAAA,EACtE;AAGA,QAAM,eAAe,MAAM,gBAAgBC,SAAQD,QAAO,YAAY,GAAG,SAAS,IAAI,OAAO,EAAE;AAG/F,QAAM,cAAc,iBAAiB,SAAS,GAAG,SAAS,IAAI,OAAO;AACrE,QAAM,qBAAmD;AAAA,IACvD,OAAO,GAAG,SAAS,IAAI,OAAO;AAAA,IAC9B,QAAQ,kBACJ,0BAA0B,aAAa,CAAC,eAAe,GAAGC,OAAM,IAChE;AAAA,IACJ,SAAS;AAAA,MACP,QAAQ;AAAA,MACR,YAAYD,QAAO;AAAA,IACrB;AAAA,EACF;AAEA,QAAM,WAAW,MAAMC,QAAO,2BAA2B,kBAAkB;AAC3E,gBAAc,IAAI,UAAU,QAAQ;AAEpC,SAAO;AACT;AAKO,SAAS,oBAA0B;AACxC,gBAAc,MAAM;AACpB,oBAAkB,MAAM;AACxB,oBAAkB,MAAM;AACxB,uBAAqB,MAAM;AAC3B,sBAAoB,MAAM;AAC5B;AAEO,SAAS,qBAA2B;AACzC,oBAAkB;AACpB;AAKO,SAAS,gBAMd;AACA,SAAO;AAAA,IACL,WAAW,cAAc;AAAA,IACzB,SAAS,kBAAkB;AAAA,IAC3B,eAAe,kBAAkB;AAAA,IACjC,kBAAkB,qBAAqB;AAAA,IACvC,iBAAiB,oBAAoB;AAAA,EACvC;AACF;AAKA,eAAsB,sBACpB,WACA,aAAqC,CAAC,GACH;AACnC,MAAI;AACF,UAAM,QAAQ,MAAM,eAAe;AACnC,UAAM,SAAS,MAAM,gBAAgB,WAAW,UAAU;AAE1D,QAAI,QAAQ;AACV,aAAO,OAAO;AAAA,IAChB;AAGA,UAAM,aAAa,MAAM,MAAM,WAAW,WAAW,UAAU;AAC/D,WAAO,WAAW;AAAA,EACpB,SAAS,GAAQ;AACf,QAAI,KAAK,kBAAkB,qBAAqB,SAAS,qBAAqB,EAAE,OAAO,EAAE;AAEzF,YAAQ,WAAW;AAAA,MACjB,KAAK;AACH,eAAO,CAAC,IAAI,IAAI,CAAC;AAAA,MACnB,KAAK;AAAA,MACL,KAAK;AAAA,MACL,KAAK;AACH,eAAO,CAAC,KAAK,GAAG,CAAC;AAAA,MACnB,KAAK;AACH,eAAO,CAAC,IAAI,GAAG,CAAC;AAAA,MAClB;AACE,eAAO,CAAC,KAAK,GAAG,CAAC;AAAA,IACrB;AAAA,EACF;AACF;AAKA,eAAsB,gBAAgB,cAAsC,CAAC,GAAiC;AAC5G,QAAM;AAAA,IACJ,aAAa;AAAA,IACb,mBAAmB;AAAA,IACnB,WAAW;AAAA,IACX,UAAU;AAAA,IACV,YAAY;AAAA,IACZ,YAAY;AAAA,EACd,IAAI;AAEJ,QAAM,QAAQ,MAAM,eAAe;AACnC,QAAM,UAA+B,CAAC;AAGtC,UAAQ,gBAAgB,MAAM,MAAM,WAAW,UAAU;AAAA,IACvD,GAAG;AAAA,IAAG,GAAG;AAAA,IAAY,GAAG;AAAA,EAC1B,CAAC;AACD,UAAQ,aAAa,MAAM,MAAM,WAAW,UAAU;AAAA,IACpD,GAAG;AAAA,IAAG,GAAG;AAAA,IAAkB,GAAG;AAAA,EAChC,CAAC;AAGD,UAAQ,YAAY,MAAM,MAAM,WAAW,aAAa;AAAA,IACtD,QAAQ;AAAA,IAAG;AAAA,IAAU;AAAA,EACvB,CAAC;AAGD,UAAQ,UAAU,MAAM,MAAM,WAAW,WAAW;AAAA,IAClD,WAAW;AAAA,IAAW,WAAW;AAAA,EACnC,CAAC;AAGD,UAAQ,UAAU,MAAM,MAAM,WAAW,WAAW;AAAA,IAClD;AAAA,IAAY,WAAW;AAAA,EACzB,CAAC;AAGD,UAAQ,UAAU,MAAM,MAAM,WAAW,WAAW;AAAA,IAClD,WAAW;AAAA,EACb,CAAC;AAED,MAAI,MAAM,kBAAkB,yBAAyB,KAAK,UAAU,OAAO,CAAC,EAAE;AAC9E,SAAO;AACT;AAKA,eAAsB,eACpB,UAAgD,CAAC,GAClC;AACf,QAAM,OAAO,sBAAsB;AACnC,QAAM,OAAO,QAAQ,QAAQ;AAC7B,QAAM,UAAU,OAAO,QAAQ,cAAc,EAC1C,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,cAAc,CAAC,CAAC,EACrC,IAAI,CAAC,CAAC,WAAW,QAAQ,MAAM,CAAC,WAAW,OAAO,QAAQ,QAAQ,EAAE,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC,MAAM,EAAE,cAAc,CAAC,CAAC,CAAC,CAAU;AAEvH,MAAI,SAAS,cAAc;AACzB,QAAI,QAAQ;AACZ,eAAW,CAAC,WAAW,QAAQ,KAAK,SAAS;AAC3C,iBAAW,CAAC,SAAS,GAAG,KAAK,UAAU;AACrC,YAAI,IAAI,YAAY,CAAC,oBAAoB,IAAI,UAAU,IAAI,GAAG;AAC5D;AAAA,QACF;AACA,YAAI;AACF,gBAAM,eAAe,WAAW,OAAO;AACvC,mBAAS;AAAA,QACX,SAAS,GAAQ;AACf,cAAI,KAAK,kBAAkB,sBAAsB,SAAS,IAAI,OAAO,KAAK,EAAE,OAAO,EAAE;AAAA,QACvF;AAAA,MACF;AAAA,IACF;AACA,QAAI,MAAM,kBAAkB,aAAa,KAAK,mBAAmB;AACjE;AAAA,EACF;AAEA,QAAM,OAAwB,CAAC;AAC/B,aAAW,CAAC,WAAW,QAAQ,KAAK,SAAS;AAC3C,eAAW,CAAC,SAAS,GAAG,KAAK,UAAU;AACrC,UAAI,IAAI,YAAY,CAAC,oBAAoB,IAAI,UAAU,IAAI,GAAG;AAC5D;AAAA,MACF;AACA,WAAK;AAAA,QACH,eAAe,WAAW,OAAO,EAC9B,KAAK,MAAM;AAAA,QAAC,CAAC,EACb,MAAM,CAAC,MAAM;AACZ,cAAI,KAAK,kBAAkB,sBAAsB,SAAS,IAAI,OAAO,KAAK,EAAE,OAAO,EAAE;AAAA,QACvF,CAAC;AAAA,MACL;AAAA,IACF;AAAA,EACF;AAEA,QAAM,QAAQ,IAAI,IAAI;AACtB,MAAI,MAAM,kBAAkB,aAAa,KAAK,MAAM,mBAAmB;AACzE;AAQO,SAAS,4BACd,OACA,MACA,UACA,gBACA,SACW;AACX,MAAI,UAAU;AACZ,WAAO,SAAS,oBAAoB,MAAM,KAAK;AAAA,EACjD;AAGA,QAAM,cAAc,gBAAgB,cAChC,OACA,KAAK,OAAO,MAAM,KAAK,YAAY,KAAK,aAAa,KAAK,UAAU;AAGxE,QAAM,WAAW,SAAS,YAAY;AACtC,MAAI,YAAY,CAAC,gBAAgB;AAC/B,WAAO,gBAAgB,EAAE,YAAY,aAAa,KAAK;AAAA,EACzD;AAGA,QAAMA,UAAS,kBAAkB,UAAU;AAC3C,MAAI,CAACA,SAAQ;AACX,UAAM,IAAI,MAAM,4BAA4B;AAAA,EAC9C;AAEA,QAAM,aAAa,YAAY;AAC/B,QAAM,SAASA,QAAO,aAAa;AAAA,IACjC;AAAA,IACA,MAAM;AAAA,IACN,OAAO,eAAe,UAAU,eAAe;AAAA,EACjD,CAAC;AACD,EAAAA,QAAO,MAAM,YAAY,QAAQ,GAAG,WAAW;AAC/C,SAAO;AACT;AAEO,SAAS,4BACd,OACA,YACA,QACA,UACA,gBACW;AACX,QAAM,OAAO,IAAI,YAAY,UAAU;AACvC,QAAM,OAAO,IAAI,SAAS,IAAI;AAC9B,SAAO,IAAI;AACX,SAAO,4BAA4B,OAAO,MAAM,UAAU,cAAc;AAC1E;AAz5CA,IAaM,mBAGA,mBAGA,eAGA,sBAGA,qBAiBA,kBA8BO;AAxEb;AAAA;AAMA;AAEA;AACA;AACA;AAGA,IAAM,oBAAoB,oBAAI,IAAoB;AAGlD,IAAM,oBAAoB,oBAAI,IAAsC;AAGpE,IAAM,gBAAgB,oBAAI,IAAgC;AAG1D,IAAM,uBAAuB,oBAAI,IAAgC;AAGjE,IAAM,sBAAsB,oBAAI,IAA+B;AAiB/D,IAAM,mBAAmB,kBAAkB;AA8BpC,IAAM,iBAA+D;AAAA,MAC1E,QAAQ;AAAA,QACN,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,IAAI,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,QACf;AAAA,QACA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,IAAI,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,QACf;AAAA,QACA,WAAW;AAAA,UACT,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,IAAI,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA;AAAA,QAEA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA;AAAA,QAEA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,cAAc,WAAW;AAAA,QACtC;AAAA,QACA,oBAAoB;AAAA,UAClB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,cAAc,WAAW;AAAA,QACtC;AAAA;AAAA;AAAA,QAGA,wBAAwB;AAAA,UACtB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,cAAc,WAAW;AAAA,UACpC,iBAAiB,EAAE,WAAW,GAAG;AAAA,QACnC;AAAA;AAAA,QAEA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,kBAAkB;AAAA,UAChB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,WAAW;AAAA,UACtB,iBAAiB,EAAE,OAAO,EAAE;AAAA,QAC9B;AAAA;AAAA,QAEA,mBAAmB;AAAA,UACjB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,UACtB,iBAAiB,EAAE,WAAW,GAAG;AAAA,QACnC;AAAA;AAAA,QAEA,uBAAuB;AAAA,UACrB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,cAAc,WAAW;AAAA,UACpC,aAAa;AAAA,UACb,iBAAiB,EAAE,WAAW,GAAG;AAAA,QACnC;AAAA,QACA,sBAAsB;AAAA,UACpB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,cAAc,WAAW;AAAA,UACpC,aAAa;AAAA,UACb,iBAAiB,EAAE,OAAO,EAAE;AAAA,QAC9B;AAAA,QACA,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,IAAI,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA;AAAA,MAEA,WAAW;AAAA,QACT,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,MACF;AAAA;AAAA,MAEA,4BAA4B;AAAA,QAC1B,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,WAAW;AAAA,UACT,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,MACF;AAAA,MACA,SAAS;AAAA,QACP,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,iBAAiB;AAAA,UACf,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,sBAAsB;AAAA,UACpB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,oBAAoB;AAAA,UAClB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA;AAAA,QAEA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,YAAY;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,cAAc;AAAA,UACZ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,YAAY;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA;AAAA,QAEA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,MACF;AAAA,MACA,WAAW;AAAA,QACT,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,UACX,UAAU;AAAA,QACZ;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,UACX,UAAU;AAAA,QACZ;AAAA,QACA,cAAc;AAAA,UACZ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,mBAAmB;AAAA,UACjB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,GAAG,GAAG,CAAC;AAAA,UACvB,UAAU,CAAC;AAAA,UACX,UAAU;AAAA,QACZ;AAAA,QACA,kBAAkB;AAAA,UAChB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,GAAG,GAAG,CAAC;AAAA,UACvB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,UACvB,UAAU;AAAA,QACZ;AAAA,QACA,cAAc;AAAA,UACZ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,qBAAqB;AAAA,UACnB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,UACvB,UAAU;AAAA,QACZ;AAAA,QACA,oBAAoB;AAAA,UAClB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,yBAAyB;AAAA,UACvB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,GAAG,GAAG,CAAC;AAAA,UACvB,UAAU,CAAC,YAAY;AAAA,UACvB,UAAU;AAAA,QACZ;AAAA,QACA,wBAAwB;AAAA,UACtB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,GAAG,GAAG,CAAC;AAAA,UACvB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA;AAAA,QAEA,sBAAsB;AAAA,UACpB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,UACvB,iBAAiB,EAAE,UAAU,KAAK;AAAA,QACpC;AAAA;AAAA,QAEA,iBAAiB;AAAA,UACf,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,MACF;AAAA,MACA,SAAS;AAAA,QACP,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,gBAAgB;AAAA,UACd,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA;AAAA,QAEA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,WAAW;AAAA,UACT,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,MACF;AAAA;AAAA;AAAA,MAGA,sBAAsB;AAAA,QACpB,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA;AAAA;AAAA,MAGA,uBAAuB;AAAA,QACrB,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,SAAS;AAAA,QACP,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,QACA,gBAAgB;AAAA,UACd,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,WAAW;AAAA,QACxB;AAAA,MACF;AAAA,MACA,MAAM;AAAA,QACJ,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,IAAI;AAAA,UACF,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,MAAM;AAAA,QACJ,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,YAAY;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,gBAAgB;AAAA,UACd,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,mBAAmB;AAAA,UACjB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,oBAAoB;AAAA,UAClB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,MACF;AAAA,MACA,OAAO;AAAA,QACL,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,QAAQ;AAAA,QACN,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA;AAAA,QAEA,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA;AAAA,QAEA,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,UACb,iBAAiB,EAAE,eAAe,EAAE;AAAA,QACtC;AAAA,QACA,cAAc;AAAA,UACZ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,UACb,iBAAiB,EAAE,eAAe,EAAE;AAAA,QACtC;AAAA;AAAA,QAEA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,UACb,iBAAiB,EAAE,eAAe,EAAE;AAAA,QACtC;AAAA,QACA,kBAAkB;AAAA,UAChB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,UACb,iBAAiB,EAAE,eAAe,EAAE;AAAA,QACtC;AAAA,MACF;AAAA,MACA,UAAU;AAAA,QACR,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,QACf;AAAA,QACA,UAAU;AAAA,UACR,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC,YAAY;AAAA,UACvB,aAAa;AAAA,QACf;AAAA,MACF;AAAA,MACA,MAAM;AAAA,QACJ,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,aAAa;AAAA,QACX,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,MAAM;AAAA,UACJ,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,YAAY;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,YAAY;AAAA,QACV,OAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,IAAI,GAAG,CAAC;AAAA,UACxB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,QAAQ;AAAA,QACN,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,UAAU;AAAA,QACR,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,KAAK;AAAA,UACH,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,MACF;AAAA,MACA,MAAM;AAAA,QACJ,YAAY;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,QACA,YAAY;AAAA,UACV,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,MACF;AAAA;AAAA,MAEA,WAAW;AAAA,QACT,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,QAAQ;AAAA,QACN,QAAQ;AAAA,UACN,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,eAAe;AAAA,UACb,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,kBAAkB;AAAA,UAChB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,kBAAkB;AAAA,UAChB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,oBAAoB;AAAA,UAClB,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,QACA,aAAa;AAAA,UACX,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,aAAa;AAAA,QACX,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC;AAAA,QACb;AAAA,MACF;AAAA,MACA,aAAa;AAAA,QACX,SAAS;AAAA,UACP,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ,eAAe,CAAC,KAAK,GAAG,CAAC;AAAA,UACzB,UAAU,CAAC,YAAY;AAAA,QACzB;AAAA,MACF;AAAA,IACF;AAAA;AAAA;;;ACr0BO,SAAS,eAAe,OAAuC;AACpE,SACE,OAAO,UAAU,YACjB,UAAU,QACV,YAAY,SACZ,WAAW,SACX,YAAY,SACZ,WAAW;AAEf;AAoBO,SAAS,UAAU,QAA6C;AACrE,SAAO,eAAe,MAAM,IAAI,OAAO,SAAS;AAClD;AAMO,SAAS,UAAU,QAAuD;AAC/E,SAAO,eAAe,MAAM,IAAI,OAAO,SAAS;AAClD;AAKO,SAAS,eAAe,QAAsD;AACnF,SAAO,eAAe,MAAM,IAAI,OAAO,QAAQ;AACjD;AAtIA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AA0EA,SAAS,QAAQ,MAAc,WAA2B;AACxD,SAAO,KAAK,KAAK,OAAO,SAAS,IAAI;AACvC;AAKA,SAAS,cACP,MACA,iBAAyB,UACzB,eAAe,iBAAiB,EAAE,WAAW,QACrC;AAER,QAAM,YAAY,aAAa;AAC/B,MAAI,QAAQ;AAAW,WAAO;AAM9B,QAAM,iBAAiB,aAAa;AACpC,MAAI,QAAQ,gBAAgB;AAC1B,UAAM,YAAY,aAAa;AAC/B,UAAMC,UAAS,KAAK,KAAK,OAAO,SAAS,IAAI;AAC7C,QAAIA,UAAS,gBAAgB;AAC3B,aAAO,QAAQ,MAAM,SAAS;AAAA,IAChC;AACA,WAAOA;AAAA,EACT;AAKA,QAAM,OAAO,KAAK,KAAK,MAAM,OAAO,CAAC;AACrC,QAAM,SAAS,KAAK,IAAI,GAAG,IAAI;AAG/B,MAAI,SAAS,gBAAgB;AAC3B,WAAO,QAAQ,MAAM,SAAS;AAAA,EAChC;AACA,SAAO;AACT;AAmaO,SAAS,gBAA4B;AAC1C,MAAI,CAAC,YAAY;AACf,iBAAa,IAAI,WAAW;AAAA,EAC9B;AACA,SAAO;AACT;AAKO,SAAS,iBAAiB,WAAqB,cAAmD;AACvG,SAAO,IAAI,WAAW,WAAW,YAAY;AAC/C;AAKO,SAAS,oBAA0B;AACxC,MAAI,YAAY;AACd,eAAW,QAAQ;AACnB,iBAAa;AAAA,EACf;AACF;AAiBA,eAAsB,WACpB,MACA,OACA,IACY;AACZ,QAAM,OAAO,cAAc;AAC3B,QAAM,SAAS,KAAK,QAAQ,MAAM,KAAK;AACvC,MAAI;AACF,WAAO,MAAM,GAAG,MAAM;AAAA,EACxB,UAAE;AACA,SAAK,QAAQ,MAAM;AAAA,EACrB;AACF;AAzkBA,IA+Da,aAyDA,YAyZT,YA8BS,qBACA,oBACA,qBACA,eAEA,eACA,YAEA;AAvjBb;AAAA;AAOA;AACA;AAEA;AAEA;AAmDO,IAAM,cAAc;AAAA,MACzB,SAAS,eAAe,UAAU,eAAe,WAAW,eAAe;AAAA,MAC3E,cAAc,eAAe,UAAU,eAAe;AAAA,MACtD,SAAS,eAAe,UAAU,eAAe;AAAA,MACjD,cAAc,WAAW,OAAO,eAAe;AAAA,MAC/C,eAAe,WAAW,QAAQ,eAAe;AAAA,IACnD;AAmDO,IAAM,aAAN,MAAiB;AAAA;AAAA;AAAA,MAGd;AAAA;AAAA,MAGA;AAAA;AAAA,MAGA;AAAA;AAAA,MAGA;AAAA,MACA;AAAA;AAAA,MAGA;AAAA;AAAA,MAGA;AAAA;AAAA,MAGA;AAAA;AAAA,MAGA;AAAA,MAER,YAAY,YAAqB,OAAO,cAAuC;AAC7E,aAAK,QAAQ,oBAAI,IAAI;AACrB,aAAK,gBAAgB,oBAAI,IAAI;AAC7B,aAAK,iBAAiB,oBAAI,IAAI;AAC9B,aAAK,YAAY;AACjB,aAAK,eAAe,gBAAgB,iBAAiB,EAAE;AACvD,aAAK,qBAAqB,oBAAI,IAAI;AAClC,aAAK,uBAAuB;AAE5B,aAAK,QAAQ;AAAA,UACX,aAAa;AAAA,UACb,QAAQ;AAAA,UACR,qBAAqB;AAAA,UACrB,oBAAoB;AAAA,UACpB,uBAAuB;AAAA,QACzB;AAGA,aAAK,SAAS;AAAA,UACZ,sBAAsB,KAAK,aAAa,OAAO;AAAA,UAC/C,uBAAuB,KAAK,aAAa,OAAO;AAAA,UAChD,eAAe;AAAA,UACf,gBAAgB,KAAK,aAAa,UAAU;AAAA,QAC9C;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,QAAQ,MAAc,QAA6B,YAAY,SAAS,QAAgB,iBAA4B;AAClH,cAAMC,UAAS,UAAU;AACzB,YAAI,CAACA,SAAQ;AACX,gBAAM,IAAI,MAAM,wBAAwB;AAAA,QAC1C;AAGA,cAAM,SAAS,gBAAgB;AAC/B,cAAM,UAAU,QAAQ,iBAAiB;AACzC,cAAM,iBAAiB,QAAQ,+BAA+B;AAC9D,cAAM,mBAAmB,QAAQ,eAAe,aAAa;AAG7D,cAAM,cAAc,QAAQ,MAAM,KAAK,OAAO,cAAc;AAC5D,cAAM,mBAAmB,kBAAkB,KAAK,IAAI,SAAS,cAAc,IAAI;AAC/E,cAAM,SAAS,cAAc,aAAa,kBAAkB,KAAK,aAAa,MAAM;AAEpF,YAAI,SAAS,SAAS;AACpB,gBAAM,IAAI;AAAA,YACR,eAAe,MAAM,kCAAkC,OAAO,iBAChD,IAAI,wBAAwB,MAAM;AAAA,UAClD;AAAA,QACF;AAEA,YAAI,mBAAmB,SAAS,gBAAgB;AAC9C,gBAAM,IAAI;AAAA,YACR,uBAAuB,MAAM,gDAAgD,cAAc;AAAA,UAE7F;AAAA,QACF;AAGA,YAAI,KAAK,OAAO,eAAe;AAC7B,gBAAM,SAAS,KAAK,aAAa,QAAQ,KAAK;AAC9C,cAAI,QAAQ;AACV,iBAAK,cAAc,IAAI,MAAM;AAC7B,iBAAK,MAAM;AAGX,gBAAI,KAAK,WAAW;AAClB,mBAAK,aAAa,QAAQ,QAAQ,OAAO,KAAK;AAAA,YAChD;AAEA,mBAAO;AAAA,UACT;AAAA,QACF;AAGA,cAAM,SAASA,QAAO,aAAa;AAAA,UACjC,OAAO,GAAG,KAAK,IAAI,MAAM;AAAA,UACzB,MAAM;AAAA,UACN;AAAA,QACF,CAAC;AAED,aAAK,cAAc,IAAI,MAAM;AAC7B,aAAK,MAAM;AACX,aAAK,MAAM,uBAAuB;AAClC,aAAK,MAAM,yBAAyB;AACpC,aAAK,MAAM,qBAAqB,KAAK;AAAA,UACnC,KAAK,MAAM;AAAA,UACX,KAAK,MAAM;AAAA,QACb;AACA,wBAAgB,QAAQ,KAAK;AAG7B,YAAI,KAAK,WAAW;AAClB,eAAK,aAAa,QAAQ,QAAQ,OAAO,KAAK;AAAA,QAChD;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,QAAQ,QAAyB;AAC/B,YAAI,CAAC,KAAK,cAAc,IAAI,MAAM,GAAG;AACnC,cAAI,KAAK,cAAc,wCAAwC;AAC/D;AAAA,QACF;AAEA,aAAK,cAAc,OAAO,MAAM;AAGhC,YAAI,KAAK,WAAW;AAClB,eAAK,eAAe,OAAO,MAAM;AAAA,QACnC;AAEA,YAAI,CAAC,KAAK,OAAO,eAAe;AAC9B,eAAK,aAAa,MAAM;AACxB,eAAK,MAAM,yBAAyB,OAAO;AAC3C;AAAA,QACF;AAGA,cAAM,SAAS,OAAO;AACtB,cAAM,QAAQ,OAAO;AAErB,YAAI,CAAC,KAAK,MAAM,IAAI,KAAK,GAAG;AAC1B,eAAK,MAAM,IAAI,OAAO,oBAAI,IAAI,CAAC;AAAA,QACjC;AACA,cAAM,YAAY,KAAK,MAAM,IAAI,KAAK;AAEtC,YAAI,CAAC,UAAU,IAAI,MAAM,GAAG;AAC1B,oBAAU,IAAI,QAAQ,CAAC,CAAC;AAAA,QAC1B;AACA,cAAM,aAAa,UAAU,IAAI,MAAM;AAEvC,YAAI,WAAW,SAAS,KAAK,OAAO,wBAChC,KAAK,qBAAqB,IAAI,KAAK,OAAO,uBAAuB;AACnE,qBAAW,KAAK,MAAM;AAAA,QACxB,OAAO;AAEL,eAAK,aAAa,MAAM;AACxB,eAAK,MAAM,yBAAyB,OAAO;AAAA,QAC7C;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA,MAMQ,aAAa,QAAyB;AAC5C,aAAK,mBAAmB,IAAI,MAAM;AAClC,YAAI,KAAK,sBAAsB;AAC7B;AAAA,QACF;AACA,cAAMA,UAAS,UAAU;AACzB,YAAI,CAACA,SAAQ;AAEX,qBAAW,WAAW,KAAK,oBAAoB;AAC7C,oBAAQ,QAAQ;AAAA,UAClB;AACA,eAAK,mBAAmB,MAAM;AAC9B,eAAK,uBAAuB;AAC5B;AAAA,QACF;AAEA,aAAK,uBAAuB;AAC5B,QAAAA,QAAO,MAAM,oBAAoB,EAC9B,KAAK,MAAM;AACV,qBAAW,WAAW,KAAK,oBAAoB;AAC7C,oBAAQ,QAAQ;AAAA,UAClB;AACA,eAAK,mBAAmB,MAAM;AAC9B,eAAK,uBAAuB;AAAA,QAC9B,CAAC,EACA,MAAM,CAAC,QAAQ;AACd,cAAI,KAAK,cAAc,gCAAiC,IAAc,OAAO,EAAE;AAC/E,eAAK,mBAAmB,MAAM;AAC9B,eAAK,uBAAuB;AAAA,QAC9B,CAAC;AAAA,MACL;AAAA;AAAA;AAAA;AAAA,MAKQ,aAAa,QAAgB,OAA8C;AACjF,cAAM,YAAY,KAAK,MAAM,IAAI,KAAK;AACtC,YAAI,CAAC;AAAW,iBAAO;AAEvB,cAAM,aAAa,UAAU,IAAI,MAAM;AACvC,YAAI,CAAC,cAAc,WAAW,WAAW;AAAG,iBAAO;AAEnD,eAAO,WAAW,IAAI;AAAA,MACxB;AAAA;AAAA;AAAA;AAAA,MAKQ,uBAA+B;AACrC,YAAI,QAAQ;AACZ,mBAAW,aAAa,KAAK,MAAM,OAAO,GAAG;AAC3C,qBAAW,cAAc,UAAU,OAAO,GAAG;AAC3C,qBAAS,WAAW;AAAA,UACtB;AAAA,QACF;AACA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKQ,aAAa,QAAmB,MAAc,OAA4B,OAAsB;AACtG,cAAM,WAA2B;AAAA,UAC/B;AAAA,UACA;AAAA,UACA;AAAA,UACA,YAAY,KAAK,IAAI;AAAA,QACvB;AAGA,YAAI,MAAM,mBAAmB;AAC3B,gBAAM,MAAM,CAAC;AACb,gBAAM,kBAAkB,GAAG;AAC3B,mBAAS,aAAc,IAAY;AAAA,QACrC;AAEA,aAAK,eAAe,IAAI,QAAQ,QAAQ;AAAA,MAC1C;AAAA;AAAA;AAAA;AAAA,MAKA,YAAY,cAAsB,KAAyB;AACzD,YAAI,CAAC,KAAK,WAAW;AACnB,cAAI,KAAK,cAAc,oCAAoC;AAC3D,iBAAO,CAAC;AAAA,QACV;AAEA,cAAM,MAAM,KAAK,IAAI;AACrB,cAAM,QAA0B,CAAC;AAEjC,mBAAW,CAAC,QAAQ,QAAQ,KAAK,KAAK,eAAe,QAAQ,GAAG;AAC9D,cAAI,KAAK,cAAc,IAAI,MAAM,GAAG;AAClC,kBAAM,MAAM,MAAM,SAAS;AAC3B,gBAAI,MAAM,aAAa;AACrB,oBAAM,KAAK,QAAQ;AAAA,YACrB;AAAA,UACF;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,oBAAoB,MAAyB;AAC3C,eAAO,KAAK,QAAQ,MAAM,YAAY,cAAc,cAAc;AAAA,MACpE;AAAA;AAAA;AAAA;AAAA,MAKA,mBAAmB,MAAyB;AAC1C,eAAO,KAAK,QAAQ,MAAM,YAAY,eAAe,eAAe;AAAA,MACtE;AAAA;AAAA;AAAA;AAAA,MAKA,oBAAoB,MAAyB;AAE3C,cAAM,cAAc,QAAQ,MAAM,GAAG;AACrC,eAAO,KAAK,QAAQ,aAAa,YAAY,SAAS,SAAS;AAAA,MACjE;AAAA;AAAA;AAAA;AAAA,MAKA,WAAW,QAAmB,MAAqC,SAAiB,GAAS;AAC3F,cAAMA,UAAS,UAAU;AACzB,YAAI,CAACA,SAAQ;AACX,gBAAM,IAAI,MAAM,wBAAwB;AAAA,QAC1C;AACA,QAAAA,QAAO,MAAM,YAAY,QAAQ,QAAQ,IAAkC;AAAA,MAC7E;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,WAAW,QAAmB,OAAe,OAAO,MAA4B;AACpF,YAAI,CAAC,cAAc,uBAAuB,GAAG;AAC3C,iBAAO,IAAI,YAAY,CAAC;AAAA,QAC1B;AAEA,cAAMA,UAAS,UAAU;AACzB,YAAI,CAACA,SAAQ;AACX,gBAAM,IAAI,MAAM,wBAAwB;AAAA,QAC1C;AAGA,cAAM,UAAU,KAAK,oBAAoB,IAAI;AAG7C,cAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,mBAAmB,CAAC;AACzE,gBAAQ,mBAAmB,QAAQ,GAAG,SAAS,GAAG,IAAI;AACtD,QAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAGtC,cAAM,QAAQ,SAAS,WAAW,IAAI;AACtC,cAAM,OAAO,QAAQ,eAAe,GAAG,IAAI,EAAE,MAAM,CAAC;AACpD,gBAAQ,MAAM;AAGd,aAAK,QAAQ,OAAO;AAEpB,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKA,YAAkB;AAChB,mBAAW,aAAa,KAAK,MAAM,OAAO,GAAG;AAC3C,qBAAW,cAAc,UAAU,OAAO,GAAG;AAC3C,uBAAW,UAAU,YAAY;AAC/B,qBAAO,QAAQ;AACf,mBAAK,MAAM,yBAAyB,OAAO;AAAA,YAC7C;AACA,uBAAW,SAAS;AAAA,UACtB;AAAA,QACF;AACA,aAAK,MAAM,MAAM;AACjB,mBAAW,UAAU,KAAK,oBAAoB;AAC5C,iBAAO,QAAQ;AAAA,QACjB;AACA,aAAK,mBAAmB,MAAM;AAC9B,aAAK,uBAAuB;AAAA,MAC9B;AAAA;AAAA;AAAA;AAAA,MAKA,UAAgB;AAEd,mBAAW,UAAU,KAAK,eAAe;AACvC,iBAAO,QAAQ;AAAA,QACjB;AACA,aAAK,cAAc,MAAM;AACzB,aAAK,eAAe,MAAM;AAG1B,aAAK,UAAU;AAEf,aAAK,MAAM,wBAAwB;AAAA,MACrC;AAAA;AAAA;AAAA;AAAA,MAKA,WAAsB;AACpB,eAAO;AAAA,UACL,GAAG,KAAK;AAAA,UACR,eAAe,KAAK,cAAc;AAAA,UAClC,eAAe,KAAK,qBAAqB;AAAA,UACzC,SAAS,KAAK,MAAM,cAAc,KAC7B,KAAK,MAAM,UAAU,KAAK,MAAM,cAAc,KAAK,MAAM,UAAU,KAAK,QAAQ,CAAC,IAAI,MACtF;AAAA,QACN;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,UAAUC,SAAmC;AAC3C,eAAO,OAAO,KAAK,QAAQA,OAAM;AAAA,MACnC;AAAA,IACF;AAGA,IAAI,aAAgC;AA8B7B,IAAM,sBAAsB,CAAC,SAA4B,cAAc,EAAE,oBAAoB,IAAI;AACjG,IAAM,qBAAqB,CAAC,SAA4B,cAAc,EAAE,mBAAmB,IAAI;AAC/F,IAAM,sBAAsB,CAAC,SAA4B,cAAc,EAAE,oBAAoB,IAAI;AACjG,IAAM,gBAAgB,CAAC,MAAc,OAA6B,UACvE,cAAc,EAAE,QAAQ,MAAM,OAAO,KAAK;AACrC,IAAM,gBAAgB,CAAC,WAA4B,cAAc,EAAE,QAAQ,MAAM;AACjF,IAAM,aAAa,CAAC,QAAmB,MAAqC,WACjF,cAAc,EAAE,WAAW,QAAQ,MAAM,MAAM;AAC1C,IAAM,aAAa,CAAC,QAAmB,SAC5C,cAAc,EAAE,WAAW,QAAQ,IAAI;AAAA;AAAA;;;ACziBlC,SAAS,SACdC,SACA,UACA,WACA,YACA,QAAgB,WACV;AACN,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,GAAG,KAAK,WAAW,CAAC;AACzE,QAAM,OAAO,QAAQ,iBAAiB,EAAE,OAAO,GAAG,KAAK,QAAQ,CAAC;AAChE,OAAK,YAAY,QAAQ;AACzB,OAAK,aAAa,GAAG,SAAS;AAE9B,MAAI,OAAO,eAAe,UAAU;AAClC,SAAK,mBAAmB,UAAU;AAAA,EACpC,OAAO;AACL,SAAK,mBAAmB,WAAW,CAAC,GAAG,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC;AAAA,EACrE;AAEA,OAAK,IAAI;AACT,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AACxC;AAMO,SAAS,eACd,UACA,UACA,WACA,YACA,QAAgB,WACV;AACN,QAAM,OAAO,SAAS,iBAAiB,KAAK;AAC5C,OAAK,YAAY,QAAQ;AACzB,OAAK,aAAa,GAAG,SAAS;AAE9B,MAAI,OAAO,eAAe,UAAU;AAClC,SAAK,mBAAmB,UAAU;AAAA,EACpC,OAAO;AACL,SAAK,mBAAmB,WAAW,CAAC,GAAG,WAAW,CAAC,GAAG,WAAW,CAAC,CAAC;AAAA,EACrE;AAEA,OAAK,IAAI;AACX;AAMO,SAAS,iBACdA,SACA,UACA,WACA,gBACA,iBAAyB,GACzB,QAAgB,WACV;AACN,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,GAAG,KAAK,WAAW,CAAC;AACzE,QAAM,OAAO,QAAQ,iBAAiB,EAAE,OAAO,GAAG,KAAK,QAAQ,CAAC;AAChE,OAAK,YAAY,QAAQ;AACzB,OAAK,aAAa,GAAG,SAAS;AAC9B,OAAK,2BAA2B,gBAAgB,cAAc;AAC9D,OAAK,IAAI;AACT,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AACxC;AAKO,SAAS,uBACd,UACA,UACA,WACA,gBACA,iBAAyB,GACzB,QAAgB,WACV;AACN,QAAM,OAAO,SAAS,iBAAiB,KAAK;AAC5C,OAAK,YAAY,QAAQ;AACzB,OAAK,aAAa,GAAG,SAAS;AAC9B,OAAK,2BAA2B,gBAAgB,cAAc;AAC9D,OAAK,IAAI;AACX;AAlGA;AAAA;AAAA;AAAA;;;ACAA,IAUa,iBAgCA,sBAKA,YAQA,mBAoBA,kBAuBA,YAsBA,cAyBA,WAiBA;AAlKb;AAAA;AAUO,IAAM,kBAAkB;AAAA;AAAA,MAE7B,SAAS;AAAA;AAAA,MAGT,cAAc;AAAA;AAAA,MAGd,uBAAuB;AAAA;AAAA,MAGvB,uBAAuB;AAAA;AAAA,MAGvB,UAAU;AAAA;AAAA,MAGV,SAAS;AAAA;AAAA,MAGT,SAAS;AAAA;AAAA,MAGT,eAAe;AAAA,MACf,eAAe;AAAA,MACf,eAAe;AAAA;AAAA,MAGf,KAAK;AAAA,IACP;AAGO,IAAM,uBAAuB,gBAAgB,eAAe;AAK5D,IAAM,aAAa;AAAA;AAAA,MAExB,gBAAgB;AAAA,IAClB;AAKO,IAAM,oBAAoB;AAAA;AAAA,MAE/B,wBAAwB;AAAA;AAAA;AAAA,MAGxB,4BAA4B;AAAA;AAAA;AAAA,MAG5B,4BAA4B;AAAA;AAAA;AAAA,MAG5B,2BAA2B;AAAA;AAAA;AAAA,MAG3B,mBAAmB;AAAA;AAAA,IACrB;AAKO,IAAM,mBAAmB;AAAA;AAAA,MAE9B,8BAA8B;AAAA;AAAA,MAG9B,8BAA8B;AAAA;AAAA,MAG9B,iCAAiC;AAAA;AAAA,MAGjC,aAAa;AAAA;AAAA,MAGb,gBAAgB;AAAA;AAAA;AAAA,MAGhB,gBAAgB;AAAA,IAClB;AAKO,IAAM,aAAa;AAAA;AAAA,MAExB,4BAA4B;AAAA,MAC5B,2BAA2B;AAAA;AAAA,MAG3B,4BAA4B;AAAA,MAC5B,2BAA2B;AAAA;AAAA,MAG3B,UAAU;AAAA,MACV,UAAU;AAAA,MACV,UAAU;AAAA;AAAA,MAGV,gBAAgB;AAAA,MAChB,sBAAsB;AAAA,IACxB;AAKO,IAAM,eAAe;AAAA;AAAA,MAE1B,UAAU;AAAA;AAAA,MAEV,iBAAiB;AAAA;AAAA,MAGjB,SAAS;AAAA;AAAA,MAGT,UAAU;AAAA;AAAA,MAGV,WAAW;AAAA;AAAA,MAGX,UAAU;AAAA;AAAA,MAGV,YAAY;AAAA,IACd;AAKO,IAAM,YAAY;AAAA;AAAA,MAEvB,QAAQ;AAAA;AAAA,MAGR,SAAS;AAAA;AAAA,MAGT,SAAS;AAAA;AAAA,MAGT,QAAQ;AAAA,IACV;AAKO,IAAM,cAAc;AAAA;AAAA,MAEzB,aAAa;AAAA;AAAA,MAGb,YAAY;AAAA;AAAA,MAGZ,iBAAiB;AAAA;AAAA,MAGjB,0BAA0B;AAAA;AAAA,MAG1B,0BAA0B;AAAA,IAC5B;AAAA;AAAA;;;ACjLA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAqDO,SAAS,gCAAgC,GAAmB;AACjE,MAAI,KAAK,gBAAgB,SAAS;AAChC,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAcA,eAAsB,sBACpB,OACA,QACA,YACA,SACiB;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA,MAAM;AAAA,IACN,WAAW;AAAA,IACX,eAAe;AAAA,IACf,aAAa;AAAA;AAAA,EACf,IAAI;AAEJ,QAAM,EAAE,UAAU,IAAI,oBAAoB,EAAE;AAC5C,MAAI,IAAI,WAAW;AACjB,UAAM,IAAI,MAAM,0BAA0B,CAAC,sBAAsB,SAAS,kDAAkD;AAAA,EAC9H;AAEA,QAAM,eAAe,UAAU,MAAM;AAGrC,QAAM,UAAU,gCAAgC,CAAC;AAEjD,QAAM,QAAQ,yBAAyB,CAAC,OAAO,CAAC,aAAa,OAAO,iBAAiB,CAAC,CAAC,QAAQ,gBAAgB,UAAU,EAAE;AAE3H,QAAM,WAAW,MAAM,gBAAgB,wBAAwB,OAAO;AAGtE,QAAM,aAAa,IAAI;AACvB,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,6BAA6B;AAGjG,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,GAAG,KAAK,IAAI;AAC5B,WAAK,UAAU,IAAI,WAAW,IAAI,GAAG,IAAI;AACzC,WAAK,UAAU,IAAI,aAAa,IAAI,GAAG,IAAI;AAAA,IAE7C;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,iBAAiB,YAAYA,QAAO,aAAa;AAAA,IACrD,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO,eAAe;AAAA,EACxB,CAAC;AAGD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,MAC/C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,eAAe,EAAE;AAAA,IACrD;AAAA,EACF,CAAC;AAGD,MAAI;AACJ,MAAI,YAAY,WAAW,YAAY,UAAU;AAC/C,iBAAa;AAAA,EACf,OAAO;AACL,iBAAa,KAAK,KAAK,IAAI,oBAAoB,EAAE,YAAY,SAAS;AAAA,EACxE;AAEA,WAASA,SAAQ,UAAU,WAAW,YAAY,sBAAsB;AAGxE,gBAAc,QAAQ;AACtB,MAAI,CAAC;AAAU,mBAAe,QAAQ;AAGtC,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,6BAA6B;AAChF;AAOA,eAAsB,yBACpB,UACA,OACA,QACA,YACA,SACiB;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA,MAAM;AAAA,IACN,WAAW;AAAA,IACX,eAAe;AAAA,IACf,aAAa;AAAA;AAAA,EACf,IAAI;AAEJ,QAAM,EAAE,UAAU,IAAI,oBAAoB,EAAE;AAC5C,MAAI,IAAI,WAAW;AACjB,UAAM,IAAI,MAAM,0BAA0B,CAAC,sBAAsB,SAAS,kDAAkD;AAAA,EAC9H;AAEA,QAAM,eAAe,UAAU,MAAM;AAGrC,QAAM,UAAU,gCAAgC,CAAC;AAEjD,QAAM,QAAQ,+BAA+B,CAAC,OAAO,CAAC,aAAa,OAAO,iBAAiB,CAAC,CAAC,QAAQ,gBAAgB,UAAU,EAAE;AAEjI,QAAM,WAAW,MAAM,gBAAgB,wBAAwB,OAAO;AAGtE,QAAM,aAAa,IAAI;AACvB,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,6BAA6B;AAGjG,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,GAAG,KAAK,IAAI;AAC5B,WAAK,UAAU,IAAI,WAAW,IAAI,GAAG,IAAI;AACzC,WAAK,UAAU,IAAI,aAAa,IAAI,GAAG,IAAI;AAAA,IAE7C;AAAA,IACA;AAAA,EACF;AAGA,QAAM,iBAAiB,YAAYA,QAAO,aAAa;AAAA,IACrD,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO,eAAe;AAAA,EACxB,CAAC;AAGD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,MAC/C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,eAAe,EAAE;AAAA,IACrD;AAAA,EACF,CAAC;AAGD,MAAI;AACJ,MAAI,YAAY,WAAW,YAAY,UAAU;AAC/C,iBAAa;AAAA,EACf,OAAO;AACL,iBAAa,KAAK,KAAK,IAAI,oBAAoB,EAAE,YAAY,SAAS;AAAA,EACxE;AAEA,iBAAe,UAAU,UAAU,WAAW,YAAY,sBAAsB;AAGhF,MAAI,CAAC,UAAU;AACb,aAAS,qBAAqB,cAAc;AAAA,EAC9C;AAGA,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,6BAA6B;AAChF;AAYO,SAAS,4BAA4B,GAAW,GAAoB;AAEzE,MAAI,MAAM,GAAG;AACX,WAAO;AAAA,EACT;AAEA,QAAM,EAAE,UAAU,IAAI,oBAAoB,EAAE;AAC5C,MAAI,IAAI,WAAW;AACjB,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAtRA;AAAA;AAgBA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAAA;AAAA;;;ACpBA;AAGA;AAGA;AACA;;;ACEA;AACA;;;AChBA;AAAA,EACE,IAAM;AAAA,EACN,MAAQ;AAAA,EACR,aAAe;AAAA,EAEf,QAAU;AAAA,IACR,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAA0B,OAAS,QAAgB,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAC9H,EAAE,IAAM,UAAgB,QAAU,wBAA0B,OAAS,iBAAiB,SAAW,6BAA6B;AAAA,MAC9H,EAAE,IAAM,UAAgB,QAAU,wBAA0B,OAAS,iBAAiB,SAAW,6BAA6B;AAAA,MAC9H,EAAE,IAAM,UAAgB,QAAU,wBAA0B,OAAS,iBAAiB,SAAW,6BAA6B;AAAA,MAC9H,EAAE,IAAM,UAAgB,QAAU,aAA0B,OAAS,OAAO;AAAA,MAC5E,EAAE,IAAM,UAAgB,QAAU,aAA0B,OAAS,OAAO;AAAA,MAC5E,EAAE,IAAM,aAAgB,QAAU,yBAA0B,OAAS,oBAA4B,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MAClI,EAAE,IAAM,UAAgB,QAAU,wBAA0B,OAAS,iBAAiB,SAAW,6BAA6B;AAAA,MAC9H,EAAE,IAAM,iBAAgB,QAAU,iBAA0B,OAAS,OAAO;AAAA,MAC5E,EAAE,IAAM,kBAAiB,QAAU,gBAAyB,OAAS,QAAgB,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAC9H,EAAE,IAAM,eAAgB,QAAU,sBAA0B,OAAS,QAAgB,SAAW,iBAAiB,WAAa,EAAE,YAAc,EAAE,EAAE;AAAA,MAClJ,EAAE,IAAM,aAAgB,QAAU,wBAA0B,OAAS,iBAAiB,SAAW,0BAA0B;AAAA,MAC3H,EAAE,IAAM,gBAAgB,QAAU,iBAA0B,OAAS,OAAO;AAAA,IAC9E;AAAA,EACF;AAAA,EAEA,SAAW;AAAA,IACT,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAA6B,OAAS,QAAa,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAC9H,EAAE,IAAM,UAAgB,QAAU,gCAAgC,OAAS,gBAAkB,SAAW,6BAA6B;AAAA,MACrI,EAAE,IAAM,UAAgB,QAAU,gCAAgC,OAAS,gBAAkB,SAAW,6BAA6B;AAAA,MACrI,EAAE,IAAM,UAAgB,QAAU,gCAAgC,OAAS,gBAAkB,SAAW,6BAA6B;AAAA,MACrI,EAAE,IAAM,UAAgB,QAAU,aAA6B,OAAS,OAAO;AAAA,MAC/E,EAAE,IAAM,UAAgB,QAAU,aAA6B,OAAS,OAAO;AAAA,MAC/E,EAAE,IAAM,aAAgB,QAAU,kBAA6B,OAAS,QAAa,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MACtH,EAAE,IAAM,UAAgB,QAAU,gCAAgC,OAAS,gBAAkB,SAAW,6BAA6B;AAAA,MACrI,EAAE,IAAM,iBAAgB,QAAU,iBAA6B,OAAS,OAAO;AAAA,MAC/E,EAAE,IAAM,kBAAiB,QAAU,gBAA4B,OAAS,QAAa,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAC9H,EAAE,IAAM,eAAgB,QAAU,sBAA6B,OAAS,gBAAgB,SAAW,iBAAiB,WAAa,EAAE,YAAc,EAAE,EAAE;AAAA,MACrJ,EAAE,IAAM,aAAgB,QAAU,gCAAgC,OAAS,gBAAkB,SAAW,0BAA0B;AAAA,MAClI,EAAE,IAAM,gBAAgB,QAAU,iBAA6B,OAAS,OAAO;AAAA,IACjF;AAAA,EACF;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,SAAgB,QAAU,eAA2B,OAAS,QAAgB,SAAW,eAAe;AAAA,EAClH;AAAA,EAEA,WAAa;AAAA,IACX,EAAE,IAAM,cAAgB,QAAU,gBAA2B,OAAS,QAAgB,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,IAC/H,EAAE,IAAM,WAAgB,QAAU,wBAA2B,OAAS,iBAAiB,SAAW,UAAU;AAAA,EAC9G;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,WAAgB,QAAU,eAA2B,OAAS,iBAAiB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,IACxH,EAAE,IAAM,UAAgB,QAAU,eAA2B,OAAS,qBAAqB;AAAA,EAC7F;AACF;;;ACtDA;AAAA,EACE,IAAM;AAAA,EACN,MAAQ;AAAA,EACR,aAAe;AAAA,EAEf,QAAU;AAAA,IACR,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAAqB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,aAAgB,QAAU,yBAAyB,OAAS,oBAAoB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MACzH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,iBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,kBAAiB,QAAU,gBAAoB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MAC9G,EAAE,IAAM,WAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,wBAAwB;AAAA,MAC5G,EAAE,IAAM,cAAgB,QAAU,aAAqB,OAAS,QAAQ;AAAA,MACxE,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MAC9G,EAAE,IAAM,gBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,IACzE;AAAA,EACF;AAAA,EAEA,SAAW;AAAA,IACT,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAAqB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,aAAgB,QAAU,kBAAqB,OAAS,QAAS,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MAC1G,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,iBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,kBAAiB,QAAU,gBAAoB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,0BAA0B;AAAA,MAC7G,EAAE,IAAM,WAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,wBAAwB;AAAA,MAC3G,EAAE,IAAM,cAAgB,QAAU,aAAqB,OAAS,QAAQ;AAAA,MACxE,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,0BAA0B;AAAA,MAC7G,EAAE,IAAM,gBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,IACzE;AAAA,EACF;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,SAAgB,QAAU,eAAuB,OAAS,QAAS,SAAW,eAAe;AAAA,EACvG;AAAA,EAEA,WAAa;AAAA,IACX,EAAE,IAAM,cAAgB,QAAU,gBAAuB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,IACpH,EAAE,IAAM,WAAgB,QAAU,mBAAuB,OAAS,QAAS,SAAW,UAAU;AAAA,EAClG;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,WAAgB,QAAU,eAAuB,OAAS,iBAAiB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,IACpH,EAAE,IAAM,UAAgB,QAAU,eAAuB,OAAS,qBAAqB;AAAA,EACzF;AACF;;;AC1DA;AAAA,EACE,IAAM;AAAA,EACN,MAAQ;AAAA,EACR,aAAe;AAAA,EAEf,QAAU;AAAA,IACR,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAAqB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,aAAgB,QAAU,yBAAyB,OAAS,oBAAoB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MACzH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACjH,EAAE,IAAM,iBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,kBAAiB,QAAU,gBAAoB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MAC9G,EAAE,IAAM,WAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,wBAAwB;AAAA,MAC5G,EAAE,IAAM,cAAgB,QAAU,aAAqB,OAAS,QAAQ;AAAA,MACxE,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MAC9G,EAAE,IAAM,gBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,IACzE;AAAA,EACF;AAAA,EAEA,SAAW;AAAA,IACT,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAAqB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,UAAgB,QAAU,aAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,aAAgB,QAAU,kBAAqB,OAAS,QAAS,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MAC1G,EAAE,IAAM,UAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,6BAA6B;AAAA,MAChH,EAAE,IAAM,iBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,MACvE,EAAE,IAAM,kBAAiB,QAAU,gBAAoB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MAClH,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,0BAA0B;AAAA,MAC7G,EAAE,IAAM,WAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,wBAAwB;AAAA,MAC3G,EAAE,IAAM,cAAgB,QAAU,aAAqB,OAAS,QAAQ;AAAA,MACxE,EAAE,IAAM,aAAgB,QAAU,mBAAqB,OAAS,QAAQ,SAAW,0BAA0B;AAAA,MAC7G,EAAE,IAAM,gBAAgB,QAAU,iBAAqB,OAAS,OAAO;AAAA,IACzE;AAAA,EACF;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,SAAgB,QAAU,eAAuB,OAAS,QAAS,SAAW,eAAe;AAAA,EACvG;AAAA,EAEA,WAAa;AAAA,IACX,EAAE,IAAM,cAAgB,QAAU,gBAAuB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,IACpH,EAAE,IAAM,WAAgB,QAAU,mBAAuB,OAAS,QAAS,SAAW,UAAU;AAAA,EAClG;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,WAAgB,QAAU,eAAuB,OAAS,iBAAiB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,IACpH,EAAE,IAAM,UAAgB,QAAU,eAAuB,OAAS,qBAAqB;AAAA,EACzF;AACF;;;AC1DA;AAAA,EACE,IAAM;AAAA,EACN,MAAQ;AAAA,EACR,aAAe;AAAA,EAEf,QAAU;AAAA,IACR,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAAwB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MACrH,EAAE,IAAM,UAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,UAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,UAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,UAAgB,QAAU,aAAwB,OAAS,OAAO;AAAA,MAC1E,EAAE,IAAM,UAAgB,QAAU,aAAwB,OAAS,OAAO;AAAA,MAC1E,EAAE,IAAM,aAAgB,QAAU,yBAAwB,OAAS,oBAAqB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MACzH,EAAE,IAAM,UAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,iBAAgB,QAAU,iBAAwB,OAAS,OAAO;AAAA,MAC1E,EAAE,IAAM,kBAAiB,QAAU,gBAAuB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MACrH,EAAE,IAAM,aAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MACjH,EAAE,IAAM,WAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,wBAAwB;AAAA,MAC/G,EAAE,IAAM,cAAgB,QAAU,aAAwB,OAAS,QAAQ;AAAA,MAC3E,EAAE,IAAM,aAAgB,QAAU,yBAAwB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MACjH,EAAE,IAAM,gBAAgB,QAAU,iBAAwB,OAAS,OAAO;AAAA,IAC5E;AAAA,EACF;AAAA,EAEA,SAAW;AAAA,IACT,OAAS;AAAA,MACP,EAAE,IAAM,cAAgB,QAAU,gBAAwB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MACrH,EAAE,IAAM,UAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,UAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,UAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,UAAgB,QAAU,aAAwB,OAAS,OAAO;AAAA,MAC1E,EAAE,IAAM,UAAgB,QAAU,aAAwB,OAAS,OAAO;AAAA,MAC1E,EAAE,IAAM,aAAgB,QAAU,kBAAwB,OAAS,QAAS,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,MAC7G,EAAE,IAAM,UAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,6BAA6B;AAAA,MACpH,EAAE,IAAM,iBAAgB,QAAU,iBAAwB,OAAS,OAAO;AAAA,MAC1E,EAAE,IAAM,kBAAiB,QAAU,gBAAuB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,MACrH,EAAE,IAAM,aAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MACjH,EAAE,IAAM,WAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,wBAAwB;AAAA,MAC/G,EAAE,IAAM,cAAgB,QAAU,aAAwB,OAAS,QAAQ;AAAA,MAC3E,EAAE,IAAM,aAAgB,QAAU,mBAAwB,OAAS,QAAS,SAAW,0BAA0B;AAAA,MACjH,EAAE,IAAM,gBAAgB,QAAU,iBAAwB,OAAS,OAAO;AAAA,IAC5E;AAAA,EACF;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,SAAgB,QAAU,mBAAyB,OAAS,QAAS,SAAW,eAAe;AAAA,EACzG;AAAA,EAEA,WAAa;AAAA,IACX,EAAE,IAAM,cAAgB,QAAU,gBAAyB,OAAS,QAAS,WAAa,EAAE,iBAAmB,KAAK,EAAE;AAAA,IACtH,EAAE,IAAM,WAAgB,QAAU,yBAAyB,OAAS,QAAS,SAAW,UAAU;AAAA,EACpG;AAAA,EAEA,UAAY;AAAA,IACV,EAAE,IAAM,WAAgB,QAAU,eAAyB,OAAS,iBAAiB,WAAa,EAAE,SAAW,GAAK,EAAE;AAAA,IACtH,EAAE,IAAM,UAAgB,QAAU,eAAyB,OAAS,qBAAqB;AAAA,EAC3F;AACF;;;AJ9BA,IAAM,uBAAyD;AAAA;AAAA,EAE7D,oBAAoB;AAAA,EACpB,0BAA0B;AAAA,EAC1B,0BAA0B;AAAA;AAAA,EAG1B,qBAAqB;AAAA;AAAA,EAGrB,aAAa;AAAA,EACb,mBAAmB;AAAA,EACnB,mBAAmB;AAAA,EACnB,cAAc;AAAA;AAAA,EAGd,YAAY;AAAA;AAAA,EACZ,YAAY;AAAA;AAAA,EACZ,gBAAgB;AAAA;AAClB;AASO,SAAS,cAAc,IAAqC;AACjE,SAAO,qBAAqB,EAAE,KAAK;AACrC;AAKO,SAAS,kBAA4B;AAC1C,SAAO,OAAO,KAAK,oBAAoB;AACzC;AAKO,SAAS,kBAAkB,KAAsC;AACtE,MAAI,OAAO,QAAQ,UAAU;AAC3B,UAAM,OAAO,cAAc,GAAG;AAC9B,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,MAAM,wBAAwB,GAAG,gBAAgB,gBAAgB,EAAE,KAAK,IAAI,CAAC,EAAE;AAAA,IAC3F;AACA,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAmEO,SAAS,cACd,MACA,YACA,OACoB;AAEpB,MAAI,KAAK,gBAAgB;AACvB,eAAW,YAAY,KAAK,gBAAgB;AAC1C,UAAI,SAAS,OAAO,SAAS,UAAU,GAAG;AACxC,eAAO,SAAS;AAAA,MAClB;AAAA,IACF;AAAA,EACF;AAGA,QAAM,YAAY,UAAU,aAAa,KAAK,UAAU,KAAK,UAAU,KAAK;AAC5E,SAAO,UAAU;AACnB;AAsCA,IAAM,sBAAqF;AAAA,EACzF,QAAQ,EAAE,SAAS,SAAS,KAAK,CAAC,QAAQ,EAAE;AAAA,EAC5C,QAAQ,EAAE,SAAS,SAAS,KAAK,CAAC,QAAQ,EAAE;AAAA,EAC5C,QAAQ,EAAE,SAAS,SAAS,KAAK,CAAC,QAAQ,EAAE;AAAA,EAC5C,UAAU,EAAE,SAAS,SAAS,KAAK,CAAC,YAAY,QAAQ,EAAE;AAAA,EAC1D,QAAQ,EAAE,SAAS,SAAS,KAAK,CAAC,QAAQ,EAAE;AAAA,EAC5C,UAAU,EAAE,SAAS,SAAS,KAAK,CAAC,YAAY,WAAW,EAAE;AAAA,EAC7D,QAAQ,EAAE,SAAS,SAAS,KAAK,CAAC,UAAU,SAAS,EAAE;AAAA,EACvD,UAAU,EAAE,SAAS,SAAS,KAAK,CAAC,YAAY,WAAW,EAAE;AAAA,EAC7D,aAAa,EAAE,SAAS,SAAS,KAAK,CAAC,aAAa,EAAE;AAAA,EACtD,SAAS,EAAE,SAAS,aAAa,KAAK,CAAC,SAAS,EAAE;AACpD;AAEA,SAAS,oBAAoB,QAAwB;AACnD,QAAM,UAAU,OAAO,KAAK;AAC5B,MAAI,CAAC;AAAS,WAAO;AACrB,QAAM,QAAQ,QAAQ,MAAM,GAAG;AAC/B,SAAO,MAAM,MAAM,SAAS,CAAC,KAAK;AACpC;AAEA,SAAS,6BACP,MACA,SACA,OACA,YACoB;AACpB,UAAQ,SAAS;AAAA,IACf,KAAK;AACH,aAAO,KAAK,YAAY,CAAC;AAAA,IAC3B,KAAK;AACH,aAAO,KAAK,aAAa,CAAC;AAAA,IAC5B,KAAK;AACH,aAAO,KAAK,YAAY,CAAC;AAAA,IAC3B,KAAK;AAAA,IACL;AACE,aAAO,cAAc,MAAM,YAAY,KAAK;AAAA,EAChD;AACF;AAEA,SAAS,aAAa,OAA2B,IAAqC;AACpF,SAAO,MAAM,KAAK,CAAC,SAAS,KAAK,OAAO,EAAE,KAAK;AACjD;AAEA,SAAS,kBACP,WACA,QACA,OACe;AACf,QAAM,WAAW,eAAe,SAAS;AACzC,MAAI,CAAC;AAAU,WAAO;AACtB,QAAM,mBAAmB,oBAAoB,MAAM;AACnD,QAAM,kBAAkB,SAAS;AAEjC,MAAI,kBAAiC;AACrC,MAAI,gBAAgB;AAEpB,aAAW,CAAC,SAASC,OAAM,KAAK,OAAO,QAAQ,QAAQ,GAAG;AACxD,QAAIA,QAAO,eAAe;AAAkB;AAC5C,sBAAkB;AAClB,qBAAiB;AACjB,QAAIA,QAAO,eAAe,iBAAiB;AACzC,aAAO;AAAA,IACT;AAAA,EACF;AAEA,MAAI,kBAAkB,GAAG;AACvB,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAEO,SAAS,2BACd,MACA,OACA,YACe;AACf,MAAI,CAAC,oBAAoB,CAAC;AAAM,WAAO;AACvC,QAAM,QAAQ,oBAAoB,IAAI,KAAK,EAAE,SAAS,SAAS,KAAK,CAAC,IAAI,EAAE;AAC3E,QAAM,QAAQ,6BAA6B,kBAAkB,MAAM,SAAS,OAAO,cAAc,CAAC;AAClG,aAAW,MAAM,MAAM,KAAK;AAC1B,UAAM,OAAO,aAAa,OAAO,EAAE;AACnC,QAAI,CAAC;AAAM;AACX,UAAM,UAAU,kBAAkB,UAAU,KAAK,QAAQ,KAAK,KAAK;AACnE,QAAI,SAAS;AACX,aAAO;AAAA,IACT;AAAA,EACF;AACA,SAAO;AACT;AAEO,SAAS,8BACd,OACA,YACe;AACf,MAAI,CAAC;AAAkB,WAAO;AAC9B,QAAM,QAAQ,6BAA6B,kBAAkB,SAAS,OAAO,cAAc,CAAC;AAC5F,QAAM,OAAO,aAAa,OAAO,WAAW;AAC5C,MAAI,CAAC;AAAM,WAAO;AAClB,SAAO,kBAAkB,aAAa,KAAK,QAAQ,KAAK,KAAK;AAC/D;AAMA,IAAI,mBAA4C;AAChD,IAAI,yBAA2C;AAMxC,SAAS,oBAAoB,MAA+B,SAA2B,QAAc;AAC1G,qBAAmB;AACnB,2BAAyB,OAAO,SAAS;AAC3C;AAaO,SAAS,sBAA+B;AAC7C,SAAO,2BAA2B,UAAU,2BAA2B;AACzE;AAMO,SAAS,6BAAsC;AACpD,MAAI,CAAC;AAAkB,WAAO;AAC9B,QAAM,cAAkC;AAAA,IACtC,GAAI,iBAAiB,QAAQ,SAAS,CAAC;AAAA,IACvC,GAAI,iBAAiB,SAAS,SAAS,CAAC;AAAA,IACxC,GAAI,iBAAiB,YAAY,CAAC;AAAA,IAClC,GAAI,iBAAiB,aAAa,CAAC;AAAA,IACnC,GAAI,iBAAiB,gBAAgB,QAAQ,CAAC,aAAa,SAAS,KAAK,KAAK,CAAC;AAAA,EACjF;AACA,SAAO,YAAY,KAAK,CAAC,SAAS,KAAK,OAAO,SAAS,iBAAiB,CAAC;AAC3E;;;AK3VA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACQA;;;ACEA;AACA;AACA;AACA;AACA;;;ACTA;AACA;AAEO,IAAe,aAAf,MAA0B;AAAA,EACZ;AAAA,EAEnB,YAAYC,SAAmB;AAC7B,SAAK,SAASA;AAAA,EAChB;AAAA,EAEA,MAAgB,eACd,WACA,SACA,kBAA6C,MAChB;AAC7B,WAAO,gBAAgB,WAAW,SAAS,eAAe;AAAA,EAC5D;AAAA,EAEU,eACR,UACA,WACA,YACA,OACM;AACN,aAAS,KAAK,QAAQ,UAAU,WAAW,YAAY,KAAK;AAAA,EAC9D;AAAA,EAEU,aACR,UACA,UACA,WACA,YACA,OACM;AACN,mBAAe,UAAU,UAAU,WAAW,YAAY,KAAK;AAAA,EACjE;AACF;;;ADxBA;AACA;AACA;AAEA;AAWA,IAAM,qBAA6C;AAAA,EACjD,aAAa;AAAA,EACb,cAAc;AAAA,EACd,cAAc;AAAA,EACd,eAAe;AACjB;AAKA,SAAS,sBAAsB,MAAe,eAAgC;AAC5E,QAAM,MAAM,GAAG,IAAI,IAAI,aAAa;AACpC,SAAO,mBAAmB,GAAG,KAAK;AACpC;AAQO,SAAS,qBAA8B;AAE5C,QAAM,aAAa,OAAO,WAAW,cAChC,SACD;AACJ,MAAI,YAAY;AAA2B,WAAO;AAGlD,MAAI,CAAC,2BAA2B;AAAG,WAAO;AAE1C,SAAO;AACT;AAMA,SAAS,cAAc,OAA4E;AACjG,MAAI,UAAU,SAAS,UAAU;AAAQ,WAAO;AAChD,MAAI,UAAU;AAAO,WAAO;AAC5B,SAAO;AACT;AA2BO,SAAS,mBAAmB,UAAyB,CAAC,GAAW;AACtE,QAAM,eAAe,sBAAsB;AAC3C,QAAM;AAAA,IACJ,YAAY;AAAA,IACZ,UAAU;AAAA,IACV,cAAc;AAAA,IACd,SAAS;AAAA,IACT,SAAS;AAAA,EACX,IAAI;AAEJ,QAAM,eAAe,WAAW,SAAS,WAAW;AACpD,QAAM,gBAAgB,WAAW,SAAS,WAAW;AAGrD,MAAI,gBAAgB,SAAS,aAAa,gBAAgB,aAAa,QAAQ;AAC7E,WAAO,UAAU,aAAa;AAAA,EAChC;AAMA,MAAI,aAAa,iBAAiB,aAAa,QAAQ;AACrD,WAAO;AAAA,EACT;AAEA,SAAO;AACT;AAEA,IAAM,eAAN,cAA2B,WAAW;AAAA,EACpC,MAAM,YAAY,SAA8C;AAC9D,WAAO,KAAK,eAAe,UAAU,OAAO;AAAA,EAC9C;AAAA,EAEA,SACE,UACA,WACA,YACM;AACN,SAAK,eAAe,UAAU,WAAW,YAAY,QAAQ;AAAA,EAC/D;AAAA,EAEA,OACE,UACA,UACA,WACA,YACM;AACN,SAAK,aAAa,UAAU,UAAU,WAAW,YAAY,QAAQ;AAAA,EACvE;AACF;AAKA,IAAI,uBAAuB;AAE3B,SAAS,kBAAkB,GAA6B,kBAA6C;AACnG,MAAI,qBAAqB,QAAQ;AAE/B,UAAM,eAAe,UAAU,CAAC;AAChC,UAAM,SAAS,UAAU,CAAC;AAE1B,UAAM,aAAa,iBAAiB;AACpC,UAAM,SAAS,CAAC;AAEhB,QAAI,eAAe,SAAS,KAAK,uBAAuB,IAAI;AAC1D;AACA,YAAM,QAAQ,6BAA6B,YAAY,mBAAmB,UAAU,gBAAgB,MAAM,aAAa,OAAO,IAAI,EAAE;AAAA,IACtI;AACA,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAEA,SAAS,yBAAyB,OAAe,GAAW,GAAW,GAAiB;AACtF,MAAI,CAAC,OAAO,SAAS,CAAC,KAAK,CAAC,OAAO,SAAS,CAAC,KAAK,CAAC,OAAO,SAAS,CAAC,GAAG;AACrE,UAAM,IAAI,MAAM,IAAI,KAAK,2BAA2B,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;AAAA,EACzE;AACA,MAAI,KAAK,KAAK,KAAK,KAAK,KAAK,GAAG;AAC9B,UAAM,IAAI,MAAM,IAAI,KAAK,oCAAoC,CAAC,OAAO,CAAC,OAAO,CAAC,EAAE;AAAA,EAClF;AACF;AAEA,SAAS,sBACP,OACA,SACA,SACA,SACM;AACN,MAAI,CAAC,OAAO,SAAS,OAAO,KAAK,UAAU,KACvC,CAAC,OAAO,SAAS,OAAO,KAAK,UAAU,KACvC,CAAC,OAAO,SAAS,OAAO,KAAK,UAAU,GAAG;AAC5C,UAAM,IAAI,MAAM,IAAI,KAAK,qCAAqC,OAAO,aAAa,OAAO,aAAa,OAAO,EAAE;AAAA,EACjH;AAEA,QAAM,mBAAmB,UAAU;AACnC,MAAI,UAAU,qBAAqB,KAC/B,UAAU,qBAAqB,KAC/B,UAAU,qBAAqB,GAAG;AACpC,UAAM,IAAI;AAAA,MACR,IAAI,KAAK,4BAA4B,gBAAgB,0BAC1C,OAAO,aAAa,OAAO,aAAa,OAAO;AAAA,IAC5D;AAAA,EACF;AACF;AAEA,SAAS,sBACP,OACA,GACA,GACA,GACA,GACA,GACA,QACA,QACA,YACA,SACA,SACgD;AAChD,QAAM,gBAAgB,WAAW,QAAQ,IAAI;AAC7C,QAAM,eAAe,KAAK,KAAM,IAAI,IAAI,gBAAiB,CAAC,IAAI;AAC9D,QAAM,YAAY,UAAU;AAC5B,MAAI,EAAE,OAAO,WAAW;AACtB,UAAM,IAAI,MAAM,IAAI,KAAK,yBAAyB,EAAE,IAAI,MAAM,SAAS,OAAO,CAAC,OAAO,CAAC,YAAY,MAAM,GAAG;AAAA,EAC9G;AAEA,QAAMC,QAAO,WAAW;AACxB,QAAM,kBAAkB,aAAa;AACrC,MAAI;AACJ,MAAI;AAEJ,MAAI,WAAW,OAAO;AACpB,UAAM,kBAAkB,KAAK,KAAK,IAAIA,KAAI;AAC1C,mBAAe,KAAK,KAAM,IAAI,kBAAkB,kBAAmB,CAAC,IAAI;AACxE,gBAAY,UAAU;AAAA,EACxB,OAAO;AACL,UAAM,gBAAgB,WAAW,QAAQ,IAAI;AAC7C,UAAM,YAAY,aAAa,IAAI,IAAI,IAAI;AAC3C,mBAAe,KAAK,KAAM,YAAY,gBAAiB,CAAC,IAAI;AAC5D,gBAAY,UAAU;AAAA,EACxB;AAEA,MAAI,EAAE,OAAO,WAAW;AACtB,UAAM,IAAI;AAAA,MACR,IAAI,KAAK,yBAAyB,EAAE,IAAI,MAAM,SAAS,OACjD,CAAC,OAAO,CAAC,YAAY,MAAM,gBAAgB,UAAU;AAAA,IAC7D;AAAA,EACF;AAEA,SAAO,EAAE,cAAc,aAAa;AACtC;AAEA,SAAS,kBAAkB,SAA0B;AACnD,SAAO,QAAQ,WAAW,UAAU;AACtC;AAEA,SAAS,cAAc,SAA0B;AAC/C,SAAO,QAAQ,WAAW,MAAM;AAClC;AAEA,SAAS,sBACP,iBACA,GACA,QACA,QACA,cACA,QACoE;AACpE,QAAM,WAAW,gBAAgB,KAAK;AACtC,MAAI,CAAC;AAAU,WAAO;AAEtB,QAAM,aAAa,CAAC,YAAwF;AAC1G,QAAI,QAAQ;AACV,YAAM,IAAI,MAAM,OAAO;AAAA,IACzB;AACA,QAAI,KAAK,UAAU,OAAO;AAC1B,WAAO;AAAA,EACT;AAEA,MAAIC;AACJ,MAAI;AACF,IAAAA,UAAS,gBAAgB,UAAU,QAAQ;AAAA,EAC7C,QAAQ;AACN,WAAO,WAAW,kCAAkC,eAAe,IAAI;AAAA,EACzE;AAEA,MAAI,CAAC,oBAAoBA,QAAO,UAAU,YAAY,GAAG;AACvD,WAAO,WAAW,kBAAkB,eAAe,sCAAsC;AAAA,EAC3F;AAEA,QAAM,cAAc,kBAAkB,QAAQ;AAC9C,MAAI,aAAa;AACf,QAAI,WAAW,OAAO;AACpB,aAAO,WAAW,kBAAkB,eAAe,yCAAyC,MAAM,GAAG;AAAA,IACvG;AACA,QAAI,mBAAmB,GAAG;AACxB,aAAO,WAAW,kBAAkB,eAAe,yCAAyC;AAAA,IAC9F;AAAA,EACF;AAEA,QAAM,UAAU,cAAc,QAAQ;AACtC,MAAI,WAAW,MAAM,GAAG;AACtB,WAAO,WAAW,kBAAkB,eAAe,4BAA4B,CAAC,GAAG;AAAA,EACrF;AAEA,SAAO,EAAE,SAAS,UAAU,aAAa,QAAQ;AACnD;AAEA,SAAS,4BACP,MACA,GACA,GACA,GACA,QACA,QACA,YACA,sBACA,SAC6D;AAC7D,QAAM,eAAe,sBAAsB;AAC3C,QAAM,SAAS,oBAAoB;AACnC,QAAM,QAAQ,MAAM,IAAI,WAAW;AACnC,QAAM,cAAc,2BAA2B,QAAQ,MAAM,OAAO,QAAQ,QAAQ;AAEpF,MAAI,aAAa;AACf,UAAM,WAAW,sBAAsB,aAAa,GAAG,QAAQ,QAAQ,cAAc,MAAM;AAC3F,QAAI,UAAU;AACZ,aAAO;AAAA,IACT;AAAA,EACF;AAEA,MAAI,UAAU;AACd,MAAI,cAAc;AAClB,MAAI,UAAU;AAGd,MAAI,WAAW,OAAO;AACpB,UAAM,aAAa,CAAC,mBAAmB;AACvC,UAAM,WAAW,aAAa,gBAAgB;AAE9C,QAAI,UAAU;AACZ,oBAAc;AACd,YAAM,gBAAgB,yBAAyB,SAAS,aAAa;AACrE,gBAAU,sBAAsB,MAAM,GAAG,aAAa;AAAA,IACxD;AAAA,EACF;AAEA,MAAI,CAAC,aAAa;AAChB,UAAM,kBAAkB,WAAW,QAAQ,QAAQ;AACnD,cAAU,mBAAmB;AAAA,MAC3B,GAAG;AAAA,MACH,QAAQ,WAAW,QAAQ,QAAQ;AAAA,MACnC,QAAQ;AAAA,MACR,aAAa;AAAA,IACf,CAAC;AAED,cAAU,MAAM,KAAK,oBAAoB,SAAS,WAAW;AAC7D,QAAI,SAAS;AACX,UAAI,aAAa,cAAc;AAE7B,cAAM,EAAE,kBAAkB,IAAI,oBAAoB,EAAE;AACpD,YAAI,IAAI,mBAAmB;AACzB,oBAAU;AAAA,QACZ,OAAO;AACL,oBAAU;AAAA,QACZ;AAAA,MACF,OAAO;AACL,kBAAU;AAAA,MACZ;AAAA,IACF;AAAA,EACF;AAEA,SAAO,EAAE,SAAS,aAAa,QAAQ;AACzC;AAEA,SAAS,oBACP,SACA,GACA,GACA,cACmG;AAEnG,QAAMA,UAAS,gBAAgB,UAAU,OAAO;AAChD,QAAM,aAAaA,QAAO,gBAAgB;AAC1C,QAAM,cAAc,aAAa,IAAI;AACrC,QAAM,oBAAmC,aAAa,QAAQ;AAC9D,QAAM,aAAa,IAAI,IAAI;AAC3B,QAAM,eAAe,KAAK,KAAK,aAAa,CAAC,IAAI;AACjD,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,eAAe;AACnF,SAAO,EAAE,QAAQ,YAAY,cAAc,kBAAkB;AAC/D;AAEA,SAAS,wBACP,SACA,aACA,SACA,GACA,GACAA,SACuE;AACvE,QAAM,gBAAgB,WAAW;AACjC,QAAM,CAAC,KAAK,GAAG,IAAIA,QAAO;AAC1B,MAAI,cAAc;AAClB,MAAI,cAAc;AAClB,MAAI;AAGJ,QAAM,YAAYA,QAAO,iBAAiB,aAAa;AAEvD,QAAM,QAAQA,QAAO,iBAAiB,SAAS;AAE/C,MAAI,YAAY,YAAY,mBAAmB,YAAY,2BAA2B;AACpF,UAAM,kBAAkB,KAAK,KAAK,IAAI,SAAS;AAC/C,QAAI,kBAAkB,eAAe;AACnC,oBAAc;AACd,oBAAc,KAAK,KAAK,kBAAkB,aAAa;AAAA,IACzD,OAAO;AACL,oBAAc;AACd,oBAAc;AAAA,IAChB;AACA,yBAAqB;AACrB,WAAO,EAAE,YAAY,CAAC,aAAa,aAAa,CAAC,GAAG,mBAAmB;AAAA,EACzE;AAEA,MAAI,aAAa;AACf,QAAI,YAAY,YAAY;AAC1B,oBAAc;AACd,oBAAc;AAAA,IAChB,WAAWA,QAAO,iBAAiB,WAAW;AAE5C,oBAAc,KAAK,KAAK,IAAI,SAAS;AACrC,oBAAc;AAAA,IAChB,WAAWA,QAAO,iBAAiB,OAAO;AAExC,oBAAc;AACd,oBAAc,KAAK,KAAK,IAAI,KAAK;AAAA,IACnC,OAAO;AAEL,oBAAc;AACd,oBAAc;AAAA,IAChB;AAAA,EACF,WAAW,SAAS;AAClB,kBAAc;AACd,kBAAc;AAAA,EAChB,OAAO;AACL,UAAM,gBAAgB,YAAY,aAAa,IAAI;AACnD,kBAAc,KAAK,KAAK,IAAI,GAAG;AAC/B,kBAAc,KAAK,KAAK,KAAK,MAAM,cAAc;AAAA,EACnD;AAEA,SAAO,EAAE,YAAY,CAAC,aAAa,aAAa,CAAC,GAAG,mBAAmB;AACzE;AAEA,SAAS,0BACP,OACA,GACA,GACA,GACA,OACA,aACA,YACA,oBACA,UACAC,SACW;AAEX,QAAM,cAAc;AAEpB,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,IAAI,OAAO,IAAI;AAC/B,UAAI,aAAa;AACf,cAAM,kBAAkB,KAAK,KAAK,IAAI,WAAW,oBAAoB;AACrE,aAAK,UAAU,IAAI,iBAAiB,IAAI;AAAA,MAC1C,OAAO;AACL,aAAK,UAAU,IAAI,aAAa,IAAI,GAAG,IAAI;AAAA,MAC7C;AAEA,WAAK,UAAU,IAAI,sBAAsB,GAAG,IAAI;AAAA,IAElD;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AACF;AAKO,SAAS,8BAAkD;AAChE,SAAO,2BAA2B,4BAA4B;AAAA,IAC5D;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,UAAU;AAAA,IAC5B;AAAA,IACA;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,oBAAoB;AAAA,IACtC;AAAA,IACA;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,oBAAoB;AAAA,IACtC;AAAA,IACA;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,UAAU;AAAA,IAC5B;AAAA,EACF,CAAC;AACH;AAGA,IAAI,uBAAuB;AAS3B,eAAsB,UACpB,GACA,GACA,GACA,GACA,GACA,UAAyB,CAAC,GACT;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,QAAQ;AAAA,IACR,eAAe;AAAA,IACf,YAAY,mBAAmB;AAAA;AAAA,IAC/B,UAAU;AAAA,IACV,UAAU;AAAA,IACV,UAAU;AAAA,EACZ,IAAI;AAGJ,QAAM,UAAU,UAAU,CAAC;AAC3B,QAAM,cAAc,eAAe,CAAC;AAGpC,MAAI,eAAe,SAAS,KAAK,uBAAuB,IAAI;AAC1D;AACA,UAAM,eAAe,UAAU,CAAC;AAChC,UAAM,QAAQ,gBAAgB,CAAC,OAAO,CAAC,OAAO,CAAC,sBAAsB,gBAAgB,kBAAkB,YAAY,iBAAiB,WAAW,EAAE;AAAA,EACnJ;AAEA,QAAM,aAAa,kBAAkB,GAAG,gBAAgB;AAExD,2BAAyB,aAAa,GAAG,GAAG,CAAC;AAG7C,QAAM,SAAS,cAAc,EAAE,KAAK;AAEpC,QAAM,SAAS,cAAc,eAAe,QAAQ,MAAM;AAC1D,QAAM,uBAAuB,QAAQ,eAAe,EAAE;AAGtD,MAAI,eAAe,SAAS,KAAK,CAAC,eAAe,CAAC,QAAQ,UAAU,KAAK,GAAG;AAC1E,QAAI,KAAK,UAAU,2CAA2C,QAAQ,IAAI,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,iBAAiB;AAAA,EACrH;AAEA,wBAAsB,aAAa,SAAS,SAAS,OAAO;AAC5D,QAAM,EAAE,cAAc,aAAa,IAAI;AAAA,IACrC;AAAA,IACA,EAAE;AAAA,IACF;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,QAAM,EAAE,SAAS,aAAa,QAAQ,IAAI;AAAA,IACxC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,MAAI,eAAe,SAAS,KAAK,WAAW,OAAO;AACjD,QAAI,aAAa;AACf,YAAM,QAAQ,gBAAgB,CAAC,OAAO,CAAC,OAAO,CAAC,aAAa,OAAO,sCAAsC;AAAA,IAC3G,OAAO;AACL,YAAM,QAAQ,kBAAkB,CAAC,OAAO,CAAC,OAAO,CAAC,iDAAiD,OAAO,EAAE;AAAA,IAC7G;AAAA,EACF;AAGA,MAAI,eAAe,SAAS,KAAK,IAAI,KAAQ;AAC3C,UAAM,QAAQ,mBAAmB,CAAC,aAAa,OAAO,YAAY,MAAM,YAAY,MAAM,gBAAgB,UAAU,EAAE;AAAA,EACxH;AAEA,QAAMD,UAAS,gBAAgB,UAAU,OAAO;AAChD,QAAM,SAAS,IAAI,aAAaC,OAAM;AAGtC,MAAI,WAAW,kBAAkB,UAAU,OAAO;AAClD,MAAI,CAAC,UAAU;AACb,eAAW,MAAM,eAAe,UAAU,OAAO;AAAA,EACnD;AAEA,QAAM,EAAE,QAAQ,GAAG,YAAY,cAAc,kBAAkB,IAAI;AAAA,IACjE;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,MAAI,CAAC,OAAO,SAAS,UAAU,KAAK,cAAc,GAAG;AACnD,UAAM,IAAI,MAAM,oCAAoC,UAAU,OAAO,CAAC,OAAO,CAAC,GAAG;AAAA,EACnF;AAEA,QAAM,YAAY,UAAU;AAC5B,MAAI,EAAE,OAAO,WAAW;AACtB,UAAM,IAAI,MAAM,wCAAwC,EAAE,IAAI,MAAM,SAAS,OAAO,CAAC,OAAO,CAAC,GAAG;AAAA,EAClG;AAEA,QAAM,eAAe,wBAAwB,SAAS,aAAa,SAAS,GAAG,GAAGD,OAAM;AACxF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,aAAa;AAAA,IACb;AAAA,IACAC;AAAA,EACF;AAGA,QAAM,WAAW,YAAY,2BAA2B,YAAY;AACpE,QAAM,UAA+B;AAAA,IACnC,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,IAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,QAAQ,QAAQ,SAAS,MAAM,aAAa,EAAE;AAAA,IAClF,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,QAAQ,SAAS,MAAM,aAAa,EAAE;AAAA,EACnF;AAEA,MAAI,UAAU;AACZ,YAAQ,KAAK,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,GAAG,QAAQ,SAAS,MAAM,aAAa,EAAE,CAAC;AAAA,EAC3F,OAAO;AACL,YAAQ,KAAK,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,GAAG,QAAQ,SAAS,MAAM,aAAa,EAAE,CAAC;AAAA,EAC3F;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAED,SAAO,SAAS,UAAU,WAAW,aAAa,UAAU;AAC5D,uBAAqB,aAAa;AAElC,SAAO,aAAa,GAAG,mBAAmB,CAAC,GAAG,CAAC,GAAG,eAAe;AACnE;AAGA,IAAI,0BAA0B;AAU9B,eAAsB,aACpB,UACA,GACA,GACA,GACA,GACA,GACA,UAAyB,CAAC,GACT;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,QAAQ;AAAA,IACR,eAAe;AAAA,IACf,YAAY,mBAAmB;AAAA;AAAA,IAC/B,UAAU;AAAA,IACV,UAAU;AAAA,IACV,UAAU;AAAA,EACZ,IAAI;AAGJ,QAAM,UAAU,UAAU,CAAC;AAC3B,QAAM,cAAc,eAAe,CAAC;AAGpC,MAAI,eAAe,SAAS,KAAK,0BAA0B,IAAI;AAC7D;AACA,UAAM,eAAe,UAAU,CAAC;AAChC,UAAM,QAAQ,mBAAmB,CAAC,OAAO,CAAC,OAAO,CAAC,sBAAsB,gBAAgB,kBAAkB,YAAY,iBAAiB,WAAW,EAAE;AAAA,EACtJ;AAEA,QAAM,aAAa,kBAAkB,GAAG,gBAAgB;AACxD,2BAAyB,gBAAgB,GAAG,GAAG,CAAC;AAGhD,QAAM,SAAS,cAAc,EAAE,KAAK;AAEpC,QAAM,SAAS,cAAc,eAAe,QAAQ,MAAM;AAC1D,QAAM,uBAAuB,QAAQ,eAAe,EAAE;AAEtD,wBAAsB,gBAAgB,SAAS,SAAS,OAAO;AAC/D,QAAM,EAAE,cAAc,aAAa,IAAI;AAAA,IACrC;AAAA,IACA,EAAE;AAAA,IACF;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,QAAM,EAAE,SAAS,aAAa,QAAQ,IAAI;AAAA,IACxC;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,QAAMD,UAAS,gBAAgB,UAAU,OAAO;AAChD,QAAM,SAAS,IAAI,aAAaC,OAAM;AAGtC,MAAI,WAAW,kBAAkB,UAAU,OAAO;AAClD,MAAI,CAAC,UAAU;AACb,eAAW,MAAM,eAAe,UAAU,OAAO;AAAA,EACnD;AAEA,QAAM,EAAE,QAAQ,GAAG,YAAY,cAAc,kBAAkB,IAAI;AAAA,IACjE;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,MAAI,CAAC,OAAO,SAAS,UAAU,KAAK,cAAc,GAAG;AACnD,UAAM,IAAI,MAAM,uCAAuC,UAAU,OAAO,CAAC,OAAO,CAAC,GAAG;AAAA,EACtF;AAEA,QAAM,YAAY,UAAU;AAC5B,MAAI,EAAE,OAAO,WAAW;AACtB,UAAM,IAAI,MAAM,2CAA2C,EAAE,IAAI,MAAM,SAAS,OAAO,CAAC,OAAO,CAAC,GAAG;AAAA,EACrG;AAEA,QAAM,eAAe,wBAAwB,SAAS,aAAa,SAAS,GAAG,GAAGD,OAAM;AACxF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,aAAa;AAAA,IACb;AAAA,IACAC;AAAA,EACF;AAGA,QAAM,WAAW,YAAY,2BAA2B,YAAY;AACpE,QAAM,UAA+B;AAAA,IACnC,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,IAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,QAAQ,QAAQ,SAAS,MAAM,aAAa,EAAE;AAAA,IAClF,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,QAAQ,SAAS,MAAM,aAAa,EAAE;AAAA,EACnF;AAEA,MAAI,UAAU;AACZ,YAAQ,KAAK,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,GAAG,QAAQ,SAAS,MAAM,aAAa,EAAE,CAAC;AAAA,EAC3F,OAAO;AACL,YAAQ,KAAK,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,GAAG,QAAQ,SAAS,MAAM,aAAa,EAAE,CAAC;AAAA,EAC3F;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAED,SAAO,OAAO,UAAU,UAAU,WAAW,aAAa,UAAU;AACpE,SAAO,aAAa,GAAG,mBAAmB,CAAC,GAAG,CAAC,GAAG,eAAe;AACnE;;;AExyBA;AACA;AACA;AAEA;;;ACQO,IAAM,kBAAkB;;;ADN/B;AACA;AACA;AAWO,SAAS,oBAAoB,UAA0B,CAAC,GAAW;AACxE,QAAM,eAAe,sBAAsB;AAC3C,QAAM,EAAE,UAAU,MAAM,cAAc,MAAM,IAAI;AAEhD,QAAM,cAAc,gBAAgB,SAAS,aAAa;AAE1D,MAAI,aAAa,cAAc;AAC7B,QAAI,aAAa;AACf,aAAO,UAAU,yBAAyB;AAAA,IAC5C;AACA,WAAO,UAAU,kBAAkB;AAAA,EACrC;AAEA,MAAI,aAAa;AACf,WAAO,UAAU,uBAAuB;AAAA,EAC1C;AAEA,SAAO,UAAU,gBAAgB;AACnC;AAEA,SAAS,2BAA2B,SAAiB,WAA6C;AAChG,QAAMC,QAAO,WAAW;AACxB,MAAI;AAEJ,MAAI,QAAQ,SAAS,MAAM,GAAG;AAC5B,iBAAa;AAAA,EACf,WAAW,QAAQ,SAAS,QAAQ,GAAG;AACrC,iBAAa;AAAA,EACf,OAAO;AACL,iBAAa,KAAK,KAAM,YAAYA,SAAS,gBAAgB,UAAU,EAAE;AAAA,EAC3E;AAEA,QAAM,gBAAgB,WAAW;AACjC,MAAI,cAAc,eAAe;AAC/B,WAAO,CAAC,YAAY,GAAG,CAAC;AAAA,EAC1B;AAEA,QAAM,MAAM,KAAK,KAAK,aAAa,aAAa;AAChD,QAAM,MAAM,KAAK,IAAI,YAAY,aAAa;AAC9C,SAAO,CAAC,KAAK,KAAK,CAAC;AACrB;AAKO,SAAS,+BAAmD;AACjE,SAAO,2BAA2B,6BAA6B;AAAA,IAC7D;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,UAAU;AAAA,IAC5B;AAAA,IACA;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,oBAAoB;AAAA,IACtC;AAAA,IACA;AAAA,MACE,SAAS;AAAA,MACT,YAAY,eAAe;AAAA,MAC3B,QAAQ,EAAE,MAAM,UAAU;AAAA,IAC5B;AAAA,EACF,CAAC;AACH;AAKA,eAAsB,WACpB,WACA,WACA,UAA0B,CAAC,GACV;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,eAAe;AAAA,IACf,eAAe;AAAA,IACf,cAAc;AAAA,EAChB,IAAI;AAGJ,QAAM,UAAU,oBAAoB,EAAE,GAAG,SAAS,YAAY,CAAC;AAC/D,QAAM,WAAW,MAAM,gBAAgB,WAAW,OAAO;AAGzD,QAAMD,QAAO,WAAW;AACxB,QAAM,eAAe,gBAAgB,QAAQ,IAAI;AACjD,QAAM,aAAa,YAAYA,QAAO;AAGtC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,gBAAgB;AAGpF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,cAAc,IAAI;AACpC,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,IAAI,GAAG,IAAI;AAAA,IAC5B;AAAA,IACA;AAAA,IACAC;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,2BAA2B,SAAS,SAAS;AAChE,WAASA,SAAQ,UAAU,WAAW,YAAY,SAAS;AAG3D,uBAAqB,aAAa;AAElC,QAAM,QAAqB,gBAAgB,QAAQ,QAAQ;AAC3D,SAAO,aAAa,QAAQ,OAAO,CAAC,YAAYD,KAAI,GAAG,gBAAgB;AACzE;AAKA,eAAsB,gBACpB,QACA,QACA,eACA,WACA,UAA0B,CAAC,GACV;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,eAAe;AAAA,IACf,YAAY;AAAA;AAAA,EACd,IAAI;AAEJ,QAAM,WAAW,MAAM,gBAAgB,WAAW,OAAO;AAEzD,QAAM,aAAa,gBAAgB;AACnC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,sBAAsB;AAG1F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,eAAe,IAAI;AACrC,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,IAAI,YAAY,WAAW,IAAI;AAAA,IAChD;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,gBAAgB,gBAAgB,OAAO;AACpE,QAAM,eAAyC;AAAA,IAC7C,KAAK,IAAI,YAAY,WAAW,cAAc;AAAA,IAC9C,KAAK,IAAI,GAAG,KAAK,KAAK,aAAa,WAAW,cAAc,CAAC;AAAA,IAC7D;AAAA,EACF;AACA,WAASA,SAAQ,UAAU,WAAW,cAAc,eAAe;AAEnE,uBAAqB,aAAa;AAElC,SAAO,aAAa,QAAQ,OAAO,CAAC,aAAa,GAAG,sBAAsB;AAC5E;AAKA,eAAsB,sBACpB,QACA,QACA,WACA,YACA,QACA,WACA,UAA0B,CAAC,GACV;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,eAAe,KAAK,IAAI;AAEhC,QAAM,WAAW,MAAM,gBAAgB,WAAW,cAAc;AAGhE,QAAM,cAAc,SAAS,YAAY;AACzC,QAAM,aAAa,cAAc;AACjC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,qBAAqB;AAGzF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,QAAQ,IAAI;AAC9B,WAAK,UAAU,IAAI,WAAW,IAAI;AAClC,WAAK,UAAU,IAAI,aAAa,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,cAAc,gBAAgB,OAAO;AAClE,QAAM,eAAyC;AAAA,IAC7C,KAAK,IAAI,YAAY,WAAW,cAAc;AAAA,IAC9C,KAAK,IAAI,GAAG,KAAK,KAAK,aAAa,WAAW,cAAc,CAAC;AAAA,IAC7D;AAAA,EACF;AACA,WAASA,SAAQ,UAAU,WAAW,cAAc,cAAc;AAElE,uBAAqB,aAAa;AAElC,SAAO,aAAa,QAAQ,OAAO,CAAC,QAAQ,YAAY,EAAE,GAAG,qBAAqB;AACpF;AAWA,eAAsB,cACpB,WACA,WACA,UAA0B,CAAC,GACV;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,eAAe;AAAA,IACf,eAAe;AAAA,IACf,cAAc;AAAA;AAAA,EAChB,IAAI;AAGJ,QAAM,WAAW,MAAM,gBAAgB,WAAW,YAAY;AAG9D,QAAMD,QAAO,WAAW;AACxB,QAAM,eAAe,gBAAgB,QAAQ,IAAI;AACjD,QAAM,aAAa,YAAYA,QAAO;AAGtC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,oBAAoB;AAGxF,QAAM,gBAAgB,WAAW;AACjC,QAAM,cAAc,KAAK,IAAI,WAAW,aAAa;AAGrD,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,cAAc,IAAI;AACpC,WAAK,UAAU,GAAG,aAAa,IAAI;AACnC,WAAK,UAAU,IAAI,GAAG,IAAI;AAAA,IAC5B;AAAA,IACA;AAAA,IACAC;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAGD,QAAM,aAAuC;AAAA,IAC3C;AAAA,IACA,YAAY,gBAAgB,KAAK,KAAK,YAAY,aAAa,IAAI;AAAA,IACnE;AAAA,EACF;AAEA,WAASA,SAAQ,UAAU,WAAW,YAAY,aAAa;AAE/D,uBAAqB,aAAa;AAElC,QAAM,QAAqB,gBAAgB,QAAQ,QAAQ;AAC3D,SAAO,aAAa,QAAQ,OAAO,CAAC,YAAYD,KAAI,GAAG,oBAAoB;AAC7E;AAWA,eAAsB,eACpB,WACA,WACA,UAA0B,CAAC,GACV;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,eAAe;AAAA,IACf,eAAe;AAAA,IACf,cAAc;AAAA;AAAA,EAChB,IAAI;AAGJ,QAAM,WAAW,MAAM,gBAAgB,WAAW,aAAa;AAG/D,QAAM,eAAe,gBAAgB,QAAQ,IAAI;AACjD,QAAM,aAAa,YAAY,kBAAkB;AAGjD,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,qBAAqB;AAGzF,QAAM,gBAAgB,WAAW;AACjC,QAAM,cAAc,KAAK,IAAI,WAAW,aAAa;AAGrD,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,cAAc,IAAI;AACpC,WAAK,UAAU,GAAG,aAAa,IAAI;AACnC,WAAK,UAAU,IAAI,GAAG,IAAI;AAAA,IAC5B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAGD,QAAM,aAAuC;AAAA,IAC3C;AAAA,IACA,YAAY,gBAAgB,KAAK,KAAK,YAAY,aAAa,IAAI;AAAA,IACnE;AAAA,EACF;AAEA,WAASA,SAAQ,UAAU,WAAW,YAAY,cAAc;AAEhE,uBAAqB,aAAa;AAElC,QAAM,QAAqB,gBAAgB,QAAQ,QAAQ;AAC3D,SAAO,aAAa,QAAQ,OAAO,CAAC,YAAY,eAAe,GAAG,qBAAqB;AACzF;AAKA,eAAsB,iBACpB,UACA,WACA,WACA,UAA0B,CAAC,GACV;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,eAAe;AAAA,IACf,eAAe;AAAA,IACf,cAAc;AAAA,EAChB,IAAI;AAGJ,QAAM,UAAU,oBAAoB,EAAE,GAAG,SAAS,YAAY,CAAC;AAC/D,QAAM,WAAW,MAAM,gBAAgB,WAAW,OAAO;AAGzD,QAAMD,QAAO,WAAW;AACxB,QAAM,eAAe,gBAAgB,QAAQ,IAAI;AACjD,QAAM,aAAa,YAAYA,QAAO;AAGtC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,gBAAgB;AAGpF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,cAAc,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYC,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,2BAA2B,SAAS,SAAS;AAChE,iBAAe,UAAU,UAAU,WAAW,YAAY,SAAS;AAEnE,QAAM,QAAqB,gBAAgB,QAAQ,QAAQ;AAC3D,SAAO,aAAa,QAAQ,OAAO,CAAC,YAAYD,KAAI,GAAG,gBAAgB;AACzE;;;AEzdA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AAEA;AAIA,IAAI,sBAAsB;AAM1B,IAAI,mBAAkC;AACtC,SAAS,qBAA6B;AACpC,MAAI,qBAAqB,MAAM;AAC7B,UAAME,UAAS,gBAAgB,aAAa,sBAAsB;AAClE,uBAAmBA,QAAO,iBAAiB,YAAY;AAAA,EACzD;AACA,SAAO;AACT;AAEA,IAAI,sBAAwC;AAC5C,SAAS,uBAAuBC,SAA8B;AAC5D,MAAI,CAAC,qBAAqB;AACxB,0BAAsBA,QAAO,aAAa;AAAA,MACxC,OAAO;AAAA,MACP,MAAM;AAAA,MACN,OAAO,eAAe,UAAU,eAAe;AAAA,IACjD,CAAC;AACD,IAAAA,QAAO,MAAM,YAAY,qBAAqB,GAAG,IAAI,YAAY,CAAC,CAAC,CAAC,CAAC;AAAA,EACvE;AACA,SAAO;AACT;AAiCA,IAAM,kBAAN,cAA8B,WAAW;AAAA,EACvC,MAAM,YAAY,SAA8C;AAC9D,WAAO,KAAK,eAAe,aAAa,OAAO;AAAA,EACjD;AAAA,EAEA,SACE,UACA,WACA,YACM;AACN,SAAK,eAAe,UAAU,WAAW,YAAY,WAAW;AAAA,EAClE;AAAA,EAEA,OACE,UACA,UACA,WACA,YACM;AACN,SAAK,aAAa,UAAU,UAAU,WAAW,YAAY,WAAW;AAAA,EAC1E;AACF;AAEA,SAAS,oBACP,SACA,QACA,UACA,YACA,aACA,MACA,QACe;AACf,QAAM,WAAW,WAAW;AAC5B,QAAM,WACJ,WAAW,iBAAiB,gCAC5B,eAAe,kBAAkB;AACnC,QAAM,gBAAgB,WAClB,kBAAkB,6BAClB,kBAAkB;AACtB,QAAM,WACJ,WAAW,iBAAiB,gCAC5B,eAAe;AACjB,QAAM,cACJ,KAAK,gBACL,WAAW,iBAAiB,mCAC5B,eAAe,kBAAkB,6BACjC;AAEF,QAAM,aAAa,CAAC,YAA0B;AAC5C,QAAI,QAAQ;AACV,YAAM,IAAI,MAAM,OAAO;AAAA,IACzB;AACA,QAAI,KAAK,aAAa,OAAO;AAAA,EAC/B;AAEA,MAAI,OAAO;AAEX,MAAI,SAAS,iBAAiB,CAAC,UAAU;AACvC,eAAW,gEAAgE,OAAO,YAAY,WAAW,IAAI;AAC7G,WAAO;AAAA,EACT;AACA,MAAI,SAAS,iBAAiB,CAAC,UAAU;AACvC,eAAW,gEAAgE,OAAO,YAAY,WAAW,IAAI;AAC7G,WAAO;AAAA,EACT;AACA,MAAI,SAAS,cAAc,CAAC,aAAa;AACvC,eAAW,uEAAuE,OAAO,YAAY,WAAW,eAAe,KAAK,YAAY,IAAI;AACpJ,WAAO;AAAA,EACT;AAEA,MAAI,CAAC,MAAM;AACT,QAAI,aAAa;AACf,aAAO;AACP,UAAI,CAAC,qBAAqB;AACxB,cAAM,KAAK,GAAG,yCAAyC,OAAO,sBAAsB;AACpF,8BAAsB;AAAA,MACxB;AAAA,IACF,WAAW,UAAU;AACnB,aAAO;AAAA,IACT,WAAW,UAAU;AACnB,aAAO;AAAA,IACT,WAAW,UAAU;AACnB,aAAO;AAAA,IACT,OAAO;AACL,UAAI,KAAK,aAAa,yCAAyC,OAAO,YAAY,WAAW,oDAAoD;AACjJ,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAGA,IAAI,sBAAsB;AAE1B,SAAS,wBACP,MACA,UACA,UACA,UACA,SACA,OACQ;AACR,QAAM,OAAO,WAAW,WAAW;AAOnC,QAAM,kBAAkB,mBAAmB;AAC3C,QAAM,uBAAuB,oBAAoB,EAAE,UAAU;AAC7D,QAAM,gBAAgB,YAAY,YAAY,WAAW,wBAAwB,SAAS;AAC1F,QAAM,yBAAyB;AAC/B,QAAM,2BAA2B,oBAAoB,EAAE,UAAU,kBAAkB;AACnF,QAAM,uBAAuB,YAAY,CAAC,YAAY,WAAW,4BAA4B,SAAS;AAEtG,MAAI,SAAS,YAAY;AAGvB,QAAI,UAAU;AACZ,UAAI,eAAe;AACjB,YAAI,CAAC,qBAAqB;AACxB,gBAAM,KAAK,GAAG,wCAAwC,OAAO,cAAc,QAAQ,eAAe;AAClG,gCAAsB;AAAA,QACxB;AACA,eAAO;AAAA,MACT;AACA,aAAO;AAAA,IACT;AACA,QAAI,sBAAsB;AACxB,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AACA,MAAI,SAAS,eAAe;AAC1B,WAAO,QAAQ,WAAW,WAAW;AAAA,EACvC;AACA,MAAI,SAAS,eAAe;AAC1B,WAAO,GAAG,IAAI,SAAS,WAAW,WAAW,EAAE;AAAA,EACjD;AAEA,MAAI,eAAe;AACjB,QAAI,CAAC,qBAAqB;AACxB,YAAM,KAAK,GAAG,wCAAwC,OAAO,cAAc,QAAQ,eAAe;AAClG,4BAAsB;AAAA,IACxB;AACA,WAAO;AAAA,EACT;AACA,SAAO,GAAG,IAAI,aAAa,WAAW,WAAW,EAAE;AACrD;AAEA,SAAS,6BAA6B,MAAqB,QAAgB,UAA0B;AACnG,MAAI,SAAS,YAAY;AACvB,WAAO;AAAA,EACT;AACA,MAAI,SAAS,aAAa;AACxB,WAAO,SAAS;AAAA,EAClB;AACA,MAAI,SAAS,eAAe;AAC1B,WAAO,KAAK,KAAK,SAAS,WAAW,0BAA0B,IAAI;AAAA,EACrE;AACA,SAAO,KAAK,KAAK,SAAS,WAAW,0BAA0B,IAAI;AACrE;AAEA,SAAS,8BAA8B,SAAgC;AACrE,MAAI,YAAY;AAAmB,WAAO;AAC1C,MAAI,QAAQ,WAAW,mBAAmB,KAAK,QAAQ,WAAW,kBAAkB,KAAK,YAAY,wBAAwB;AAC3H,WAAO;AAAA,EACT;AACA,MAAI,QAAQ,WAAW,eAAe,KAAK,QAAQ,WAAW,cAAc;AAAG,WAAO;AACtF,SAAO;AACT;AAEA,SAAS,yBACP,SACA,UACA,UACA,MACA,QACe;AACf,QAAM,aAAa,QAAQ,KAAK;AAChC,QAAM,aAAa,CAAC,YAAmC;AACrD,QAAI,QAAQ;AACV,YAAM,IAAI,MAAM,OAAO;AAAA,IACzB;AACA,QAAI,KAAK,aAAa,OAAO;AAC7B,WAAO;AAAA,EACT;AAEA,MAAID;AACJ,MAAI;AACF,IAAAA,UAAS,gBAAgB,aAAa,UAAU;AAAA,EAClD,QAAQ;AACN,WAAO,WAAW,qCAAqC,OAAO,IAAI;AAAA,EACpE;AAEA,MAAI,CAAC,oBAAoBA,QAAO,UAAU,IAAI,GAAG;AAC/C,WAAO,WAAW,qBAAqB,OAAO,sCAAsC;AAAA,EACtF;AAEA,QAAM,eAAe,WAAW,SAAS,QAAQ;AACjD,MAAI,iBAAiB,UAAU;AAC7B,UAAM,UAAU,WAAW,QAAQ;AACnC,WAAO,WAAW,qBAAqB,OAAO,uBAAuB,OAAO,YAAY;AAAA,EAC1F;AAEA,QAAM,kBAAkB,WAAW,WAAW,QAAQ;AACtD,QAAM,mBAAmB,WAAW,WAAW,SAAS;AACxD,MAAI,YAAY,kBAAkB;AAChC,WAAO,WAAW,qBAAqB,OAAO,yCAAyC;AAAA,EACzF;AACA,MAAI,CAAC,YAAY,iBAAiB;AAChC,WAAO,WAAW,qBAAqB,OAAO,yCAAyC;AAAA,EACzF;AAEA,SAAO;AACT;AAEA,SAAS,qBACP,QACA,OACA,SACA,UACA,SACA,aACA,MACA,UACe;AACf,QAAM,WAAW,YAAY;AAC7B,QAAM,WAAW,WAAW;AAC5B,QAAM,SAAS,oBAAoB;AACnC,QAAM,cAAc,8BAA8B,WAAW,WAAW,WAAW,QAAQ;AAE3F,MAAI,aAAa;AACf,UAAM,kBAAkB,yBAAyB,aAAa,UAAU,UAAU,MAAM,MAAM;AAC9F,QAAI,iBAAiB;AACnB,YAAME,QAAO,8BAA8B,eAAe;AAC1D,YAAMC,cAAa,6BAA6BD,OAAM,QAAQ,QAAQ;AACtE,aAAO,EAAE,MAAAA,OAAM,SAAS,iBAAiB,YAAAC,aAAY,UAAU,SAAS;AAAA,IAC1E;AAAA,EACF;AAEA,QAAM,OAAO,oBAAoB,SAAS,QAAQ,UAAU,MAAM,aAAa,MAAM,MAAM;AAC3F,QAAM,UAAU,wBAAwB,MAAM,UAAU,UAAU,UAAU,SAAS,KAAK;AAC1F,QAAM,aAAa,6BAA6B,MAAM,QAAQ,QAAQ;AAEtE,SAAO,EAAE,MAAM,SAAS,YAAY,UAAU,SAAS;AACzD;AAEA,SAAS,6BACPF,SACA,UACA,QAaW;AACX,SAAO;AAAA,IACL;AAAA,IACA;AAAA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,OAAO,UAAU,IAAI;AACvC,WAAK,UAAU,GAAG,OAAO,YAAY,IAAI;AACzC,WAAK,UAAU,GAAG,OAAO,SAAS,IAAI;AACtC,WAAK,UAAU,IAAI,OAAO,OAAO,IAAI;AACrC,WAAK,UAAU,IAAI,OAAO,QAAQ,IAAI;AACtC,WAAK,WAAW,IAAI,OAAO,OAAO,IAAI;AACtC,WAAK,UAAU,IAAI,OAAO,SAAS,IAAI,GAAG,IAAI;AAC9C,WAAK,UAAU,IAAI,OAAO,UAAU,IAAI;AACxC,WAAK,WAAW,IAAI,OAAO,aAAa,IAAI;AAC5C,WAAK,UAAU,IAAI,OAAO,eAAe,IAAI;AAC7C,WAAK,UAAU,IAAI,OAAO,aAAa,IAAI;AAAA,IAC7C;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AACF;AAKA,eAAsB,aACpB,GACA,GACA,GACA,MACA,UACA,SACA,UAA4B,CAAC,GACZ;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,SAAS;AAAA,IACT,QAAQ;AAAA,IACR,aAAa;AAAA,IACb,QAAQ,IAAM,KAAK,KAAK,OAAO;AAAA,IAC/B,SAAS;AAAA,IACT,WAAW;AAAA,IACX;AAAA,IACA,eAAe;AAAA,IACf,cAAc;AAAA,IACd,gBAAgB;AAAA,IAChB,cAAc;AAAA,IACd,iBAAiB;AAAA,IACjB,iBAAiB;AAAA,EACnB,IAAI;AAEJ,QAAM,SAAS,gBAAgB;AAC/B,QAAM,cAAc,QAAQ,kCAAkC;AAC9D,QAAM,OAAO,sBAAsB;AACnC,QAAM,UAAuB,EAAE;AAC/B,QAAM,OAAO;AAAA,IACX;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACA,QAAM,SAAS,IAAI,gBAAgBA,OAAM;AACzC,QAAM,WAAW,MAAM,OAAO,YAAY,KAAK,OAAO;AAGtD,QAAM,cAA2B;AACjC,QAAM,aAAa,SAAS,WAAW,UAAU;AACjD,QAAM,YAAY,gBAAgB,cAAc,YAAY,QAAW,kBAAkB;AAGzF,QAAM,gBAAgB,6BAA6BA,SAAQ,MAAM;AAAA,IAC/D;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,aAAa,cAAc,IAAI;AAAA,EACjC,CAAC;AAGD,QAAM,eAAe,eAAe,uBAAuBA,OAAM;AACjE,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,OAAO,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,OAAO,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,OAAO,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,IACnD;AAAA,EACF,CAAC;AAED,MAAI,CAAC,kBAAkB,UAAU,KAAK,aAAa,OAAO,kCAAkC;AAC1F,UAAM,IAAI;AAAA,MACR,+BAA+B,KAAK,UAAU,mCAC3C,OAAO,gCAAgC;AAAA,IAC5C;AAAA,EACF;AAEA,MAAI,gBAAgB;AAClB,qBAAiBA,SAAQ,UAAU,WAAW,gBAAgB,gBAAgB,WAAW;AAAA,EAC3F,OAAO;AACL,WAAO,SAAS,UAAU,WAAW,KAAK,UAAU;AAAA,EACtD;AAEA,uBAAqB,aAAa;AAElC,SAAO,aAAa,WAAW,aAAa,CAAC,QAAQ,UAAU,OAAO,GAAG,kBAAkB;AAC7F;AAKA,eAAsB,gBACpB,UACA,GACA,GACA,GACA,MACA,UACA,SACA,UAA4B,CAAC,GACZ;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,SAAS;AAAA,IACT,QAAQ;AAAA,IACR,aAAa;AAAA,IACb,QAAQ,IAAM,KAAK,KAAK,OAAO;AAAA,IAC/B,SAAS;AAAA,IACT,WAAW;AAAA,IACX;AAAA,IACA,eAAe;AAAA,IACf,cAAc;AAAA,IACd,gBAAgB;AAAA,IAChB,cAAc;AAAA,IACd,iBAAiB;AAAA,IACjB,iBAAiB;AAAA,EACnB,IAAI;AAEJ,QAAM,SAAS,gBAAgB;AAC/B,QAAM,cAAc,QAAQ,kCAAkC;AAC9D,QAAM,OAAO,sBAAsB;AACnC,QAAM,UAAuB,EAAE;AAC/B,QAAM,OAAO;AAAA,IACX;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,QAAM,KAAK,GAAG,6BAA6B,KAAK,QAAQ,UAAU,KAAK,IAAI,aAAa,KAAK,OAAO,YAAY,MAAM,WAAW,KAAK,cAAc,QAAQ,aAAa,OAAO,cAAc,KAAK,QAAQ,EAAE;AAE7M,QAAM,SAAS,IAAI,gBAAgBA,OAAM;AACzC,QAAM,WAAW,MAAM,OAAO,YAAY,KAAK,OAAO;AAGtD,QAAM,cAA2B;AACjC,QAAM,aAAa,SAAS,WAAW,UAAU;AACjD,QAAM,YAAY,gBAAgB,cAAc,YAAY,QAAW,kBAAkB;AAEzF,QAAM,gBAAgB,6BAA6BA,SAAQ,UAAU;AAAA,IACnE;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,aAAa,cAAc,IAAI;AAAA,EACjC,CAAC;AAED,QAAM,eAAe,eAAe,uBAAuBA,OAAM;AACjE,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,OAAO,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,OAAO,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,EAAE,OAAO,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,IACnD;AAAA,EACF,CAAC;AAED,MAAI,CAAC,kBAAkB,UAAU,KAAK,aAAa,OAAO,kCAAkC;AAC1F,UAAM,IAAI;AAAA,MACR,+BAA+B,KAAK,UAAU,mCAC3C,OAAO,gCAAgC;AAAA,IAC5C;AAAA,EACF;AAEA,MAAI,gBAAgB;AAClB,2BAAuB,UAAU,UAAU,WAAW,gBAAgB,gBAAgB,WAAW;AAAA,EACnG,OAAO;AACL,WAAO,OAAO,UAAU,UAAU,WAAW,KAAK,UAAU;AAAA,EAC9D;AAEA,SAAO,aAAa,WAAW,aAAa,CAAC,QAAQ,UAAU,OAAO,GAAG,kBAAkB;AAC7F;;;ACnjBA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAaA,SAAS,UAAU,OAAe,UAAkC;AAClE,MAAI,MAAM,UAAU;AAAO,WAAO;AAClC,MAAI,YAAY,SAAS,UAAU;AAAO,WAAO;AACjD,SAAO;AACT;AAMO,SAAS,oBAAoB,UAA0B,CAAC,GAAG,QAAiB,OAAe;AAChG,QAAM,EAAE,WAAW,MAAM,aAAa,KAAK,IAAI;AAC/C,QAAM,EAAE,eAAe,IAAI,oBAAoB,EAAE;AAGjD,QAAM,OAAO,sBAAsB;AACnC,QAAM,eAAe,MAAM,gBAAgB;AAG3C,MAAI,OAAO;AACT,QAAI,eAAe,QAAQ,cAAc,gBAAgB;AACvD,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AAGA,MAAI,UAAU;AACZ,QAAI,eAAe,QAAQ,cAAc,gBAAgB;AACvD,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AAGA,MAAI,cAAc;AAChB,QAAI,eAAe,QAAQ,cAAc,gBAAgB;AACvD,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AAGA,MAAI,eAAe,QAAQ,cAAc,gBAAgB;AACvD,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAKA,eAAsB,WACpB,OACA,QACA,MAAc,MACd,UAA0B,CAAC,GACV;AACjB,QAAMG,UAAS,UAAU;AACzB,QAAM,EAAE,YAAY,GAAG,YAAY,WAAW,MAAM,eAAe,KAAK,IAAI;AAG5E,QAAM,QAAQ,UAAU,OAAO,QAAQ;AACvC,QAAM,UAAU,oBAAoB,SAAS,KAAK;AAClD,QAAM,QAAQ,wBAAwB,MAAM,KAAK,WAAW,KAAK,aAAa,OAAO,EAAE;AAEvF,MAAI,UAAU;AACZ,UAAM,QAAQ,kDAAkD,SAAS,OAAO,IAAI,wBAAwB,cAAe,OAAO,OAAO,CAAE,eAAe,SAAS,EAAE;AAAA,EACvK;AAEA,QAAM,WAAW,MAAM,gBAAgB,WAAW,OAAO;AAIzD,QAAM,qBAAqB,cAAe,OAAO,OAAO;AACxD,QAAM,kBAAkB,QAAQ,IAAI;AACpC,QAAM,aAAa,YAAY,qBAAqB;AACpD,QAAM,YAAY,gBAAgB,cAAc,YAAY,QAAW,gBAAgB;AAGvF,QAAM,kBAAkB,WAAW,IAAI;AACvC,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,oBAAoB,IAAI;AAC1C,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,WAAW,GAAG,KAAK,IAAI;AAC5B,WAAK,UAAU,IAAI,iBAAiB,IAAI;AAAA,IAC1C;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AACA,MAAI,iBAAiB;AACnB,UAAM,QAAQ,gCAAgC,eAAe,gBAAgB,kBAAkB,eAAe,SAAS,EAAE;AAAA,EAC3H;AAGA,QAAM,iBAAiB,UAAU,UAAUA,QAAO,aAAa;AAAA,IAC7D,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO,eAAe;AAAA,EACxB,CAAC;AAGD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,eAAe,EAAE;AAAA,IACrD;AAAA,EACF,CAAC;AAED,WAASA,SAAQ,UAAU,WAAW,WAAW,SAAS;AAE1D,gBAAc,QAAQ;AACtB,MAAI,CAAC;AAAU,mBAAe,QAAQ;AAEtC,SAAO,aAAa,WAAW,MAAM,OAAO,CAAC,WAAW,kBAAkB,GAAG,gBAAgB;AAC/F;AAKA,eAAsB,cACpB,UACA,OACA,QACA,MAAc,MACd,UAA0B,CAAC,GACV;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,YAAY;AAAA,IACZ,aAAa;AAAA,IACb,WAAW;AAAA,IACX,eAAe;AAAA,EACjB,IAAI;AAGJ,QAAM,qBAAqB,cAAe,OAAO,OAAO;AAGxD,QAAM,QAAQ,UAAU,OAAO,QAAQ;AACvC,QAAM,UAAU,oBAAoB,SAAS,KAAK;AAClD,QAAM,kBAAkB,QAAQ,IAAI;AACpC,QAAM,aAAa,YAAY,qBAAqB;AAEpD,QAAM,WAAW,MAAM,gBAAgB,WAAW,OAAO;AAGzD,QAAM,YAAY,gBAAgB,cAAc,YAAY,QAAW,gBAAgB;AAGvF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,oBAAoB,IAAI;AAC1C,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,WAAW,GAAG,KAAK,IAAI;AAC5B,WAAK,UAAU,IAAI,WAAW,IAAI,GAAG,IAAI;AAAA,IAC3C;AAAA,IACA;AAAA,EACF;AAGA,QAAM,iBAAiB,UAAU,UAAUA,QAAO,aAAa;AAAA,IAC7D,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO,eAAe;AAAA,EACxB,CAAC;AAGD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,MAC9C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,eAAe,EAAE;AAAA,IACrD;AAAA,EACF,CAAC;AAED,iBAAe,UAAU,UAAU,WAAW,WAAW,SAAS;AAGlE,MAAI,CAAC,UAAU;AACb,aAAS,qBAAqB,cAAc;AAAA,EAC9C;AAEA,SAAO,aAAa,WAAW,MAAM,OAAO,CAAC,WAAW,kBAAkB,GAAG,gBAAgB;AAC/F;;;ACzNA;AACA;AAEA;AACA;AACA;AAEA;AAYA,IAAM,0BAA0B;AAMhC,SAAS,qBAAqB,WAA2B;AACvD,QAAM,OAAO,sBAAsB;AACnC,QAAM,eAAe,MAAM,gBAAgB;AAE3C,MAAI,cAAc;AAChB,QAAI,aAAa,yBAAyB;AACxC,aAAO;AAAA,IACT;AACA,WAAO;AAAA,EACT;AAEA,MAAI,aAAa,yBAAyB;AACxC,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAKA,eAAsB,WACpB,OACA,MACA,UAA0B,CAAC,GACV;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,YAAY,GAAG,MAAM,cAAc,GAAK,eAAe,KAAK,IAAI;AAExE,QAAM,kBAAkB,MAAM,UAAU,QAAQ,IAAI;AACpD,QAAM,eAAe,QAAS,MAAM,OAAO,QAAQ,YAAY;AAC/D,QAAM,UAAU,qBAAqB,YAAY;AACjD,QAAM,QAAQ,iBAAiB,YAAY,aAAa,OAAO,EAAE;AACjE,QAAM,WAAW,MAAM,eAAe,WAAW,OAAO;AAExD,QAAM,aAAa,YAAY,eAAe;AAC9C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,gBAAgB;AAIpF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,cAAc,IAAI;AACpC,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,WAAW,GAAG,aAAa,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,WAASA,SAAQ,UAAU,WAAW,WAAW,SAAS;AAE1D,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,WAAW,YAAY,GAAG,gBAAgB;AACtF;AAKA,eAAsB,eACpB,QACA,WACA,YACA,MACA,UAA0B,CAAC,GAC0B;AACrD,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,YAAY,KAAK,IAAI;AAE7B,QAAM,WAAW,MAAM,eAAe,QAAQ,OAAO;AAGrD,QAAM,cAAc,YAAY,OAAO;AACvC,QAAM,cAAc,YAAY,OAAO;AAEvC,QAAM,UAAU,cAAc,aAAa,QAAW,sBAAsB;AAC5E,QAAM,UAAU,cAAc,aAAa,QAAW,sBAAsB;AAG5E,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,MAAM,IAAI;AAC5B,WAAK,UAAU,IAAI,YAAY,IAAI,GAAG,IAAI;AAAA,IAC5C;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,IAC9C;AAAA,EACF,CAAC;AAED,WAASA,SAAQ,UAAU,WAAW,WAAW,cAAc;AAE/D,gBAAc,QAAQ;AAEtB,SAAO,EAAE,SAAS,QAAQ;AAC5B;AAKA,eAAsB,cACpB,UACA,OACA,MACA,UAA0B,CAAC,GACV;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,YAAY;AAAA,IACZ,SAAS;AAAA,IACT,eAAe;AAAA,EACjB,IAAI;AAEJ,QAAM,kBAAkB,MAAM,UAAU,QAAQ,IAAI;AACpD,QAAM,iBAAiB,UAAW,MAAM,OAAO,QAAQ,YAAY;AACnE,QAAM,WAAW,MAAM,eAAe,WAAW,SAAS;AAE1D,QAAM,aAAa,YAAY,iBAAiB;AAChD,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,gBAAgB;AAIpF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,gBAAgB,IAAI;AACtC,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,WAAW,GAAG,GAAK,IAAI;AAAA,IAC9B;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,iBAAe,UAAU,UAAU,WAAW,WAAW,SAAS;AAElE,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,WAAW,cAAc,GAAG,gBAAgB;AACxF;;;ACtMA;AAEA;AACA;AACA;AACA;AAEA;AAGA,IAAM,kBAAkB,MAAM,oBAAoB,EAAE;AAapD,eAAsB,QACpB,OACA,UACA,UACA,QACA,UAAuB,CAAC,GACP;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,eAAe,gBAAgB;AACrC,QAAM;AAAA,IACJ,WAAW;AAAA,IACX,UAAU;AAAA,IACV,YAAY,aAAa;AAAA,EAC3B,IAAI;AAEJ,QAAM,WAAW,MAAM,gBAAgB,QAAQ,SAAS;AAMxD,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA,aAAa;AAAA,IACb,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,QAAQ,IAAI;AAC9B,WAAK,UAAU,GAAG,UAAU,IAAI;AAChC,WAAK,UAAU,GAAG,SAAS,IAAI;AAC/B,WAAK,UAAU,IAAI,QAAQ,YAAY,GAAG,IAAI;AAC9C,WAAK,WAAW,IAAI,WAAW,IAAI;AACnC,WAAK,WAAW,IAAI,GAAK,IAAI;AAAA,IAC/B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,IAC/C;AAAA,EACF,CAAC;AAGD,MAAI,UAAU,MAAM,GAAG;AACrB,UAAM,IAAI,MAAM,kCAAkC,OAAO,EAAE;AAAA,EAC7D;AACA,QAAM,UAAU,UAAU;AAC1B,QAAM,aAAa,KAAK,KAAM,SAAS,WAAW,UAAW,gBAAgB,OAAO;AACpF,WAASA,SAAQ,UAAU,WAAW,YAAY,MAAM;AAExD,gBAAc,QAAQ;AAGtB,SAAO,aAAa,MAAM,QAAQ,MAAM,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,aAAa;AAChF;AAKA,eAAsB,WACpB,UACA,OACA,UACA,UACA,QACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,eAAe,gBAAgB;AACrC,QAAM;AAAA,IACJ,WAAW;AAAA,IACX,UAAU;AAAA,IACV,YAAY,aAAa;AAAA,EAC3B,IAAI;AAEJ,QAAM,WAAW,MAAM,gBAAgB,QAAQ,SAAS;AAMxD,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA,aAAa;AAAA,IACb,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,QAAQ,IAAI;AAC9B,WAAK,UAAU,GAAG,UAAU,IAAI;AAChC,WAAK,UAAU,GAAG,SAAS,IAAI;AAC/B,WAAK,UAAU,IAAI,QAAQ,YAAY,GAAG,IAAI;AAC9C,WAAK,WAAW,IAAI,WAAW,IAAI;AACnC,WAAK,WAAW,IAAI,GAAK,IAAI;AAAA,IAC/B;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,MAC7C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,IAC/C;AAAA,EACF,CAAC;AAED,MAAI,UAAU,MAAM,GAAG;AACrB,UAAM,IAAI,MAAM,kCAAkC,OAAO,EAAE;AAAA,EAC7D;AACA,QAAM,UAAU,UAAU;AAC1B,QAAM,aAAa,KAAK,KAAM,SAAS,WAAW,UAAW,gBAAgB,OAAO;AACpF,iBAAe,UAAU,UAAU,WAAW,YAAY,MAAM;AAGhE,SAAO,aAAa,MAAM,QAAQ,MAAM,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,aAAa;AAChF;;;ACjJA;AACA;AAEA;AACA;AACA;AACA;AAWA,IAAM,gBAAwC;AAAA,EAC5C,iBAAiB;AAAA,EACjB,gBAAgB;AAAA,EAChB,cAAc;AAAA,EACd,aAAa;AAAA,EACb,cAAc;AAAA,EACd,aAAa;AAAA,EACb,uBAAuB;AAAA,EACvB,sBAAsB;AAAA,EACtB,wBAAwB;AAAA,EACxB,uBAAuB;AACzB;AAKA,SAAS,kBAAkB,MAAc,OAAwB;AAC/D,QAAM,MAAM,GAAG,IAAI,IAAI,KAAK;AAC5B,SAAO,cAAc,GAAG,KAAK;AAC/B;AAKA,SAASC,WAAU,OAAwB;AACzC,SAAO,MAAM,UAAU;AACzB;AAKA,SAAS,2BACP,eACA,OACA,QACA,MACqB;AACrB,QAAM,UAA+B;AAAA,IACnC,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,IAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,IACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,EAC7C;AACA,MAAI,MAAM;AACR,YAAQ,KAAK,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,KAAK,OAAO,EAAE,CAAC;AAAA,EAChE;AACA,SAAO;AACT;AAaA,eAAsB,QACpB,OACA,UAAuB,CAAC,GACP;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,MAAM,OAAO,MAAM,eAAe,MAAM,UAAU,MAAM,IAAI;AAEpE,QAAM,QAAQD,WAAU,KAAK;AAC7B,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAG9C,QAAM,cAAc,OAAO,SAAU,UAAU,SAAS;AACxD,QAAM,UAAU,kBAAkB,aAAa,KAAK;AACpD,QAAM,WAAW,MAAM,gBAAgB,QAAQ,OAAO;AAEtD,QAAM,eAAe,QAAS,MAAM,OAAO,OAAO;AAClD,QAAM,aAAa,eAAe;AAClC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,aAAa;AAGjF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,cAAc,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,IACAC;AAAA,EACF;AAGA,QAAM,UAAU,2BAA2B,eAAe,OAAO,QAAQ,IAAI;AAE7E,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,eAAe,gBAAgB,OAAO;AACnE,WAASA,SAAQ,UAAU,WAAW,YAAY,MAAM;AAExD,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,YAAY,GAAG,aAAa;AACxE;AAKA,eAAsB,sBACpB,OACA,MACA,WACA,KACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,eAAe,MAAM,aAAa,EAAE,IAAI;AAEhD,QAAM,WAAW,MAAM,gBAAgB,UAAU,eAAe;AAEhE,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAC9C,QAAM,aAAa,YAAY,MAAM;AACrC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,eAAe;AAGnF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,KAAK,IAAI;AAC3B,WAAK,UAAU,GAAG,YAAY,IAAI;AAAA,IACpC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,KAAK,OAAO,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAM,YAAY,MAAO,gBAAgB,OAAO;AACxE,WAASA,SAAQ,UAAU,WAAW,YAAY,QAAQ;AAE1D,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,WAAW,GAAG,GAAG,eAAe;AAC5E;AAiBA,eAAsB,gBACpB,OACA,SACiB;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,WAAW,KAAK,aAAa,QAAQ,eAAe,KAAK,IAAI;AAErE,QAAM,QAAQD,WAAU,KAAK;AAC7B,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAG9C,MAAI,UAAU,eAAe,SAAS,mBAAmB;AACzD,MAAI,OAAO;AACT,cAAU,UAAU;AAAA,EACtB;AACA,QAAM,WAAW,MAAM,gBAAgB,QAAQ,OAAO;AAEtD,QAAM,aAAa,YAAY,MAAM;AACrC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,sBAAsB;AAI1F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,YAAY,KAAK,IAAI;AACvC,WAAK,UAAU,GAAG,KAAK,IAAI;AAC3B,WAAK,UAAU,GAAG,GAAG,IAAI;AAAA,IAC3B;AAAA,IACA;AAAA,IACAC;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAM,YAAY,MAAO,gBAAgB,OAAO;AACxE,WAASA,SAAQ,UAAU,WAAW,YAAY,eAAe;AAEjE,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,WAAW,GAAG,GAAG,sBAAsB;AACnF;AAKA,eAAsB,mBACpB,UACA,OACA,SACiB;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,WAAW,KAAK,aAAa,QAAQ,eAAe,KAAK,IAAI;AAErE,QAAM,QAAQD,WAAU,KAAK;AAC7B,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAG9C,MAAI,UAAU,eAAe,SAAS,mBAAmB;AACzD,MAAI,OAAO;AACT,cAAU,UAAU;AAAA,EACtB;AACA,QAAM,WAAW,MAAM,gBAAgB,QAAQ,OAAO;AAEtD,QAAM,aAAa,YAAY,MAAM;AACrC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,sBAAsB;AAG1F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,YAAY,KAAK,IAAI;AACvC,WAAK,UAAU,GAAG,KAAK,IAAI;AAAA,IAC7B;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYC,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAM,YAAY,MAAO,gBAAgB,OAAO;AACxE,iBAAe,UAAU,UAAU,WAAW,YAAY,eAAe;AAEzE,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,WAAW,GAAG,GAAG,sBAAsB;AACnF;AAMA,eAAsB,WACpB,UACA,OACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,MAAM,OAAO,MAAM,eAAe,KAAK,IAAI;AAEnD,QAAM,QAAQD,WAAU,KAAK;AAC7B,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAG9C,QAAM,cAAc,OAAO,SAAS;AACpC,QAAM,UAAU,kBAAkB,aAAa,KAAK;AACpD,QAAM,WAAW,MAAM,gBAAgB,QAAQ,OAAO;AAEtD,QAAM,eAAe,QAAS,MAAM,OAAO,OAAO;AAClD,QAAM,aAAa,eAAe;AAClC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,aAAa;AAGjF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,cAAc,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,UAAU,2BAA2B,eAAe,OAAO,QAAQ,IAAI;AAE7E,QAAM,YAAYC,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,eAAe,gBAAgB,OAAO;AACnE,iBAAe,UAAU,UAAU,WAAW,YAAY,MAAM;AAEhE,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,YAAY,GAAG,aAAa;AACxE;;;ACzVA;AACA;AAEA;AACA;AACA;AACA;AAMA,SAASC,WAAU,OAAwB;AACzC,SAAO,MAAM,UAAU;AACzB;AAWA,eAAsB,QACpB,OACA,UAAuB,CAAC,GACP;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,MAAM,OAAO,MAAM,eAAe,KAAK,IAAI;AAEnD,QAAM,QAAQD,WAAU,KAAK;AAC7B,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAI9C,MAAI;AACJ,MAAI,MAAM;AACR,cAAU,QAAQ,uBAAuB;AAAA,EAC3C,OAAO;AACL,cAAU;AAAA,EACZ;AACA,QAAM,WAAW,MAAM,eAAe,QAAQ,OAAO;AAErD,QAAM,eAAe,QAAS,MAAM,OAAO,OAAO;AAClD,QAAM,aAAa,eAAe;AAClC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,aAAa;AAGjF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,cAAc,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,IACAC;AAAA,EACF;AAIA,QAAM,aAAa,OAAO,KAAK,SAAS,MAAM;AAC9C,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IACjD;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,eAAe,gBAAgB,OAAO;AACnE,WAASA,SAAQ,UAAU,WAAW,YAAY,MAAM;AAExD,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,YAAY,GAAG,aAAa;AACxE;AAMA,eAAsB,WACpB,UACA,OACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,MAAM,OAAO,MAAM,eAAe,KAAK,IAAI;AAEnD,QAAM,QAAQD,WAAU,KAAK;AAC7B,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAI9C,MAAI;AACJ,MAAI,MAAM;AACR,cAAU,QAAQ,uBAAuB;AAAA,EAC3C,OAAO;AACL,cAAU;AAAA,EACZ;AACA,QAAM,WAAW,MAAM,eAAe,QAAQ,OAAO;AAErD,QAAM,eAAe,QAAS,MAAM,OAAO,OAAO;AAClD,QAAM,aAAa,eAAe;AAClC,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,aAAa;AAGjF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,cAAc,IAAI;AAAA,IACtC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,UAA+B;AAAA,IACnC,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,IAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,IACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,EAC7C;AAGA,MAAI,MAAM;AACR,YAAQ,KAAK,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,KAAK,OAAO,EAAE,CAAC;AAAA,EAChE;AAEA,QAAM,YAAYC,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,eAAe,gBAAgB,OAAO;AACnE,iBAAe,UAAU,UAAU,WAAW,YAAY,MAAM;AAEhE,SAAO,aAAa,QAAQ,MAAM,OAAO,CAAC,YAAY,GAAG,aAAa;AACxE;;;AChJA;AACA;AAEA;AAEA;AACA;AACA;AAcA,eAAsB,SACpB,OACA,OACA,UAAwB,CAAC,GACR;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,OAAO,eAAe,MAAM,UAAU,MAAM,IAAI;AAExD,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAC9C,QAAM,gBAAgB,SAAS,KAAK,MAAM,MAAM,OAAO,OAAO,eAAe;AAC7E,QAAM,UAAU,UAAU,YAAY;AACtC,QAAM,WAAW,MAAM,eAAe,SAAS,OAAO;AAEtD,QAAM,aAAa,gBAAgB;AACnC,QAAM,YAAY,UAAU,MAAM,SAAU,gBAAgB,cAAc,YAAY,QAAW,cAAc;AAG/G,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,eAAe,IAAI;AACrC,WAAK,WAAW,GAAG,OAAO,IAAI;AAAA,IAEhC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,IAChD;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,gBAAgB,gBAAgB,OAAO;AACpE,WAASA,SAAQ,UAAU,WAAW,YAAY,OAAO;AAEzD,gBAAc,QAAQ;AAEtB,SAAO,aAAa,WAAW,MAAM,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,cAAc;AAC9E;AAKA,eAAsB,YACpB,UACA,OACA,OACA,UAAwB,CAAC,GACR;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,OAAO,eAAe,MAAM,UAAU,MAAM,IAAI;AAExD,QAAM,kBAAkB,WAAW,MAAM,KAAK;AAC9C,QAAM,gBAAgB,SAAS,KAAK,MAAM,MAAM,OAAO,OAAO,eAAe;AAC7E,QAAM,UAAU,UAAU,YAAY;AACtC,QAAM,WAAW,MAAM,eAAe,SAAS,OAAO;AAEtD,QAAM,aAAa,gBAAgB;AACnC,QAAM,YAAY,UAAU,MAAM,SAAU,gBAAgB,cAAc,YAAY,QAAW,cAAc;AAG/G,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,eAAe,IAAI;AACrC,WAAK,WAAW,GAAG,OAAO,IAAI;AAAA,IAEhC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,IAChD;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,gBAAgB,gBAAgB,OAAO;AACpE,iBAAe,UAAU,UAAU,WAAW,YAAY,OAAO;AAEjE,SAAO,aAAa,WAAW,MAAM,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,cAAc;AAC9E;;;ACnHA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAUA,IAAM,kBAA0C;AAAA,EAC9C,qBAAqB;AAAA,EACrB,oBAAoB;AAAA,EACpB,oBAAoB;AAAA,EACpB,mBAAmB;AAAA,EACnB,oBAAoB;AAAA,EACpB,mBAAmB;AAAA,EACnB,mBAAmB;AAAA,EACnB,kBAAkB;AACpB;AAKA,SAAS,oBAAoB,aAAsB,cAAuB,SAA0B;AAClG,QAAM,MAAM,GAAG,WAAW,IAAI,YAAY,IAAI,OAAO;AACrD,QAAM,UAAU,gBAAgB,GAAG;AACnC,MAAI,CAAC,SAAS;AACZ,UAAM,IAAI,MAAM,uCAAuC,GAAG,EAAE;AAAA,EAC9D;AACA,SAAO;AACT;AAKA,SAAS,iBAAiB,SAAiB,cAA+B;AACxE,MAAI,CAAC,cAAc;AACjB,WAAO;AAAA,EACT;AACA,QAAMC,UAAS,gBAAgB,UAAU,OAAO;AAChD,SAAOA,QAAO,iBAAiB,iBAAiB;AAClD;AA6BA,eAAsB,UACpB,SACA,YACA,WACA,YACA,WACA,UAAyB,CAAC,GACT;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,UAAU;AAAA,IACV,eAAe;AAAA,IACf;AAAA,IACA,cAAc;AAAA,IACd,YAAY;AAAA,IACZ,iBAAiB;AAAA,IACjB,iBAAiB;AAAA,EACnB,IAAI;AAGJ,QAAM,OAAO,sBAAsB;AACnC,QAAM,gBAAgB,kBAAkB;AACxC,QAAM,cAAc,kBAAkB,SAAS,KAAK;AACpD,QAAM,eAAe,gBAAgB,SAAS,KAAK;AACnD,QAAM,MAAM,qBAAqB,SAAS,gBAAgB,UAAU,eAAe,SAAS,eAAe,SAAS,mBAAmB,aAAa,iBAAiB,WAAW,kBAAkB,YAAY,EAAE;AAGhN,QAAM,UAAU,oBAAoB,aAAa,cAAc,OAAO;AACtE,QAAM,MAAM,mBAAmB,OAAO,EAAE;AACxC,QAAM,WAAW,MAAM,gBAAgB,UAAU,OAAO;AAGxD,QAAM,iBAAiB,eAAe,QAAQ;AAC9C,QAAM,kBAAkB,YAAY,cAAc;AAClD,QAAM,aAAa,YAAY,aAAa;AAC5C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,eAAe;AAGnF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,IAAI,YAAY,IAAI,GAAG,IAAI;AAAA,IAC5C;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,gBAAgB,iBAAiB,SAAS,YAAY;AAC5D,QAAM,UAA+B;AAAA,IACnC,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,IAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,IAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IAC/C,EAAE,SAAS,eAAe,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,EACzD;AACA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAID,QAAM,aAAa,UACf,KAAK,KAAM,YAAY,aAAc,oBAAoB,IACzD,KAAK,KAAM,YAAY,aAAc,gBAAgB,OAAO;AAChE,MAAI,gBAAgB;AAClB,qBAAiBA,SAAQ,UAAU,WAAW,gBAAgB,gBAAgB,QAAQ;AAAA,EACxF,OAAO;AACL,aAASA,SAAQ,UAAU,WAAW,YAAY,QAAQ;AAAA,EAC5D;AAEA,gBAAc,QAAQ;AAEtB,QAAM,cAA2B,eAAe,QAAQ;AACxD,SAAO,aAAa,QAAQ,aAAa,CAAC,WAAW,UAAU,GAAG,eAAe;AACnF;AAMA,eAAsB,aACpB,UACA,SACA,YACA,WACA,YACA,WACA,UAAyB,CAAC,GACT;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,UAAU;AAAA,IACV,eAAe;AAAA,IACf;AAAA,IACA,cAAc;AAAA,IACd,YAAY;AAAA,IACZ,iBAAiB;AAAA,IACjB,iBAAiB;AAAA,EACnB,IAAI;AAGJ,QAAM,OAAO,sBAAsB;AACnC,QAAM,gBAAgB,kBAAkB;AACxC,QAAM,cAAc,kBAAkB,SAAS,KAAK;AACpD,QAAM,eAAe,gBAAgB,SAAS,KAAK;AAGnD,QAAM,UAAU,oBAAoB,aAAa,cAAc,OAAO;AACtE,QAAM,MAAM,mBAAmB,OAAO,EAAE;AACxC,QAAM,WAAW,MAAM,gBAAgB,UAAU,OAAO;AAGxD,QAAM,iBAAiB,eAAe,QAAQ;AAC9C,QAAM,kBAAkB,YAAY,cAAc;AAClD,QAAM,aAAa,YAAY,aAAa;AAC5C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,eAAe;AAGnF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,IAAI,YAAY,IAAI,GAAG,IAAI;AAAA,IAC5C;AAAA,IACA;AAAA,EACF;AAGA,QAAM,gBAAgB,iBAAiB,SAAS,YAAY;AAC5D,QAAM,UAA+B;AAAA,IACnC,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,IAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,IAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IAC/C,EAAE,SAAS,eAAe,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,EACzD;AACA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC;AAAA,EACF,CAAC;AAID,QAAM,aAAa,UACf,KAAK,KAAM,YAAY,aAAc,oBAAoB,IACzD,KAAK,KAAM,YAAY,aAAc,gBAAgB,OAAO;AAChE,MAAI,gBAAgB;AAClB,2BAAuB,UAAU,UAAU,WAAW,gBAAgB,gBAAgB,QAAQ;AAAA,EAChG,OAAO;AACL,mBAAe,UAAU,UAAU,WAAW,YAAY,QAAQ;AAAA,EACpE;AAEA,QAAM,cAA2B,eAAe,QAAQ;AACxD,SAAO,aAAa,QAAQ,aAAa,CAAC,WAAW,UAAU,GAAG,eAAe;AACnF;;;ACjPA;AACA;AAEA;AACA;AACA;AACA;;;ACLA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAUA,SAAS,oBAAoB,YAA8C;AACzE,QAAM,sBAAsB,WAAW;AACvC,SAAO,cAAc,sBACjB,CAAC,YAAY,GAAG,CAAC,IACjB,CAAC,qBAAqB,KAAK,KAAK,aAAa,mBAAmB,GAAG,CAAC;AAC1E;AAKA,SAAS,IAAI,GAAW,GAAmB;AACzC,QAAM,MAAM,CAAC,GAAW,MAAsB;AAC5C,QAAI,KAAK;AACT,QAAI,KAAK;AACT,WAAO,OAAO,GAAG;AACf,YAAM,IAAI;AACV,WAAK,KAAK;AACV,WAAK;AAAA,IACP;AACA,WAAO;AAAA,EACT;AACA,SAAQ,IAAI,IAAI,GAAG,CAAC,IAAK;AAC3B;AAQA,eAAsB,aACpB,OACA,UAAuB,CAAC,GACP;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,eAAe,KAAK,IAAI;AAChC,QAAM,cAAc,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAEzD,QAAM,WAAW,MAAM,eAAe,QAAQ,YAAY;AAE1D,QAAM,aAAa,cAAc,YAAY;AAC7C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,wBAAwB;AAE5F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,aAAa,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAGD,QAAM,aAAa,KAAK,KAAK,cAAc,gBAAgB,OAAO;AAClE,QAAM,eAAe,oBAAoB,UAAU;AAEnD,WAASA,SAAQ,UAAU,WAAW,cAAc,iBAAiB;AAIrE,QAAMA,QAAO,MAAM,oBAAoB;AAEvC,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,MAAM,QAAQ,GAAG,MAAM,KAAK,SAAS,wBAAwB;AACpH;AAKA,eAAsB,aACpB,OACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,eAAe,KAAK,IAAI;AAChC,QAAM,cAAc,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAEzD,QAAM,WAAW,MAAM,eAAe,QAAQ,YAAY;AAE1D,QAAM,aAAa,cAAc,YAAY;AAC7C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,wBAAwB;AAE5F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,aAAa,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,cAAc,gBAAgB,OAAO;AAClE,QAAM,eAAe,oBAAoB,UAAU;AAEnD,WAASA,SAAQ,UAAU,WAAW,cAAc,iBAAiB;AAErE,QAAMA,QAAO,MAAM,oBAAoB;AAEvC,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,MAAM,QAAQ,GAAG,MAAM,KAAK,SAAS,wBAAwB;AACpH;AAKA,eAAsB,mBACpB,UACA,OACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,eAAe,KAAK,IAAI;AAChC,QAAM,cAAc,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAEzD,QAAM,WAAW,MAAM,eAAe,QAAQ,YAAY;AAE1D,QAAM,aAAa,cAAc,YAAY;AAC7C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,wBAAwB;AAE5F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,aAAa,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,EACF;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAGD,QAAM,aAAa,KAAK,KAAK,cAAc,gBAAgB,OAAO;AAClE,QAAM,eAAe,oBAAoB,UAAU;AAEnD,iBAAe,UAAU,UAAU,WAAW,cAAc,iBAAiB;AAE7E,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,MAAM,QAAQ,GAAG,MAAM,KAAK,SAAS,wBAAwB;AACpH;AAKA,eAAsB,mBACpB,UACA,OACA,UAAuB,CAAC,GACP;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,eAAe,KAAK,IAAI;AAChC,QAAM,cAAc,MAAM,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAEzD,QAAM,WAAW,MAAM,eAAe,QAAQ,YAAY;AAE1D,QAAM,aAAa,cAAc,YAAY;AAC7C,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,wBAAwB;AAE5F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,aAAa,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,EACF;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAK,cAAc,gBAAgB,OAAO;AAClE,QAAM,eAAe,oBAAoB,UAAU;AAEnD,iBAAe,UAAU,UAAU,WAAW,cAAc,iBAAiB;AAE7E,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,MAAM,KAAK,GAAG,MAAM,QAAQ,GAAG,MAAM,KAAK,SAAS,wBAAwB;AACpH;AAKA,eAAsB,aACpB,OACA,OACA,OAAe,sBACE;AACjB,QAAM,cAAc,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AACnD,QAAM,QAAQ,gCAAgC,WAAW,UAAU,IAAI,eAAe,MAAM,IAAI,EAAE;AAClG,QAAMA,UAAS,UAAU;AAGzB,QAAM,SAASA,QAAO;AACtB,QAAM,gBAAgB,OAAO;AAC7B,QAAM,iBAAiB,OAAO;AAC9B,QAAM,aAAa,cAAc,YAAY;AAC7C,QAAM,QAAQ,yBAAyB,UAAU,mBAAmB,aAAa,oBAAoB,cAAc,EAAE;AAErH,MAAI,aAAa,eAAe;AAC9B,UAAM,IAAI;AAAA,MACR,yBAAoB,UAAU,yCAAyC,aAAa;AAAA,IAGtF;AAAA,EACF;AAEA,MAAI,aAAa,gBAAgB;AAE/B,WAAO,oBAAoB,OAAO,OAAO,MAAM,cAAc;AAAA,EAC/D;AAEA,QAAM,WAAW,MAAM,eAAe,eAAe,SAAS;AAC9D,QAAM,QAAQ,6BAA6B;AAE3C,QAAM,SAAS,cAAc,YAAY,QAAW,IAAI;AACxD,QAAM,QAAQ,2CAA2C,OAAO,IAAI,EAAE;AAEtE,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,aAAa,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AACA,QAAM,QAAQ,kCAAkC,WAAW,EAAE;AAE7D,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,EAAE;AAAA,MAC1C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AACD,QAAM,QAAQ,8BAA8B;AAI5C,QAAM,WAAW,KAAK,KAAK,cAAc,CAAC;AAC1C,QAAM,aAAa,KAAK,KAAK,WAAW,gBAAgB,OAAO;AAC/D,QAAM,eAAe,oBAAoB,UAAU;AAEnD,QAAM,QAAQ,0BAA0B,aAAa,CAAC,CAAC,IAAI,aAAa,CAAC,CAAC,mBAAmB,QAAQ,WAAW,WAAW,YAAY;AACvI,WAASA,SAAQ,UAAU,WAAW,cAAc,aAAa;AAGjE,QAAMA,QAAO,MAAM,oBAAoB;AACvC,QAAM,QAAQ,+BAA+B;AAE7C,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,KAAK,GAAG,IAAI;AACrD;AAKA,eAAsB,aACpB,OACA,OACA,OAAe,sBACE;AACjB,QAAM,cAAc,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AACnD,QAAMA,UAAS,UAAU;AACzB,QAAM,WAAW,MAAM,eAAe,eAAe,SAAS;AAE9D,QAAM,SAASA,QAAO;AACtB,QAAM,gBAAgB,OAAO;AAC7B,QAAM,iBAAiB,OAAO;AAC9B,QAAM,aAAa,cAAc,YAAY;AAE7C,MAAI,aAAa,eAAe;AAC9B,UAAM,IAAI;AAAA,MACR,yBAAoB,UAAU,yCAAyC,aAAa;AAAA,IACtF;AAAA,EACF;AACA,MAAI,aAAa,gBAAgB;AAC/B,UAAM,IAAI;AAAA,MACR,yBAAoB,UAAU,uDAAuD,cAAc;AAAA,IACrG;AAAA,EACF;AAEA,QAAM,SAAS,cAAc,YAAY,QAAW,IAAI;AAExD,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,aAAa,IAAI;AACnC,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AAAA,IAC3B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAEA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,EAAE;AAAA,MAC1C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,WAAW,KAAK,KAAK,cAAc,CAAC;AAC1C,QAAM,aAAa,KAAK,KAAK,WAAW,gBAAgB,OAAO;AAC/D,QAAM,eAAe,oBAAoB,UAAU;AAEnD,WAASA,SAAQ,UAAU,WAAW,cAAc,aAAa;AACjE,QAAMA,QAAO,MAAM,oBAAoB;AAEvC,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,KAAK,GAAG,IAAI;AACrD;AAKA,eAAe,oBACb,OACA,OACA,MACA,gBACiB;AACjB,QAAM,cAAc,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AACnD,QAAMA,UAAS,UAAU;AACzB,QAAM,WAAW,MAAM,eAAe,eAAe,SAAS;AAG9D,QAAM,iBAAiBA,QAAO,OAAO;AAErC,QAAM,cAAc,KAAK,IAAI,GAAG,KAAK,MAAM,iBAAiB,YAAY,IAAI,CAAC;AAC7E,QAAM,eAAe,KAAK,IAAI,GAAG,KAAK,MAAM,iBAAiB,YAAY,GAAG,CAAC;AAC7E,QAAM,YAAY,IAAI,aAAa,YAAY;AAE/C,MAAI,sBAAsB,KAAK,MAAM,iBAAiB,YAAY,GAAG;AACrE,yBAAuB,sBAAsB;AAC7C,MAAI,uBAAuB,GAAG;AAC5B,UAAM,IAAI,MAAM,sDAAiD,cAAc,eAAe,cAAc,GAAG;AAAA,EACjH;AACA,QAAM,YAAY,KAAK,KAAK,cAAc,mBAAmB;AAG7D,QAAM,aAAa,cAAc,YAAY;AAC7C,QAAM,SAAS,cAAc,YAAY,QAAW,IAAI;AAExD,QAAM,QAAQ,uBAAuB,WAAW,gBAAgB,SAAS,SAAS;AAElF,WAAS,WAAW,GAAG,WAAW,WAAW,YAAY;AACvD,UAAM,aAAa,WAAW;AAC9B,UAAM,WAAW,KAAK,KAAK,WAAW,KAAK,qBAAqB,WAAW;AAC3E,UAAM,YAAY,WAAW;AAE7B,UAAM,gBAAgB;AAAA,MACpB,oBAAoB,QAAQ;AAAA,MAC5B;AAAA,MACA,CAAC,SAAS;AACR,aAAK,UAAU,GAAG,WAAW,IAAI;AACjC,aAAK,UAAU,GAAG,GAAG,IAAI;AACzB,aAAK,UAAU,GAAG,GAAG,IAAI;AAAA,MAC3B;AAAA,MACA;AAAA,MACAA;AAAA,IACF;AAEA,UAAM,mBAAmB,aAAa,YAAY;AAClD,UAAM,oBAAoB,aAAa,YAAY;AACnD,UAAM,aAAa,KAAK,KAAK,YAAY,CAAC;AAC1C,UAAM,iBAAiB,aAAa,YAAY;AAChD,UAAM,kBAAkB,YAAY,YAAY;AAEhD,UAAM,YAAYA,QAAO,gBAAgB;AAAA,MACvC,OAAO,oBAAoB,QAAQ;AAAA,MACnC,QAAQ,SAAS,mBAAmB,CAAC;AAAA,MACrC,SAAS;AAAA,QACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,QAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,QAAQ,kBAAkB,MAAM,eAAe,EAAE;AAAA,QAC1F,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,QAAQ,mBAAmB,MAAM,gBAAgB,EAAE;AAAA,MAC/F;AAAA,IACF,CAAC;AAGD,UAAM,WAAW,KAAK,KAAK,YAAY,CAAC;AACxC,UAAM,aAAa,KAAK,KAAK,WAAW,gBAAgB,OAAO;AAC/D,UAAM,eAAe,oBAAoB,UAAU;AAEnD,aAASA,SAAQ,UAAU,WAAW,cAAc,oBAAoB,QAAQ,EAAE;AAElF,kBAAc,QAAQ;AAAA,EACxB;AAEA,SAAO,aAAa,QAAQ,OAAO,CAAC,GAAG,KAAK,GAAG,IAAI;AACrD;;;ADrbA,eAAe,oBACb,GACA,GACA,UACuD;AACvD,MAAI,EAAE,UAAU,EAAE,OAAO;AACvB,WAAO,EAAE,GAAG,GAAG,OAAO,CAAC,EAAE;AAAA,EAC3B;AAEA,MAAI,EAAE,UAAU,SAAS,EAAE,UAAU,OAAO;AAC1C,UAAM,SAAS,WAAW,MAAM,mBAAmB,UAAU,CAAC,IAAI,MAAM,aAAa,CAAC;AACtF,WAAO,EAAE,GAAG,QAAQ,GAAG,OAAO,CAAC,OAAO,MAAM,EAAE;AAAA,EAChD;AAEA,MAAI,EAAE,UAAU,SAAS,EAAE,UAAU,OAAO;AAC1C,UAAM,SAAS,WAAW,MAAM,mBAAmB,UAAU,CAAC,IAAI,MAAM,aAAa,CAAC;AACtF,WAAO,EAAE,GAAG,GAAG,QAAQ,OAAO,CAAC,OAAO,MAAM,EAAE;AAAA,EAChD;AAEA,SAAO,EAAE,GAAG,GAAG,OAAO,CAAC,EAAE;AAC3B;AAEA,eAAe,gBACb,MACA,MACA,UAC+C;AAC/C,MAAI,KAAK,UAAU,KAAK,OAAO;AAC7B,WAAO,EAAE,MAAM,OAAO,CAAC,EAAE;AAAA,EAC3B;AAEA,MAAI,KAAK,UAAU,SAAS,KAAK,UAAU,OAAO;AAChD,UAAM,SAAS,WAAW,MAAM,mBAAmB,UAAU,IAAI,IAAI,MAAM,aAAa,IAAI;AAC5F,WAAO,EAAE,MAAM,QAAQ,OAAO,CAAC,OAAO,MAAM,EAAE;AAAA,EAChD;AAEA,MAAI,KAAK,UAAU,SAAS,KAAK,UAAU,OAAO;AAChD,UAAM,SAAS,WAAW,MAAM,mBAAmB,UAAU,IAAI,IAAI,MAAM,aAAa,IAAI;AAC5F,WAAO,EAAE,MAAM,QAAQ,OAAO,CAAC,OAAO,MAAM,EAAE;AAAA,EAChD;AAEA,SAAO,EAAE,MAAM,OAAO,CAAC,EAAE;AAC3B;AAKA,eAAsB,eACpB,GACA,GACA,MACA,UAA2B,CAAC,GACX;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,UAAU,MAAM,eAAe,KAAK,IAAI;AAEhD,QAAM,EAAE,GAAG,UAAU,GAAG,UAAU,MAAM,IAAI,MAAM,oBAAoB,GAAG,CAAC;AAC1E,QAAM,cAAc,iBAAiB,UAAU,QAAQ;AACvD,QAAM,kBAAkB,WAAW,WAAW;AAE9C,QAAM,UAAU,UACX,gBAAgB,QAAQ,aAAa,SACrC,gBAAgB,QAAQ,gBAAgB;AAC7C,QAAM,WAAW,MAAM,gBAAgB,YAAY,OAAO;AAE1D,QAAM,aAAa,OAAO;AAC1B,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,iBAAiB;AAGrF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,MAAM,IAAI;AAAA,IAC9B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,OAAO,EAAE;AAAA,MACpD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,OAAO,EAAE;AAAA,MACpD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAID,QAAM,aAAa,UACf,KAAK,KAAK,OAAO,oBAAoB,IACrC,KAAK,KAAK,OAAO,gBAAgB,OAAO;AAC5C,WAASA,SAAQ,UAAU,WAAW,YAAY,UAAU;AAE5D,gBAAc,QAAQ;AAEtB,aAAW,QAAQ,OAAO;AACxB,kBAAc,IAAI;AAAA,EACpB;AAEA,SAAO,aAAa,QAAQ,aAAa,CAAC,IAAI,GAAG,iBAAiB;AACpE;AAKA,eAAsB,WACpB,MACA,MACA,WACA,KACA,UAA2B,CAAC,GACX;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,aAAa,GAAG,aAAa,EAAE,IAAI;AAE3C,QAAM,EAAE,MAAM,aAAa,MAAM,IAAI,MAAM,gBAAgB,MAAM,IAAI;AACrE,QAAM,UAAU,KAAK,UAAU,SAAS,YAAY,UAAU,QAAQ,QAAQ;AAC9E,QAAM,WAAW,MAAM,gBAAgB,YAAY,OAAO;AAG1D,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,KAAK,IAAI;AAC3B,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,IAAI,YAAY,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,KAAK,OAAO,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,OAAO,EAAE;AAAA,IACzD;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAM,YAAY,MAAO,gBAAgB,OAAO;AACxE,WAASA,SAAQ,UAAU,WAAW,YAAY,UAAU;AAE5D,gBAAc,QAAQ;AAEtB,aAAW,QAAQ,OAAO;AACxB,kBAAc,IAAI;AAAA,EACpB;AAGA,SAAO,aAAa,KAAK,QAAQ,KAAK,OAAO,CAAC,WAAW,GAAG,GAAG,iBAAiB;AAClF;AAKA,eAAsB,kBACpB,UACA,GACA,GACA,MACA,UAA2B,CAAC,GACX;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,eAAe,MAAM,UAAU,KAAK,IAAI;AAEhD,QAAM,EAAE,GAAG,UAAU,GAAG,UAAU,MAAM,IAAI,MAAM,oBAAoB,GAAG,GAAG,QAAQ;AACpF,QAAM,cAAc,iBAAiB,UAAU,QAAQ;AACvD,QAAM,kBAAkB,WAAW,WAAW;AAE9C,QAAM,UAAU,UACX,gBAAgB,QAAQ,aAAa,SACrC,gBAAgB,QAAQ,gBAAgB;AAC7C,QAAM,WAAW,MAAM,gBAAgB,YAAY,OAAO;AAE1D,QAAM,aAAa,OAAO;AAC1B,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,iBAAiB;AAGrF,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,MAAM,IAAI;AAAA,IAC9B;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,OAAO,EAAE;AAAA,MACpD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,OAAO,EAAE;AAAA,MACpD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,QAAM,aAAa,UACf,KAAK,KAAK,OAAO,oBAAoB,IACrC,KAAK,KAAK,OAAO,gBAAgB,OAAO;AAC5C,iBAAe,UAAU,UAAU,WAAW,YAAY,UAAU;AAEpE,aAAW,QAAQ,OAAO;AACxB,aAAS,qBAAqB,IAAI;AAAA,EACpC;AAEA,SAAO,aAAa,QAAQ,aAAa,CAAC,IAAI,GAAG,iBAAiB;AACpE;AAKA,eAAsB,cACpB,UACA,MACA,MACA,WACA,KACA,UAA2B,CAAC,GACX;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,aAAa,GAAG,aAAa,EAAE,IAAI;AAE3C,QAAM,EAAE,MAAM,aAAa,MAAM,IAAI,MAAM,gBAAgB,MAAM,MAAM,QAAQ;AAC/E,QAAM,UAAU,KAAK,UAAU,SAAS,YAAY,UAAU,QAAQ,QAAQ;AAC9E,QAAM,WAAW,MAAM,gBAAgB,YAAY,OAAO;AAG1D,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,KAAK,IAAI;AAC3B,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,IAAI,YAAY,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,KAAK,OAAO,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,OAAO,EAAE;AAAA,IACzD;AAAA,EACF,CAAC;AAED,QAAM,aAAa,KAAK,KAAM,YAAY,MAAO,gBAAgB,OAAO;AACxE,iBAAe,UAAU,UAAU,WAAW,YAAY,UAAU;AAEpE,aAAW,QAAQ,OAAO;AACxB,aAAS,qBAAqB,IAAI;AAAA,EACpC;AAGA,SAAO,aAAa,KAAK,QAAQ,KAAK,OAAO,CAAC,WAAW,GAAG,GAAG,iBAAiB;AAClF;;;AEhSA;AACA;AACA;AAEA;AACA;AACA;AAoBA,eAAsB,QACpB,OACA,WACA,YACA,MACA,UAAsB,CAAC,GAC8B;AACrD,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,YAAY,KAAK,IAAI;AAE7B,QAAM,WAAW,MAAM,eAAe,QAAQ,SAAS;AAGvD,QAAM,cAAc,YAAY,OAAO;AACvC,QAAM,cAAc,YAAY,OAAO;AACvC,QAAM,UAAU,cAAc,aAAa,QAAW,cAAc;AACpE,QAAM,UAAU,cAAc,aAAa,QAAW,cAAc;AAGpE,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,MAAM,IAAI;AAC5B,WAAK,UAAU,IAAI,YAAY,IAAI,GAAG,IAAI;AAAA,IAC5C;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,EAAE;AAAA,MAC1C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,IAC9C;AAAA,EACF,CAAC;AAED,WAASA,SAAQ,UAAU,WAAW,WAAW,MAAM;AAEvD,gBAAc,QAAQ;AAEtB,SAAO,EAAE,SAAS,QAAQ;AAC5B;AAqDA,IAAI,2BAAsD;AAE1D,SAAS,4BAA4BC,SAAuC;AAC1E,MAAI;AAA0B,WAAO;AAErC,6BAA2BA,QAAO,sBAAsB;AAAA,IACtD,OAAO;AAAA,IACP,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,MAC9E,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,oBAAoB,EAAE;AAAA,MACxF,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,oBAAoB,EAAE;AAAA,MACxF,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,MAC9E,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,MAC9E,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,IAChF;AAAA,EACF,CAAC;AACD,SAAO;AACT;AAMA,eAAsB,aACpB,cACA,eACA,WACA,YACA,YACA,MACA,UAAsB,CAAC,GACG;AAC1B,QAAMA,UAAS,UAAU;AACzB,QAAM,EAAE,qBAAqB,UAAU,IAAI;AAG3C,QAAM,iBAAiB,4BAA4BA,OAAM;AAGzD,QAAM,gBAAgB,MAAM,eAAe,cAAc,SAAS,cAAc;AAChF,QAAM,iBAAiB,MAAM,eAAe,cAAc,UAAU,cAAc;AAMlF,QAAM,kBAAkB,aAAa,UAAU,QAAQ,IAAI;AAC3D,QAAM,eAAe,aAAa,qBAAqB,aAAa;AACpE,QAAM,kBAAkB,aAAa;AACrC,QAAM,eAAe,aAAa,qBAAqB,IAAI;AAE3D,QAAM,iBAAiB,cAAc,cAAc,QAAW,cAAc;AAC5E,QAAM,cAAc,cAAc,iBAAiB,QAAW,kBAAkB;AAChF,QAAM,WAAW,cAAc,cAAc,QAAW,eAAe;AAGvE,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,IAAI,MAAM,IAAI;AAC7B,WAAK,UAAU,IAAI,oBAAoB,IAAI;AAC3C,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAAA,IAC5B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,OAAO,EAAE;AAAA,MACxD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,eAAe,EAAE;AAAA,MACnD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,EAAE;AAAA,IAC/C;AAAA,EACF,CAAC;AAGD,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,qBAAqB,CAAC;AAC3E,UAAQ,YAAY,WAAW;AAE/B,QAAM,YAAY,QAAQ,iBAAiB,EAAE,OAAO,wBAAwB,CAAC;AAC7E,YAAU,YAAY,aAAa;AACnC,YAAU,aAAa,GAAG,SAAS;AACnC,QAAM,kBAAkB,KAAK,KAAM,YAAY,OAAQ,gBAAgB,OAAO;AAC9E,YAAU,mBAAmB,eAAe;AAC5C,YAAU,IAAI;AAGd,QAAM,aAAa,QAAQ,iBAAiB,EAAE,OAAO,yBAAyB,CAAC;AAC/E,aAAW,YAAY,cAAc;AACrC,aAAW,aAAa,GAAG,SAAS;AACpC,QAAM,mBAAmB,KAAK,KAAM,aAAa,qBAAqB,aAAc,gBAAgB,OAAO;AAC3G,aAAW,mBAAmB,gBAAgB;AAC9C,aAAW,IAAI;AAEf,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAEtC,gBAAc,QAAQ;AAEtB,QAAM,WAAW;AAAA,IACf;AAAA,IACA,aAAa;AAAA,IACb,CAAC,YAAY,oBAAoB,UAAU;AAAA,IAC3C;AAAA,EACF;AAEA,SAAO,EAAE,UAAU,aAAa,UAAU,mBAAmB;AAC/D;AA+FA,eAAsB,cACpB,eACA,SACA,SACA,WACA,YACA,YACA,MACA,UAAsB,CAAC,GACN;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,eAAe,KAAK,IAAI;AAEhC,QAAM,WAAW,MAAM,eAAe,eAAe,SAAS;AAG9D,QAAM,kBAAkB,cAAc,UAAU,QAAQ,IAAI;AAC5D,QAAM,aAAa,YAAY,aAAa;AAC5C,QAAM,YAAY,gBAAgB,cAAc,YAAY,QAAW,oBAAoB;AAI3F,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,MAAM,IAAI;AAC5B,WAAK,UAAU,IAAI,YAAY,IAAI;AAAA,IACrC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,OAAO,EAAE;AAAA,MACzD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,IAChD;AAAA,EACF,CAAC;AAGD,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,sBAAsB,CAAC;AAC5E,UAAQ,YAAY,SAAS;AAC7B,QAAM,OAAO,QAAQ,iBAAiB,EAAE,OAAO,mBAAmB,CAAC;AACnE,OAAK,YAAY,QAAQ;AACzB,OAAK,aAAa,GAAG,SAAS;AAG9B,QAAM,aAAa,KAAK,KAAM,YAAY,aAAc,gBAAgB,OAAO;AAC/E,OAAK,mBAAmB,UAAU;AAClC,OAAK,IAAI;AAET,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAEtC,gBAAc,QAAQ;AAEtB,SAAO,aAAa,WAAW,cAAc,OAAO,CAAC,WAAW,UAAU,GAAG,oBAAoB;AACnG;AAgEA,eAAsB,qBACpB,eACA,SACA,SACA,cACA,WACA,YACA,MACA,UAAsB,CAAC,GACN;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM,EAAE,eAAe,KAAK,IAAI;AAEhC,QAAM,WAAW,MAAM,eAAe,eAAe,SAAS;AAG9D,QAAM,kBAAkB,cAAc,UAAU,QAAQ,IAAI;AAC5D,QAAM,aAAa,YAAY,aAAa;AAC5C,QAAM,YAAY,gBAAgB,cAAc,YAAY,QAAW,4BAA4B;AAGnG,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,YAAY,IAAI;AAClC,WAAK,UAAU,GAAG,MAAM,IAAI;AAAA,IAC9B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,OAAO,EAAE;AAAA,MACzD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,EAAE;AAAA,IAChD;AAAA,EACF,CAAC;AAGD,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,8BAA8B,CAAC;AACpF,UAAQ,YAAY,SAAS;AAC7B,QAAM,OAAO,QAAQ,iBAAiB,EAAE,OAAO,2BAA2B,CAAC;AAC3E,OAAK,YAAY,QAAQ;AACzB,OAAK,aAAa,GAAG,SAAS;AAE9B,QAAM,aAAa,KAAK,KAAM,YAAY,OAAO,aAAc,gBAAgB,OAAO;AACtF,OAAK,mBAAmB,UAAU;AAClC,OAAK,IAAI;AAET,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAEtC,gBAAc,QAAQ;AAEtB,SAAO,aAAa,WAAW,cAAc,OAAO,CAAC,WAAW,UAAU,GAAG,4BAA4B;AAC3G;;;AClhBA;AACA;AACA;AACA;AACA;AAEA;AAoBA,SAAS,yBAAyBC,SAAuC;AACvE,SAAO;AAAA,IACL;AAAA,IACA;AAAA,MACE,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,MAC9E,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,oBAAoB,EAAE;AAAA,MACxF,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,MAC9E,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,MAC9E,EAAE,SAAS,GAAG,YAAY,eAAe,SAAS,QAAQ,EAAE,MAAM,UAAU,EAAE;AAAA,IAChF;AAAA,IACAA;AAAA,EACF;AACF;AAKA,eAAe,qBAAqBA,SAAmB,YAAiD;AACtG,SAAO,eAAe,UAAU,YAAY,yBAAyBA,OAAM,CAAC;AAC9E;AAMA,eAAsB,UACpB,QACA,WACA,UAAyB,CAAC,GACT;AACjB,MAAI,CAAC,cAAc,kBAAkB,GAAG;AACtC,UAAM,IAAI,MAAM,2CAA2C;AAAA,EAC7D;AAEA,QAAMA,UAAS,UAAU;AACzB,MAAI,CAACA;AAAQ,UAAM,IAAI,MAAM,4BAA4B;AAGzD,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,QAAQ;AAClE,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,eAAe;AAGzE,QAAM,gBAAgB,gBAAgB;AACtC,QAAM,gBAAgB,KAAK,IAAI,eAAe,KAAK,KAAK,YAAY,aAAa,CAAC;AAGlF,QAAM,aAAa,cAAc,gBAAgB,GAAG,QAAW,oBAAoB;AACnF,QAAM,cAAc,cAAc,gBAAgB,GAAG,QAAW,qBAAqB;AACrF,QAAM,eAAe,cAAc,GAAG,QAAW,eAAe;AAGhE,QAAM,aAAa,QAAQ,cAAc;AACzC,QAAM,eAAe,QAAQ,gBAAgB;AAC7C,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,GAAG,GAAK,IAAI;AAC5B,WAAK,WAAW,IAAI,GAAK,IAAI;AAC7B,WAAK,UAAU,IAAI,YAAY,IAAI;AACnC,WAAK,WAAW,IAAI,cAAc,IAAI;AAAA,IACxC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,kBAAkB,yBAAyBA,OAAM;AACvD,QAAM,kBAAkBA,QAAO,gBAAgB;AAAA,IAC7C,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IACjD;AAAA,EACF,CAAC;AAED,QAAM,kBAAkBA,QAAO,gBAAgB;AAAA,IAC7C,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IACjD;AAAA,EACF,CAAC;AAGD,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,iBAAiB,CAAC;AAGvE,QAAM,QAAQ,QAAQ,iBAAiB,EAAE,OAAO,eAAe,CAAC;AAChE,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,eAAe;AACrC,QAAM,mBAAmB,aAAa;AACtC,QAAM,IAAI;AAGV,QAAM,QAAQ,QAAQ,iBAAiB,EAAE,OAAO,eAAe,CAAC;AAChE,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,eAAe;AACrC,QAAM,mBAAmB,CAAC;AAC1B,QAAM,IAAI;AAEV,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAGtC,QAAM,gBAAgBA,QAAO,aAAa;AAAA,IACxC,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO,eAAe,WAAW,eAAe;AAAA,EAClD,CAAC;AAED,QAAM,cAAcA,QAAO,qBAAqB,EAAE,OAAO,cAAc,CAAC;AACxE,cAAY,mBAAmB,cAAc,GAAG,eAAe,GAAG,CAAC;AACnE,EAAAA,QAAO,MAAM,OAAO,CAAC,YAAY,OAAO,CAAC,CAAC;AAE1C,QAAM,cAAc,SAAS,WAAW,IAAI;AAC5C,QAAM,UAAU,IAAI,YAAY,cAAc,eAAe,CAAC,EAAE,CAAC;AACjE,gBAAc,MAAM;AAGpB,gBAAc,QAAQ;AACtB,gBAAc,QAAQ;AACtB,gBAAc,UAAU;AACxB,gBAAc,WAAW;AACzB,gBAAc,YAAY;AAE1B,SAAO;AACT;AAMA,eAAsB,aACpB,QACA,WACA,UAAyB,CAAC,GACT;AACjB,MAAI,CAAC,cAAc,qBAAqB,GAAG;AACzC,UAAM,IAAI,MAAM,6CAA6C;AAAA,EAC/D;AAEA,QAAM,mBAAmB,iBAAiB,EAAE,UAAU;AACtD,QAAM;AAAA,IACJ,cAAc,iBAAiB;AAAA,IAC/B,OAAO,iBAAiB;AAAA,IACxB;AAAA,IACA;AAAA,IACA,eAAe;AAAA,EACjB,IAAI;AAGJ,QAAM,EAAE,gBAAgB,IAAI,iBAAiB,EAAE,UAAU;AACzD,MAAI,cAAc,iBAAiB;AACjC,WAAO,UAAU,QAAQ,WAAW,EAAE,YAAY,aAAa,CAAC;AAAA,EAClE;AAEA,QAAMA,UAAS,UAAU;AACzB,MAAI,CAACA;AAAQ,UAAM,IAAI,MAAM,4BAA4B;AAGzD,QAAM,cAAc,eAAe,SAC/B,aAAa,UAAU,IACvB,KAAK,OAAO;AAGhB,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,kBAAkB;AAC5E,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,kBAAkB;AAC5E,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,oBAAoB;AAG9E,QAAM,gBAAgB,gBAAgB;AACtC,QAAM,gBAAgB,KAAK,IAAI,eAAe,KAAK,KAAK,YAAY,aAAa,CAAC;AAGlF,QAAM,aAAa,cAAc,gBAAgB,GAAG,QAAW,aAAa;AAC5E,QAAM,cAAc,cAAc,gBAAgB,GAAG,QAAW,cAAc;AAC9E,QAAM,eAAe,cAAc,GAAG,QAAW,eAAe;AAGhE,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,MAAM,IAAI;AAC5B,WAAK,WAAW,GAAG,aAAa,IAAI;AACpC,WAAK,WAAW,IAAI,aAAa,IAAI;AACrC,WAAK,UAAU,IAAI,cAAc,YAAY,IAAI;AACjD,WAAK,WAAW,IAAI,cAAc,IAAI;AAAA,IACxC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,kBAAkB,yBAAyBA,OAAM;AACvD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IACjD;AAAA,EACF,CAAC;AAGD,QAAM,UAAUA,QAAO,qBAAqB,EAAE,OAAO,iBAAiB,CAAC;AAGvE,QAAM,QAAQ,QAAQ,iBAAiB,EAAE,OAAO,gBAAgB,CAAC;AACjE,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,SAAS;AAC/B,QAAM,mBAAmB,aAAa;AACtC,QAAM,IAAI;AAGV,QAAM,QAAQ,QAAQ,iBAAiB,EAAE,OAAO,gBAAgB,CAAC;AACjE,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,SAAS;AAC/B,QAAM,mBAAmB,CAAC;AAC1B,QAAM,IAAI;AAGV,QAAM,QAAQ,QAAQ,iBAAiB,EAAE,OAAO,gBAAgB,CAAC;AACjE,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,SAAS;AAC/B,QAAM,mBAAmB,CAAC;AAC1B,QAAM,IAAI;AAEV,EAAAA,QAAO,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAGtC,QAAM,gBAAgBA,QAAO,aAAa;AAAA,IACxC,OAAO;AAAA,IACP,MAAM;AAAA,IACN,OAAO,eAAe,WAAW,eAAe;AAAA,EAClD,CAAC;AAED,QAAM,cAAcA,QAAO,qBAAqB,EAAE,OAAO,cAAc,CAAC;AACxE,cAAY,mBAAmB,cAAc,GAAG,eAAe,GAAG,CAAC;AACnE,EAAAA,QAAO,MAAM,OAAO,CAAC,YAAY,OAAO,CAAC,CAAC;AAE1C,QAAM,cAAc,SAAS,WAAW,IAAI;AAC5C,QAAM,UAAU,IAAI,YAAY,cAAc,eAAe,CAAC,EAAE,CAAC;AACjE,gBAAc,MAAM;AAGpB,gBAAc,QAAQ;AACtB,gBAAc,QAAQ;AACtB,gBAAc,UAAU;AACxB,gBAAc,WAAW;AACzB,gBAAc,YAAY;AAE1B,SAAO;AACT;AAMA,eAAsB,aACpB,UACA,QACA,WACA,UAAyB,CAAC,GACN;AACpB,QAAMA,UAAS,SAAS;AAGxB,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,QAAQ;AAClE,QAAM,iBAAiB,MAAM,qBAAqBA,SAAQ,eAAe;AAEzE,QAAM,gBAAgB,KAAK,IAAI,gBAAgB,SAAS,KAAK,KAAK,YAAY,gBAAgB,OAAO,CAAC;AAGtG,QAAM,aAAa,cAAc,gBAAgB,UAAU,GAAG,QAAW,oBAAoB;AAC7F,QAAM,cAAc,cAAc,gBAAgB,UAAU,GAAG,QAAW,qBAAqB;AAC/F,QAAM,eAAe,cAAc,GAAG,QAAW,eAAe;AAGhE,QAAM,aAAa,QAAQ,cAAc;AACzC,QAAM,eAAe,QAAQ,gBAAgB;AAC7C,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,GAAG,GAAK,IAAI;AAC5B,WAAK,WAAW,IAAI,GAAK,IAAI;AAC7B,WAAK,UAAU,IAAI,YAAY,IAAI;AACnC,WAAK,WAAW,IAAI,cAAc,IAAI;AAAA,IACxC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,kBAAkB,yBAAyBA,OAAM;AACvD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IACjD;AAAA,EACF,CAAC;AAGD,QAAM,QAAQ,SAAS,iBAAiB,eAAe;AACvD,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,SAAS;AAC/B,QAAM,mBAAmB,aAAa;AACtC,QAAM,IAAI;AAGV,QAAM,kBAAkBA,QAAO,gBAAgB;AAAA,IAC7C,OAAO;AAAA,IACP,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,YAAY,EAAE;AAAA,MAChD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,WAAW,EAAE;AAAA,IACjD;AAAA,EACF,CAAC;AAED,QAAM,QAAQ,SAAS,iBAAiB,eAAe;AACvD,QAAM,YAAY,cAAc;AAChC,QAAM,aAAa,GAAG,eAAe;AACrC,QAAM,mBAAmB,CAAC;AAC1B,QAAM,IAAI;AAGV,WAAS,qBAAqB,UAAU;AACxC,WAAS,qBAAqB,WAAW;AAEzC,SAAO;AACT;AA2GA,SAAS,aAAa,MAAsB;AAC1C,QAAM,IAAI,KAAK,IAAI,IAAI,IAAI;AAC3B,SAAO,IAAI,KAAK,MAAM,CAAC;AACzB;AAKO,SAAS,yBAAkC;AAChD,SAAO,UAAU,MAAM;AACzB;;;AC3eA;AACA;AACA;AAGA;AAEA;AACA;AAgBA,IAAM,iBAAN,cAA6B,WAAW;AAAA,EACtC,MAAM,YAAY,SAA8C;AAC9D,WAAO,KAAK,eAAe,aAAa,OAAO;AAAA,EACjD;AAAA,EAEA,SACE,UACA,WACA,aACA,cAAsB,GAChB;AACN,SAAK,eAAe,UAAU,WAAW,CAAC,aAAa,aAAa,CAAC,GAAG,WAAW;AAAA,EACrF;AAAA,EAEA,OACE,UACA,UACA,WACA,aACA,cAAsB,GAChB;AACN,SAAK,aAAa,UAAU,UAAU,WAAW,CAAC,aAAa,aAAa,CAAC,GAAG,WAAW;AAAA,EAC7F;AACF;AAEA,SAAS,iBACP,WACA,aACA,kBACQ;AAER,MAAI,gBAAgB,SAAS,CAAC,mBAAmB,GAAG;AAClD,WAAO,YAAY,IAAI,gBAAgB;AAAA,EACzC;AAGA,MAAI,YAAY,GAAG;AACjB,WAAO;AAAA,EACT;AAEA,MAAI,gBAAgB,OAAO;AACzB,WAAO;AAAA,EACT;AAEA,MAAI,oBAAoB,MAAM;AAC5B,WAAO;AAAA,EACT;AAGA,SAAO;AACT;AAEA,SAAS,uBACPC,SACA,UACA,QAQW;AACX,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,OAAO,GAAG,IAAI;AAChC,WAAK,UAAU,GAAG,OAAO,YAAY,IAAI;AACzC,WAAK,UAAU,GAAG,OAAO,kBAAkB,IAAI;AAC/C,WAAK,WAAW,IAAI,OAAO,OAAO,IAAI;AACtC,WAAK,UAAU,IAAI,OAAO,eAAe,SAAS,IAAI,GAAG,IAAI;AAE7D,UAAI,OAAO,OAAO;AAChB,aAAK,UAAU,IAAI,KAAK,MAAM,OAAO,aAAa,GAAG,GAAG,IAAI;AAAA,MAC9D;AAAA,IACF;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AACF;AAeA,eAAsB,YACpB,OACA,QACA,MACA,YACA,kBACA,UAA2B,CAAC,GACX;AACjB,QAAMA,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ,YAAY;AAAA,IACZ,aAAa;AAAA,IACb,QAAQ;AAAA,IACR,eAAe;AAAA,EACjB,IAAI;AAEJ,MAAI,MAAM,UAAU,OAAO;AACzB,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAEA,QAAM,YAAY,eAAe,MAAM,KAAK;AAC5C,QAAM,UAAU,eAAe,IAAI,KAAK;AACxC,MAAI,cAAc,SAAS;AACzB,UAAM,IAAI,MAAM,oDAAoD,SAAS,QAAQ,OAAO,GAAG;AAAA,EACjG;AACA,MAAI,cAAc,SAAS,cAAc,SAAS,cAAc,OAAO;AACrE,UAAM,IAAI,MAAM,8BAA8B,SAAS,UAAU;AAAA,EACnE;AAEA,QAAM,QAAQ,cAAc;AAC5B,QAAM,UAAU,iBAAiB,WAAW,WAAoC,gBAAgB;AAEhG,QAAM,QAAQ,qBAAqB,OAAO,WAAW,SAAS,YAAY,UAAU,kBAAkB,gBAAgB,gBAAgB,UAAU,WAAW,KAAK,EAAE;AAElK,QAAM,SAAS,IAAI,eAAeA,OAAM;AACxC,QAAM,WAAW,MAAM,OAAO,YAAY,OAAO;AAGjD,QAAM,aAAa,YAAY,mBAAmB;AAClD,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,kBAAkB;AAGtF,QAAM,gBAAgB,uBAAuBA,SAAQ,MAAM;AAAA,IACzD,GAAG;AAAA,IACH;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC;AAGD,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,MAAM,EAAE,EAAE;AAAA,MACtD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,IAAI,EAAE,EAAE;AAAA,MACpD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAGD,MAAI;AACJ,MAAI,cAAsB;AAE1B,MAAI,YAAY,SAAS;AACvB,UAAM,eAAe;AACrB,kBAAc,KAAK,KAAK,mBAAmB,YAAY;AAAA,EACzD,WAAW,YAAY,SAAS,YAAY,eAAe;AAEzD,UAAM,YAAY;AAClB,kBAAc,KAAK,KAAK,mBAAmB,SAAS;AACpD,kBAAc,YAAY,gBAAgB,YAAY;AAAA,EACxD,WAAW,YAAY,WAAW;AAChC,kBAAc;AACd,kBAAc;AAAA,EAChB,OAAO;AACL,kBAAc;AAAA,EAChB;AAEA,SAAO,SAAS,UAAU,WAAW,aAAa,WAAW;AAE7D,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,OAAO,CAAC,WAAW,gBAAgB,GAAG,kBAAkB;AACtF;AAKA,eAAsB,eACpB,UACA,OACA,QACA,MACA,YACA,kBACA,UAA2B,CAAC,GACX;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ,YAAY;AAAA,IACZ,aAAa;AAAA,IACb,QAAQ;AAAA,IACR,eAAe;AAAA,EACjB,IAAI;AAEJ,MAAI,MAAM,UAAU,OAAO;AACzB,UAAM,IAAI,MAAM,oCAAoC;AAAA,EACtD;AAEA,QAAM,YAAY,eAAe,MAAM,KAAK;AAC5C,QAAM,UAAU,eAAe,IAAI,KAAK;AACxC,MAAI,cAAc,SAAS;AACzB,UAAM,IAAI,MAAM,oDAAoD,SAAS,QAAQ,OAAO,GAAG;AAAA,EACjG;AACA,MAAI,cAAc,SAAS,cAAc,SAAS,cAAc,OAAO;AACrE,UAAM,IAAI,MAAM,8BAA8B,SAAS,UAAU;AAAA,EACnE;AAEA,QAAM,QAAQ,cAAc;AAC5B,QAAM,UAAU,iBAAiB,WAAW,WAAoC,gBAAgB;AAEhG,QAAM,QAAQ,4BAA4B,OAAO,WAAW,SAAS,YAAY,UAAU,kBAAkB,gBAAgB,gBAAgB,UAAU,WAAW,KAAK,EAAE;AAEzK,QAAM,SAAS,IAAI,eAAeA,OAAM;AACxC,QAAM,WAAW,MAAM,OAAO,YAAY,OAAO;AAEjD,QAAM,aAAa,YAAY,mBAAmB;AAClD,QAAM,SAAS,gBAAgB,cAAc,YAAY,QAAW,kBAAkB;AAEtF,QAAM,gBAAgB,uBAAuBA,SAAQ,UAAU;AAAA,IAC7D,GAAG;AAAA,IACH;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC;AAED,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,MAAM,EAAE,EAAE;AAAA,MACtD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,IAAI,EAAE,EAAE;AAAA,MACpD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,IAC7C;AAAA,EACF,CAAC;AAED,MAAI;AACJ,MAAI,cAAsB;AAE1B,MAAI,YAAY,SAAS;AACvB,UAAM,eAAe;AACrB,kBAAc,KAAK,KAAK,mBAAmB,YAAY;AAAA,EACzD,WAAW,YAAY,SAAS,YAAY,eAAe;AAEzD,UAAM,YAAY;AAClB,kBAAc,KAAK,KAAK,mBAAmB,SAAS;AACpD,kBAAc,YAAY,gBAAgB,YAAY;AAAA,EACxD,WAAW,YAAY,WAAW;AAChC,kBAAc;AACd,kBAAc;AAAA,EAChB,OAAO;AACL,kBAAc;AAAA,EAChB;AAEA,SAAO,OAAO,UAAU,UAAU,WAAW,aAAa,WAAW;AAErE,SAAO,aAAa,QAAQ,OAAO,CAAC,WAAW,gBAAgB,GAAG,kBAAkB;AACtF;AAKO,SAAS,yBACd,WACA,YACA,kBAMA;AAIA,QAAM,aAAa,YAAY,aAAa;AAC5C,QAAM,oBAAoB,YAAY,mBAAmB;AACzD,QAAM,gBAAgB,IAAI,aAAa,IAAI;AAK3C,QAAM,aAAa,aAAa;AAEhC,QAAM,eAAe,gBAAgB;AACrC,QAAM,aAAc,eAAe,gBAAiB;AAEpD,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;;;AjBtLA;AASA;;;AkBnKA;AACA;AACA;AAEA;AAEA;AACA;AAGA;AAiBO,SAAS,6BAA6B,GAAoB;AAC/D,SAAO,MAAM;AACf;AAcA,eAAsB,uBACpB,OACA,QACA,UACA,SACiB;AACjB,QAAMC,UAAS,UAAU;AACzB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA,QAAQ;AAAA,IACR,eAAe;AAAA,EACjB,IAAI;AAEJ,QAAM,eAAe,UAAU,MAAM;AACrC,QAAM,cAA2B,MAAM;AAEvC,QAAM,QAAQ,0BAA0B,CAAC,OAAO,CAAC,WAAW,KAAK,WAAW,WAAW,EAAE;AAEzF,QAAM,WAAW,MAAM,gBAAgB,yBAAyB,SAAS;AAEzE,QAAM,SAAS,gBAAgB,cAAc,IAAI,WAAW,WAAW,GAAG,QAAW,wBAAwB;AAG7G,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,IAAI,OAAO,IAAI;AAC/B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAAA,IAC5B;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,OAAO,EAAE;AAAA,IACtD;AAAA,EACF,CAAC;AAGD,QAAM,aAAa;AACnB,WAASA,SAAQ,UAAU,WAAW,YAAY,uBAAuB;AAEzE,gBAAc,QAAQ;AAEtB,SAAO,aAAa,QAAQ,aAAa,CAAC,GAAG,CAAC,GAAG,wBAAwB;AAC3E;AAKA,eAAsB,0BACpB,UACA,OACA,QACA,UACA,SACiB;AACjB,QAAMA,UAAS,SAAS;AACxB,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA,QAAQ;AAAA,IACR,eAAe;AAAA,EACjB,IAAI;AAEJ,QAAM,eAAe,UAAU,MAAM;AACrC,QAAM,cAA2B,MAAM;AAEvC,QAAM,WAAW,MAAM,gBAAgB,yBAAyB,SAAS;AAEzE,QAAM,SAAS,gBAAgB,cAAc,IAAI,WAAW,WAAW,GAAG,QAAW,wBAAwB;AAG7G,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,UAAU,GAAG,GAAG,IAAI;AACzB,WAAK,WAAW,IAAI,OAAO,IAAI;AAC/B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAC1B,WAAK,UAAU,IAAI,GAAG,IAAI;AAAA,IAC5B;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,MAAM,OAAO,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,aAAa,EAAE;AAAA,MACjD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,OAAO,EAAE;AAAA,MAC3C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,SAAS,OAAO,EAAE;AAAA,IACtD;AAAA,EACF,CAAC;AAGD,QAAM,aAAa;AACnB,iBAAe,UAAU,UAAU,WAAW,YAAY,uBAAuB;AAEjF,SAAO,aAAa,QAAQ,aAAa,CAAC,GAAG,CAAC,GAAG,wBAAwB;AAC3E;;;AC3JA;AACA;AACA;AACA;AA4BO,IAAM,kBAAN,MAAM,iBAAgB;AAAA,EAClB;AAAA,EACA;AAAA,EACD;AAAA;AAAA,EAGA;AAAA,EACA,iBAAuC;AAAA;AAAA,EAGvC;AAAA;AAAA,EAGA;AAAA;AAAA,EAGA;AAAA,EACA,WAA+B;AAAA,EAC/B,cAAgC;AAAA,EAChC,iBAAmC;AAAA,EACnC,iBAAiC,CAAC;AAAA,EAClC,iBAAiB;AAAA,EACzB,OAAwB,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOtC,YAAYC,UAA2B,MAAM,QAAgB,oBAAoB,UAA2B,CAAC,GAAG;AAC9G,SAAK,SAASA,WAAU,UAAU;AAClC,QAAI,CAAC,KAAK,QAAQ;AAChB,YAAM,IAAI,MAAM,2CAA2C;AAAA,IAC7D;AAEA,SAAK,QAAQ;AACb,SAAK,UAAU,KAAK,OAAO,qBAAqB,EAAE,MAAM,CAAC;AAGzD,SAAK,cAAc,CAAC;AACpB,SAAK,iBAAiB;AAGtB,SAAK,YAAY;AAGjB,SAAK,UAAU;AAGf,SAAK,mBAAmB,QAAQ,YAAY,QAAQ,WAAW,SAAS,eAAe;AACvF,QAAI,KAAK,kBAAkB;AACzB,WAAK,eAAe;AAAA,IACtB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,iBAAuB;AAC7B,QAAI;AACF,WAAK,WAAW,KAAK,OAAO,eAAe;AAAA,QACzC,MAAM;AAAA,QACN,OAAO,iBAAgB;AAAA,MACzB,CAAC;AAGD,WAAK,cAAc,KAAK,OAAO,aAAa;AAAA,QAC1C,OAAO,GAAG,KAAK,KAAK;AAAA,QACpB,MAAM,iBAAgB,cAAc;AAAA,QACpC,OAAO,eAAe,gBAAgB,eAAe;AAAA,MACvD,CAAC;AAGD,WAAK,iBAAiB,KAAK,OAAO,aAAa;AAAA,QAC7C,OAAO,GAAG,KAAK,KAAK;AAAA,QACpB,MAAM,iBAAgB,cAAc;AAAA,QACpC,OAAO,eAAe,WAAW,eAAe;AAAA,MAClD,CAAC;AAAA,IACH,SAAS,GAAG;AACV,UAAI,KAAK,mBAAmB,mCAAmC,CAAC,EAAE;AAClE,WAAK,mBAAmB;AAAA,IAC1B;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,qBAA8B;AAC5B,WAAO,KAAK;AAAA,EACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAWA,iBAAiB,MAAc,OAA4B,QAAgB,eAA0B;AACnG,QAAI,KAAK,WAAW;AAClB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AAEA,UAAM,SAAS,KAAK,OAAO,aAAa;AAAA,MACtC,OAAO,GAAG,KAAK,KAAK,IAAI,KAAK,IAAI,KAAK,YAAY,MAAM;AAAA,MACxD;AAAA,MACA;AAAA,IACF,CAAC;AACD,oBAAgB,MAAM,KAAK;AAE3B,SAAK,YAAY,KAAK,MAAM;AAC5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,6BACE,aAAqD,CAAC,GAAG,GAAG,CAAC,GAC7D,QAAgB,qBACL;AACX,UAAM,OAAO,sBAAsB,cAC/B,aACA,IAAI,YAAY,UAAU;AAC9B,UAAM,OAAO,KAAK,IAAI,IAAI,KAAK,UAAU;AACzC,UAAM,SAAS,KAAK;AAAA,MAClB;AAAA,MACA,eAAe,WAAW,eAAe,UAAU,eAAe;AAAA,MAClE;AAAA,IACF;AACA,UAAM,SAAS,KAAK;AACpB,SAAK,OAAO,MAAM,YAAY,QAAQ,GAAG,QAAQ,KAAK,YAAY,KAAK,UAAU;AACjF,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,4BACE,QACA,YACA,SAAiB,GACX;AACN,QAAI,KAAK,WAAW;AAClB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AACA,UAAM,OAAO,sBAAsB,cAC/B,aACA,IAAI,YAAY,UAAU;AAC9B,UAAM,SAAS,KAAK;AACpB,SAAK,OAAO,MAAM,YAAY,QAAQ,QAAQ,QAAQ,KAAK,YAAY,KAAK,UAAU;AAAA,EACxF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,oBAAoB,MAAqC,QAAgB,YAAuB;AAE9F,UAAM,cAAc,gBAAgB,cAChC,OACA,KAAK,OAAO,MAAM,KAAK,YAAY,KAAK,aAAa,KAAK,UAAU;AAIxE,WAAO,gBAAgB,EAAE,YAAY,aAAa,KAAK;AAAA,EACzD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,iBAAiB,QAAgB,gBAAuC;AACtE,QAAI,KAAK,WAAW;AAClB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACpE;AACA,SAAK;AAEL,UAAM,YAAY,GAAG,KAAK,KAAK,IAAI,KAAK,IAAI,KAAK,OAAO;AAGxD,QAAI,KAAK,oBAAoB,KAAK,YAAY,KAAK,iBAAiB,KAAK,iBAAgB,aAAa;AACpG,YAAM,aAAa,KAAK;AACxB,YAAM,WAAW,aAAa;AAC9B,WAAK,kBAAkB;AAGvB,WAAK,eAAe,KAAK;AAAA,QACvB;AAAA,QACA,iBAAiB;AAAA,QACjB,eAAe;AAAA,MACjB,CAAC;AAED,aAAO,KAAK,QAAQ,iBAAiB;AAAA,QACnC,OAAO;AAAA,QACP,iBAAiB;AAAA,UACf,UAAU,KAAK;AAAA,UACf,2BAA2B;AAAA,UAC3B,qBAAqB;AAAA,QACvB;AAAA,MACF,CAAC;AAAA,IACH;AAGA,WAAO,KAAK,QAAQ,iBAAiB;AAAA,MACnC,OAAO;AAAA,IACT,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,aAAgC;AAC9B,QAAI,KAAK,WAAW;AAClB,YAAM,IAAI,MAAM,sDAAsD;AAAA,IACxE;AACA,WAAO,KAAK;AAAA,EACd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,qBAAqB,QAAyB;AAC5C,QAAI,KAAK,WAAW;AAClB,YAAM,IAAI,MAAM,qDAAqD;AAAA,IACvE;AACA,SAAK,YAAY,KAAK,MAAM;AAAA,EAC9B;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,SAAe;AACb,QAAI,KAAK,WAAW;AAClB,YAAM,IAAI,MAAM,qCAAqC;AAAA,IACvD;AAGA,SAAK,OAAO,MAAM,OAAO,CAAC,KAAK,QAAQ,OAAO,CAAC,CAAC;AAChD,SAAK,YAAY;AAEjB,UAAM,mBAAmB,KAAK;AAC9B,SAAK,cAAc,CAAC;AAEpB,SAAK,iBAAiB,KAAK,OAAO,MAAM,oBAAoB,EAAE,KAAK,MAAM;AACvE,iBAAW,UAAU,kBAAkB;AACrC,eAAO,QAAQ;AAAA,MACjB;AAEA,sBAAgB,EAAE,wBAAwB;AAAA,IAC5C,CAAC,EAAE,MAAM,CAAC,QAAQ;AAChB,UAAI,KAAK,mBAAmB,4BAA6B,IAAc,OAAO,EAAE;AAAA,IAClF,CAAC;AAAA,EACH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,gBAA+B;AACnC,SAAK,OAAO;AACZ,QAAI,KAAK,gBAAgB;AACvB,YAAM,KAAK;AAAA,IACb,OAAO;AACL,YAAM,KAAK,OAAO,MAAM,oBAAoB;AAE5C,sBAAgB,EAAE,wBAAwB;AAAA,IAC5C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,WAA0B;AACxB,WAAO;AAAA,MACL,SAAS,KAAK;AAAA,MACd,iBAAiB,KAAK,YAAY;AAAA,MAClC,WAAW,KAAK;AAAA,IAClB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,QAAc;AACZ,QAAI,KAAK;AAAW;AAGpB,eAAW,UAAU,KAAK,aAAa;AACrC,aAAO,QAAQ;AAAA,IACjB;AACA,SAAK,cAAc,CAAC;AACpB,SAAK,2BAA2B;AAChC,SAAK,YAAY;AAAA,EACnB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAWA,MAAM,wBAAwD;AAC5D,QAAI,CAAC,KAAK,oBAAoB,CAAC,KAAK,YAAY,CAAC,KAAK,eAAe,CAAC,KAAK,gBAAgB;AACzF,aAAO;AAAA,IACT;AAEA,QAAI,CAAC,KAAK,WAAW;AACnB,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,QAAI,KAAK,eAAe,WAAW,GAAG;AACpC,aAAO,CAAC;AAAA,IACV;AAGA,UAAM,KAAK,OAAO,MAAM,oBAAoB;AAG5C,UAAM,WAAW,KAAK,IAAI,GAAG,KAAK,eAAe,IAAI,OAAK,EAAE,aAAa,CAAC,IAAI;AAC9E,UAAM,iBAAiB,KAAK,OAAO,qBAAqB,EAAE,OAAO,kBAAkB,CAAC;AACpF,mBAAe,gBAAgB,KAAK,UAAU,GAAG,UAAU,KAAK,aAAa,CAAC;AAC9E,mBAAe,mBAAmB,KAAK,aAAa,GAAG,KAAK,gBAAgB,GAAG,WAAW,CAAC;AAC3F,SAAK,OAAO,MAAM,OAAO,CAAC,eAAe,OAAO,CAAC,CAAC;AAElD,QAAI,CAAC,cAAc,uCAAuC,GAAG;AAC3D,aAAO;AAAA,IACT;AAGA,UAAM,KAAK,eAAe,SAAS,WAAW,IAAI;AAClD,UAAM,aAAa,IAAI,eAAe,KAAK,eAAe,eAAe,CAAC;AAG1E,UAAM,UAA0B,CAAC;AAEjC,eAAW,SAAS,KAAK,gBAAgB;AACvC,YAAM,UAAU,WAAW,MAAM,eAAe;AAChD,YAAM,QAAQ,WAAW,MAAM,aAAa;AAC5C,YAAM,aAAa,OAAO,QAAQ,OAAO,IAAI;AAG7C,UAAI,aAAa,KAAK,aAAa,KAAO;AACxC;AAAA,MACF;AAGA,UAAI,QAAQ,MAAM,KAAK,MAAM,QAAW;AACtC,gBAAQ,MAAM,KAAK,KAAK;AAAA,MAC1B,OAAO;AACL,gBAAQ,MAAM,KAAK,IAAI;AAAA,MACzB;AAAA,IACF;AAEA,SAAK,eAAe,MAAM;AAG1B,SAAK,2BAA2B;AAEhC,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,OAAO,oBAAoB,SAAiC;AAC1D,UAAM,UAAU,OAAO,QAAQ,OAAO,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,CAAC,IAAI,EAAE,CAAC,CAAC;AAClE,UAAM,QAAQ,QAAQ,OAAO,CAAC,KAAK,CAAC,EAAE,CAAC,MAAM,MAAM,GAAG,CAAC;AAEvD,QAAI,SAAS;AACb,cAAU,SAAI,OAAO,EAAE,IAAI;AAC3B,cAAU,SAAS,OAAO,EAAE,IAAI,YAAY,SAAS,EAAE,IAAI,IAAI,SAAS,CAAC,IAAI;AAC7E,cAAU,SAAI,OAAO,EAAE,IAAI;AAE3B,eAAW,CAAC,OAAO,IAAI,KAAK,SAAS;AACnC,YAAM,OAAO,OAAO,QAAQ,KAAK,QAAQ,CAAC;AAC1C,gBAAU,MAAM,OAAO,EAAE,IAAI,KAAK,QAAQ,CAAC,EAAE,SAAS,EAAE,IAAI,IAAI,SAAS,CAAC,IAAI;AAAA,IAChF;AAEA,cAAU,SAAI,OAAO,EAAE,IAAI;AAC3B,cAAU,QAAQ,OAAO,EAAE,IAAI,MAAM,QAAQ,CAAC,EAAE,SAAS,EAAE,IAAI,QAAQ,SAAS,CAAC,IAAI;AAErF,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMQ,6BAAmC;AACzC,QAAI,KAAK,UAAU;AACjB,WAAK,SAAS,QAAQ;AACtB,WAAK,WAAW;AAAA,IAClB;AACA,QAAI,KAAK,aAAa;AACpB,WAAK,YAAY,QAAQ;AACzB,WAAK,cAAc;AAAA,IACrB;AACA,QAAI,KAAK,gBAAgB;AACvB,WAAK,eAAe,QAAQ;AAC5B,WAAK,iBAAiB;AAAA,IACxB;AACA,SAAK,iBAAiB,CAAC;AAAA,EACzB;AACF;AAQO,SAAS,sBAAsB,QAAgB,oBAAoB,SAA4C;AACpH,SAAO,IAAI,gBAAgB,MAAM,OAAO,OAAO;AACjD;AASO,SAAS,wBAAwB,QAAgB,qBAAsC;AAC5F,SAAO,IAAI,gBAAgB,MAAM,OAAO,EAAE,SAAS,KAAK,CAAC;AAC3D;;;AChfA;AACA;AACA;AAKA;AACA;AAyFA,IAAMC,kBAA4C;AAAA,EAChD,kBAAkB,YAAY;AAAA,EAC9B,iBAAiB,YAAY;AAAA,EAC7B,aAAa;AAAA,IACX,YAAY;AAAA;AAAA,IACZ,kBAAkB;AAAA;AAAA,IAClB,UAAU;AAAA;AAAA,IACV,YAAY;AAAA;AAAA,IACZ,SAAS;AAAA;AAAA,IACT,WAAW;AAAA;AAAA,IACX,WAAW;AAAA;AAAA,EACb;AACF;AAKA,SAAS,eAAe,OAQtB;AACA,QAAM,SAAS,CAAC,GAAG,KAAK,EAAE,KAAK,CAAC,GAAG,MAAM,IAAI,CAAC;AAC9C,QAAM,IAAI,OAAO;AAEjB,QAAM,OAAO,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,IAAI;AAChD,QAAM,WAAW,MAAM,OAAO,CAAC,KAAK,MAAM,OAAO,IAAI,SAAS,GAAG,CAAC,IAAI;AACtE,QAAM,SAAS,KAAK,KAAK,QAAQ;AAEjC,SAAO;AAAA,IACL,QAAQ,OAAO,KAAK,MAAM,IAAI,CAAC,CAAC;AAAA,IAChC,KAAK,OAAO,CAAC;AAAA,IACb,KAAK,OAAO,IAAI,CAAC;AAAA,IACjB,KAAK,OAAO,KAAK,MAAM,IAAI,IAAI,CAAC;AAAA,IAChC,KAAK,OAAO,KAAK,MAAM,IAAI,IAAI,CAAC;AAAA,IAChC;AAAA,IACA;AAAA,EACF;AACF;AAKA,SAAS,cACP,QACAC,SACA,WACyC;AACzC,MAAI,QAAQ;AAEZ,UAAQ,QAAQ;AAAA,IACd,KAAK;AAEH,cAAQ,KAAKA,QAAO,KAAK,MAAMA,QAAO,KAAK,MAAMA,QAAO,KAAK;AAC7D;AAAA,IACF,KAAK;AAIH,YAAM,KAAK,KAAKA,QAAO,UAAU,MAAMA,QAAO,SAAS,MAAMA,QAAO,WAAW,QAAQA,QAAO,YAAY;AAC1G,YAAM,KAAK,KAAKA,QAAO,UAAU,MAAMA,QAAO,SAAS,MAAMA,QAAO,YAAY;AAChF,YAAM,IAAI,KAAKA,QAAO,UAAU,MAAMA,QAAO,SAAS,MAAMA,QAAO,WAAW,QAAQA,QAAO,YAAY;AACzG,cAAQ,KAAK,KAAK;AAClB;AAAA,IACF,KAAK;AAEH,cAAQ,KAAKA,QAAO,QAAQ;AAC5B;AAAA,IACF,KAAK;AAEH,cAAQ,KAAKA,QAAO,QAAQ;AAC5B;AAAA,IACF;AACE,cAAQA,QAAO,QAAQA,QAAO,YAAY;AAAA,EAC9C;AAEA,QAAM,SAAS,SAAS,YAAY;AAEpC,QAAM,cAAc;AAEpB,SAAO,EAAE,QAAQ,YAAY;AAC/B;AAKA,SAAS,iBAAiB,MAAc,OAA0B;AAChE,QAAM,SAAS,cAAc,MAAM,QAAW,KAAK;AACnD,QAAMC,UAAS,UAAU;AAGzB,QAAM,OAAO,IAAI,aAAa,OAAO,CAAC;AACtC,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,SAAK,CAAC,KAAK,KAAK,OAAO,IAAI,OAAO;AAAA,EACpC;AACA,EAAAA,QAAO,MAAM,YAAY,QAAQ,GAAG,IAAI;AAExC,SAAO;AACT;AAKA,eAAe,gBACb,MACA,SACAD,SACA,OACA,kBACA,iBACgC;AAChC,QAAMC,UAAS,UAAU;AAGzB,WAAS,IAAI,GAAG,IAAI,kBAAkB,KAAK;AACzC,UAAM,MAAM;AACZ,UAAMA,QAAO,MAAM,oBAAoB;AAAA,EACzC;AAGA,QAAM,QAAkB,CAAC;AACzB,WAAS,IAAI,GAAG,IAAI,iBAAiB,KAAK;AACxC,UAAM,QAAQ,YAAY,IAAI;AAC9B,UAAM,MAAM;AACZ,UAAMA,QAAO,MAAM,oBAAoB;AACvC,UAAM,KAAK,YAAY,IAAI,IAAI,KAAK;AAAA,EACtC;AAEA,QAAM,QAAQ,eAAe,KAAK;AAClC,QAAM,YAAY,cAAc,MAAMD,SAAQ,MAAM,MAAM;AAG1D,QAAM,YAAYA,QAAO,aAAaA,QAAO,OAAO,KAAK;AACzD,QAAM,aAAaA,QAAO,cAAcA,QAAO,OAAO,KAAK;AAC3D,QAAM,aAAa,YAAY;AAC/B,QAAM,WAAW,cAAc,MAAM,SAAS;AAE9C,SAAO;AAAA,IACL,QAAQ;AAAA,IACR;AAAA,IACA,QAAAA;AAAA,IACA,SAAS;AAAA,MACP,WAAW,MAAM;AAAA,MACjB,QAAQ,MAAM;AAAA,MACd,QAAQ,MAAM;AAAA,MACd,QAAQ,MAAM;AAAA,MACd,QAAQ,MAAM;AAAA,MACd,WAAW,MAAM;AAAA,IACnB;AAAA,IACA,YAAY;AAAA,MACV,YAAY;AAAA,MACZ,mBAAmBA,QAAO,QAAQA,QAAO,YAAY,MAAM,MAAM,SAAS;AAAA,IAC5E;AAAA,IACA,OAAO;AAAA,MACL,QAAQ,UAAU;AAAA,MAClB,oBAAoB,UAAU;AAAA,MAC9B,gBAAiB,UAAU,SAAS,UAAU,cAAe;AAAA,IAC/D;AAAA,IACA,QAAQ;AAAA,MACN,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,aAAa;AAAA,IACf;AAAA,IACA,YAAY;AAAA,IACZ,mBAAmB;AAAA,IACnB,YAAW,oBAAI,KAAK,GAAE,YAAY;AAAA,EACpC;AACF;AAKA,eAAsB,gBACpB,GACA,GACA,GACA,UAA2B,CAAC,GACI;AAChC,QAAMA,UAAS,EAAE,GAAGD,iBAAgB,GAAG,QAAQ;AAC/C,QAAME,UAAS,UAAU;AAEzB,QAAM,IAAI,iBAAiB,IAAI,IAAI,GAAG,SAAS;AAC/C,QAAM,IAAI,iBAAiB,IAAI,IAAI,GAAG,SAAS;AAC/C,QAAM,UAAU,aAAa,GAAG,OAAO,CAAC,GAAG,CAAC,GAAG,SAAS;AAExD,QAAM,SAAS,MAAM;AAAA,IACnB;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAAA,MAAG;AAAA,MAAG;AAAA,MACN,YAAY,IAAI,IAAI,IAAI,KAAK;AAAA,MAC7B,YAAY,IAAI,IAAI;AAAA,IACtB;AAAA,IACA,YAAY;AACV,YAAM,IAAI,MAAM,UAAU,SAAS,GAAG,GAAG,GAAG,CAAC;AAC7C,oBAAc,EAAE,MAAM;AAAA,IACxB;AAAA,IACAD,QAAO;AAAA,IACPA,QAAO;AAAA,EACT;AAEA,gBAAc,CAAC;AACf,gBAAc,CAAC;AAEf,SAAO;AACT;AAKA,eAAsB,yBACpB,UACA,SACA,OACA,UAA2B,CAAC,GACI;AAChC,QAAMA,UAAS,EAAE,GAAGD,iBAAgB,GAAG,QAAQ;AAE/C,QAAM,OAAO,iBAAiB,WAAW,UAAU,GAAG,SAAS;AAC/D,QAAM,OAAO,iBAAiB,QAAQ,WAAW,UAAU,GAAG,SAAS;AACvE,QAAM,OAAO,iBAAiB,QAAQ,WAAW,UAAU,GAAG,SAAS;AACvE,QAAM,IAAI,aAAa,MAAM,OAAO,CAAC,GAAG,WAAW,OAAO,GAAG,SAAS;AACtE,QAAM,IAAI,aAAa,MAAM,OAAO,CAAC,OAAO,WAAW,OAAO,GAAG,SAAS;AAC1E,QAAM,IAAI,aAAa,MAAM,OAAO,CAAC,OAAO,WAAW,OAAO,GAAG,SAAS;AAE1E,QAAM,SAAS,MAAM;AAAA,IACnB;AAAA,IACA;AAAA,IACA;AAAA,MACE,QAAQ;AAAA,MACR;AAAA,MACA;AAAA,MACA;AAAA,MACA,YAAY,WAAW,UAAU,IAAI,QAAQ,WAAW,WAAW;AAAA,MACnE,YAAY,WAAW,UAAU;AAAA,IACnC;AAAA,IACA,YAAY;AACV,YAAM,MAAM,MAAM,aAAa,GAAG,GAAG,GAAG,MAAM,UAAU,SAAS;AAAA,QAC/D,QAAQ;AAAA,QACR;AAAA,QACA,YAAY;AAAA,MACd,CAAC;AACD,oBAAc,IAAI,MAAM;AAAA,IAC1B;AAAA,IACAC,QAAO;AAAA,IACPA,QAAO;AAAA,EACT;AAEA,gBAAc,IAAI;AAClB,gBAAc,IAAI;AAClB,gBAAc,IAAI;AAElB,SAAO;AACT;AAKA,eAAsB,iBACpB,WACA,YACA,UAA2B,CAAC,GACI;AAChC,QAAMA,UAAS,EAAE,GAAGD,iBAAgB,GAAG,QAAQ;AAE/C,QAAM,OAAO,YAAY;AACzB,QAAM,QAAQ,iBAAiB,OAAO,GAAG,aAAa;AACtD,QAAM,SAAS,iBAAiB,aAAa,GAAG,cAAc;AAC9D,QAAM,cAAc,aAAa,OAAO,OAAO,CAAC,WAAW,UAAU,GAAG,aAAa;AAErF,QAAM,SAAS,MAAM;AAAA,IACnB;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAAA,MACA;AAAA,MACA;AAAA,MACA,YAAY,OAAO,cAAc;AAAA,MACjC,YAAY,OAAO;AAAA,IACrB;AAAA,IACA,YAAY;AACV,YAAM,MAAM,MAAM,WAAW,aAAa,QAAQ,MAAM,EAAE,WAAW,WAAW,CAAC;AACjF,oBAAc,IAAI,MAAM;AAAA,IAC1B;AAAA,IACAC,QAAO;AAAA,IACPA,QAAO;AAAA,EACT;AAEA,gBAAc,KAAK;AACnB,gBAAc,MAAM;AAEpB,SAAO;AACT;AAKA,eAAsB,cACpB,MACA,UAA2B,CAAC,GACI;AAChC,QAAMA,UAAS,EAAE,GAAGD,iBAAgB,GAAG,QAAQ;AAE/C,QAAM,QAAQ,iBAAiB,OAAO,GAAG,aAAa;AACtD,QAAM,cAAc,aAAa,OAAO,OAAO,CAAC,IAAI,GAAG,aAAa;AAEpE,QAAM,SAAS,MAAM;AAAA,IACnB;AAAA,IACA;AAAA,IACA;AAAA,MACE;AAAA,MACA,WAAW,OAAO;AAAA,MAClB,YAAY,OAAO;AAAA,IACrB;AAAA,IACA,YAAY;AACV,YAAM,MAAM,MAAM,QAAQ,aAAa,EAAE,KAAK,CAAC;AAC/C,oBAAc,IAAI,MAAM;AAAA,IAC1B;AAAA,IACAC,QAAO;AAAA,IACPA,QAAO;AAAA,EACT;AAEA,gBAAc,KAAK;AAEnB,SAAO;AACT;AAOA,eAAsB,4BACpB,GACA,GACA,UAA2B,CAAC,GAK3B;AACD,QAAMA,UAAS,EAAE,GAAGD,iBAAgB,GAAG,QAAQ;AAG/C,QAAM,EAAE,uBAAAG,wBAAuB,6BAAAC,6BAA4B,IAAI,MAAM;AAErE,MAAI,CAACA,6BAA4B,GAAG,CAAC,GAAG;AACtC,UAAM,IAAI,MAAM,oCAAoC,CAAC,2BAA2B;AAAA,EAClF;AAEA,QAAM,QAAQ,iBAAiB,IAAI,GAAG,aAAa;AACnD,QAAM,SAAS,iBAAiB,IAAI,IAAI,GAAG,cAAc;AACzD,QAAM,aAAa,iBAAiB,IAAI,GAAG,mBAAmB;AAC9D,QAAM,WAAW,iBAAiB,IAAI,GAAG,gBAAgB;AACzD,QAAM,cAAc,aAAa,OAAO,OAAO,CAAC,GAAG,CAAC,GAAG,aAAa;AACpE,QAAM,iBAAiB,aAAa,UAAU,OAAO,CAAC,GAAG,CAAC,GAAG,gBAAgB;AAG7E,QAAM,iBAAiB,MAAM;AAAA,IAC3B;AAAA,IACA;AAAA,IACA;AAAA,MACE,GAAG;AAAA,MAAG;AAAA,MAAG;AAAA,MACT,YAAY,IAAI,IAAI,IAAI,IAAI,KAAK;AAAA;AAAA,MACjC,YAAY,IAAI;AAAA,IAClB;AAAA,IACA,YAAY;AACV,YAAM,YAAY,MAAM,UAAU,aAAa,QAAQ,GAAG,GAAG,CAAC;AAC9D,YAAM,UAAU,MAAM,WAAW,WAAW,YAAY,MAAM;AAAA,QAC5D,WAAW;AAAA,QACX,YAAY;AAAA,QACZ,UAAU;AAAA,MACZ,CAAC;AACD,oBAAc,UAAU,MAAM;AAC9B,oBAAc,QAAQ,MAAM;AAAA,IAC9B;AAAA,IACAH,QAAO;AAAA,IACPA,QAAO;AAAA,EACT;AAGA,QAAM,cAAc,MAAM;AAAA,IACxB;AAAA,IACA;AAAA,IACA;AAAA,MACE,GAAG;AAAA,MAAG;AAAA,MAAG;AAAA,MACT,YAAY,IAAI,IAAI,IAAI,IAAI,KAAK;AAAA,MACjC,YAAY,IAAI;AAAA,IAClB;AAAA,IACA,YAAY;AACV,YAAM,MAAM,MAAME,uBAAsB,aAAa,QAAQ,YAAY;AAAA,QACvE;AAAA,QAAG;AAAA,QACH,KAAK;AAAA,QACL;AAAA;AAAA,MACF,CAAC;AACD,oBAAc,IAAI,MAAM;AAAA,IAC1B;AAAA,IACAF,QAAO;AAAA,IACPA,QAAO;AAAA,EACT;AAEA,gBAAc,KAAK;AACnB,gBAAc,MAAM;AACpB,gBAAc,UAAU;AACxB,gBAAc,QAAQ;AAGtB,QAAM,UAAU,eAAe,QAAQ,YAAY,YAAY,QAAQ;AACvE,QAAM,aAAkC;AAAA,IACtC,UAAU;AAAA,IACV,WAAW;AAAA,IACX;AAAA,IACA,wBAAwB,IAAI,YAAY,QAAQ,YAAY,eAAe,QAAQ,aAAa;AAAA,IAChG,0BAA0B,UAAU,KAAK;AAAA,EAC3C;AAEA,QAAM,KAAK,gCAAgC,CAAC,OAAO,CAAC,gBAAgB,eAAe,QAAQ,UAAU,QAAQ,CAAC,CAAC,cAAc,YAAY,QAAQ,UAAU,QAAQ,CAAC,CAAC,gBAAgB,QAAQ,QAAQ,CAAC,CAAC,GAAG;AAE1M,SAAO,EAAE,UAAU,gBAAgB,OAAO,aAAa,WAAW;AACpE;AAKA,eAAsB,oBACpB,UAA2B,CAAC,GACF;AAC1B,QAAMA,UAAS,EAAE,GAAGD,gBAAe,aAAa,GAAG,QAAQ,YAAY;AACvE,QAAME,UAAS,UAAU;AACzB,QAAM,SAAS,gBAAgB;AAC/B,QAAM,OAAO,sBAAsB;AAEnC,QAAM,UAAmC,CAAC;AAE1C,QAAM,KAAK,qEAAqED,QAAO,UAAU,kBAAkBA,QAAO,gBAAgB,WAAWA,QAAO,QAAQ,EAAE;AAGtK,QAAM,KAAK,+BAA+B;AAC1C,UAAQ,KAAK,MAAM,iBAAiB,GAAGA,QAAO,YAAY,OAAO,CAAC;AAGlE,QAAM,KAAK,sCAAsC;AACjD,QAAM,UAAUA,QAAO,WAAW,IAAIA,QAAO,cAAcA,QAAO;AAClE,UAAQ,KAAK,MAAM,gBAAgB,GAAG,QAAQA,QAAO,YAAY,OAAO,CAAC;AAGzE,QAAM,KAAK,wCAAwC;AACnD,QAAM,QAAQ;AACd,UAAQ,KAAK,MAAM,yBAAyBA,QAAO,UAAUA,QAAO,SAAS,OAAO,OAAO,CAAC;AAG5F,QAAM,KAAK,yCAAyC;AACpD,UAAQ,KAAK,MAAM,gBAAgB,GAAGA,QAAO,YAAYA,QAAO,WAAWA,QAAO,SAAS,OAAO,CAAC;AAGnG,QAAM,KAAK,mCAAmC;AAC9C,UAAQ,KAAK,MAAM,gBAAgB,GAAGA,QAAO,mBAAmB,GAAGA,QAAO,YAAY,OAAO,CAAC;AAG9F,QAAM,KAAK,4BAA4B;AACvC,UAAQ,KAAK,MAAM,cAAcA,QAAO,kBAAkB,OAAO,CAAC;AAGlE,QAAM,KAAK,gCAAgC;AAC3C,UAAQ,KAAK,MAAM,gBAAgB,GAAGA,QAAO,YAAYA,QAAO,kBAAkB,OAAO,CAAC;AAG1F,QAAM,KAAK,qCAAqC;AAChD,UAAQ,KAAK,MAAM,iBAAiB,GAAGA,QAAO,YAAY,OAAO,CAAC;AAGlE,QAAM,KAAK,+BAA+B;AAC1C,UAAQ,KAAK,MAAM,gBAAgB,GAAGA,QAAO,WAAWA,QAAO,YAAY,OAAO,CAAC;AAGnF,QAAM,kBAAkB,QAAQ,MAAM,GAAG,CAAC,EAAE,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,QAAQ,WAAW,CAAC;AAC3F,QAAM,gBAAgB,QAAQ,CAAC,EAAE,QAAQ;AACzC,QAAM,qBAAqB,kBAAkBA,QAAO,YAAY;AAChE,QAAM,YAAY,MAAO;AAGzB,QAAM,kBAAkB,CAAC,GAAG,OAAO,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,YAAY,EAAE,QAAQ,SAAS;AAC7F,QAAM,aAAa,gBAAgB,CAAC;AACpC,QAAM,gBAAiB,WAAW,QAAQ,YAAY,qBAAsB;AAE5E,QAAM,SAA0B;AAAA,IAC9B,aAAa;AAAA,MACX,QAAQ;AAAA,MACR,cAAc;AAAA,MACd,oBAAoB,QAAQ,qCAAqC;AAAA,MACjE,mBAAmB,QAAQ,kCAAkC;AAAA,MAC7D,SAAS,KAAK;AAAA,MACd,eAAe,KAAK;AAAA,IACtB;AAAA,IACA,cAAc;AAAA,MACZ,MAAM;AAAA,MACN,aAAaA,QAAO;AAAA,MACpB,mBAAmBA,QAAO;AAAA,MAC1B,WAAWA,QAAO;AAAA,MAClB,cAAcA,QAAO;AAAA,MACrB,UAAUA,QAAO;AAAA,MACjB,YAAYA,QAAO;AAAA,MACnB,YAAYA,QAAO;AAAA,IACrB;AAAA,IACA;AAAA,IACA,aAAa,CAAC;AAAA,IACd,SAAS;AAAA,MACP,yBAAyB;AAAA,MACzB,uBAAuB;AAAA,MACvB,mBAAmB,GAAG,WAAW,MAAM,IAAI,WAAW,OAAO;AAAA,MAC7D,uBAAuB;AAAA,IACzB;AAAA,IACA,eAAc,oBAAI,KAAK,GAAE,YAAY;AAAA,EACvC;AAEA,QAAM,KAAK,4CAA4C,mBAAmB,QAAQ,CAAC,CAAC,6BAA6B,UAAU,QAAQ,CAAC,CAAC,iBAAiB,WAAW,MAAM,KAAK,cAAc,QAAQ,CAAC,CAAC,IAAI;AAExM,SAAO;AACT;AAKO,SAAS,kBACd,UACA,WACqB;AACrB,QAAM,UAAU,SAAS,QAAQ,YAAY,UAAU,QAAQ;AAC/D,QAAM,oBAAqB,SAAS,QAAQ,YAAY,UAAU,QAAQ,aAAa,SAAS,QAAQ,YAAa;AACrH,QAAM,sBAAuB,UAAU,WAAW,aAAa,SAAS,WAAW,cAAc,SAAS,WAAW,aAAc;AAEnI,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA,uBAAuB;AAAA,IACvB,yBAAyB;AAAA,EAC3B;AACF;AAKO,SAAS,oBAAoB,QAAiC;AACnE,SAAO,KAAK,UAAU,QAAQ,MAAM,CAAC;AACvC;AAKO,SAAS,qBAAqB,QAA+B;AAClE,MAAI,KAAK,aAAa,IAAI,OAAO,EAAE,CAAC;AACpC,MAAI,KAAK,aAAa,yBAAyB;AAC/C,MAAI,KAAK,aAAa,IAAI,OAAO,EAAE,CAAC;AAEpC,MAAI,KAAK,aAAa,cAAc;AACpC,MAAI,KAAK,aAAa,yBAAyB,OAAO,YAAY,kBAAkB,EAAE;AACtF,MAAI,KAAK,aAAa,yBAAyB,OAAO,YAAY,oBAAoB,MAAM,QAAQ,CAAC,CAAC,IAAI;AAC1G,MAAI,KAAK,aAAa,kBAAkB,OAAO,YAAY,OAAO,EAAE;AACpE,MAAI,KAAK,aAAa,uBAAuB,OAAO,YAAY,aAAa,EAAE;AAE/E,MAAI,KAAK,aAAa,eAAe;AACrC,MAAI,KAAK,aAAa,WAAW,OAAO,aAAa,IAAI,EAAE;AAC3D,MAAI,KAAK,aAAa,kBAAkB,OAAO,aAAa,WAAW,EAAE;AACzE,MAAI,KAAK,aAAa,wBAAwB,OAAO,aAAa,iBAAiB,EAAE;AACrF,MAAI,KAAK,aAAa,YAAY,OAAO,aAAa,SAAS,SAAS,OAAO,aAAa,YAAY,GAAG;AAE3G,MAAI,KAAK,aAAa,iBAAiB;AACvC,MAAI,KAAK,aAAa,IAAI,OAAO,EAAE,CAAC;AACpC,MAAI,KAAK,aAAa,oDAAoD;AAC1E,MAAI,KAAK,aAAa,IAAI,OAAO,EAAE,CAAC;AAEpC,aAAW,KAAK,OAAO,SAAS;AAC9B,QAAI;AAAA,MAAK;AAAA,MACP,IAAI,EAAE,SAAS,MAAM,EAAE,SAAS,OAAO,EAAE,CAAC,MACvC,EAAE,QAAQ,UAAU,QAAQ,CAAC,EAAE,SAAS,EAAE,CAAC,MAC3C,EAAE,WAAW,WAAW,QAAQ,CAAC,EAAE,SAAS,CAAC,CAAC,MAC9C,EAAE,MAAM,OAAO,QAAQ,CAAC,EAAE,SAAS,CAAC,CAAC;AAAA,IAC1C;AAAA,EACF;AAEA,MAAI,KAAK,aAAa,IAAI,OAAO,EAAE,CAAC;AACpC,MAAI,KAAK,aAAa,UAAU;AAChC,MAAI,KAAK,aAAa,2BAA2B,OAAO,QAAQ,wBAAwB,QAAQ,CAAC,CAAC,IAAI;AACtG,MAAI,KAAK,aAAa,2BAA2B,OAAO,QAAQ,sBAAsB,QAAQ,CAAC,CAAC,EAAE;AAClG,MAAI,KAAK,aAAa,iBAAiB,OAAO,QAAQ,iBAAiB,KAAK,OAAO,QAAQ,sBAAsB,QAAQ,CAAC,CAAC,IAAI;AAE/H,MAAI,OAAO,YAAY,SAAS,GAAG;AACjC,QAAI,KAAK,aAAa,cAAc;AACpC,eAAW,KAAK,OAAO,aAAa;AAClC,UAAI,KAAK,aAAa,KAAK,EAAE,SAAS,MAAM,KAAK,EAAE,QAAQ,QAAQ,CAAC,CAAC,WAAW;AAAA,IAClF;AAAA,EACF;AAEA,MAAI,KAAK,aAAa,IAAI,OAAO,EAAE,CAAC;AACtC;;;AC7rBA;AACA;AAEA;AACA;AACA;AACA;AA8BA,eAAsB,YACpB,WACA,SACyB;AACzB,QAAMI,UAAS,UAAU;AACzB,QAAM,EAAE,WAAW,OAAO,OAAO,OAAO,UAAU,MAAM,UAAU,MAAM,UAAU,KAAK,IAAI;AAE3F,QAAM,WAAW,MAAM,gBAAgB,aAAa,SAAS;AAE7D,QAAM,cAA2B,UAAU;AAC3C,QAAM,kBAAkB,WAAW,WAAW;AAG9C,QAAM,UAAU,SAAS,UAAU,cAAc,YAAY,QAAQ,iBAAiB,QAAW,GAAG;AACpG,QAAM,UAAU,SAAS,UAAU,cAAc,YAAY,QAAQ,iBAAiB,QAAW,GAAG;AACpG,QAAM,UAAU,SAAS,UAAU,cAAc,YAAY,QAAQ,iBAAiB,QAAW,GAAG;AAGpG,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,OAAO,IAAI;AAC7B,WAAK,UAAU,GAAG,OAAO,IAAI;AAC7B,WAAK,UAAU,IAAI,OAAO,IAAI;AAAA,IAChC;AAAA,IACA;AAAA,IACAA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,OAAO,EAAE;AAAA,MACrD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,IAC9C;AAAA,EACF,CAAC;AAGD,QAAM,gBAAgB,aAAa,QAAQ,QAAQ;AACnD,QAAM,aAAa,KAAK,KAAK,gBAAgB,gBAAgB,OAAO;AACpE,WAASA,SAAQ,UAAU,WAAW,YAAY,WAAW;AAE7D,gBAAc,QAAQ;AAEtB,QAAM,IAAI,WAAW,aAAa,SAAS,aAAa,CAAC,WAAW,KAAK,GAAG,GAAG;AAC/E,QAAM,IAAI,WAAW,aAAa,SAAS,aAAa,CAAC,WAAW,KAAK,GAAG,GAAG;AAC/E,QAAM,IAAI,WAAW,aAAa,SAAS,aAAa,CAAC,WAAW,KAAK,GAAG,GAAG;AAE/E,SAAO,EAAE,GAAG,GAAG,EAAE;AACnB;AAKA,eAAsB,eACpB,UACA,WACA,SACyB;AACzB,QAAMA,UAAS,SAAS;AACxB,QAAM,EAAE,WAAW,OAAO,OAAO,OAAO,UAAU,MAAM,UAAU,MAAM,UAAU,KAAK,IAAI;AAE3F,QAAM,WAAW,MAAM,gBAAgB,aAAa,SAAS;AAE7D,QAAM,cAA2B,UAAU;AAC3C,QAAM,kBAAkB,WAAW,WAAW;AAG9C,QAAM,UAAU,SAAS,UAAU,cAAc,YAAY,QAAQ,iBAAiB,QAAW,GAAG;AACpG,QAAM,UAAU,SAAS,UAAU,cAAc,YAAY,QAAQ,iBAAiB,QAAW,GAAG;AACpG,QAAM,UAAU,SAAS,UAAU,cAAc,YAAY,QAAQ,iBAAiB,QAAW,GAAG;AAGpG,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA;AAAA,IACA,CAAC,SAAS;AACR,WAAK,UAAU,GAAG,WAAW,IAAI;AACjC,WAAK,UAAU,GAAG,OAAO,IAAI;AAC7B,WAAK,UAAU,GAAG,OAAO,IAAI;AAC7B,WAAK,UAAU,IAAI,OAAO,IAAI;AAAA,IAChC;AAAA,IACA;AAAA,EACF;AAGA,QAAM,YAAYA,QAAO,gBAAgB;AAAA,IACvC,OAAO;AAAA,IACP,QAAQ,SAAS,mBAAmB,CAAC;AAAA,IACrC,SAAS;AAAA,MACP,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,cAAc,EAAE;AAAA,MAClD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,UAAU,OAAO,EAAE;AAAA,MACrD,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,MAC5C,EAAE,SAAS,GAAG,UAAU,EAAE,QAAQ,QAAQ,EAAE;AAAA,IAC9C;AAAA,EACF,CAAC;AAGD,QAAM,gBAAgB,aAAa,QAAQ,QAAQ;AACnD,QAAM,aAAa,KAAK,KAAK,gBAAgB,gBAAgB,OAAO;AACpE,iBAAe,UAAU,UAAU,WAAW,YAAY,WAAW;AAErE,QAAM,IAAI,WAAW,aAAa,SAAS,aAAa,CAAC,WAAW,KAAK,GAAG,GAAG;AAC/E,QAAM,IAAI,WAAW,aAAa,SAAS,aAAa,CAAC,WAAW,KAAK,GAAG,GAAG;AAC/E,QAAM,IAAI,WAAW,aAAa,SAAS,aAAa,CAAC,WAAW,KAAK,GAAG,GAAG;AAE/E,SAAO,EAAE,GAAG,GAAG,EAAE;AACnB;;;AClJA;AACA;AAwCA,IAAI,mBAAmB;AACvB,IAAI,iBAAiC,CAAC;AACtC,IAAI,mBAAmB;AAKhB,SAAS,qBAA8B;AAC5C,MAAI,OAAO,WAAW,aAAa;AACjC,WAAO,QAAS,OAAoD,eAAe;AAAA,EACrF;AACA,SAAO;AACT;AAKO,SAAS,oBAAoB,SAAwB;AAC1D,qBAAmB;AACnB,MAAI,OAAO,WAAW,aAAa;AACjC,IAAC,OAAoD,kBAAkB;AAAA,EACzE;AACF;AAKO,SAAS,eAAqB;AACnC,mBAAiB,CAAC;AAClB,qBAAmB;AACrB;AAKO,SAAS,sBAA4B;AAC1C,eAAa;AACb,qBAAmB,YAAY,IAAI;AACrC;AAKO,SAAS,mBACd,MACA,UACA,WACA,SACA,UACM;AACN,MAAI,CAAC,mBAAmB;AAAG;AAE3B,iBAAe,KAAK;AAAA,IAClB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA,UAAU,UAAU;AAAA,IACpB;AAAA,EACF,CAAC;AACH;AAKA,eAAsB,aACpB,MACA,UACA,IACA,UACY;AACZ,MAAI,CAAC,mBAAmB,GAAG;AACzB,WAAO,GAAG;AAAA,EACZ;AAEA,QAAM,YAAY,YAAY,IAAI;AAClC,MAAI;AACF,UAAM,SAAS,MAAM,GAAG;AACxB,UAAM,UAAU,YAAY,IAAI;AAChC,uBAAmB,MAAM,UAAU,WAAW,SAAS,QAAQ;AAC/D,WAAO;AAAA,EACT,SAAS,OAAO;AACd,UAAM,UAAU,YAAY,IAAI;AAChC,uBAAmB,MAAM,UAAU,WAAW,SAAS,EAAE,GAAG,UAAU,OAAO,KAAK,CAAC;AACnF,UAAM;AAAA,EACR;AACF;AAKO,SAAS,YACd,MACA,UACA,IACA,UACG;AACH,MAAI,CAAC,mBAAmB,GAAG;AACzB,WAAO,GAAG;AAAA,EACZ;AAEA,QAAM,YAAY,YAAY,IAAI;AAClC,MAAI;AACF,UAAM,SAAS,GAAG;AAClB,UAAM,UAAU,YAAY,IAAI;AAChC,uBAAmB,MAAM,UAAU,WAAW,SAAS,QAAQ;AAC/D,WAAO;AAAA,EACT,SAAS,OAAO;AACd,UAAM,UAAU,YAAY,IAAI;AAChC,uBAAmB,MAAM,UAAU,WAAW,SAAS,EAAE,GAAG,UAAU,OAAO,KAAK,CAAC;AACnF,UAAM;AAAA,EACR;AACF;AAKA,eAAsB,cACpB,MACA,YACA,UACe;AACf,MAAI,CAAC,mBAAmB,GAAG;AACzB,eAAW;AACX;AAAA,EACF;AAEA,QAAMC,UAAS,UAAU;AACzB,QAAM,YAAY,YAAY,IAAI;AAElC,aAAW;AAGX,QAAMA,QAAO,MAAM,oBAAoB;AAEvC,QAAM,UAAU,YAAY,IAAI;AAChC,qBAAmB,MAAM,UAAU,WAAW,SAAS,QAAQ;AACjE;AAKO,SAAS,mBAAkC;AAChD,QAAM,UAAU,CAAC,GAAG,cAAc;AAClC,QAAM,YAAY,QAAQ,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC;AAGhE,QAAM,gBAAgB,QAAQ,OAAO,OAAK,EAAE,aAAa,QAAQ;AACjE,QAAM,gBAAgB,QAAQ,OAAO,OAAK,EAAE,aAAa,QAAQ;AACjE,QAAM,cAAc,QAAQ,OAAO,OAAK,EAAE,aAAa,MAAM;AAC7D,QAAM,eAAe,QAAQ,OAAO,OAAK,EAAE,aAAa,OAAO;AAE/D,QAAM,aAAa,cAAc,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC;AACvE,QAAM,aAAa,cAAc,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC;AACvE,QAAM,WAAW,YAAY,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC;AACnE,QAAM,YAAY,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC;AAGrE,QAAM,SAAS,oBAAI,IAAkD;AACrE,aAAW,SAAS,SAAS;AAC3B,UAAM,WAAW,OAAO,IAAI,MAAM,IAAI,KAAK,EAAE,WAAW,GAAG,OAAO,EAAE;AACpE,aAAS,aAAa,MAAM;AAC5B,aAAS,SAAS;AAClB,WAAO,IAAI,MAAM,MAAM,QAAQ;AAAA,EACjC;AAEA,QAAM,YAAY,MAAM,KAAK,OAAO,QAAQ,CAAC,EAC1C,IAAI,CAAC,CAAC,MAAM,KAAK,OAAO;AAAA,IACvB;AAAA,IACA,WAAW,MAAM;AAAA,IACjB,OAAO,MAAM;AAAA,IACb,SAAS,MAAM,YAAY,MAAM;AAAA,IACjC,YAAa,MAAM,YAAY,YAAa;AAAA,EAC9C,EAAE,EACD,KAAK,CAAC,GAAG,MAAM,EAAE,YAAY,EAAE,SAAS;AAG3C,QAAM,cAA4C,CAAC;AAGnD,MAAI,YAAY,SAAS,QAAQ,SAAS,KAAK;AAC7C,gBAAY,KAAK;AAAA,MACf,MAAM;AAAA,MACN,QAAQ,WAAW;AAAA,MACnB,YAAY;AAAA,IACd,CAAC;AAAA,EACH;AAGA,MAAI,aAAa,YAAY;AAC3B,gBAAY,KAAK;AAAA,MACf,MAAM;AAAA,MACN,QAAQ,aAAa;AAAA,MACrB,YAAY;AAAA,IACd,CAAC;AAAA,EACH;AAGA,QAAM,eAAe,cAAc,OAAO,OAAK,EAAE,WAAW,GAAG;AAC/D,MAAI,aAAa,SAAS,cAAc,SAAS,KAAK;AACpD,UAAM,kBAAkB,aAAa,OAAO,CAAC,KAAK,MAAM,MAAM,EAAE,UAAU,CAAC;AAC3E,gBAAY,KAAK;AAAA,MACf,MAAM;AAAA,MACN,QAAQ,kBAAkB;AAAA,MAC1B,YAAY;AAAA,IACd,CAAC;AAAA,EACH;AAGA,aAAW,QAAQ,UAAU,MAAM,GAAG,CAAC,GAAG;AACxC,QAAI,KAAK,aAAa,IAAI;AACxB,kBAAY,KAAK;AAAA,QACf,MAAM,GAAG,KAAK,IAAI,eAAe,KAAK,WAAW,QAAQ,CAAC,CAAC;AAAA,QAC3D,QAAQ,KAAK,aAAa;AAAA,QAC1B,YAAY,YAAY,KAAK,IAAI;AAAA,MACnC,CAAC;AAAA,IACH;AAAA,EACF;AAEA,SAAO;AAAA,IACL;AAAA,IACA,SAAS;AAAA,MACP;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,aAAa,cAAc;AAAA,MAC3B,WAAW,cAAc;AAAA,MACzB,SAAS,YAAY;AAAA,IACvB;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAKO,SAAS,mBAAmB,QAA8B;AAC/D,QAAM,IAAI,UAAU,iBAAiB;AAErC,MAAI,KAAK,WAAW,IAAI,OAAO,EAAE,CAAC;AAClC,MAAI,KAAK,WAAW,4BAA4B;AAChD,MAAI,KAAK,WAAW,IAAI,OAAO,EAAE,CAAC;AAElC,MAAI,KAAK,WAAW,UAAU;AAC9B,MAAI,KAAK,WAAW,iBAAiB,EAAE,QAAQ,UAAU,QAAQ,CAAC,CAAC,IAAI;AACvE,MAAI,KAAK,WAAW,kBAAkB,EAAE,QAAQ,WAAW,QAAQ,CAAC,CAAC,QAAS,EAAE,QAAQ,aAAa,EAAE,QAAQ,YAAa,KAAK,QAAQ,CAAC,CAAC,IAAI;AAC/I,MAAI,KAAK,WAAW,kBAAkB,EAAE,QAAQ,WAAW,QAAQ,CAAC,CAAC,QAAS,EAAE,QAAQ,aAAa,EAAE,QAAQ,YAAa,KAAK,QAAQ,CAAC,CAAC,IAAI;AAC/I,MAAI,KAAK,WAAW,gBAAgB,EAAE,QAAQ,SAAS,QAAQ,CAAC,CAAC,QAAS,EAAE,QAAQ,WAAW,EAAE,QAAQ,YAAa,KAAK,QAAQ,CAAC,CAAC,IAAI;AACzI,MAAI,KAAK,WAAW,mBAAmB,EAAE,QAAQ,WAAW,EAAE;AAE9D,MAAI,KAAK,WAAW,iBAAiB;AACrC,MAAI,KAAK,WAAW,IAAI,OAAO,EAAE,CAAC;AAClC,MAAI,KAAK,WAAW,4DAA4D;AAChF,MAAI,KAAK,WAAW,IAAI,OAAO,EAAE,CAAC;AAElC,aAAW,QAAQ,EAAE,UAAU,MAAM,GAAG,EAAE,GAAG;AAC3C,QAAI;AAAA,MAAK;AAAA,MACP,GAAG,KAAK,KAAK,OAAO,EAAE,CAAC,MAAM,KAAK,UAAU,QAAQ,CAAC,EAAE,SAAS,CAAC,CAAC,MAC/D,KAAK,MAAM,SAAS,EAAE,SAAS,CAAC,CAAC,MAAM,KAAK,WAAW,QAAQ,CAAC,EAAE,SAAS,CAAC,CAAC;AAAA,IAClF;AAAA,EACF;AAEA,MAAI,EAAE,YAAY,SAAS,GAAG;AAC5B,QAAI,KAAK,WAAW,cAAc;AAClC,QAAI,KAAK,WAAW,IAAI,OAAO,EAAE,CAAC;AAClC,eAAW,KAAK,EAAE,aAAa;AAC7B,UAAI,KAAK,WAAW,OAAO,EAAE,SAAS,KAAK,QAAQ,CAAC,CAAC,MAAM,EAAE,IAAI,EAAE;AACnE,UAAI,KAAK,WAAW,eAAe,EAAE,UAAU,EAAE;AAAA,IACnD;AAAA,EACF;AAEA,MAAI,KAAK,WAAW,IAAI,OAAO,EAAE,CAAC;AACpC;AAKO,SAAS,kBAAkB,QAAgC;AAChE,SAAO,KAAK,UAAU,UAAU,iBAAiB,GAAG,MAAM,CAAC;AAC7D;AAKO,SAAS,yBACd,iBACA,aACA,kBAA0B,IAM1B;AACA,QAAM,mBAAoB,kBAAkB,cAAe;AAC3D,QAAM,MAAM,kBAAkB;AAE9B,QAAM,cAAwB,CAAC;AAE/B,MAAI,MAAM,GAAG;AACX,gBAAY,KAAK,wDAAwD;AACzE,gBAAY,KAAK,8DAA8D;AAC/E,gBAAY,KAAK,wDAAwD;AAAA,EAC3E;AAEA,MAAI,MAAM,GAAG;AACX,gBAAY,KAAK,iDAAiD;AAClE,gBAAY,KAAK,0CAA0C;AAC3D,gBAAY,KAAK,uDAAuD;AAAA,EAC1E;AAEA,MAAI,MAAM,KAAK;AACb,gBAAY,KAAK,gDAAgD;AACjE,gBAAY,KAAK,mCAAmC;AACpD,gBAAY,KAAK,iCAAiC;AAAA,EACpD;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;;;AC3XA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBAAAC;AAAA,EAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACgBO,SAAS,UACd,GACA,GACA,GACA,GACA,GACA,QAAgB,GACF;AACd,QAAM,IAAI,IAAI,aAAa,IAAI,CAAC;AAEhC,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,aAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,UAAI,MAAM;AACV,eAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,eAAO,EAAE,IAAI,IAAI,CAAC,IAAI,EAAE,IAAI,IAAI,CAAC;AAAA,MACnC;AACA,QAAE,IAAI,IAAI,CAAC,IAAI,MAAM;AAAA,IACvB;AAAA,EACF;AAEA,SAAO;AACT;AAYO,SAAS,eACd,GACA,GACA,OACA,GACA,GACA,GACc;AACd,QAAM,IAAI,IAAI,aAAa,QAAQ,IAAI,CAAC;AACxC,QAAM,UAAU,IAAI;AACpB,QAAM,UAAU,IAAI;AACpB,QAAM,UAAU,IAAI;AAEpB,WAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,aAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,eAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,YAAI,MAAM;AACV,iBAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,iBAAO,EAAE,IAAI,UAAU,IAAI,IAAI,CAAC,IAAI,EAAE,IAAI,UAAU,IAAI,IAAI,CAAC;AAAA,QAC/D;AACA,UAAE,IAAI,UAAU,IAAI,IAAI,CAAC,IAAI;AAAA,MAC/B;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAWO,SAAS,UAAU,GAAiB,GAAiB,GAAW,GAAyB;AAC9F,QAAM,IAAI,IAAI,aAAa,CAAC;AAE5B,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,aAAO,EAAE,IAAI,IAAI,CAAC,IAAI,EAAE,CAAC;AAAA,IAC3B;AACA,MAAE,CAAC,IAAI;AAAA,EACT;AAEA,SAAO;AACT;;;ACrFO,SAAS,WACd,OACA,WACA,WACA,cAAsB,GACR;AACd,QAAM,SAAS,IAAI,aAAa,MAAM,MAAM;AAE5C,WAAS,MAAM,GAAG,MAAM,WAAW,OAAO;AACxC,UAAM,SAAS,MAAM;AAGrB,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,eAAS,KAAK,IAAI,QAAQ,MAAM,SAAS,CAAC,IAAI,WAAW;AAAA,IAC3D;AAGA,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,YAAM,SAAS,KAAK,IAAI,MAAM,SAAS,CAAC,IAAI,cAAc,MAAM;AAChE,aAAO,SAAS,CAAC,IAAI;AACrB,aAAO;AAAA,IACT;AAGA,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,aAAO,SAAS,CAAC,KAAK;AAAA,IACxB;AAAA,EACF;AAEA,SAAO;AACT;AAUO,SAAS,cACd,OACA,WACA,WACA,cAAsB,GACR;AACd,QAAM,SAAS,IAAI,aAAa,MAAM,MAAM;AAE5C,WAAS,MAAM,GAAG,MAAM,WAAW,OAAO;AACxC,UAAM,SAAS,MAAM;AAGrB,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,eAAS,KAAK,IAAI,QAAQ,MAAM,SAAS,CAAC,IAAI,WAAW;AAAA,IAC3D;AAGA,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,gBAAU,KAAK,IAAI,MAAM,SAAS,CAAC,IAAI,cAAc,MAAM;AAAA,IAC7D;AACA,aAAS,KAAK,IAAI,MAAM;AAGxB,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,aAAO,SAAS,CAAC,IAAI,MAAM,SAAS,CAAC,IAAI,cAAc,SAAS;AAAA,IAClE;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,kBACd,OACA,WACA,WACA,cAAsB,GACR;AACd,WAAS,MAAM,GAAG,MAAM,WAAW,OAAO;AACxC,UAAM,SAAS,MAAM;AAErB,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,eAAS,KAAK,IAAI,QAAQ,MAAM,SAAS,CAAC,IAAI,WAAW;AAAA,IAC3D;AAEA,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,YAAM,SAAS,CAAC,IAAI,KAAK,IAAI,MAAM,SAAS,CAAC,IAAI,cAAc,MAAM;AACrE,aAAO,MAAM,SAAS,CAAC;AAAA,IACzB;AAEA,aAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,YAAM,SAAS,CAAC,KAAK;AAAA,IACvB;AAAA,EACF;AAEA,SAAO;AACT;;;AC5GA,SAAS,KAAK,GAAmB;AAC/B,SAAO,KAAK,IAAI,KAAK,IAAI,CAAC,CAAC;AAC7B;AASO,SAAS,QAAQ,OAAmC;AACzD,QAAM,SAAS,IAAI,aAAa,MAAM,MAAM;AAE5C,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,WAAO,CAAC,IAAI,KAAK,MAAM,CAAC,CAAC;AAAA,EAC3B;AAEA,SAAO;AACT;AAUO,SAAS,aAAa,MAAoB,IAAgC;AAC/E,QAAM,SAAS,IAAI,aAAa,KAAK,MAAM;AAE3C,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,WAAO,CAAC,IAAI,KAAK,KAAK,CAAC,CAAC,IAAI,GAAG,CAAC;AAAA,EAClC;AAEA,SAAO;AACT;AAMO,SAAS,aAAa,OAAmC;AAC9D,QAAM,WAAW,MAAM,SAAS;AAChC,QAAM,SAAS,IAAI,aAAa,QAAQ;AAExC,WAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,UAAM,UAAU,MAAM,CAAC;AACvB,UAAM,QAAQ,MAAM,WAAW,CAAC;AAChC,WAAO,CAAC,IAAI,KAAK,OAAO,IAAI;AAAA,EAC9B;AAEA,SAAO;AACT;AAKO,SAAS,eAAe,OAAmC;AAChE,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,UAAM,CAAC,IAAI,KAAK,MAAM,CAAC,CAAC;AAAA,EAC1B;AACA,SAAO;AACT;;;AC1DO,SAAS,WACd,OACA,QACA,WACA,YACA,MAAc,MACA;AACd,QAAM,SAAS,IAAI,aAAa,MAAM,MAAM;AAE5C,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,UAAM,SAAS,IAAI;AAGnB,QAAI,QAAQ;AACZ,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,YAAM,MAAM,MAAM,SAAS,CAAC;AAC5B,eAAS,MAAM;AAAA,IACjB;AACA,UAAM,SAAS,QAAQ;AAGvB,UAAM,QAAQ,IAAM,KAAK,KAAK,SAAS,GAAG;AAG1C,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,aAAO,SAAS,CAAC,IAAI,MAAM,SAAS,CAAC,IAAI,QAAQ,OAAO,CAAC;AAAA,IAC3D;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,mBACd,OACA,WACA,YACA,MAAc,MACA;AACd,QAAM,SAAS,IAAI,aAAa,MAAM,MAAM;AAE5C,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,UAAM,SAAS,IAAI;AAEnB,QAAI,QAAQ;AACZ,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,YAAM,MAAM,MAAM,SAAS,CAAC;AAC5B,eAAS,MAAM;AAAA,IACjB;AACA,UAAM,QAAQ,IAAM,KAAK,KAAK,QAAQ,aAAa,GAAG;AAEtD,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,aAAO,SAAS,CAAC,IAAI,MAAM,SAAS,CAAC,IAAI;AAAA,IAC3C;AAAA,EACF;AAEA,SAAO;AACT;;;AC1DO,SAAS,iBAAiB,KAAa,WAAmB,OAAe,KAAwB;AACtG,QAAM,UAAU,MAAM;AACtB,QAAM,MAAM,IAAI,aAAa,YAAY,OAAO;AAChD,QAAM,MAAM,IAAI,aAAa,YAAY,OAAO;AAEhD,WAAS,MAAM,GAAG,MAAM,WAAW,OAAO;AACxC,aAAS,IAAI,GAAG,IAAI,SAAS,KAAK;AAChC,YAAM,OAAO,IAAM,KAAK,IAAI,MAAO,IAAI,IAAK,GAAG;AAC/C,YAAM,QAAQ,MAAM;AACpB,UAAI,MAAM,UAAU,CAAC,IAAI,KAAK,IAAI,KAAK;AACvC,UAAI,MAAM,UAAU,CAAC,IAAI,KAAK,IAAI,KAAK;AAAA,IACzC;AAAA,EACF;AAEA,SAAO,EAAE,KAAK,IAAI;AACpB;AAeO,SAAS,QACd,GACA,KACA,KACA,QACA,UACA,SACA,WAAmB,GACL;AACd,QAAM,SAAS,IAAI,aAAa,EAAE,MAAM;AACxC,QAAM,UAAU,UAAU;AAE1B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAM,MAAM,IAAI;AAEhB,aAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,YAAM,SAAS,IAAI,WAAW,UAAU,IAAI;AAE5C,eAAS,IAAI,GAAG,IAAI,SAAS,KAAK;AAChC,cAAM,KAAK,EAAE,SAAS,CAAC;AACvB,cAAM,KAAK,EAAE,SAAS,IAAI,OAAO;AAEjC,cAAM,SAAS,IAAI,MAAM,UAAU,CAAC;AACpC,cAAM,SAAS,IAAI,MAAM,UAAU,CAAC;AAGpC,eAAO,SAAS,CAAC,IAAI,KAAK,SAAS,KAAK;AACxC,eAAO,SAAS,IAAI,OAAO,IAAI,KAAK,SAAS,KAAK;AAAA,MACpD;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAMO,SAAS,mBACd,GACA,KACA,KACA,QACA,UACA,SACA,WAAmB,GACL;AACd,QAAM,SAAS,IAAI,aAAa,EAAE,MAAM;AACxC,QAAM,UAAU,UAAU;AAE1B,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAM,MAAM,IAAI;AAEhB,aAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,YAAM,SAAS,IAAI,WAAW,UAAU,IAAI;AAE5C,eAAS,IAAI,GAAG,IAAI,SAAS,KAAK;AAChC,cAAM,KAAK,EAAE,SAAS,IAAI,CAAC;AAC3B,cAAM,KAAK,EAAE,SAAS,IAAI,IAAI,CAAC;AAE/B,cAAM,SAAS,IAAI,MAAM,UAAU,CAAC;AACpC,cAAM,SAAS,IAAI,MAAM,UAAU,CAAC;AAEpC,eAAO,SAAS,IAAI,CAAC,IAAI,KAAK,SAAS,KAAK;AAC5C,eAAO,SAAS,IAAI,IAAI,CAAC,IAAI,KAAK,SAAS,KAAK;AAAA,MAClD;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;;;AClGO,SAAS,aACd,GACA,GACA,GACA,QACA,OACA,UACA,YACA,SACA,OAA4B,MACd;AACd,QAAM,SAAS,IAAI,aAAa,SAAS,WAAW,OAAO;AAC3D,QAAM,QAAQ,IAAM,KAAK,KAAK,OAAO;AAGrC,QAAM,aAAa,WAAW;AAE9B,WAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,UAAM,SAAS,KAAK,MAAM,IAAI,UAAU;AAExC,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAE/B,YAAM,SAAS,IAAI,aAAa,KAAK;AAGrC,eAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,YAAI,QAAQ;AACZ,iBAAS,IAAI,GAAG,IAAI,SAAS,KAAK;AAChC,gBAAM,OAAO,IAAI,WAAW,UAAU,IAAI,UAAU;AACpD,gBAAM,OAAO,IAAI,aAAa,UAAU,SAAS,UAAU;AAC3D,mBAAS,EAAE,IAAI,IAAI,EAAE,IAAI;AAAA,QAC3B;AACA,eAAO,CAAC,IAAI,QAAQ;AAGpB,YAAI,MAAM;AACR,iBAAO,CAAC,KAAK,KAAK,IAAI,QAAQ,CAAC;AAAA,QACjC;AAAA,MACF;AAGA,UAAI,WAAW;AACf,eAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,mBAAW,KAAK,IAAI,UAAU,OAAO,CAAC,CAAC;AAAA,MACzC;AAEA,UAAI,SAAS;AACb,eAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,eAAO,CAAC,IAAI,KAAK,IAAI,OAAO,CAAC,IAAI,QAAQ;AACzC,kBAAU,OAAO,CAAC;AAAA,MACpB;AAEA,eAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,eAAO,CAAC,KAAK;AAAA,MACf;AAGA,eAAS,IAAI,GAAG,IAAI,SAAS,KAAK;AAChC,YAAI,MAAM;AACV,iBAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAC9B,gBAAM,OAAO,IAAI,aAAa,UAAU,SAAS,UAAU;AAC3D,iBAAO,OAAO,CAAC,IAAI,EAAE,IAAI;AAAA,QAC3B;AACA,eAAO,IAAI,WAAW,UAAU,IAAI,UAAU,CAAC,IAAI;AAAA,MACrD;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAMO,SAAS,iBAAiB,QAAgB,QAAuB,MAAoB;AAC1F,MAAI,UAAU;AAAM,YAAQ;AAE5B,QAAM,OAAO,IAAI,aAAa,SAAS,KAAK;AAE5C,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,aAAS,IAAI,GAAG,IAAI,OAAO,KAAK;AAG9B,YAAM,SAAS,QAAQ;AACvB,WAAK,IAAI,QAAQ,CAAC,IAAI,KAAK,IAAI,SAAS,IAAI;AAAA,IAC9C;AAAA,EACF;AAEA,SAAO;AACT;AAMO,SAAS,kBACd,GACA,GACA,GACA,QACA,OACA,UACA,YACA,SACA,YAAoB,IACN;AAGd,SAAO,aAAa,GAAG,GAAG,GAAG,QAAQ,OAAO,UAAU,YAAY,SAAS,iBAAiB,QAAQ,KAAK,CAAC;AAC5G;AAKO,SAAS,OACd,GACA,GACA,GACA,QACA,OACA,UACA,SACA,OAA4B,MACd;AACd,SAAO,aAAa,GAAG,GAAG,GAAG,QAAQ,OAAO,UAAU,GAAG,SAAS,IAAI;AACxE;;;AC/HO,SAAS,QACd,OACA,WACA,YACA,MACA,YAAqB,MACT;AACZ,QAAM,UAAU,IAAI,YAAY,YAAY,IAAI;AAChD,QAAM,UAAU,IAAI,aAAa,YAAY,IAAI;AAEjD,WAAS,QAAQ,GAAG,QAAQ,WAAW,SAAS;AAC9C,UAAM,SAAS,QAAQ;AAGvB,UAAM,QAA8C,CAAC;AACrD,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,YAAM,KAAK,EAAE,MAAM,MAAM,SAAS,CAAC,GAAG,KAAK,EAAE,CAAC;AAAA,IAChD;AAGA,UAAM,KAAK,CAAC,GAAG,MAAM,EAAE,OAAO,EAAE,IAAI;AAGpC,QAAI,YAAY;AAChB,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,cAAQ,QAAQ,OAAO,CAAC,IAAI,MAAM,CAAC,EAAE;AACrC,cAAQ,QAAQ,OAAO,CAAC,IAAI,MAAM,CAAC,EAAE;AACrC,mBAAa,MAAM,CAAC,EAAE;AAAA,IACxB;AAGA,QAAI,aAAa,YAAY,GAAG;AAC9B,eAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,gBAAQ,QAAQ,OAAO,CAAC,KAAK;AAAA,MAC/B;AAAA,IACF;AAAA,EACF;AAEA,SAAO,EAAE,SAAS,QAAQ;AAC5B;AAWO,SAAS,eACd,QACA,WACA,YACA,MACA,YAAqB,MACT;AACZ,QAAM,UAAU,IAAI,YAAY,YAAY,IAAI;AAChD,QAAM,UAAU,IAAI,aAAa,YAAY,IAAI;AAEjD,WAAS,QAAQ,GAAG,QAAQ,WAAW,SAAS;AAC9C,UAAM,SAAS,QAAQ;AAGvB,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,eAAS,KAAK,IAAI,QAAQ,OAAO,SAAS,CAAC,CAAC;AAAA,IAC9C;AAGA,UAAM,UAAU,IAAI,aAAa,UAAU;AAC3C,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,cAAQ,CAAC,IAAI,KAAK,IAAI,OAAO,SAAS,CAAC,IAAI,MAAM;AACjD,gBAAU,QAAQ,CAAC;AAAA,IACrB;AAGA,UAAM,QAA8C,CAAC;AACrD,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,YAAM,KAAK,EAAE,MAAM,QAAQ,CAAC,IAAI,QAAQ,KAAK,EAAE,CAAC;AAAA,IAClD;AAGA,UAAM,KAAK,CAAC,GAAG,MAAM,EAAE,OAAO,EAAE,IAAI;AAGpC,QAAI,YAAY;AAChB,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,cAAQ,QAAQ,OAAO,CAAC,IAAI,MAAM,CAAC,EAAE;AACrC,cAAQ,QAAQ,OAAO,CAAC,IAAI,MAAM,CAAC,EAAE;AACrC,mBAAa,MAAM,CAAC,EAAE;AAAA,IACxB;AAEA,QAAI,aAAa,YAAY,GAAG;AAC9B,eAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,gBAAQ,QAAQ,OAAO,CAAC,KAAK;AAAA,MAC/B;AAAA,IACF;AAAA,EACF;AAEA,SAAO,EAAE,SAAS,QAAQ;AAC5B;;;ACvGO,SAAS,cACd,eACA,SACA,SACA,WACA,YACA,YACA,MACc;AACd,QAAM,SAAS,IAAI,aAAa,YAAY,UAAU;AAEtD,WAAS,QAAQ,GAAG,QAAQ,WAAW,SAAS;AAC9C,aAAS,MAAM,GAAG,MAAM,YAAY,OAAO;AACzC,UAAI,MAAM;AAEV,eAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,cAAM,YAAY,QAAQ,QAAQ,OAAO,CAAC;AAC1C,cAAM,SAAS,QAAQ,QAAQ,OAAO,CAAC;AAGvC,cAAM,eAAe,YAAY,YAAY,aAAa,QAAQ,aAAa;AAC/E,eAAO,SAAS,cAAc,YAAY;AAAA,MAC5C;AAEA,aAAO,QAAQ,aAAa,GAAG,IAAI;AAAA,IACrC;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,wBACd,eACA,SACA,SACA,WACA,YACA,YACA,MACA,gBACc;AACd,QAAM,SAAS,IAAI,aAAa,cAAc;AAE9C,WAAS,QAAQ,GAAG,QAAQ,WAAW,SAAS;AAC9C,aAAS,MAAM,GAAG,MAAM,YAAY,OAAO;AACzC,UAAI,MAAM;AAEV,eAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,cAAM,YAAY,QAAQ,QAAQ,OAAO,CAAC;AAC1C,cAAM,SAAS,QAAQ,QAAQ,OAAO,CAAC;AACvC,cAAM,eAAe,YAAY,YAAY,aAAa,QAAQ,aAAa;AAC/E,eAAO,SAAS,cAAc,YAAY;AAAA,MAC5C;AAEA,aAAO,QAAQ,aAAa,GAAG,KAAK;AAAA,IACtC;AAAA,EACF;AAEA,SAAO;AACT;;;ACxDO,SAAS,aACd,QACA,eACA,WACA,YACA,YACA,MACiB;AAEjB,QAAM,cAAc,IAAI,YAAY,UAAU;AAE9C,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,YAAM,YAAY,cAAc,IAAI,OAAO,CAAC;AAC5C,kBAAY,SAAS;AAAA,IACvB;AAAA,EACF;AAGA,MAAI,qBAAqB;AACzB,WAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,yBAAqB,KAAK,IAAI,oBAAoB,YAAY,CAAC,CAAC;AAAA,EAClE;AAGA,QAAM,iBAAiB,IAAI,aAAa,aAAa,qBAAqB,UAAU;AACpF,QAAM,eAAe,IAAI,YAAY,aAAa,kBAAkB;AAGpE,eAAa,KAAK,UAAU;AAG5B,QAAM,gBAAgB,IAAI,YAAY,UAAU;AAGhD,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,YAAM,YAAY,cAAc,IAAI,OAAO,CAAC;AAC5C,YAAM,UAAU,cAAc,SAAS;AAGvC,YAAM,YAAY,IAAI;AACtB,YAAM,YAAY,YAAY,qBAAqB,aAAa,UAAU;AAE1E,eAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,uBAAe,YAAY,CAAC,IAAI,OAAO,YAAY,CAAC;AAAA,MACtD;AAGA,mBAAa,YAAY,qBAAqB,OAAO,IAAI;AAEzD,oBAAc,SAAS;AAAA,IACzB;AAAA,EACF;AAEA,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAYO,SAAS,yBACd,eACA,WACA,YACA,MACqB;AACrB,QAAM,cAAc,IAAI,YAAY,UAAU;AAC9C,QAAM,gBAAgB,IAAI,YAAY,UAAU;AAGhD,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,YAAM,YAAY,cAAc,IAAI,OAAO,CAAC;AAC5C,kBAAY,SAAS;AAAA,IACvB;AAAA,EACF;AAGA,MAAI,SAAS;AACb,WAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACnC,kBAAc,CAAC,IAAI;AACnB,cAAU,YAAY,CAAC;AAAA,EACzB;AAEA,SAAO,EAAE,aAAa,eAAe,kBAAkB,OAAO;AAChE;;;AC3GO,SAAS,UACd,YACA,SACA,WACA,UACc;AACd,QAAM,SAAS,QAAQ;AACvB,QAAM,SAAS,IAAI,aAAa,SAAS,QAAQ;AAEjD,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAM,MAAM,QAAQ,CAAC;AACrB,UAAM,YAAY,MAAM;AACxB,UAAM,YAAY,IAAI;AAEtB,aAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,aAAO,YAAY,CAAC,IAAI,WAAW,YAAY,CAAC;AAAA,IAClD;AAAA,EACF;AAEA,SAAO;AACT;AAWO,SAAS,eACd,YACA,SACA,WACA,QACA,UACc;AACd,QAAM,SAAS,IAAI,aAAa,YAAY,SAAS,QAAQ;AAE7D,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,aAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,YAAM,MAAM,QAAQ,IAAI,SAAS,CAAC;AAClC,YAAM,YAAY,MAAM;AACxB,YAAM,aAAa,IAAI,SAAS,KAAK;AAErC,eAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,eAAO,YAAY,CAAC,IAAI,WAAW,YAAY,CAAC;AAAA,MAClD;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,iBACd,YACA,eACA,SACA,WACA,UACA,WAAmB,GACL;AACd,QAAM,SAAS,QAAQ;AACvB,QAAM,SAAS,IAAI,aAAa,SAAS,QAAQ;AAEjD,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAM,WAAW,QAAQ,CAAC;AAC1B,UAAM,SAAS,IAAI;AAEnB,UAAM,cAAc,WAAW;AAC/B,UAAM,YAAY,SAAS;AAC3B,UAAM,YAAY,IAAI;AAEtB,aAAS,IAAI,GAAG,IAAI,UAAU,KAAK;AACjC,aAAO,YAAY,CAAC,IAAI,WAAW,cAAc,CAAC,IAAI,cAAc,YAAY,CAAC;AAAA,IACnF;AAAA,EACF;AAEA,SAAO;AACT;;;ACrFO,SAAS,eAAe,GAAiB,UAAsC;AACpF,QAAM,SAAS,IAAI,aAAa,EAAE,MAAM;AAExC,WAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,WAAO,CAAC,IAAI,EAAE,CAAC,IAAI,SAAS,CAAC;AAAA,EAC/B;AAEA,SAAO;AACT;AAKO,SAAS,sBAAsB,GAAiB,UAAsC;AAC3F,WAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,MAAE,CAAC,KAAK,SAAS,CAAC;AAAA,EACpB;AACA,SAAO;AACT;AAMO,SAAS,qBAAqB,GAAiB,UAAwB,OAA6B;AACzG,QAAM,SAAS,IAAI,aAAa,EAAE,MAAM;AAExC,WAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,WAAO,CAAC,IAAI,EAAE,CAAC,IAAI,QAAQ,SAAS,CAAC;AAAA,EACvC;AAEA,SAAO;AACT;;;ACjCA,SAAS,iBAAiB,MAAsB;AAC9C,QAAM,OAAQ,QAAQ,KAAM;AAC5B,QAAM,MAAO,QAAQ,KAAM;AAC3B,QAAM,OAAO,OAAO;AAEpB,MAAI,QAAQ,GAAG;AACb,QAAI,SAAS;AAAG,aAAO,OAAO,KAAK;AAEnC,YAAQ,OAAO,KAAK,KAAK,KAAK,IAAI,GAAG,GAAG,KAAK,OAAO;AAAA,EACtD;AAEA,MAAI,QAAQ,IAAI;AACd,WAAO,OAAO,MAAO,OAAO,YAAY;AAAA,EAC1C;AAEA,UAAQ,OAAO,KAAK,KAAK,KAAK,IAAI,GAAG,MAAM,EAAE,KAAK,IAAI,OAAO;AAC/D;AAEO,SAAS,iBAAiB,OAAuB;AACtD,QAAM,YAAY,IAAI,aAAa,CAAC;AACpC,QAAM,YAAY,IAAI,WAAW,UAAU,MAAM;AACjD,YAAU,CAAC,IAAI;AACf,QAAM,IAAI,UAAU,CAAC;AAErB,QAAM,OAAQ,KAAK,KAAM;AACzB,MAAI,MAAO,KAAK,KAAM;AACtB,MAAI,OAAO,IAAI;AAEf,MAAI,QAAQ,KAAM;AAChB,WAAQ,QAAQ,KAAM,SAAU,OAAO,MAAQ;AAAA,EACjD;AAEA,MAAI,QAAQ,GAAG;AACb,WAAO,QAAQ;AAAA,EACjB;AAEA,QAAM,MAAM,MAAM;AAElB,MAAI,OAAO,IAAI;AACb,WAAQ,QAAQ,KAAM;AAAA,EACxB;AAEA,MAAI,OAAO,GAAG;AACZ,QAAI,MAAM,KAAK;AACb,aAAO,QAAQ;AAAA,IACjB;AACA,YAAQ,OAAO,YAAc,IAAI;AACjC,WAAQ,QAAQ,KAAO,QAAQ;AAAA,EACjC;AAEA,SAAQ,QAAQ,KAAO,OAAO,KAAO,QAAQ;AAC/C;AAaO,SAAS,eACd,WACA,QACA,aAA+B,MAC/B,cAAsB,GACtB,cAAsB,GACR;AACd,QAAM,SAAS,IAAI,aAAa,UAAU,MAAM;AAEhD,MAAI,gBAAgB,GAAG;AACrB,kBAAc,UAAU,SAAS;AAAA,EACnC;AAEA,WAAS,IAAI,GAAG,IAAI,aAAa,KAAK;AACpC,UAAM,QAAQ,OAAO,CAAC;AACtB,UAAM,KAAK,aAAa,WAAW,CAAC,IAAI;AAExC,aAAS,IAAI,GAAG,IAAI,aAAa,KAAK;AACpC,YAAM,MAAM,IAAI,cAAc;AAC9B,aAAO,GAAG,KAAK,UAAU,GAAG,IAAI,MAAM;AAAA,IACxC;AAAA,EACF;AAEA,SAAO;AACT;AAUO,SAAS,eACd,WACA,QACA,aACA,YAAoB,IACN;AACd,QAAM,SAAS,IAAI,aAAa,WAAW;AAC3C,QAAM,YAAY,KAAK,KAAK,cAAc,SAAS;AAEnD,WAAS,IAAI,GAAG,IAAI,aAAa,KAAK;AACpC,UAAM,UAAU,KAAK,MAAM,IAAI,CAAC;AAChC,UAAM,WAAW,KAAK,MAAM,IAAI,SAAS;AACzC,UAAM,QAAQ,OAAO,QAAQ;AAE7B,QAAI;AACJ,QAAI,IAAI,MAAM,GAAG;AAEf,YAAM,UAAU,OAAO,IAAI;AAAA,IAC7B,OAAO;AAEL,YAAO,UAAU,OAAO,KAAK,IAAK;AAAA,IACpC;AAGA,QAAI,OAAO,GAAG;AACZ,YAAM,MAAM;AAAA,IACd;AAEA,WAAO,CAAC,IAAI,MAAM;AAAA,EACpB;AAEA,SAAO;AACT;AAMO,SAAS,eAAe,WAAuB,WAAiC;AACrF,QAAM,YAAY;AAClB,QAAM,SAAS,IAAI,aAAa,YAAY,SAAS;AACrD,QAAM,WAAW,IAAI,SAAS,UAAU,MAAM;AAE9C,WAAS,QAAQ,GAAG,QAAQ,WAAW,SAAS;AAE9C,UAAM,cAAc,QAAQ;AAG5B,UAAM,aAAa,SAAS,UAAU,aAAa,IAAI;AACvD,UAAM,QAAQ,iBAAiB,UAAU;AAGzC,aAAS,IAAI,GAAG,IAAI,IAAI,KAAK;AAC3B,YAAM,OAAO,UAAU,cAAc,IAAI,CAAC;AAE1C,YAAM,OAAO,OAAO,MAAQ;AAC5B,YAAM,QAAS,QAAQ,IAAK,MAAQ;AAEpC,aAAO,QAAQ,YAAY,IAAI,CAAC,IAAI,MAAM;AAC1C,aAAO,QAAQ,YAAY,IAAI,IAAI,CAAC,IAAI,OAAO;AAAA,IACjD;AAAA,EACF;AAEA,SAAO;AACT;AAMA,IAAM,QAAQ;AACd,IAAM,iBAAiB;AAEvB,SAAS,WAAW,MAAoB,QAAgB,QAA8C;AACpG,MAAI,MAAM;AACV,MAAI,MAAM;AACV,WAAS,IAAI,GAAG,IAAI,QAAQ,KAAK;AAC/B,UAAM,MAAM,KAAK,SAAS,CAAC;AAC3B,QAAI,MAAM;AAAK,YAAM;AACrB,QAAI,MAAM;AAAK,YAAM;AAAA,EACvB;AACA,SAAO,EAAE,KAAK,IAAI;AACpB;AAMO,SAAS,qBAAqB,MAAoB,QAA4B;AACnF,QAAM,QAAQ,IAAI,WAAW,cAAc;AAC3C,QAAM,OAAO,IAAI,SAAS,MAAM,MAAM;AAEtC,QAAM,SAAS,IAAI,aAAa,CAAC;AACjC,QAAM,aAAa,IAAI,aAAa,CAAC;AACrC,QAAM,KAAK,IAAI,WAAW,GAAG;AAE7B,WAAS,KAAK,GAAG,KAAK,GAAG,MAAM;AAC7B,UAAM,WAAW,SAAS,KAAK;AAC/B,UAAM,EAAE,KAAK,IAAI,IAAI,WAAW,MAAM,UAAU,EAAE;AAElD,eAAW,EAAE,IAAI,CAAC;AAClB,UAAM,QAAQ,MAAM;AACpB,WAAO,EAAE,IAAI,QAAQ,IAAI,QAAQ,KAAK;AAEtC,UAAM,WAAW,OAAO,EAAE,IAAI,IAAI,IAAI,OAAO,EAAE,IAAI;AACnD,aAAS,IAAI,GAAG,IAAI,IAAI,KAAK;AAC3B,YAAM,MAAM,KAAK,WAAW,CAAC;AAC7B,UAAI,IAAI,KAAK,OAAO,MAAM,OAAO,QAAQ;AACzC,UAAI,KAAK,IAAI,GAAG,KAAK,IAAI,IAAI,CAAC,CAAC;AAC/B,SAAG,KAAK,KAAK,CAAC,IAAI;AAAA,IACpB;AAAA,EACF;AAEA,MAAI,WAAW;AACf,MAAI,eAAe;AACnB,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,QAAI,OAAO,CAAC,IAAI;AAAU,iBAAW,OAAO,CAAC;AAC7C,QAAI,WAAW,CAAC,IAAI;AAAc,qBAAe,WAAW,CAAC;AAC7D,QAAI,WAAW,CAAC,IAAI;AAAG,iBAAW,CAAC,IAAI;AAAA,EACzC;AAEA,QAAM,IAAI,WAAW;AACrB,QAAM,OAAO,eAAe;AAE5B,OAAK,UAAU,GAAG,iBAAiB,CAAC,GAAG,IAAI;AAC3C,OAAK,UAAU,GAAG,iBAAiB,IAAI,GAAG,IAAI;AAE9C,QAAM,OAAO,IAAI,IAAI,IAAI,IAAI;AAC7B,QAAM,UAAU,OAAO,IAAI,IAAI,OAAO;AAEtC,QAAM,YAAY,IAAI,WAAW,CAAC;AAClC,QAAM,UAAU,IAAI,WAAW,CAAC;AAChC,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,cAAU,CAAC,IAAI,KAAK,IAAI,IAAI,KAAK,MAAM,OAAO,CAAC,IAAI,IAAI,CAAC;AACxD,YAAQ,CAAC,IAAI,KAAK,IAAI,IAAI,KAAK,MAAM,KAAK,IAAI,GAAG,WAAW,CAAC,CAAC,IAAI,OAAO,CAAC;AAAA,EAC5E;AAGA,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,UAAM,UAAU,UAAU,CAAC,IAAI;AAC/B,UAAM,WAAY,UAAU,IAAI,CAAC,KAAK,IAAK;AAC3C,UAAM,IAAI,CAAC,IAAI,UAAW,YAAY;AAAA,EACxC;AAGA,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,UAAM,QAAQ,QAAQ,CAAC,IAAI;AAC3B,UAAM,SAAU,QAAQ,IAAI,CAAC,KAAK,IAAK;AACvC,UAAM,IAAI,IAAI,CAAC,IAAI,QAAS,UAAU;AAAA,EACxC;AAGA,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,UAAM,WAAW,UAAU,IAAI,CAAC,IAAI;AACpC,UAAM,SAAS,QAAQ,IAAI,CAAC,IAAI;AAChC,UAAM,IAAI,IAAI,CAAC,IAAI,WAAY,UAAU;AAAA,EAC3C;AAGA,WAAS,QAAQ,GAAG,QAAQ,GAAG,SAAS;AACtC,UAAM,YAAY,QAAQ;AAC1B,UAAM,WAAW,KAAK,QAAQ;AAC9B,aAAS,IAAI,GAAG,IAAI,IAAI,KAAK;AAC3B,YAAM,KAAK,GAAG,YAAY,CAAC,IAAI;AAC/B,YAAM,KAAK,GAAG,YAAY,KAAK,CAAC,IAAI;AACpC,YAAM,WAAW,CAAC,IAAI,KAAM,MAAM;AAAA,IACpC;AAAA,EACF;AAEA,SAAO;AACT;AAEO,SAAS,gBAAgB,QAAsB,WAA+B;AACnF,QAAM,MAAM,IAAI,WAAW,YAAY,cAAc;AACrD,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,UAAM,QAAQ,qBAAqB,QAAQ,IAAI,KAAK;AACpD,QAAI,IAAI,OAAO,IAAI,cAAc;AAAA,EACnC;AACA,SAAO;AACT;AAEO,SAAS,uBAAuB,OAAiC;AACtE,QAAM,OAAO,IAAI,SAAS,MAAM,QAAQ,MAAM,UAAU;AACxD,QAAM,MAAM,IAAI,aAAa,KAAK;AAElC,QAAM,IAAI,iBAAiB,KAAK,UAAU,GAAG,IAAI,CAAC;AAClD,QAAM,OAAO,iBAAiB,KAAK,UAAU,GAAG,IAAI,CAAC;AAErD,QAAM,YAAY,IAAI,WAAW,CAAC;AAClC,QAAM,UAAU,IAAI,WAAW,CAAC;AAEhC,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,cAAU,CAAC,IAAI,MAAM,IAAI,CAAC,IAAI;AAC9B,cAAU,IAAI,CAAC,KAAM,MAAM,IAAI,CAAC,KAAK,IAAK,MAAS;AAAA,EACrD;AACA,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,YAAQ,CAAC,IAAI,MAAM,IAAI,IAAI,CAAC,IAAI;AAChC,YAAQ,IAAI,CAAC,KAAM,MAAM,IAAI,IAAI,CAAC,KAAK,IAAK,MAAS;AAAA,EACvD;AACA,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,cAAU,IAAI,CAAC,KAAK,MAAM,IAAI,IAAI,CAAC,IAAI;AACvC,YAAQ,IAAI,CAAC,KAAM,MAAM,IAAI,IAAI,CAAC,KAAK,IAAK;AAAA,EAC9C;AAEA,QAAM,SAAS,IAAI,aAAa,CAAC;AACjC,QAAM,OAAO,IAAI,aAAa,CAAC;AAC/B,WAAS,IAAI,GAAG,IAAI,GAAG,KAAK;AAC1B,WAAO,CAAC,IAAI,IAAI,UAAU,CAAC;AAC3B,SAAK,CAAC,IAAI,OAAO,QAAQ,CAAC;AAAA,EAC5B;AAEA,WAAS,QAAQ,GAAG,QAAQ,GAAG,SAAS;AACtC,UAAM,YAAY,QAAQ;AAC1B,UAAM,WAAW,KAAK,QAAQ;AAC9B,aAAS,IAAI,GAAG,IAAI,IAAI,KAAK;AAC3B,YAAM,OAAO,MAAM,WAAW,CAAC;AAC/B,YAAM,KAAK,OAAO;AAClB,YAAM,KAAM,QAAQ,IAAK;AAEzB,YAAM,MAAM,KAAK,OAAO,YAAY,KAAK,EAAE;AAC3C,YAAM,MAAM,KAAK,OAAO,YAAY,KAAK,KAAK,EAAE;AAEhD,UAAI,YAAY,CAAC,IAAI,OAAO,GAAG,IAAI,KAAK,KAAK,GAAG;AAChD,UAAI,YAAY,KAAK,CAAC,IAAI,OAAO,GAAG,IAAI,KAAK,KAAK,GAAG;AAAA,IACvD;AAAA,EACF;AAEA,SAAO;AACT;AAEO,SAAS,eAAe,WAAuB,WAAiC;AACrF,QAAM,MAAM,IAAI,aAAa,YAAY,KAAK;AAC9C,WAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,UAAM,QAAQ,IAAI;AAClB,UAAM,QAAQ,UAAU,SAAS,OAAO,QAAQ,cAAc;AAC9D,QAAI,IAAI,uBAAuB,KAAK,GAAG,IAAI,KAAK;AAAA,EAClD;AACA,SAAO;AACT;;;AClVO,SAAS,UAAU,QAA8B;AACtD,MAAI,SAAS;AACb,MAAI,SAAS,OAAO,CAAC;AAErB,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,QAAI,OAAO,CAAC,IAAI,QAAQ;AACtB,eAAS,OAAO,CAAC;AACjB,eAAS;AAAA,IACX;AAAA,EACF;AAEA,SAAO;AACT;AAKO,SAAS,cAAc,QAAsB,GAAoD;AAEtG,QAAM,UAAU,MAAM,KAAK,MAAM,EAAE,IAAI,CAAC,KAAK,SAAS,EAAE,KAAK,IAAI,EAAE;AACnE,UAAQ,KAAK,CAAC,GAAG,MAAM,EAAE,MAAM,EAAE,GAAG;AAEpC,QAAM,OAAO,QAAQ,MAAM,GAAG,CAAC;AAC/B,SAAO;AAAA,IACL,SAAS,KAAK,IAAI,OAAK,EAAE,GAAG;AAAA,IAC5B,QAAQ,KAAK,IAAI,OAAK,EAAE,GAAG;AAAA,EAC7B;AACF;AAKO,SAAS,gBAAgB,QAAsB,aAAmC;AACvF,QAAM,SAAS,IAAI,aAAa,OAAO,MAAM;AAG7C,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,WAAO,CAAC,IAAI,OAAO,CAAC,IAAI;AAAA,EAC1B;AAGA,MAAI,MAAM,OAAO,CAAC;AAClB,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,QAAI,OAAO,CAAC,IAAI;AAAK,YAAM,OAAO,CAAC;AAAA,EACrC;AAGA,MAAI,MAAM;AACV,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,WAAO,CAAC,IAAI,KAAK,IAAI,OAAO,CAAC,IAAI,GAAG;AACpC,WAAO,OAAO,CAAC;AAAA,EACjB;AAGA,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACtC,WAAO,CAAC,KAAK;AAAA,EACf;AAEA,SAAO;AACT;AAUO,SAAS,cACd,QACA,aACA,MACA,aACQ;AAER,MAAI,cAAc,MAAM;AACtB,WAAO,UAAU,MAAM;AAAA,EACzB;AAGA,QAAM,EAAE,SAAS,OAAO,IAAI,cAAc,QAAQ,IAAI;AAGtD,QAAM,eAAe,OAAO,IAAI,OAAK,IAAI,WAAW;AAGpD,QAAM,MAAM,KAAK,IAAI,GAAG,YAAY;AACpC,QAAM,YAAY,aAAa,IAAI,OAAK,KAAK,IAAI,IAAI,GAAG,CAAC;AACzD,QAAM,MAAM,UAAU,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAC/C,QAAM,QAAQ,UAAU,IAAI,OAAK,IAAI,GAAG;AAGxC,MAAI,UAAU;AACd,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,eAAW,MAAM,CAAC;AAClB,QAAI,WAAW,aAAa;AAC1B,aAAO,QAAQ,CAAC;AAAA,IAClB;AAAA,EACF;AAGA,SAAO,QAAQ,QAAQ,SAAS,CAAC;AACnC;AAKO,SAASC,cAAa,MAAsB;AACjD,QAAM,IAAI,KAAK,IAAI,IAAI,IAAI;AAC3B,SAAO,IAAI,KAAK,MAAM,CAAC;AACzB;;;ACvFO,IAAM,oBAAsC;AAAA,EACjD,YAAY,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA,EACrC,YAAY,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA;AAAA,EAErC,WAAW,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA;AAAA,EAEpC,SAAS,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA;AAAA,EAElC,SAAS,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA,EAElC,MAAM,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA;AAAA,EAE/B,MAAM,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA,EAE/B,MAAM;AAAA,IACJ,SAAS,EAAE,OAAO,KAAK;AAAA;AAAA,IACvB,SAAS,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA,EACpC;AAAA,EAEA,aAAa,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA,EAEtC,YAAY,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA,EAErC,QAAQ,EAAE,OAAO,KAAK;AAAA;AAAA,EAEtB,UAAU,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA;AAAA,EAEnC,SAAS,EAAE,MAAM,MAAM,MAAM,KAAK;AAAA;AACpC;AA2BO,SAAS,cACd,UACA,QACA,UAAoC,CAAC,GACnB;AAClB,QAAM,EAAE,OAAO,MAAM,OAAO,KAAK,IAAI;AAErC,MAAI,SAAS,WAAW,OAAO,QAAQ;AACrC,WAAO;AAAA,MACL,QAAQ;AAAA,MACR,OAAO,6BAA6B,SAAS,MAAM,SAAS,OAAO,MAAM;AAAA,MACzE,UAAU;AAAA,MACV,UAAU;AAAA,MACV,eAAe,SAAS;AAAA,IAC1B;AAAA,EACF;AAEA,MAAI,WAAW;AACf,MAAI,WAAW;AACf,MAAI,gBAAgB;AACpB,QAAM,aAAyB,CAAC;AAEhC,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,KAAK;AACxC,UAAM,IAAI,SAAS,CAAC;AACpB,UAAM,IAAI,OAAO,CAAC;AAClB,UAAM,QAAQ,KAAK,IAAI,IAAI,CAAC;AAC5B,UAAM,YAAY,OAAO,OAAO,KAAK,IAAI,CAAC;AAE1C,eAAW,KAAK,IAAI,UAAU,KAAK;AACnC,gBAAY;AAEZ,QAAI,QAAQ,WAAW;AACrB;AACA,UAAI,WAAW,SAAS,IAAI;AAC1B,mBAAW,KAAK,EAAE,OAAO,GAAG,UAAU,GAAG,QAAQ,GAAG,OAAO,UAAU,CAAC;AAAA,MACxE;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AAAA,IACL,QAAQ,kBAAkB;AAAA,IAC1B;AAAA,IACA,UAAU,WAAW,SAAS;AAAA,IAC9B;AAAA,IACA,eAAe,gBAAgB,SAAS;AAAA,IACxC,iBAAiB;AAAA,EACnB;AACF;AAmEO,SAAS,iBACd,MACA,OAAe,IACf,UAA2B,CAAC,GACa;AACzC,QAAM,EAAE,MAAM,IAAI,MAAM,GAAG,QAAQ,UAAU,IAAI;AAEjD,MAAI;AACJ,UAAQ,OAAO;AAAA,IACb,KAAK;AACH,aAAO,IAAI,YAAY,IAAI;AAC3B;AAAA,IACF,KAAK;AACH,aAAO,IAAI,WAAW,IAAI;AAC1B;AAAA,IACF;AACE,aAAO,IAAI,aAAa,IAAI;AAAA,EAChC;AAGA,MAAI,QAAQ;AACZ,QAAM,QAAQ,MAAM;AAEpB,WAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,YAAS,QAAQ,aAAa,QAAS;AACvC,UAAM,aAAa,QAAQ;AAE3B,QAAI,UAAU,WAAW;AACvB,WAAK,CAAC,IAAI,MAAM,aAAa;AAAA,IAC/B,OAAO;AACL,WAAK,CAAC,IAAI,KAAK,MAAM,MAAM,aAAa,KAAK;AAAA,IAC/C;AAAA,EACF;AAEA,SAAO;AACT;;;A5CvNA,IAAM;AAAA,EACJ,WAAAC,aAAY;AAAA,EACZ,YAAAC,cAAa;AAAA,EACb,SAAAC,WAAU;AAAA,EACV,gBAAAC,kBAAiB;AAAA,EACjB,eAAAC,iBAAgB;AAAA,EAChB,cAAAC,gBAAe;AAAA,EACf,YAAAC,cAAa;AAAA,EACb,SAAAC,WAAU;AAAA,EACV,SAAAC,WAAU;AAAA,EACV,uBAAAC,yBAAwB;AAAA,EACxB,UAAAC,YAAW;AAAA,EACX,WAAAC,aAAY;AAAA,EACZ,gBAAAC,kBAAiB;AAAA,EACjB,YAAAC,cAAa;AAAA,EACb,cAAAC,gBAAe;AAAA,EACf,YAAAC,cAAa;AAAA,EACb,eAAAC,iBAAgB;AAAA,EAChB,cAAAC,gBAAe;AAAA,EACf,cAAAC,gBAAe;AAAA,EACf,cAAAC,gBAAe;AACjB,IAAI;AAMJ,IAAI,aAAkB;AACtB,IAAI;AACF,eAAa,MAAM;AACrB,SAAS,GAAG;AACV,UAAQ,KAAK,8BAA+B,EAAY,OAAO;AACjE;AASA,IAAI,SAA2B;AAC/B,IAAI,cAAc;AAKlB,SAASC,UAAS,GAAmB;AACnC,QAAM,QAAQ,IAAI,UAAW;AAC7B,QAAM,YAAY,IAAI,UAAW;AACjC,QAAM,WAAW,IAAI;AAErB,MAAI,aAAa,GAAG;AAElB,QAAI,aAAa;AAAG,aAAO,OAAO,KAAK;AACvC,YAAQ,OAAO,KAAK,KAAK,KAAK,IAAI,GAAG,GAAG,KAAK,WAAW;AAAA,EAC1D,WAAW,aAAa,IAAI;AAE1B,WAAO,aAAa,IAAK,OAAO,YAAY,WAAY;AAAA,EAC1D;AAGA,UAAQ,OAAO,KAAK,KAAK,KAAK,IAAI,GAAG,WAAW,EAAE,KAAK,IAAI,WAAW;AACxE;AAKA,eAAe,UAA8B;AAC3C,MAAI;AAAQ,WAAO;AAEnB,sBAAoB,oBAAoB;AACxC,iBAAe,+BAA+B;AAE9C,WAAS,MAAM,WAAW;AAC1B,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,sBAAsB;AAAA,EACxC;AAGA,sBAAoB,kBAAkB,WAAW,GAAG,SAAS;AAE7D,gBAAc;AACd,SAAO;AACT;AAKA,eAAe,SAA0D;AACvE,MAAI,CAAC,QAAQ;AACX,UAAM,QAAQ;AAAA,EAChB;AACA,SAAO,EAAE,QAAiB,OAAO,OAAQ,MAAM;AACjD;AAKA,SAAS,WACP,MACA,QAAgB,eAAe,UAAU,eAAe,UAC7C;AACX,QAAM,aAAa,gBAAgB,cAAc,KAAK,aAAa,KAAK;AACxE,QAAM,SAAS,OAAQ,aAAa;AAAA,IAClC,MAAM;AAAA,IACN,OAAO,QAAQ,eAAe;AAAA,IAC9B,kBAAkB;AAAA,EACpB,CAAC;AAED,QAAM,cAAc,OAAO,eAAe;AAC1C,MAAI,gBAAgB,cAAc;AAChC,QAAI,aAAa,WAAW,EAAE,IAAI,IAAI;AAAA,EACxC,WAAW,gBAAgB,aAAa;AACtC,QAAI,YAAY,WAAW,EAAE,IAAI,IAAI;AAAA,EACvC,WAAW,gBAAgB,YAAY;AACrC,QAAI,WAAW,WAAW,EAAE,IAAI,IAAI;AAAA,EACtC,WAAW,gBAAgB,aAAa;AACtC,QAAI,YAAY,WAAW,EAAE,IAAI,IAAI;AAAA,EACvC,WAAW,gBAAgB,YAAY;AACrC,QAAI,WAAW,WAAW,EAAE,IAAI,IAAI;AAAA,EACtC,OAAO;AACL,QAAI,WAAW,WAAW,EAAE,IAAI,IAAI,WAAW,IAAI,CAAC;AAAA,EACtD;AACA,SAAO,MAAM;AAEb,SAAO;AACT;AAKA,eAAe,eAAe,QAAmB,MAAoC;AACnF,QAAM,gBAAgB,OAAQ,aAAa;AAAA,IACzC;AAAA,IACA,OAAO,eAAe,WAAW,eAAe;AAAA,EAClD,CAAC;AAED,QAAM,UAAU,OAAQ,qBAAqB;AAC7C,UAAQ,mBAAmB,QAAQ,GAAG,eAAe,GAAG,IAAI;AAC5D,SAAQ,MAAM,OAAO,CAAC,QAAQ,OAAO,CAAC,CAAC;AAEvC,QAAM,cAAc,SAAS,WAAW,IAAI;AAC5C,QAAM,OAAO,IAAI,WAAW,cAAc,eAAe,CAAC,EAAE,MAAM;AAClE,gBAAc,MAAM;AACpB,gBAAc,QAAQ;AAEtB,SAAO,KAAK;AACd;AAyNA,IAAM,cAA+B;AAAA;AAAA,EAEnC;AAAA,EACA,QAAQ,MAAM;AAAA;AAAA,EAGd;AAAA,EACA,SAAoB;AAAA,EACpB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA,EAGA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASA,MAAM,UAAU,KAAK,GAAG,GAAG,GAAG,GAAG,GAAG,QAAQ,GAAK;AAC/C,QAAI,CAACpB,YAAW;AAEd,aAAkB,UAAU,GAAG,GAAG,GAAG,GAAG,GAAG,KAAK;AAAA,IAClD;AAEA,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,UAAU,aAAa,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,UAAU;AAC5D,UAAM,OAAO,WAAW,CAAC;AAIzB,UAAM,eAAe,MAAMA,WAAU,SAAS,MAAM,GAAG,GAAG,GAAG,EAAE,OAAO,YAAY,MAAM,CAAC;AAEzF,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,IAAI,IAAI,CAAC,CAAC;AAEpF,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,eAAe,KAAK,GAAG,GAAG,OAAO,GAAG,GAAG,GAAG;AAE9C,WAAkB,eAAe,GAAG,GAAG,OAAO,GAAG,GAAG,CAAC;AAAA,EACvD;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,UAAU,KAAK,GAAG,GAAG,GAAG,GAAG;AAE/B,WAAkB,UAAU,GAAG,GAAG,GAAG,CAAC;AAAA,EACxC;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,aAAa,KAAK,GAAG,OAAO,GAAG,GAAG,GAAG,QAAQ,GAAK;AACtD,QAAI,CAACA,YAAW;AACd,YAAM,IAAI,MAAM,gCAAgC;AAAA,IAClD;AAGA,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,UAAU,aAAa,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,cAAc;AAGhE,UAAM,OAAO,WAAW,OAAO,eAAe,UAAU,eAAe,QAAQ;AAI/E,UAAM,eAAe,MAAMA,WAAU,SAAS,MAAM,GAAG,GAAG,GAAG,EAAE,OAAO,QAAQ,MAAM,CAAC;AAErF,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,IAAI,IAAI,CAAC,CAAC;AAEpF,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,WAAW,KAAK,OAAO,WAAW,WAAW,cAAc,GAAK;AACpE,QAAI,CAACC,aAAY;AACf,aAAkB,WAAW,OAAO,WAAW,WAAW,WAAW;AAAA,IACvE;AAEA,UAAM,WAAW,WAAW,KAAK;AACjC,UAAM,cAAc,aAAa,UAAU,OAAO,CAAC,WAAW,SAAS,GAAG,eAAe;AAEzF,UAAM,eAAe,MAAMA,YAAW,aAAa,IAAI;AAAA,MACrD,WAAW;AAAA,MACX,MAAM;AAAA,MACN;AAAA,IACF,CAAC;AAED,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,MAAM,SAAS,CAAC,CAAC;AAE3F,aAAS,QAAQ;AACjB,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,eAAe,KAAK,QAAQ,WAAW,YAAY,MAAM,UAAU,CAAC,GAAG;AAC3E,QAAI,CAACE,iBAAgB;AACnB,aAAkB,eAAe,QAAQ,WAAW,YAAY,MAAM,QAAQ,cAAc,KAAK;AAAA,IACnG;AAEA,UAAM,WAAW,WAAW,MAAM;AAElC,UAAM,EAAE,SAAS,YAAY,SAAS,WAAW,IAAI,MAAMA;AAAA,MACzD;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,EAAE,WAAW,QAAQ,cAAc,MAAM;AAAA,IAC3C;AAEA,UAAM,UAAU,IAAI,YAAY,MAAM,eAAe,YAAY,YAAY,OAAO,CAAC,CAAC;AACtF,UAAM,UAAU,IAAI,aAAa,MAAM,eAAe,YAAY,YAAY,OAAO,CAAC,CAAC;AAEvF,aAAS,QAAQ;AACjB,eAAW,QAAQ;AACnB,eAAW,QAAQ;AAEnB,WAAO,EAAE,SAAS,QAAQ;AAAA,EAC5B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,KAAK,OAAO,WAAW,YAAY,MAAM,UAAU,CAAC,GAAG;AACnE,UAAM,WAAW,WAAW,KAAK;AAEjC,UAAM,EAAE,SAAS,YAAY,SAAS,WAAW,IAAI,MAAMD;AAAA,MACzD;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,EAAE,WAAW,QAAQ,cAAc,MAAM;AAAA,IAC3C;AAEA,UAAM,UAAU,IAAI,YAAY,MAAM,eAAe,YAAY,YAAY,OAAO,CAAC,CAAC;AACtF,UAAM,UAAU,IAAI,aAAa,MAAM,eAAe,YAAY,YAAY,OAAO,CAAC,CAAC;AAEvF,aAAS,QAAQ;AACjB,eAAW,QAAQ;AACnB,eAAW,QAAQ;AAEnB,WAAO,EAAE,SAAS,QAAQ;AAAA,EAC5B;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,KAAK,eAAe,SAAS,SAAS,WAAW,YAAY,YAAY,MAAM;AACjG,QAAI,CAACE,gBAAe;AAClB,aAAkB,cAAc,eAAe,SAAS,SAAS,WAAW,YAAY,YAAY,IAAI;AAAA,IAC1G;AAEA,UAAM,YAAY,WAAW,aAAa;AAC1C,UAAM,aAAa,WAAW,OAAO;AACrC,UAAM,aAAa,WAAW,OAAO;AAGrC,UAAM,eAAe,aAAa,WAAW,OAAO,CAAC,YAAY,WAAW,UAAU,GAAG,gBAAgB;AACzG,UAAM,eAAe,MAAMA;AAAA,MACzB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,YAAY,aAAa,CAAC,CAAC;AAErG,cAAU,QAAQ;AAClB,eAAW,QAAQ;AACnB,eAAW,QAAQ;AACnB,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,WAAW,KAAK,OAAO,QAAQ,WAAW,YAAY,MAAM,MAAM;AACtE,QAAI,CAACE,aAAY;AACf,aAAkB,WAAW,OAAO,QAAQ,WAAW,YAAY,GAAG;AAAA,IACxE;AAEA,UAAM,WAAW,WAAW,KAAK;AACjC,UAAM,YAAY,WAAW,MAAM;AACnC,UAAM,cAAc,aAAa,UAAU,OAAO,CAAC,WAAW,UAAU,GAAG,eAAe;AAE1F,UAAM,eAAe,MAAMA,YAAW,aAAa,WAAW,KAAK;AAAA,MACjE,WAAW;AAAA,MACX;AAAA,IACF,CAAC;AAED,QAAI;AACJ,QAAI,aAAa,UAAU,OAAO;AAChC,YAAM,UAAU,MAAM,eAAe,aAAa,QAAQ,YAAY,aAAa,CAAC;AACpF,YAAM,UAAU,IAAI,YAAY,OAAO;AACvC,eAAS,IAAI,aAAa,QAAQ,MAAM;AACxC,eAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,eAAO,CAAC,IAAIc,UAAS,QAAQ,CAAC,CAAC;AAAA,MACjC;AAAA,IACF,OAAO;AACL,eAAS,IAAI;AAAA,QACX,MAAM,eAAe,aAAa,QAAQ,YAAY,aAAa,CAAC;AAAA,MACtE;AAAA,IACF;AAEA,aAAS,QAAQ;AACjB,cAAU,QAAQ;AAClB,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,KAAK,OAAO,QAAQ,UAAU,SAAS,WAAW,GAAG;AACjE,UAAM,EAAE,KAAK,IAAI,IAAe,iBAAiB,SAAS,SAAS,QAAQ;AAE3E,QAAI,CAACb,UAAS;AACZ,aAAkB,QAAQ,OAAO,KAAK,KAAK,QAAQ,UAAU,SAAS,QAAQ;AAAA,IAChF;AAEA,UAAM,WAAW,WAAW,KAAK;AACjC,UAAM,SAAS,WAAW,GAAG;AAC7B,UAAM,SAAS,WAAW,GAAG;AAE7B,UAAMA,SAAQ,UAAU,QAAQ,QAAQ,QAAQ;AAAA,MAC9C;AAAA,MACA;AAAA,MACA;AAAA,IACF,CAAC;AAED,UAAM,SAAS,IAAI;AAAA,MACjB,MAAM,eAAe,UAAU,SAAS,WAAW,UAAU,CAAC;AAAA,IAChE;AAEA,aAAS,QAAQ;AACjB,WAAO,QAAQ;AACf,WAAO,QAAQ;AAEf,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,QAAQ,KAAK,OAAO;AACxB,QAAI,CAACC,UAAS;AACZ,aAAkB,QAAQ,KAAK;AAAA,IACjC;AAEA,UAAM,WAAW,WAAW,KAAK;AACjC,UAAM,YAAY,MAAMA,SAAQ,UAAU,EAAE,MAAM,MAAM,OAAO,CAAC;AAChE,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,WAAW,MAAM,SAAS,CAAC,CAAC;AAEjF,aAAS,QAAQ;AACjB,cAAU,QAAQ;AAElB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAAa,KAAK,MAAM,IAAI;AAChC,QAAI,CAACA,UAAS;AACZ,aAAkB,aAAa,MAAM,EAAE;AAAA,IACzC;AAEA,UAAM,UAAU,WAAW,IAAI;AAC/B,UAAM,QAAQ,WAAW,EAAE;AAE3B,UAAM,YAAY,MAAMA,SAAQ,OAAO,EAAE,MAAM,GAAG,QAAQ,MAAM,QAAQ,CAAC;AACzE,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,WAAW,GAAG,SAAS,CAAC,CAAC;AAE9E,YAAQ,QAAQ;AAChB,UAAM,QAAQ;AACd,cAAU,QAAQ;AAElB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,UAAU,KAAK,YAAY,SAAS,WAAW,UAAU;AAC7D,QAAI,CAACG,YAAW;AACd,aAAkB,UAAU,YAAY,SAAS,WAAW,QAAQ;AAAA,IACtE;AAEA,UAAM,SAAS,WAAW,UAAU;AACpC,UAAM,SAAS,WAAW,OAAO;AACjC,UAAM,YAAY,QAAQ;AAE1B,UAAM,eAAe,MAAMA,WAAU,QAAQ,QAAQ,WAAW,UAAU,WAAW,EAAE,WAAW,MAAM,CAAC;AACzG,QAAI;AACJ,QAAI,aAAa,UAAU,OAAO;AAChC,YAAM,UAAU,MAAM,eAAe,aAAa,QAAQ,YAAY,WAAW,CAAC;AAClF,YAAM,UAAU,IAAI,YAAY,OAAO;AACvC,eAAS,IAAI,aAAa,QAAQ,MAAM;AACxC,eAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,eAAO,CAAC,IAAIS,UAAS,QAAQ,CAAC,CAAC;AAAA,MACjC;AAAA,IACF,OAAO;AACL,eAAS,IAAI;AAAA,QACX,MAAM,eAAe,aAAa,QAAQ,YAAY,WAAW,CAAC;AAAA,MACpE;AAAA,IACF;AAEA,WAAO,QAAQ;AACf,WAAO,QAAQ;AACf,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,YAAY,KAAK,GAAG,UAAU;AAClC,QAAI,CAACR,iBAAgB;AACnB,aAAkB,eAAe,GAAG,QAAQ;AAAA,IAC9C;AAEA,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,SAAS,WAAW,QAAQ;AAClC,UAAM,OAAO,EAAE;AACf,UAAM,YAAY,MAAMA,gBAAe,MAAM,QAAQ,IAAI;AACzD,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,WAAW,OAAO,CAAC,CAAC;AAEzE,SAAK,QAAQ;AACb,WAAO,QAAQ;AACf,cAAU,QAAQ;AAElB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,WAAW,KAAK,MAAM,MAAM,WAAW,KAAK;AAChD,QAAI,CAACC,aAAY;AACf,YAAMQ,UAAS,IAAI,aAAa,IAAI;AACpC,eAAS,IAAI,GAAG,IAAI,WAAW,KAAK;AAClC,cAAM,YAAY,IAAI;AACtB,iBAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC5B,UAAAA,QAAO,YAAY,CAAC,KAAK,KAAK,CAAC;AAAA,QACjC;AAAA,MACF;AACA,aAAOA;AAAA,IACT;AAEA,UAAM,UAAU,WAAW,IAAI;AAC/B,UAAM,UAAU,WAAW,IAAI;AAC/B,UAAM,aAAa,aAAa,SAAS,OAAO,CAAC,WAAW,GAAG,GAAG,eAAe;AACjF,UAAM,aAAa,aAAa,SAAS,OAAO,CAAC,GAAG,GAAG,eAAe;AAEtE,UAAM,eAAe,MAAMR,YAAW,YAAY,YAAY,WAAW,GAAG;AAC5E,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,YAAY,MAAM,CAAC,CAAC;AAE9F,YAAQ,QAAQ;AAChB,YAAQ,QAAQ;AAChB,QAAI,aAAa,WAAW,SAAS;AACnC,mBAAa,OAAO,QAAQ;AAAA,IAC9B;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,cAAc,KAAK,WAAW,WAAW;AAC7C,QAAI,CAACE,aAAY;AACf,YAAM,IAAI,MAAM,iCAAiC;AAAA,IACnD;AAEA,UAAM,OAAO,WAAW,WAAW,eAAe,OAAO;AACzD,UAAM,YAAY,MAAMA,YAAW,MAAM,WAAW,EAAE,aAAa,OAAO,SAAS,MAAM,CAAC;AAC1F,UAAM,MAAM,IAAI,aAAa,MAAM,eAAe,UAAU,QAAQ,YAAY,MAAM,CAAC,CAAC;AAExF,SAAK,QAAQ;AACb,cAAU,OAAO,QAAQ;AAEzB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,kBAAkB,KAAK,WAAW,WAAW;AACjD,QAAI,CAACA,aAAY;AACf,YAAM,IAAI,MAAM,iCAAiC;AAAA,IACnD;AAEA,UAAM,OAAO,WAAW,WAAW,eAAe,OAAO;AAEzD,UAAM,YAAY,MAAMA,YAAW,MAAM,WAAW,EAAE,aAAa,OAAO,SAAS,KAAK,CAAC;AAGzF,UAAM,WAAW,YAAY,MAAM;AACnC,UAAM,UAAU,MAAM,eAAe,UAAU,QAAQ,QAAQ;AAC/D,UAAM,MAAM,IAAI,YAAY,OAAO;AACnC,UAAM,MAAM,IAAI,aAAa,YAAY,GAAG;AAG5C,aAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;AACnC,YAAM,IAAI,IAAI,CAAC;AACf,YAAM,OAAQ,KAAK,KAAM;AACzB,YAAM,MAAO,KAAK,KAAM;AACxB,YAAM,OAAO,IAAI;AACjB,UAAI;AACJ,UAAI,QAAQ,GAAG;AACb,YAAI,SAAS,IAAI,IAAI,KAAK,IAAI,GAAG,GAAG,KAAK,OAAO;AAAA,MAClD,WAAW,QAAQ,IAAI;AACrB,YAAI,SAAS,IAAI,WAAW;AAAA,MAC9B,OAAO;AACL,YAAI,KAAK,IAAI,GAAG,MAAM,EAAE,KAAK,IAAI,OAAO;AAAA,MAC1C;AACA,UAAI,CAAC,IAAI,OAAO,CAAC,IAAI;AAAA,IACvB;AAEA,SAAK,QAAQ;AACb,cAAU,OAAO,QAAQ;AAEzB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,aAAa,KAAK,GAAG,GAAG,GAAG,QAAQ,OAAO,UAAU,YAAY,SAAS,OAAO,MAAM;AAC1F,QAAI,CAACD,eAAc;AAEjB,aAAkB,aAAa,GAAG,GAAG,GAAG,QAAQ,OAAO,UAAU,YAAY,SAAS,IAAI;AAAA,IAC5F;AAGA,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,UAAU,OAAO,WAAW,IAAI,IAAI;AAC1C,UAAM,WAAW,CAAC,CAAC;AAGnB,UAAM,SAAS,MAAMA,cAAa,MAAM,MAAM,MAAM,SAAS,UAAU,SAAS;AAAA,MAC9E;AAAA,MACA;AAAA,MACA;AAAA,MACA,OAAO,IAAI,KAAK,KAAK,OAAO;AAAA,MAC5B,QAAQ;AAAA,IACV,CAAC;AAGD,UAAM,MAAM,IAAI,aAAa,MAAM,eAAe,QAAQ,SAAS,WAAW,UAAU,CAAC,CAAC;AAC1F,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,aAAS,QAAQ;AACjB,WAAO,QAAQ;AACf,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,aAAa,KAAK,QAAQ,eAAe,WAAW,YAAY,YAAY,MAAM;AACtF,QAAI,CAACT,eAAc;AAEjB,YAAMgB,UAAoB,aAAa,QAAQ,eAAe,WAAW,YAAY,YAAY,IAAI;AACrG,aAAO;AAAA,QACL,gBAAgBA,QAAO;AAAA,QACvB,aAAaA,QAAO;AAAA,MACtB;AAAA,IACF;AAGA,UAAM,YAAY,WAAW,MAAM;AACnC,UAAM,aAAa,WAAW,aAAa;AAG3C,UAAM,eAAe,aAAa,WAAW,OAAO,CAAC,WAAW,UAAU,GAAG,WAAW;AAGxF,UAAM,SAAS,MAAMhB,cAAa,cAAc,YAAY,WAAW,YAAY,YAAY,IAAI;AAGnG,UAAM,qBAAqB,OAAO;AAClC,UAAM,iBAAiB,IAAI,aAAa,MAAM,eAAe,OAAO,SAAS,QAAQ,aAAa,qBAAqB,aAAa,CAAC,CAAC;AACtI,UAAM,cAAc,IAAI,YAAY,MAAM,eAAe,OAAO,aAAa,aAAa,CAAC,CAAC;AAE5F,cAAU,QAAQ;AAClB,eAAW,QAAQ;AACnB,WAAO,SAAS,OAAO,QAAQ;AAC/B,WAAO,YAAY,QAAQ;AAC3B,WAAO,SAAS,QAAQ;AAExB,WAAO;AAAA,MACL;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,UAAU,KAAK,QAAQ;AAC3B,UAAM,YAAY,WAAW,MAAM;AACnC,UAAM,UAAU,MAAmB,UAAU,WAAW,OAAO,MAAM;AACrE,cAAU,QAAQ;AAClB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,cAAc,KAAK,QAAQ,aAAa,MAAM,aAAa;AAC/D,UAAM,YAAY,WAAW,MAAM;AACnC,UAAM,UAAU,MAAmB,aAAa,WAAW,OAAO,QAAQ;AAAA,MACxE;AAAA,MACA;AAAA,MACA,YAAY,cAAc;AAAA;AAAA,IAC5B,CAAC;AACD,cAAU,QAAQ;AAClB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,UAAU,KAAK,MAAM,IAAI,UAAU,QAAQ;AAE/C,UAAM,OAAO,KAAK;AAGlB,UAAM,eAAe,IAAI,aAAa,IAAI;AAC1C,UAAM,aAAa,IAAI,aAAa,IAAI;AACxC,aAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,mBAAa,CAAC,IAAI,KAAK,CAAC,IAAI,SAAS,CAAC;AACtC,iBAAW,CAAC,IAAI,GAAG,CAAC,IAAI,OAAO,CAAC;AAAA,IAClC;AAEA,QAAI,CAACG,UAAS;AAEZ,YAAMa,UAAS,IAAI,aAAa,IAAI;AACpC,eAAS,IAAI,GAAG,IAAI,MAAM,KAAK;AAC7B,cAAMC,QAAO,aAAa,CAAC,KAAK,IAAI,KAAK,IAAI,CAAC,aAAa,CAAC,CAAC;AAC7D,QAAAD,QAAO,CAAC,IAAIC,QAAO,WAAW,CAAC;AAAA,MACjC;AACA,aAAOD;AAAA,IACT;AAEA,UAAM,UAAU,WAAW,YAAY;AACvC,UAAM,QAAQ,WAAW,UAAU;AAGnC,UAAM,YAAY,MAAMb,SAAQ,OAAO,EAAE,MAAM,MAAM,QAAQ,CAAC;AAE9D,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,WAAW,OAAO,CAAC,CAAC;AAEzE,YAAQ,QAAQ;AAChB,UAAM,QAAQ;AACd,cAAU,QAAQ;AAElB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,SAAS,KAAK,OAAO,OAAO;AAChC,QAAI,CAACE,WAAU;AAEb,YAAMW,UAAS,IAAI,aAAa,MAAM,MAAM;AAC5C,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,QAAAA,QAAO,CAAC,IAAI,MAAM,CAAC,IAAI;AAAA,MACzB;AACA,aAAOA;AAAA,IACT;AAEA,UAAM,WAAW,WAAW,KAAK;AACjC,UAAM,YAAY,MAAMX,UAAS,UAAU,OAAO,EAAE,OAAO,MAAM,OAAO,CAAC;AACzE,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,WAAW,MAAM,SAAS,CAAC,CAAC;AAEjF,aAAS,QAAQ;AACjB,cAAU,QAAQ;AAElB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAAa,KAAK,OAAO;AAC7B,QAAI,CAACO,eAAc;AACjB,YAAMM,OAAM,IAAI,aAAa,MAAM,MAAM;AACzC,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,cAAM,OAAO,IAAI,SAAS,IAAI,YAAY,CAAC,CAAC;AAC5C,aAAK,UAAU,GAAG,MAAM,CAAC,KAAK,IAAI,IAAI;AACtC,QAAAA,KAAI,CAAC,IAAI,KAAK,WAAW,GAAG,IAAI;AAAA,MAClC;AACA,aAAOA;AAAA,IACT;AAEA,UAAM,WAAW,WAAW,OAAO,eAAe,OAAO;AACzD,UAAM,YAAY,MAAMN,cAAa,UAAU,CAAC,MAAM,MAAM,GAAG,kBAAkB;AACjF,UAAM,MAAM,IAAI,aAAa,MAAM,eAAe,UAAU,QAAQ,MAAM,SAAS,CAAC,CAAC;AAErF,aAAS,QAAQ;AACjB,cAAU,OAAO,QAAQ;AAEzB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,YAAY,KAAK,OAAO;AAC5B,QAAI,CAACE,eAAc;AACjB,YAAMI,OAAM,IAAI,YAAY,MAAM,MAAM;AACxC,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,cAAM,OAAO,IAAI,SAAS,IAAI,YAAY,CAAC,CAAC;AAC5C,aAAK,WAAW,GAAG,MAAM,CAAC,GAAG,IAAI;AACjC,cAAM,OAAO,KAAK,UAAU,GAAG,IAAI;AACnC,cAAM,OAAQ,QAAQ,KAAM;AAC5B,cAAM,MAAO,QAAQ,KAAM;AAC3B,cAAM,OAAO,OAAO;AAEpB,YAAI,OAAO;AACX,YAAI,QAAQ;AACZ,YAAI,QAAQ,KAAM;AAChB,iBAAO;AACP,kBAAQ,OAAO,MAAQ;AAAA,QACzB,WAAW,QAAQ,GAAG;AACpB,gBAAM,SAAS,MAAM,MAAM;AAC3B,cAAI,UAAU,IAAM;AAClB,mBAAO;AAAA,UACT,WAAW,SAAS,GAAG;AACrB,mBAAO;AACP,oBAAQ,QAAQ;AAAA,UAClB;AAAA,QACF;AACA,QAAAA,KAAI,CAAC,IAAK,QAAQ,KAAO,QAAQ,KAAM;AAAA,MACzC;AACA,aAAOA;AAAA,IACT;AAEA,UAAM,WAAW,WAAW,KAAK;AACjC,UAAM,cAAc,aAAa,UAAU,OAAO,CAAC,MAAM,MAAM,GAAG,kBAAkB;AACpF,UAAM,YAAY,MAAMJ,cAAa,WAAW;AAChD,UAAM,MAAM,IAAI,YAAY,MAAM,eAAe,UAAU,QAAQ,MAAM,SAAS,CAAC,CAAC;AAEpF,aAAS,QAAQ;AACjB,cAAU,OAAO,QAAQ;AAEzB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aAAa,KAAK,OAAO;AAC7B,QAAI,CAACD,eAAc;AACjB,YAAMK,OAAM,IAAI,YAAY,MAAM,MAAM;AACxC,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,cAAM,OAAO,IAAI,SAAS,IAAI,YAAY,CAAC,CAAC;AAC5C,aAAK,UAAU,GAAG,MAAM,CAAC,KAAK,IAAI,IAAI;AACtC,cAAM,OAAO,KAAK,UAAU,GAAG,IAAI;AACnC,cAAM,OAAQ,QAAQ,KAAM;AAC5B,cAAM,MAAO,QAAQ,KAAM;AAC3B,cAAM,OAAO,OAAO;AAEpB,YAAI,OAAO;AACX,YAAI,QAAQ;AACZ,YAAI,QAAQ,KAAM;AAChB,iBAAO;AACP,kBAAQ,OAAO,MAAQ;AAAA,QACzB,WAAW,QAAQ,GAAG;AACpB,gBAAM,SAAS,MAAM,MAAM;AAC3B,cAAI,UAAU,IAAM;AAClB,mBAAO;AAAA,UACT,WAAW,SAAS,GAAG;AACrB,mBAAO;AACP,oBAAQ,QAAQ;AAAA,UAClB;AAAA,QACF;AACA,QAAAA,KAAI,CAAC,IAAK,QAAQ,KAAO,QAAQ,KAAM;AAAA,MACzC;AACA,aAAOA;AAAA,IACT;AAEA,UAAM,WAAW,WAAW,OAAO,eAAe,OAAO;AACzD,UAAM,YAAY,MAAML,cAAa,UAAU,CAAC,MAAM,MAAM,GAAG,kBAAkB;AACjF,UAAM,MAAM,IAAI,YAAY,MAAM,eAAe,UAAU,QAAQ,MAAM,SAAS,CAAC,CAAC;AAEpF,aAAS,QAAQ;AACjB,cAAU,OAAO,QAAQ;AAEzB,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,MAAM,cAAc,KAAK,WAAW,WAAW;AAC7C,QAAI,CAACF,gBAAe;AAClB,YAAM,IAAI,MAAM,oCAAoC;AAAA,IACtD;AAEA,UAAM,YAAY;AAClB,UAAM,OAAO,WAAW,WAAW,eAAe,OAAO;AACzD,UAAM,SAAS,MAAMA,eAAc,MAAM,WAAW,EAAE,cAAc,EAAE,CAAC;AAGvE,UAAM,UAAU,MAAM,eAAe,QAAQ,YAAY,YAAY,CAAC;AACtE,UAAM,UAAU,IAAI,YAAY,OAAO;AACvC,UAAM,MAAM,IAAI,aAAa,QAAQ,MAAM;AAG3C,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACvC,UAAI,CAAC,IAAII,UAAS,QAAQ,CAAC,CAAC;AAAA,IAC9B;AAEA,SAAK,QAAQ;AACb,WAAO,QAAQ;AAEf,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,cAAc,KAAK,GAAiB,OAAoB,GAAW,GAAW,GAAW;AAC7F,QAAI,CAACpB,YAAW;AACd,YAAM,IAAI,MAAM,gCAAgC;AAAA,IAClD;AAGA,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,UAAU,aAAa,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,eAAe;AAGjE,UAAM,OAAO,WAAW,OAAO,eAAe,UAAU,eAAe,QAAQ;AAI/E,UAAM,eAAe,MAAMA,WAAU,SAAS,MAAM,GAAG,GAAG,GAAG;AAAA,MAC3D,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,YAAY;AAAA,IACd,CAAC;AAED,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,IAAI,IAAI,CAAC,CAAC;AAEpF,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,wBAAwB,KAAK,GAAiB,OAAmB,GAAW,GAAW,GAAW,WAAmB;AACzH,QAAI,CAACA,cAAa,CAACe,aAAY;AAC7B,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAGA,UAAM,OAAO,WAAW,OAAO,eAAe,OAAO;AACrD,UAAM,gBAAgB,MAAMA,YAAW,MAAM,WAAW,EAAE,aAAa,OAAO,SAAS,KAAK,CAAC;AAG7F,UAAM,OAAO,WAAW,CAAC;AACzB,UAAM,UAAU,aAAa,MAAM,OAAO,CAAC,GAAG,CAAC,GAAG,kBAAkB;AAIpE,UAAM,eAAe,MAAMf,WAAU,SAAS,cAAc,QAAQ,GAAG,GAAG,GAAG;AAAA,MAC3E,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,YAAY;AAAA,IACd,CAAC;AAED,UAAM,SAAS,IAAI,aAAa,MAAM,eAAe,aAAa,QAAQ,IAAI,IAAI,CAAC,CAAC;AAEpF,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,kBAAc,OAAO,QAAQ;AAC7B,iBAAa,OAAO,QAAQ;AAE5B,WAAO;AAAA,EACT;AACF;AAGC,OAAe,cAAc;AAC7B,OAAe,WAAW;AAC1B,OAAe,WAAW;AAG3B,OAAO,iBAAiB,oBAAoB,YAAY;AACtD,MAAI;AACF,UAAM,QAAQ;AACd,YAAQ,IAAI,iCAAiC;AAC7C,IAAC,OAAe,WAAW;AAG3B,UAAM,SAAS,SAAS,eAAe,QAAQ;AAC/C,QAAI,QAAQ;AACV,YAAM,OAAO,sBAAsB;AACnC,aAAO,YAAY;AAAA;AAAA,mBAEN,MAAM,eAAe,SAAS;AAAA,uBAC1B,MAAM,SAAS,QAAQ,IAAI;AAAA,qBAC7B,MAAM,eAAe,QAAQ,IAAI;AAAA;AAEhD,aAAO,MAAM,QAAQ;AAAA,IACvB;AAAA,EACF,SAAS,GAAG;AACV,YAAQ,MAAM,gCAAgC,CAAC;AAC/C,IAAC,OAAe,WAAW;AAC3B,IAAC,OAAe,WAAY,EAAY;AAExC,UAAM,SAAS,SAAS,eAAe,QAAQ;AAC/C,QAAI,QAAQ;AACV,aAAO,YAAY,kCAAmC,EAAY,OAAO;AACzE,aAAO,MAAM,QAAQ;AAAA,IACvB;AAAA,EACF;AACF,CAAC;",
  "names": ["LOG_LEVELS", "config", "device", "mergeBindings", "resolveKernelConfig", "gpuDevice", "device", "device", "config", "device", "bucket", "device", "config", "device", "device", "config", "device", "QK_K", "config", "device", "QK_K", "device", "config", "device", "tier", "workgroups", "device", "device", "device", "canUseF16", "device", "canUseF16", "device", "device", "config", "device", "device", "device", "device", "device", "device", "device", "device", "device", "device", "device", "DEFAULT_CONFIG", "config", "device", "runMatmulRMSNormFused", "shouldUseFusedMatmulRMSNorm", "device", "device", "seededRandom", "seededRandom", "runMatmul", "runSoftmax", "runTopK", "runSoftmaxTopK", "runScatterAdd", "runMoEGather", "runRMSNorm", "runRoPE", "runSiLU", "runSwiGLURowsplitBias", "runScale", "runGather", "runResidualAdd", "runBiasAdd", "runAttention", "dequantize", "dequantizeQ6K", "runBF16ToF32", "runBF16ToF16", "castF32ToF16", "f16ToF32", "result", "silu", "out"]
}
