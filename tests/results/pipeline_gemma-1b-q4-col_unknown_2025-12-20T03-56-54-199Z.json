{
  "schemaVersion": 1,
  "timestamp": "2025-12-20T03:56:44.103Z",
  "suite": "pipeline",
  "runType": "warm",
  "env": {
    "browser": {
      "name": "Chrome",
      "version": "143.0.0.0"
    },
    "os": {
      "name": "macOS",
      "version": "10.15.7"
    },
    "gpu": {
      "vendor": "unknown",
      "device": "unknown",
      "description": "unknown"
    },
    "webgpu": {
      "hasF16": true,
      "hasSubgroups": true,
      "hasTimestampQuery": true
    }
  },
  "model": {
    "modelId": "gemma-1b-q4-col",
    "quantization": "Q4_K_M",
    "totalSizeBytes": 1012170496,
    "tensorCount": 340,
    "numLayers": 26,
    "hiddenSize": 1152
  },
  "workload": {
    "promptName": "xs",
    "promptTokens": 7,
    "maxNewTokens": 8,
    "sampling": {
      "temperature": 0.7,
      "topK": 1,
      "topP": 1
    }
  },
  "metrics": {
    "ttft_ms": 446,
    "prefill_ms": 242,
    "prefill_tokens_per_sec": 29,
    "decode_ms_total": 439,
    "decode_tokens_per_sec": 16,
    "gpu_submit_count_prefill": 7,
    "gpu_submit_count_decode": 49,
    "decode_ms_per_token_p50": 63.19999998807907,
    "decode_ms_per_token_p90": 64,
    "decode_ms_per_token_p99": 64,
    "gpu_readback_bytes_total": 1048604,
    "gpu_timestamp_available": true,
    "gpu_time_ms_prefill": 0,
    "gpu_time_ms_decode": 0,
    "estimated_vram_bytes_peak": 3383558400,
    "opfs_usage_bytes": 2724733235,
    "storage_persisted": false
  },
  "raw": {
    "decode_latencies_ms": [
      64,
      60.69999998807907,
      63.69999998807907,
      61.10000002384186,
      61.80000001192093,
      63.19999998807907,
      64
    ],
    "submit_times_ms": [
      0,
      0,
      0,
      0.09999996423721313,
      0,
      0.10000002384185791,
      0,
      0.09999996423721313,
      0.10000002384185791,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "generated_token_ids": [
      478,
      68,
      478,
      68,
      478,
      68,
      478,
      68
    ],
    "generated_text": "รฐ<unused62>รฐ<unused62>รฐ<unused62>รฐ<unused62>"
  }
}