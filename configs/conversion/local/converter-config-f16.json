{
    "quantization": {
        "weights": "f16",
        "embeddings": "f16",
        "lmHead": "f16",
        "computePrecision": "f16"
    }
}